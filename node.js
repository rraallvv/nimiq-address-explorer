module.exports = {};
const atob = require('atob');
const btoa = require('btoa');
const JDB = require('@nimiq/jungle-db');
const fs = require('fs');
const https = require('https');
const http = require('http');
const tls = require('tls');
let cpuid;
try {
    cpuid = require('cpuid-git');
} catch (e) {}
const chalk = require('chalk');

// Allow the user to specify the WebSocket engine through an environment variable. Default to ws
const WebSocket = require(process.env.NIMIQ_WS_ENGINE || 'ws');

global.Class = {
    scope: module.exports,
    register: clazz => {
        module.exports[clazz.prototype.constructor.name] = clazz;
    }
};

// Always try to use the node.js addon that was compiled locally (as it is
// optimized specifically to this CPU), if that fails (i.e. this instance
// was not compiled from source code), use one of the generic addons
function detectAddOn() {
    let NodeNativeTry;
    let cpuSupport = 'native';
    try {
        NodeNativeTry = require('bindings')(`nimiq_node_${cpuSupport}.node`);
    } catch (e) {
        cpuSupport = undefined;
    }

    // Use CPUID to get the available processor extensions
    // and choose the right version of the node.js addon
    cpuSupport = cpuSupport || function() {
        try {
            const cpu = cpuid();
            return ['avx512f', 'avx2', 'sse2'].find(f => cpu.features[f]) || 'compat';
        } catch (e) {
            return 'compat';
        }
    }();

    let NodeNative = NodeNativeTry || require('bindings')(`nimiq_node_${cpuSupport}.node`);

    return {NodeNative, cpuSupport};
}

const {NodeNative, cpuSupport} = detectAddOn();

class LogNative {
    constructor() {
        this._global_level = Log.INFO;
        this._tag_levels = {};
        this._global_prefix = '';
    }

    isLoggable(tag, level) {
        if (tag && tag.name) tag = tag.name;
        if (tag && this._tag_levels[tag]) {
            return this._tag_levels[tag] <= level;
        }
        return this._global_level <= level;
    }

    setLoggable(tag, level) {
        this._tag_levels[tag] = level;
    }

    /**
     * @param {Log.Level} level
     * @param {string} tag
     * @param {Array} args
     */
    msg(level, tag, args) {
        if (!this.isLoggable(tag, level)) return;
        if (tag && tag.name) tag = tag.name;
        if (tag) args.unshift(chalk.bold(tag) + ':');
        let prefix = `${this._global_prefix}[${Log.Level.toStringTag(level)} ${new Date().toTimeString().substr(0, 8)}] `;
        if (level >= Log.ERROR) {
            console.log(prefix + chalk.red(args.join(' ')));
        } else if (level >= Log.WARNING) {
            console.log(prefix + chalk.yellow(args.join(' ')));
        } else if (level >= Log.INFO) {
            console.log(prefix + chalk.cyan(args.join(' ')));
        } else if (level >= Log.DEBUG) {
            console.log(prefix + chalk.magenta(args.join(' ')));
        } else if (level <= Log.TRACE) {
            console.trace(prefix + args.join(' '));
        } else {
            console.log(prefix + args.join(' '));
        }
    }
}
Class.register(LogNative);

class Log {
    /**
     * @returns {Log}
     */
    static get instance() {
        if (!Log._instance) {
            Log._instance = new Log(new LogNative());
        }
        return Log._instance;
    }

    /**
     * @param {LogNative} native
     */
    constructor(native) {
        /** @type {LogNative} */
        this._native = native;
    }

    /**
     * @param {string} tag
     * @param {Log.Level} level
     */
    setLoggable(tag, level) {
        this._native.setLoggable(tag, Log.Level.get(level));
    }

    /** @type {Log.Level} */
    get level() {
        return this._native._global_level;
    }

    /** @type {Log.Level} */
    set level(l) {
        this._native._global_level = Log.Level.get(l);
    }

    /**
     * @param {Log.Level} level
     * @param {string|{name:string}} tag
     * @param {Array} args
     */
    msg(level, tag, args) {
        if (this._native.isLoggable(tag, level)) {
            for (let i = 0; i < args.length; ++i) {
                if (typeof args[i] === 'function') {
                    args[i] = args[i]();
                }
                if (typeof args[i] === 'object') {
                    if (typeof args[i].toString === 'function') {
                        args[i] = args[i].toString();
                    } else if (args[i].constructor && args[i].constructor.name) {
                        args[i] = `{Object: ${args[i].constructor.name}}`;
                    } else {
                        args[i] = '{Object}';
                    }
                }
            }
            this._native.msg(level, tag, args);
        }
    }

    /**
     * @param {?string|{name:string}} [tag=undefined]
     * @param {string|function():string} message
     * @param {...*} args
     */
    static d(tag, message, ...args) {
        if (arguments.length >= 2) {
            tag = arguments[0];
            args = Array.prototype.slice.call(arguments, 1);
        } else {
            tag = undefined;
            args = Array.prototype.slice.call(arguments, 0);
        }
        Log.instance.msg(Log.DEBUG, tag, args);
    }

    /**
     * @param {?string|{name:string}} [tag=undefined]
     * @param {string|function():string} message
     * @param {...*} args
     */
    static e(tag, message, ...args) {
        if (arguments.length >= 2) {
            tag = arguments[0];
            args = Array.prototype.slice.call(arguments, 1);
        } else {
            tag = undefined;
            args = Array.prototype.slice.call(arguments, 0);
        }
        Log.instance.msg(Log.ERROR, tag, args);
    }

    /**
     * @param {?string|{name:string}} [tag=undefined]
     * @param {string|function():string} message
     * @param {...*} args
     */
    static i(tag, message, ...args) {
        if (arguments.length >= 2) {
            tag = arguments[0];
            args = Array.prototype.slice.call(arguments, 1);
        } else {
            tag = undefined;
            args = Array.prototype.slice.call(arguments, 0);
        }
        Log.instance.msg(Log.INFO, tag, args);
    }

    /**
     * @param {?string|{name:string}} [tag=undefined]
     * @param {string|function():string} message
     * @param {...*} args
     */
    static v(tag, message, ...args) {
        if (arguments.length >= 2) {
            tag = arguments[0];
            args = Array.prototype.slice.call(arguments, 1);
        } else {
            tag = undefined;
            args = Array.prototype.slice.call(arguments, 0);
        }
        Log.instance.msg(Log.VERBOSE, tag, args);
    }

    /**
     * @param {?string|{name:string}} [tag=undefined]
     * @param {string|function():string} message
     * @param {...*} args
     */
    static w(tag, message, ...args) {
        if (arguments.length >= 2) {
            tag = arguments[0];
            args = Array.prototype.slice.call(arguments, 1);
        } else {
            tag = undefined;
            args = Array.prototype.slice.call(arguments, 0);
        }
        Log.instance.msg(Log.WARNING, tag, args);
    }

    /**
     * @param {?string|{name:string}} [tag=undefined]
     * @param {string|function():string} message
     * @param {...*} args
     */
    static t(tag, message, ...args) {
        if (arguments.length >= 2) {
            tag = arguments[0];
            args = Array.prototype.slice.call(arguments, 1);
        } else {
            tag = undefined;
            args = Array.prototype.slice.call(arguments, 0);
        }
        Log.instance.msg(Log.TRACE, tag, args);
    }
}

/**
 * @enum {number|string}
 */
Log.Level = {
    TRACE: 1,
    VERBOSE: 2,
    DEBUG: 3,
    INFO: 4,
    WARNING: 5,
    ERROR: 6,
    ASSERT: 7,

    /**
     * @param {Log.Level} level
     * @returns {string}
     */
    toStringTag: function (level) {
        switch (level) {
            case Log.Level.TRACE:
                return 'T';
            case Log.Level.VERBOSE:
                return 'V';
            case Log.Level.DEBUG:
                return 'D';
            case Log.Level.INFO:
                return 'I';
            case Log.Level.WARNING:
                return 'W';
            case Log.Level.ERROR:
                return 'E';
            case Log.Level.ASSERT:
                return 'A';
            default:
                return '*';
        }
    },

    toString: function (level) {
        switch (level) {
            case Log.Level.TRACE:
                return 'trace';
            case Log.Level.VERBOSE:
                return 'verbose';
            case Log.Level.DEBUG:
                return 'debug';
            case Log.Level.INFO:
                return 'info';
            case Log.Level.WARNING:
                return 'warn';
            case Log.Level.ERROR:
                return 'error';
            case Log.Level.ASSERT:
                return 'assert';
            default:
                return 'unknown';
        }
    },

    /**
     * @param {string|number|Log.Level} v
     * @returns {Log.Level}
     */
    get: function (v) {
        if (typeof v === 'number') return /** @type {Log.Level} */ v;
        if (!isNaN(parseInt(v))) return /** @type {Log.Level} */ parseInt(v);
        switch (v.toLowerCase()) {
            case 't':
            case 'trace':
                return Log.Level.TRACE;
            case 'v':
            case 'verbose':
                return Log.Level.VERBOSE;
            case 'd':
            case 'debug':
                return Log.Level.DEBUG;
            case 'i':
            case 'info':
                return Log.Level.INFO;
            case 'w':
            case 'warn':
            case 'warning':
                return Log.Level.WARNING;
            case 'e':
            case 'error':
            case 'exception':
                return Log.Level.ERROR;
            case 'a':
            case 'assert':
            case 'assertion':
                return Log.Level.ASSERT;
        }
        return /** @type {Log.Level} */ 0;
    }
};
Log.TRACE = Log.Level.TRACE;
Log.VERBOSE = Log.Level.VERBOSE;
Log.DEBUG = Log.Level.DEBUG;
Log.INFO = Log.Level.INFO;
Log.WARNING = Log.Level.WARNING;
Log.ERROR = Log.Level.ERROR;
Log.ASSERT = Log.Level.ASSERT;
Log._instance = null;

Log.d.tag = (tag) => Log.d.bind(null, tag);
Log.e.tag = (tag) => Log.e.bind(null, tag);
Log.i.tag = (tag) => Log.i.bind(null, tag);
Log.v.tag = (tag) => Log.v.bind(null, tag);
Log.w.tag = (tag) => Log.w.bind(null, tag);
Log.t.tag = (tag) => Log.t.bind(null, tag);

Class.register(Log);

class Observable {
    /**
     * @returns {string}
     * @constant
     */
    static get WILDCARD() {
        return '*';
    }

    constructor() {
        /** @type {Map.<string, Array.<Function>>} */
        this._listeners = new Map();
    }

    _offAll() {
        this._listeners.clear();
    }

    /**
     * @param {string} type
     * @param {Function} callback
     * @return {number}
     */
    on(type, callback) {
        if (!this._listeners.has(type)) {
            this._listeners.set(type, [callback]);
            return 0;
        } else {
            return this._listeners.get(type).push(callback) - 1;
        }
    }

    /**
     * @param {string} type
     * @param {number} id
     */
    off(type, id) {
        if (!this._listeners.has(type) || !this._listeners.get(type)[id]) return;
        delete this._listeners.get(type)[id];
    }

    /**
     * @param {string} type
     * @param {...*} args
     * @returns {?Promise}
     */
    fire(type, ...args) {
        const promises = [];
        // Notify listeners for this event type.
        if (this._listeners.has(type)) {
            const listeners = this._listeners.get(type);
            for (const key in listeners) {
                if (!listeners.hasOwnProperty(key)) continue;
                const res = listeners[key].apply(null, args);
                if (res instanceof Promise) promises.push(res);
            }
        }

        // Notify wildcard listeners. Pass event type as first argument
        if (this._listeners.has(Observable.WILDCARD)) {
            const listeners = this._listeners.get(Observable.WILDCARD);
            for (const key in listeners) {
                if (!listeners.hasOwnProperty(key)) continue;
                const res = listeners[key].apply(null, arguments);
                if (res instanceof Promise) promises.push(res);
            }
        }

        if (promises.length > 0) return Promise.all(promises);
        return null;
    }

    /**
     * @param {Observable} observable
     * @param {...string} types
     */
    bubble(observable, ...types) {
        for (const type of types) {
            let callback;
            if (type === Observable.WILDCARD) {
                callback = function() {
                    this.fire.apply(this, arguments);
                };
            } else {
                callback = function() {
                    this.fire.apply(this, [type, ...arguments]);
                };
            }
            observable.on(type, callback.bind(this));
        }
    }
}
Class.register(Observable);

/**
 * @abstract
 */
class DataChannel extends Observable {
    constructor() {
        super();

        // Buffer for chunked messages.
        // XXX We currently only support one chunked message at a time.
        /** @type {SerialBuffer} */
        this._buffer = null;
        /** @type {number} */
        this._currentMessageLength = 0;

        /** @type {Message.Type} */
        this._msgType = 0;

        /** @type {number} */
        this._receivingTag = -1;

        /** @type {number} */
        this._sendingTag = 0;

        /** @type {Map.<Message.Type, ExpectedMessage>} */
        this._expectedMessagesByType = new Map();

        /** @type {Timers} */
        this._timers = new Timers();

        /** @type {number} */
        this._lastChunkReceivedAt = 0;

        /** @type {boolean} */
        this._closed = false;
    }

    /**
     * @param {Message.Type} type
     * @returns {boolean}
     */
    isExpectingMessage(type) {
        return this._expectedMessagesByType.has(type);
    }

    /**
     * @param {Message.Type} type
     * @param {boolean} success
     */
    confirmExpectedMessage(type, success) {
        const expectedMsg = this._expectedMessagesByType.get(type);
        if (!expectedMsg) return;

        this._timers.clearTimeout(`chunk-${expectedMsg.id}`);
        this._timers.clearTimeout(`msg-${expectedMsg.id}`);
        for (const type of expectedMsg.types) {
            this._expectedMessagesByType.delete(type);
        }

        if (!success) {
            expectedMsg.timeoutCallback();
        }
    }

    /**
     * @param {Message.Type|Array.<Message.Type>} types
     * @param {function()} timeoutCallback
     * @param {number} [msgTimeout]
     * @param {number} [chunkTimeout]
     */
    expectMessage(types, timeoutCallback, msgTimeout = DataChannel.MESSAGE_TIMEOUT, chunkTimeout = DataChannel.CHUNK_TIMEOUT) {
        if (!Array.isArray(types)) {
            types = [types];
        }

        if (types.length === 0) return;

        const expectedMsg = new ExpectedMessage(types, timeoutCallback, msgTimeout, chunkTimeout);
        for (const type of types) {
            this._expectedMessagesByType.set(type, expectedMsg);
        }

        // Set timers for any of the expected types.
        this._timers.resetTimeout(`chunk-${expectedMsg.id}`, this._onTimeout.bind(this, expectedMsg), chunkTimeout);
        this._timers.resetTimeout(`msg-${expectedMsg.id}`, this._onTimeout.bind(this, expectedMsg), msgTimeout);
    }

    close() {
        if (this._closed) {
            return;
        }
        this._closed = true;

        this._timers.clearAll();

        this._close();

        this.fire('close', this);

        this._offAll();
    }

    /**
     * @abstract
     */
    /* istanbul ignore next */
    _close() { throw new Error('Not implemented'); }

    /**
     * @param {string} msg
     * @private
     */
    _error(msg) {
        this.fire('error', msg, this);
        Log.e(DataChannel, msg);
        this.close();
    }

    /**
     * @param {ArrayBuffer} msg
     * @protected
     */
    _onMessage(msg) {
        try {
            // Drop message if the channel is not open.
            if (this.readyState !== DataChannel.ReadyState.OPEN) {
                return;
            }

            // Drop empty messages.
            const buffer = new SerialBuffer(msg);
            if (buffer.byteLength === 0) {
                return;
            }

            // Chunk is too large.
            if (buffer.byteLength > DataChannel.CHUNK_SIZE_MAX) {
                this._error('Received chunk larger than maximum chunk size, discarding');
                return;
            }

            const tag = buffer.readUint8();

            // Buffer length without tag.
            const effectiveChunkLength = buffer.byteLength - buffer.readPos;
            const chunk = buffer.read(effectiveChunkLength);

            // Detect if this is a new message.
            if (this._buffer === null && tag === (this._receivingTag + 1) % NumberUtils.UINT8_MAX) {
                const chunkBuffer = new SerialBuffer(chunk);
                const messageSize = Message.peekLength(chunkBuffer);

                if (messageSize > DataChannel.MESSAGE_SIZE_MAX) {
                    this._error(`Received message with excessive message size ${messageSize} > ${DataChannel.MESSAGE_SIZE_MAX}`);
                    return;
                }

                this._buffer = new SerialBuffer(Math.min(messageSize, DataChannel.CHUNK_SIZE_MAX));
                this._currentMessageLength = messageSize;
                this._receivingTag = tag;
                this._msgType = Message.peekType(chunkBuffer);
            }

            if (this._buffer === null) {
                Log.e(DataChannel, `Message does not start with next tag ${this._receivingTag + 1} (got ${tag} instead), but buffer is null`);
                return;
            }

            // Currently, we only support one message at a time.
            if (tag !== this._receivingTag) {
                this._error(`Received message with wrong message tag ${tag}, expected ${this._receivingTag}`);
                return;
            }

            let remainingBytes = this._currentMessageLength - this._buffer.writePos;

            // Mismatch between buffer sizes.
            if (effectiveChunkLength > remainingBytes) {
                this._error('Received chunk larger than remaining bytes to read, discarding');
                return;
            }

            // Chunk too short
            if (buffer.byteLength !== DataChannel.CHUNK_SIZE_MAX && effectiveChunkLength !== remainingBytes) {
                this._error('Received chunk that is neither max chunk size nor the final chunk');
                return;
            }

            // Write chunk and subtract remaining byte length.
            if (this._buffer.byteLength < this._buffer.writePos + effectiveChunkLength) {
                // XXX: Use ArrayBuffer.transfer once available
                const newBuffer = new SerialBuffer(Math.min(this._buffer.byteLength * 2, this._currentMessageLength));
                newBuffer.set(this._buffer);
                newBuffer.writePos = this._buffer.writePos;
                this._buffer = newBuffer;
            }
            this._buffer.write(chunk);
            remainingBytes -= effectiveChunkLength;

            // Update last chunk timestamp.
            this._lastChunkReceivedAt = Date.now();

            const expectedMsg = this._expectedMessagesByType.get(this._msgType);
            if (remainingBytes === 0) {
                const msg = this._buffer.buffer;
                this._buffer = null;
                this._currentMessageLength = 0;
                this._timers.clearTimeout('next-chunk');
                this.fire('message', msg, this);
            } else {
                // Set timeout.
                if (expectedMsg) {
                    this._timers.resetTimeout(`chunk-${expectedMsg.id}`, this._onTimeout.bind(this, expectedMsg), expectedMsg.chunkTimeout);
                } else {
                    this._timers.resetTimeout('next-chunk', this._onTimeout.bind(this), DataChannel.CHUNK_TIMEOUT);
                }
                this.fire('chunk', this._buffer);
            }
        } catch (e) {
            this._error(`Error occurred while parsing incoming message: ${e.message || e}`);
        }
    }

    /**
     * @param {ExpectedMessage} [expectedMsg]
     * @private
     */
    _onTimeout(expectedMsg) {
        if (expectedMsg) {
            this._timers.clearTimeout(`chunk-${expectedMsg.id}`);
            this._timers.clearTimeout(`msg-${expectedMsg.id}`);

            for (const type of expectedMsg.types) {
                this._expectedMessagesByType.delete(type);
            }

            expectedMsg.timeoutCallback();
        } else {
            Log.w(DataChannel, 'DataChannel receive timeout');
        }

        this._buffer = null;
    }

    /**
     * @param {Uint8Array} msg
     */
    send(msg) {
        Assert.that(msg.byteLength <= DataChannel.MESSAGE_SIZE_MAX, 'DataChannel.send() max message size exceeded');

        const tag = this._sendingTag;
        this._sendingTag = (this._sendingTag + 1) % NumberUtils.UINT8_MAX;
        this._sendChunked(msg, tag);
    }

    /**
     * @param {Uint8Array} msg
     * @param {number} tag
     * @private
     */
    _sendChunked(msg, tag) {
        // Send chunks.
        let remaining = msg.byteLength;
        let chunk = null;
        while (remaining > 0) {
            let buffer = null;
            if (remaining + /*tag*/ 1 >= DataChannel.CHUNK_SIZE_MAX) {
                buffer = new SerialBuffer(DataChannel.CHUNK_SIZE_MAX);
                buffer.writeUint8(tag);
                chunk = new Uint8Array(msg.buffer, msg.byteLength - remaining, DataChannel.CHUNK_SIZE_MAX - /*tag*/ 1);
            } else {
                buffer = new SerialBuffer(remaining + /*tag*/ 1);
                buffer.writeUint8(tag);
                chunk = new Uint8Array(msg.buffer, msg.byteLength - remaining, remaining);
            }

            buffer.write(chunk);
            this.sendChunk(buffer);
            remaining -= chunk.byteLength;
        }
    }

    /**
     * @abstract
     * @param {Uint8Array} msg
     */
    /* istanbul ignore next */
    sendChunk(msg) { throw  new Error('Not implemented'); }

    /**
     * @abstract
     * @type {DataChannel.ReadyState}
     */
    /* istanbul ignore next */
    get readyState() { throw new Error('Not implemented'); }

    /** @type {number} */
    get lastMessageReceivedAt() {
        return this._lastChunkReceivedAt;
    }
}

DataChannel.CHUNK_SIZE_MAX = 1024 * 16; // 16 kb
DataChannel.MESSAGE_SIZE_MAX = 10 * 1024 * 1024; // 10 mb
DataChannel.CHUNK_TIMEOUT = 1000 * 5; // 5 seconds
DataChannel.MESSAGE_TIMEOUT = (DataChannel.MESSAGE_SIZE_MAX / DataChannel.CHUNK_SIZE_MAX) * DataChannel.CHUNK_TIMEOUT;
Class.register(DataChannel);

class ExpectedMessage {
    /**
     * @param {Array.<Message.Type>} types
     * @param {function()} timeoutCallback
     * @param {number} msgTimeout
     * @param {number} chunkTimeout
     */
    constructor(types, timeoutCallback, msgTimeout = DataChannel.MESSAGE_TIMEOUT, chunkTimeout = DataChannel.CHUNK_TIMEOUT) {
        this.id = types.join(':');
        this.types = types;
        this.timeoutCallback = timeoutCallback;
        this.msgTimeout = msgTimeout;
        this.chunkTimeout = chunkTimeout;
    }
}

/**
 * @enum {number}
 */
DataChannel.ReadyState = {
    CONNECTING: 0,
    OPEN: 1,
    CLOSING: 2,
    CLOSED: 3,

    /**
     * @param {string} str
     * @returns {DataChannel.ReadyState}
     */
    fromString: function (str) {
        switch (str) {
            case 'connecting':
                return DataChannel.ReadyState.CONNECTING;
            case 'open':
                return DataChannel.ReadyState.OPEN;
            case 'closing':
                return DataChannel.ReadyState.CLOSING;
            case 'closed':
                return DataChannel.ReadyState.CLOSED;
            default:
                throw new Error('Invalid string');
        }
    }
};

class CryptoLib {
    static get instance() {
        if (!CryptoLib._instance) {
            const instance = {};
            const crypto = require('crypto');
            instance.getRandomValues = (buf) => {
                if (!(buf instanceof Uint8Array)) {
                    throw new TypeError('expected Uint8Array');
                }
                if (buf.length > 65536) {
                    const e = new Error();
                    e.code = 22;
                    e.message = `Failed to execute 'getRandomValues' on 'Crypto': The ArrayBufferView's byte length ${buf.length} exceeds the number of bytes of entropy available via this API (65536).`;
                    e.name = 'QuotaExceededError';
                    throw e;
                }
                const bytes = crypto.randomBytes(buf.length);
                buf.set(bytes);
                return buf;
            };

            CryptoLib._instance = instance;
        }
        return CryptoLib._instance;
    }
}

CryptoLib._instance = null;
Class.register(CryptoLib);

/**
 * We don't have support for WebRTC in node.js, none of the methods
 * of this factory should ever be called in production. This may
 * change in the future.
 */
class WebRtcFactory {
    /**
     * @param {?RTCConfiguration} configuration
     * @returns {?RTCPeerConnection}
     */
    static newPeerConnection(configuration) {
        return null;
    }

    /**
     * @param {*} rtcSessionDescriptionInit
     * @returns {?RTCSessionDescription}
     */
    static newSessionDescription(rtcSessionDescriptionInit) {
        return null;
    }

    /**
     * @param {*} rtcIceCandidateInit
     * @returns {?RTCIceCandidate}
     */
    static newIceCandidate(rtcIceCandidateInit) {
        return null;
    }
}
Class.register(WebRtcFactory);

class WebSocketServer extends WebSocket.Server {
    /**
     * @param {WsNetworkConfig|WssNetworkConfig} networkConfig
     * @returns {http.Server|https.Server}
     */
    static _newHttpServer(networkConfig) {
        if (networkConfig.secure) {
            // Debounce utility
            let timeout;
            const debounce = (fn) => {
                clearTimeout(timeout);
                timeout = setTimeout(fn, 1000);
            };

            let secureContext;
            const options = {
                SNICallback: (servername, cb) => cb(null, secureContext),
                handshakeTimeout: WebSocketServer.TLS_HANDSHAKE_TIMEOUT
            };

            const reloadTlsConfig = () => {
                Log.d(WebSocketServer, `(Re-)Loading SSL config`);
                options.key = fs.readFileSync(networkConfig.ssl.key);
                options.cert = fs.readFileSync(networkConfig.ssl.cert);
                secureContext = tls.createSecureContext({key: options.key, cert: options.cert});
            };
            reloadTlsConfig();

            // Watch filesystem for changes to the key and cert files
            fs.watch(networkConfig.ssl.key, () => debounce(reloadTlsConfig));
            fs.watch(networkConfig.ssl.cert, () => debounce(reloadTlsConfig));

            return https.createServer(options, (req, res) => {
                res.writeHead(200);
                res.end('Nimiq Node.js Client\n');
            }).listen(networkConfig.port);
        } else {
            return http.createServer((req, res) => {
                res.writeHead(200);
                res.end('Nimiq Node.js Client\n');
            }).listen(networkConfig.port);
        }
    }

    /**
     * @param {WsNetworkConfig|WssNetworkConfig} networkConfig
     */
    constructor(networkConfig) {
        const server = WebSocketServer._newHttpServer(networkConfig);
        super({ server, maxPayload: WebSocketServer.PAYLOAD_MAX });

        /** @type {Map.<string,{listener:function(),timeout:*}>} */
        this._clients = new Map();

        /** @type {HashMap.<NetAddress,number>} */
        this._pendingClientsByIp = new HashMap();
        /** @type {HashMap.<NetAddress,number>} */
        this._pendingClientsBySubnet = new HashMap();
        /** @type {HashMap.<NetAddress,RateLimit>} */
        this._newConnectionsPerIp = new HashMap();
        /** @type {HashMap.<NetAddress,RateLimit>} */
        this._newConnectionsPerSubnet = new HashMap();

        /** @type {number} */
        this._pendingUpgrades = 0;

        if (!networkConfig.reverseProxy.enabled) {
            server.on('connection', this._onNetSocketConnection.bind(this));
            this.on('connection', this._onWebSocketConnection.bind(this));

            setInterval(this._housekeeping.bind(this), WebSocketServer.HOUSEKEEPING_INTERVAL);
        }
    }

    _onNetSocketConnection(socket) {
        // Track this client until the upgrade completes or it disconnects.
        this._addClient(socket);
    }

    _onWebSocketConnection(ws, req) {
        this._removeClient(req.connection);
    }

    _addClient(socket) {
        // Reject this client if we have too many pending upgrades.
        if (this._pendingUpgrades >= WebSocketServer.PENDING_UPGRADES_MAX) {
            Log.v(WebSocketServer, () => `Closing socket to ${socket.remoteAddress} - max pending upgrades exceeded`);
            socket.destroy();
            return;
        }

        // Parse IP address.
        let netAddress;
        try {
            netAddress = NetAddress.fromIP(socket.remoteAddress, true);
        } catch (e) {
            Log.e(WebSocketServer, `Closing socket to ${socket.remoteAddress} - ${e.message || e}`);
            socket.destroy();
            return;
        }

        // Reject if this ip:port is already pending.
        const clientConnectionId = `${netAddress}|${socket.remotePort}`;
        if (this._clients.has(clientConnectionId)) {
            Log.v(WebSocketServer, () => `Closing socket to ${socket.remoteAddress} - duplicate connection`);
            socket.destroy();
            return;
        }

        // Enforce max clients per ip/subnet.
        const subnet = netAddress.subnet(netAddress.isIPv4() ? Network.IPV4_SUBNET_MASK : Network.IPV6_SUBNET_MASK);
        const clientsByIp = this._pendingClientsByIp.get(netAddress) || 0;
        const clientsBySubnet = this._pendingClientsBySubnet.get(subnet) || 0;
        if (!netAddress.isPrivate() && (clientsByIp >= WebSocketServer.PENDING_UPGRADES_PER_IP_MAX || clientsBySubnet >=WebSocketServer.PENDING_UPGRADES_PER_SUBNET_MAX)) {
            Log.v(WebSocketServer, () => `Closing socket to ${socket.remoteAddress} - max peer count per ip/subnet exceeded`);
            socket.destroy();
            return;
        }

        // Enforce new connection rate limit per ip/subnet.
        let newConnectionsPerIp = this._newConnectionsPerIp.get(netAddress);
        if (!newConnectionsPerIp) {
            newConnectionsPerIp = new RateLimit(WebSocketServer.CONNECTION_RATE_LIMIT_PER_IP);
            this._newConnectionsPerIp.put(netAddress, newConnectionsPerIp);
        }
        let newConnectionsPerSubnet = this._newConnectionsPerSubnet.get(subnet);
        if (!newConnectionsPerSubnet) {
            newConnectionsPerSubnet = new RateLimit(WebSocketServer.CONNECTION_RATE_LIMIT_PER_SUBNET);
            this._newConnectionsPerSubnet.put(subnet, newConnectionsPerSubnet);
        }
        const newConnectionAllowedPerIp = newConnectionsPerIp.note();
        const newConnectionAllowedPerSubnet = newConnectionsPerSubnet.note();
        if (!newConnectionAllowedPerIp || !newConnectionAllowedPerSubnet) {
            Log.v(WebSocketServer, () => `Closing socket to ${socket.remoteAddress} - connection rate limit per ip/subnet exceeded`);
            socket.destroy();
            return;
        }

        // Remove this client if the socket is closed pre-upgrade.
        const listener = () => this._removeClient(socket);
        socket.on('close', listener);

        // Set upgrade timeout.
        const timeout = setTimeout(() => {
            Log.v(WebSocketServer, () => `Closing socket to ${socket.remoteAddress} - upgrade timeout`);
            this._removeClient(socket);
            socket.destroy();
        }, WebSocketServer.UPGRADE_TIMEOUT);

        this._clients.set(clientConnectionId, { listener, timeout, ts: Date.now() });
        this._pendingClientsByIp.put(netAddress, clientsByIp + 1);
        this._pendingClientsBySubnet.put(subnet, clientsBySubnet + 1);
        this._pendingUpgrades++;
    }

    _removeClient(socket) {
        const netAddress = NetAddress.fromIP(socket.remoteAddress, true);
        const clientConnectionId = `${netAddress}|${socket.remotePort}`;

        const client = this._clients.get(clientConnectionId);
        // Timeout and close event might be on the event-queue at the same time
        if (!client) {
            return;
        }
        this._clients.delete(clientConnectionId);

        clearTimeout(client.timeout);
        socket.removeListener('close', client.listener);

        const subnet = netAddress.subnet(netAddress.isIPv4() ? Network.IPV4_SUBNET_MASK : Network.IPV6_SUBNET_MASK);
        const clientsByIp = this._pendingClientsByIp.get(netAddress);
        const clientsBySubnet = this._pendingClientsBySubnet.get(subnet);
        Assert.that(clientsByIp > 0 && clientsBySubnet > 0, 'clientsByIp/Subnet <= 0');

        if (clientsByIp === 1) {
            this._pendingClientsByIp.remove(netAddress);
        } else {
            this._pendingClientsByIp.put(netAddress, clientsByIp - 1);
        }
        if (clientsBySubnet === 1) {
            this._pendingClientsBySubnet.remove(subnet);
        } else {
            this._pendingClientsBySubnet.put(subnet, clientsBySubnet - 1);
        }

        this._pendingUpgrades--;
        Assert.that(this._pendingUpgrades >= 0, 'pendingUpgrades < 0');
    }

    _housekeeping() {
        // Delete old rate limits.
        const now = Date.now();
        for (const ip of this._newConnectionsPerIp.keyIterator()) {
            const newConnections = this._newConnectionsPerIp.get(ip);
            if (newConnections.lastReset < now - WebSocketServer.LIMIT_TRACKING_AGE_MAX) {
                this._newConnectionsPerIp.remove(ip);
            }
        }
        for (const subnet of this._newConnectionsPerSubnet.keyIterator()) {
            const newConnections = this._newConnectionsPerSubnet.get(subnet);
            if (newConnections.lastReset < now - WebSocketServer.LIMIT_TRACKING_AGE_MAX) {
                this._newConnectionsPerSubnet.remove(subnet);
            }
        }
    }
}
WebSocketServer.UPGRADE_TIMEOUT = 1000 * 3; // 3 seconds
WebSocketServer.TLS_HANDSHAKE_TIMEOUT = 1000 * 3; // 3 seconds
WebSocketServer.PAYLOAD_MAX = DataChannel.CHUNK_SIZE_MAX;
WebSocketServer.PENDING_UPGRADES_MAX = 1000;
WebSocketServer.PENDING_UPGRADES_PER_IP_MAX = 2;
WebSocketServer.PENDING_UPGRADES_PER_SUBNET_MAX = 6;
WebSocketServer.CONNECTION_RATE_LIMIT_PER_IP = 10; // per minute
WebSocketServer.CONNECTION_RATE_LIMIT_PER_SUBNET = 30; // per minute
WebSocketServer.LIMIT_TRACKING_AGE_MAX = 1000 * 60 * 2; // 2 minutes
WebSocketServer.HOUSEKEEPING_INTERVAL = 1000 * 60 * 5; // 5 minutes
Class.register(WebSocketServer);

class WebSocketFactory {
    /**
     * @static
     * @param {WsNetworkConfig|WssNetworkConfig} networkConfig
     * @returns {WebSocketServer}
     */
    static newWebSocketServer(networkConfig) {
        return new WebSocketServer(networkConfig);
    }

    /**
     * @static
     * @param {string} url
     * @param {*} [options]
     * @returns {WebSocket}
     */
    static newWebSocket(url, options) {
        return new WebSocket(url, options);
    }
}
Class.register(WebSocketFactory);

const URL = require('url');

class HttpRequest {
    /**
     * @param {string} url
     * @param {number} [timeout]
     * @param {number} [maxResponseSize]
     * @returns {Promise.<string>}
     */
    static get(url, timeout = 5000, maxResponseSize = -1) {
        const parsedUrl = URL.parse(url);
        const protocol = parsedUrl.protocol === 'http:' ? http : https;
        return new Promise((resolve, reject) => {
            const req = protocol.get(parsedUrl, res => {
                if (res.statusCode !== 200) {
                    res.resume(); // Consume response data to free up memory.
                    reject(new Error(`Request failed (status ${res.statusCode})`));
                    return;
                }

                let data = '';
                res.on('data', chunk => {
                    data += chunk;

                    // Abort if maxResponseSize is exceeded.
                    if (maxResponseSize > 0 && data.length > maxResponseSize) {
                        res.resume(); // Consume response data to free up memory.
                        reject(new Error(`Max response size ${maxResponseSize} exceeded`));
                        req.abort();
                    }
                });
                res.on('end', () => resolve(data));
                res.on('error', e => {
                    res.resume(); // Consume response data to free up memory.
                    reject(e);
                });
            });

            req.on('error', reject);
            req.on('abort', () => reject(new Error('Request timed out')));
            req.on('timeout', () => req.abort());
            req.setTimeout(timeout);

            setTimeout(() => req.abort(), timeout);
        });
    }
}
Class.register(HttpRequest);

class PlatformUtils {
    /**
     * @returns {boolean}
     */
    static isBrowser() {
        return false;
    }

    /**
     * @returns {boolean}
     */
    static isWeb() {
        return false;
    }

    /**
     * @return {boolean}
     */
    static isNodeJs() {
        return typeof process === 'object' && typeof require === 'function';
    }

    /**
     * @returns {boolean}
     */
    static supportsWebRTC() {
        return false;
    }

    /**
     * @returns {boolean}
     */
    static supportsWS() {
        return true;
    }

    /**
     * @returns {boolean}
     */
    static isOnline() {
        return true; // TODO: Online check for NodeJS?
    }

    /**
     * @returns {boolean}
     */
    static isWindows() {
        return /^win/.test(process.platform);
    }

    static get userAgentString() {
        try {
            const os = require('os');
            return os.type() + ' ' + os.arch();
        } catch (e) {
            return 'unknown';
        }
    }

    static get hardwareConcurrency() {
        return require('os').cpus().length;
    }
}

Class.register(PlatformUtils);

class ConstantHelper {
    constructor() {
        this._originalValues = new Map();
    }

    /**
     * @returns {ConstantHelper}
     */
    static get instance() {
        if (!ConstantHelper._instance) {
            ConstantHelper._instance = new ConstantHelper();
        }
        return ConstantHelper._instance;
    }

    /**
     * @param {string} constant
     * @return {boolean}
     */
    isConstant(constant) {
        if (constant.indexOf('.') < 1) return false;
        const clazz = constant.split('.', 2)[0];
        constant = constant.split('.', 2)[1];
        if (constant.startsWith('_')) return false;
        if (constant.toUpperCase() !== constant) return false;
        if (!(clazz in Class.scope)) return false;
        if (!Class.scope[clazz]) return false;
        if (!Class.scope[clazz].hasOwnProperty) return false;
        if (!Class.scope[clazz].hasOwnProperty(constant)) return false;
        if (!Object.keys(Class.scope[clazz]).includes(constant)) return false;
        if (typeof Class.scope[clazz][constant] !== 'number') return false;
        return true;
    }

    /**
     * @param {string} constant
     */
    _ensureIsConstant(constant) {
        if (!this.isConstant(constant)) {
            throw new Error(`${constant} is not a numerical constant.`);
        }
    }

    /**
     * @param {string} constant
     * @returns {number}
     */
    get(constant) {
        this._ensureIsConstant(constant);
        const clazz = constant.split('.', 2)[0];
        constant = constant.split('.', 2)[1];
        return Class.scope[clazz][constant];
    }

    /**
     * @param {string} constant
     * @param {number} value
     */
    set(constant, value) {
        this._ensureIsConstant(constant);
        if (!this._originalValues.has(constant)) {
            this._originalValues.set(constant, this.get(constant));
        }
        const clazz = constant.split('.', 2)[0];
        constant = constant.split('.', 2)[1];
        Class.scope[clazz][constant] = value;
    }

    /**
     * @param {string} constant
     */
    reset(constant) {
        this._ensureIsConstant(constant);
        if (this._originalValues.has(constant)) {
            this.set(constant, this._originalValues.get(constant));
            this._originalValues.delete(constant);
        }
    }

    resetAll() {
        for(const constant of this._originalValues.keys()) {
            this.set(constant, this._originalValues.get(constant));
        }
        this._originalValues.clear();
    }
}

Class.register(ConstantHelper);

class Services {
    /**
     * @constructor
     * @param {number} [provided=Services.NONE] Bitmap of services that can be provided by this node
     * @param {number} [accepted=Services.NONE] Bitmap of services that can be accepted by this node
     */
    constructor(provided = Services.NONE, accepted = Services.NONE) {
        this._provided = provided;
        this._accepted = accepted;
    }

    /**
     * @type {number}
     */
    get provided() {
        return this._provided;
    }

    /**
     * @type {number}
     */
    get accepted() {
        return this._accepted;
    }

    /**
     * @param {number} services Bitmap of services that can be provided
     */
    set provided(services) {
        this._provided = services;
    }

    /**
     * @param {number} services Bitmap of services that can be accepted
     */
    set accepted(services) {
        this._accepted = services;
    }

    /**
     * @param {number} services Bitmap of the services to check
     * @returns {boolean}
     * @deprecated
     */
    static isFullNode(services) {
        return (services & Services.FLAG_FULL) !== 0;
    }

    /**
     * @param {number} services Bitmap of the services to check
     * @returns {boolean}
     * @deprecated
     */
    static isLightNode(services) {
        return (services & Services.FLAG_LIGHT) !== 0;
    }

    /**
     * @param {number} services Bitmap of the services to check
     * @returns {boolean}
     * @deprecated
     */
    static isNanoNode(services) {
        return services === Services.FLAG_NANO;
    }

    /**
     * @param {number} flags
     * @param {...number} services
     */
    static providesServices(flags, ...services) {
        flags = Services.legacyProvideToCurrent(flags);
        const all = services.reduce((a, b) => a | b) & Services.ALL_CURRENT;
        return (flags & all) === all;
    }

    static legacyProvideToCurrent(flags) {
        if (flags === Services.FLAG_NANO) flags = Services.PROVIDES_NANO;
        if (flags === Services.FLAG_LIGHT) flags = Services.PROVIDES_LIGHT;
        if (flags === Services.FLAG_FULL) flags = Services.PROVIDES_FULL;
        return flags;
    }

    /**
     * @param {number} flags
     * @returns {Array.<string>}
     */
    static toNameArray(flags) {
        const res = [];
        let i = 1;
        do {
            if ((flags & i) === i && Services.NAMES[i]) res.push(Services.NAMES[i]);
            i <<= 1;
        } while (i < Services.ALL_CURRENT);
        return res;
    }
}

Services.NONE    = 0;

/** @deprecated */
Services.FLAG_NANO  = 1 << 0;
/** @deprecated */
Services.FLAG_LIGHT = 1 << 1;
/** @deprecated */
Services.FLAG_FULL  = 1 << 2;
/** @deprecated */
Services.ALL_LEGACY = (1 << 3) - 1;

/**
 * The node provides at least the latest {@link Policy.NUM_BLOCKS_VERIFICATION} as full blocks.
 */
Services.FULL_BLOCKS       = 1 << 3;
/**
 * The node provides the full block history.
 *
 * If {@link Services.FULL_BLOCKS} is set, these blocks are provided as full blocks.
 */
Services.BLOCK_HISTORY     = 1 << 4;
/**
 * The node provides a proof that a certain block is included in the current chain.
 *
 * If {@link Services.FULL_BLOCKS} is set, these blocks may be requested as full blocks.
 *
 * However, if {@link Services.BLOCK_HISTORY} is not set, this service is only provided for the latest
 * {@link Policy.NUM_BLOCKS_VERIFICATION} blocks.
 */
Services.BLOCK_PROOF       = 1 << 5;
/**
 * The node provides a chain proof for the tip of the current main chain.
 */
Services.CHAIN_PROOF       = 1 << 6;
/**
 * The node provides inclusion and exclusion proofs for accounts that are necessary to verify active accounts as well as
 * accounts in all transactions it provided from its mempool.
 *
 * However, if {@link Services.ACCOUNTS_CHUNKS} is not set, the node may occasionally not provide a proof if it
 * decided to prune the account from local storage.
 */
Services.ACCOUNTS_PROOF    = 1 << 7;
/**
 * The node provides the full accounts tree in form of chunks.
 * This implies that the client stores the full accounts tree.
 */
Services.ACCOUNTS_CHUNKS   = 1 << 8;
/**
 * The node tries to stay on sync with the network wide mempool and will provide access to it.
 *
 * Nodes that do not have this flag set may occasionally announce transactions from their mempool and/or reply to
 * mempool requests to announce locally crafted transactions.
 */
Services.MEMPOOL           = 1 << 9;
/**
 * The node provides an index of transactions allowing it to find historic transactions by address or by hash.
 *
 * Nodes that have this flag set may prune any part of their transaction index at their discretion, they do not claim
 * completeness of their results either.
 */
Services.TRANSACTION_INDEX = 1 << 10;
/**
 * The node provides proofs for details from the block body, i.e. transaction proofs.
 *
 * However, if {@link Services.BLOCK_HISTORY} is not set, this service is only provided for the latest
 * {@link Policy.NUM_BLOCKS_VERIFICATION} blocks.
 */
Services.BODY_PROOF        = 1 << 11;
Services.ALL_CURRENT       = (1 << 12) - 1 - Services.ALL_LEGACY;

Services.NAMES = {};
Services.NAMES[Services.FULL_BLOCKS] = 'FULL_BLOCKS';
Services.NAMES[Services.BLOCK_HISTORY] = 'BLOCK_HISTORY';
Services.NAMES[Services.BLOCK_PROOF] = 'BLOCK_PROOF';
Services.NAMES[Services.CHAIN_PROOF] = 'CHAIN_PROOF';
Services.NAMES[Services.ACCOUNTS_PROOF] = 'ACCOUNTS_PROOF';
Services.NAMES[Services.ACCOUNTS_CHUNKS] = 'ACCOUNTS_CHUNKS';
Services.NAMES[Services.MEMPOOL] = 'MEMPOOL';
Services.NAMES[Services.TRANSACTION_INDEX] = 'TRANSACTION_INDEX';
Services.NAMES[Services.BODY_PROOF] = 'BODY_PROOF';

Services.PROVIDES_FULL =        Services.FLAG_FULL | Services.ALL_CURRENT;
Services.PROVIDES_LIGHT =       Services.FLAG_LIGHT | Services.FULL_BLOCKS | Services.BLOCK_PROOF |
                                Services.CHAIN_PROOF | Services.ACCOUNTS_PROOF | Services.ACCOUNTS_CHUNKS |
                                Services.MEMPOOL | Services.BODY_PROOF;
Services.PROVIDES_NANO =        Services.FLAG_NANO | Services.CHAIN_PROOF;
Services.PROVIDES_PICO =        Services.NONE;

Services.ACCEPTS_FULL =         Services.FLAG_FULL | Services.FULL_BLOCKS | Services.BLOCK_HISTORY;
Services.ACCEPTS_LIGHT =        Services.FLAG_LIGHT | Services.FLAG_FULL | Services.FULL_BLOCKS | Services.CHAIN_PROOF |
                                Services.ACCOUNTS_CHUNKS;
Services.ACCEPTS_NANO =         Services.FLAG_NANO | Services.FLAG_LIGHT | Services.FLAG_FULL | Services.CHAIN_PROOF;
Services.ACCEPTS_PICO =         Services.FLAG_NANO | Services.FLAG_LIGHT | Services.FLAG_FULL;

Services.ACCEPTS_SPV =          Services.BLOCK_PROOF | Services.ACCOUNTS_PROOF | Services.MEMPOOL |
                                Services.TRANSACTION_INDEX | Services.BODY_PROOF;

Class.register(Services);

class Timers {
    constructor() {
        this._timeouts = Object.create(null);
        this._intervals = Object.create(null);
    }

    setTimeout(key, fn, waitTime) {
        if (this._timeouts[key]) throw new Error(`Duplicate timeout for key ${key}`);
        this._timeouts[key] = setTimeout(fn, waitTime);
    }

    clearTimeout(key) {
        clearTimeout(this._timeouts[key]);
        delete this._timeouts[key];
    }

    resetTimeout(key, fn, waitTime) {
        clearTimeout(this._timeouts[key]);
        this._timeouts[key] = setTimeout(fn, waitTime);
    }

    timeoutExists(key) {
        return this._timeouts[key] !== undefined;
    }

    setInterval(key, fn, intervalTime) {
        if (this._intervals[key]) throw new Error(`Duplicate interval for key ${key}`);
        this._intervals[key] = setInterval(fn, intervalTime);
    }

    clearInterval(key) {
        clearInterval(this._intervals[key]);
        delete this._intervals[key];
    }

    resetInterval(key, fn, intervalTime) {
        clearInterval(this._intervals[key]);
        this._intervals[key] = setInterval(fn, intervalTime);
    }

    intervalExists(key) {
        return this._intervals[key] !== undefined;
    }

    clearAll() {
        for (const key in this._timeouts) {
            this.clearTimeout(key);
        }
        for (const key in this._intervals) {
            this.clearInterval(key);
        }
    }
}
Class.register(Timers);

class Version {
    /**
     * @param {number} code
     * @return {boolean}
     */
    static isCompatible(code) {
        return code >= 1;
    }

    /**
     * @param {string} [appAgent]
     * @return {string}
     */
    static createUserAgent(appAgent) {
        appAgent = appAgent ? appAgent.trim() : '';
        if (appAgent.length > 0) appAgent = ` ${appAgent}`;
        const platformPrefix = PlatformUtils.isBrowser() ? 'browser; ' : PlatformUtils.isNodeJs() ? 'nodejs; ' : '';
        return `core-js/${Version.CORE_JS_VERSION} (${platformPrefix}${PlatformUtils.userAgentString})${appAgent}`;
    }
}
Version.CODE = 2;
Version.CORE_JS_VERSION = '<filled-by-build-system>';
Class.register(Version);

Version.CORE_JS_VERSION = '1.5.4';
/**
 * This class stores and provides the network time (current system
 * time with an offset calculated from our peer's time)
 */
class Time {
    /**
     * @constructor
     * @param {number} [offset=0]
     */
    constructor(offset = 0) {
        this._offset = offset;
    }

    /**
     * Returns the network's offset
     * @returns {number}
     */
    get offset() {
        return this._offset;
    }

    /**
     * @param {number} offset
     */
    set offset(offset) {
        this._offset = offset;
    }

    /**
     * Returns the current time adjusted with the network's offset
     * @return {number}
     */
    now() {
        return Date.now() + this._offset;
    }
}
Class.register(Time);

class EventLoopHelper {
    static webYield() {
        return PlatformUtils.isWeb() ? EventLoopHelper.yield() : Promise.resolve();
    }

    static yield() {
        return new Promise((resolve) => setTimeout(resolve));
    }
}

Class.register(EventLoopHelper);

class IteratorUtils {
    static alternate(...iterators) {
        const numIterators = iterators.length;
        let i = 0, done = false;
        const it = () => {
            if (!done) {
                for (let tries = 0; tries < numIterators; tries++) {
                    const result = iterators[i].next();
                    i = (i + 1) % numIterators;
                    if (!result.done) {
                        return result;
                    }
                }
            }
            done = true;
            return {done: true};
        };
        return {
            next: it,
            [Symbol.iterator]: () => { return { next: it }; }
        };
    }
}
Class.register(IteratorUtils);

class ArrayUtils {
    /**
     * @template T
     * @param {Array.<T>} arr
     * @return {T}
     */
    static randomElement(arr) {
        return arr[Math.floor(Math.random() * arr.length)];
    }

    /**
     * @param {Uint8Array} uintarr
     * @param {number} begin
     * @param {number} end
     * @return {Uint8Array}
     */
    static subarray(uintarr, begin, end) {
        function clamp(v, min, max) { return v < min ? min : v > max ? max : v; }

        if (begin === undefined) { begin = 0; }
        if (end === undefined) { end = uintarr.byteLength; }

        begin = clamp(begin, 0, uintarr.byteLength);
        end = clamp(end, 0, uintarr.byteLength);

        let len = end - begin;
        if (len < 0) {
            len = 0;
        }

        return new Uint8Array(uintarr.buffer, uintarr.byteOffset + begin, len);
    }

    /**
     * @param {Array} list
     * @param {number} k
     * @yields {Array}
     */
    static *k_combinations(list, k) {
        const n = list.length;
        // Shortcut:
        if (k > n) {
            return;
        }
        const indices = Array.from(new Array(k), (x,i) => i);
        yield indices.map(i => list[i]);
        const reverseRange = Array.from(new Array(k), (x,i) => k-i-1);
        /*eslint no-constant-condition: ["error", { "checkLoops": false }]*/
        while (true) {
            let i = k-1, found = false;
            for (i of reverseRange) {
                if (indices[i] !== i + n - k) {
                    found = true;
                    break;
                }
            }
            if (!found) {
                return;
            }
            indices[i] += 1;
            for (const j of Array.from(new Array(k-i-1), (x,k) => i+k+1)) {
                indices[j] = indices[j-1] + 1;
            }
            yield indices.map(i => list[i]);
        }
    }
}
Class.register(ArrayUtils);

/**
 * @template K,V
 */
class HashMap {
    /**
     * @param {function(o: object): string} [fnHash]
     */
    constructor(fnHash = HashMap._hash) {
        /** @type {Map.<string,V>} */
        this._map = new Map();
        /** @type {function(o: object): string} */
        this._fnHash = fnHash;
    }

    /**
     * @param {{hashCode: function():string}|*} o
     * @returns {string}
     * @private
     */
    static _hash(o) {
        if (o === null || o === undefined) return o;
        return o.hashCode ? o.hashCode() : o.toString();
    }

    /**
     * @param {K|*} key
     * @returns {V|*}
     */
    get(key) {
        return this._map.get(this._fnHash(key));
    }

    /**
     * @param {K|*} key
     * @param {V|*} value
     */
    put(key, value) {
        this._map.set(this._fnHash(key), value);
    }

    /**
     * @param {K|*} key
     */
    remove(key) {
        this._map.delete(this._fnHash(key));
    }

    clear() {
        this._map.clear();
    }

    /**
     * @param {K|*} key
     * @returns {boolean}
     */
    contains(key) {
        return this._map.has(this._fnHash(key));
    }

    /**
     * @returns {Array.<K|*>}
     */
    keys() {
        return Array.from(this._map.keys());
    }

    /**
     * @returns {Iterator.<K|*>}
     */
    keyIterator() {
        return this._map.keys();
    }

    /**
     * @returns {Array.<V|*>}
     */
    values() {
        return Array.from(this._map.values());
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    valueIterator() {
        return this._map.values();
    }

    /**
     * @returns {Array.<Array.<K|V|*>>}
     */
    entries() {
        return Array.from(this._map.entries());
    }

    /**
     * @returns {Iterator.<Array.<K|V|*>>}
     */
    entryIterator() {
        return this._map.entries();
    }

    /**
     * @returns {number}
     */
    get length() {
        return this._map.size;
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._map.size === 0;
    }
}
Class.register(HashMap);

/**
 * @template V
 * @implements {Iterable.<V>}
 */
class HashSet {
    constructor(fnHash = HashSet._hash) {
        /** @type {Map.<string,V>} */
        this._map = new Map();
        /** @type {function(o: object): string} */
        this._fnHash = fnHash;
    }

    /**
     * @param {{hashCode: function():string}|*} o
     * @returns {string}
     * @private
     */
    static _hash(o) {
        if (o === null || o === undefined) return o;
        return o.hashCode ? o.hashCode() : o.toString();
    }

    /**
     * @param {V|*} value
     */
    add(value) {
        this._map.set(this._fnHash(value), value);
    }

    /**
     * @param {Iterable.<V|*>} collection
     */
    addAll(collection) {
        for (const value of collection) {
            this.add(value);
        }
    }

    /**
     * @param {V|*} value
     * @returns {V|*}
     */
    get(value) {
        return this._map.get(this._fnHash(value));
    }

    /**
     * @param {V|*} value
     */
    remove(value) {
        this._map.delete(this._fnHash(value));
    }

    /**
     * @param {Array.<V|*>} collection
     */
    removeAll(collection) {
        for (const value of collection) {
            this.remove(value);
        }
    }

    clear() {
        this._map.clear();
    }

    /**
     * @param {V|*} value
     * @returns {boolean}
     */
    contains(value) {
        return this._map.has(this._fnHash(value));
    }

    /**
     * @returns {Array.<V|*>}
     */
    values() {
        return Array.from(this._map.values());
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    valueIterator() {
        return this._map.values();
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    [Symbol.iterator]() {
        return this.valueIterator();
    }

    /**
     * @returns {number}
     */
    get length() {
        return this._map.size;
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._map.size === 0;
    }
}
Class.register(HashSet);

/**
 * @template V
 * @implements {Iterable.<V>}
 */
class LimitHashSet {
    /**
     * @param {number} limit
     * @param {function(o: object): string} [fnHash]
     */
    constructor(limit, fnHash = LimitHashSet._hash) {
        if (limit <= 0) throw new Error('Invalid limit');
        /** @type {number} */
        this._limit = limit;
        /** @type {function(o: object): string} */
        this._fnHash = fnHash;
        /** @type {UniqueLinkedList.<V>} */
        this._list = new UniqueLinkedList(fnHash);
    }

    /**
     * @param {{hashCode: function():string}|*} o
     * @returns {string}
     * @private
     */
    static _hash(o) {
        if (o === null || o === undefined) return o;
        return o.hashCode ? o.hashCode() : o.toString();
    }


    /**
     * @param {V|*} value
     */
    add(value) {
        this._list.push(value, true);
        if (this._list.length > this._limit) {
            this._list.shift();
        }
    }

    /**
     * @param {Iterable.<V|*>} collection
     */
    addAll(collection) {
        for (const value of collection) {
            this.add(value);
        }
    }

    /**
     * @param {V|*} value
     * @returns {V|*}
     */
    get(value) {
        return this._list.get(value);
    }

    /**
     * @param {V|*} value
     */
    remove(value) {
        this._list.remove(value);
    }

    /**
     * @param {Array.<V|*>} collection
     */
    removeAll(collection) {
        for (const value of collection) {
            this.remove(value);
        }
    }

    /**
     * @returns {void}
     */
    clear() {
        this._list.clear();
    }

    /**
     * @param {V|*} value
     * @returns {boolean}
     */
    contains(value) {
        return this._list.contains(value);
    }

    /**
     * @returns {Array.<V|*>}
     */
    values() {
        return Array.from(this._list.iterator());
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    valueIterator() {
        return this._list.iterator();
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    [Symbol.iterator]() {
        return this.valueIterator();
    }

    /**
     * @returns {number}
     */
    get length() {
        return this._list.length;
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._list.length === 0;
    }
}
Class.register(LimitHashSet);

/**
 * @template V
 * @implements {Iterable.<V>}
 */
class InclusionHashSet {
    /**
     * @param {function(o: object): string} [fnHash]
     */
    constructor(fnHash = InclusionHashSet._hash) {
        /** @type {Set.<string>} */
        this._set = new Set();
        /** @type {function(o: object): string} */
        this._fnHash = fnHash;
    }

    /**
     * @param {{hashCode: function():string}|*} o
     * @returns {string}
     * @private
     */
    static _hash(o) {
        if (o === null || o === undefined) return o;
        return o.hashCode ? o.hashCode() : o.toString();
    }

    /**
     * @param {V|*} value
     */
    add(value) {
        this._set.add(this._fnHash(value));
    }

    /**
     * @param {Iterable.<V|*>} collection
     */
    addAll(collection) {
        for (const value of collection) {
            this.add(value);
        }
    }

    /**
     * @param {V|*} value
     */
    remove(value) {
        this._set.delete(this._fnHash(value));
    }

    /**
     * @param {Array.<V|*>} collection
     */
    removeAll(collection) {
        for (const value of collection) {
            this.remove(value);
        }
    }

    clear() {
        this._set.clear();
    }

    /**
     * @param {V|*} value
     * @returns {boolean}
     */
    contains(value) {
        return this._set.has(this._fnHash(value));
    }

    /**
     * @returns {Array.<string>}
     */
    values() {
        return Array.from(this._set.values());
    }

    /**
     * @returns {Iterator.<string>}
     */
    valueIterator() {
        return this._set.values();
    }

    /**
     * @returns {Iterator.<string>}
     */
    [Symbol.iterator]() {
        return this.valueIterator();
    }

    /**
     * @returns {number}
     */
    get length() {
        return this._set.size;
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._set.size === 0;
    }

    /**
     * @param {string} hash
     * @protected
     */
    _addHashed(hash) {
        this._set.add(hash);
    }

    /**
     * @returns {InclusionHashSet}
     */
    clone() {
        const set = new InclusionHashSet(this._fnHash);
        for (const hash of this) {
            set._addHashed(hash);
        }
        return set;
    }
}
Class.register(InclusionHashSet);

/**
 * @template V
 * @implements {Iterable.<V>}
 */
class LimitInclusionHashSet {
    /**
     * @param {number} limit
     * @param {function(o: object): string} [fnHash]
     */
    constructor(limit, fnHash = LimitInclusionHashSet._hash) {
        if (limit <= 0) throw new Error('Invalid limit');
        /** @type {number} */
        this._limit = limit;
        /** @type {function(o: object): string} */
        this._fnHash = fnHash;
        /** @type {UniqueLinkedList.<string>} */
        this._list = new UniqueLinkedList(it => /** @type {string} */ it);
    }

    /**
     * @param {{hashCode: function():string}|*} o
     * @returns {string}
     * @private
     */
    static _hash(o) {
        if (o === null || o === undefined) return o;
        return o.hashCode ? o.hashCode() : o.toString();
    }

    /**
     * @param {V|*} value
     */
    add(value) {
        if (this.length >= this._limit) {
            this._list.shift();
        }
        this._list.push(this._fnHash(value));
    }

    /**
     * @param {Iterable.<V|*>} collection
     */
    addAll(collection) {
        for (const value of collection) {
            this.add(value);
        }
    }

    /**
     * @param {V|*} value
     */
    remove(value) {
        this._list.remove(this._fnHash(value));
    }

    /**
     * @param {Array.<V|*>} collection
     */
    removeAll(collection) {
        for (const value of collection) {
            this.remove(value);
        }
    }

    clear() {
        this._list.clear();
    }

    /**
     * @param {V|*} value
     * @returns {boolean}
     */
    contains(value) {
        return this._list.contains(this._fnHash(value));
    }

    /**
     * @returns {Array.<string>}
     */
    values() {
        return Array.from(this._list);
    }

    /**
     * @returns {Iterator.<string>}
     */
    valueIterator() {
        return this._list.iterator();
    }

    /**
     * @returns {Iterator.<string>}
     */
    [Symbol.iterator]() {
        return this.valueIterator();
    }

    /**
     * @returns {number}
     */
    get length() {
        return this._list.length;
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._list.length === 0;
    }

    /**
     * @param {string} hash
     * @protected
     */
    _addHashed(hash) {
        this._list.push(hash);
    }

    /**
     * @returns {LimitInclusionHashSet}
     */
    clone() {
        const set = new LimitInclusionHashSet(this._limit, this._fnHash);
        for (const hash of this) {
            set._addHashed(hash);
        }
        return set;
    }
}
Class.register(LimitInclusionHashSet);

/**
 * @template T
 * @implements {Iterable.<T>}
 */
class LimitIterable {
    /**
     * @param {Iterable.<T>|Iterator.<T>} it
     * @param {number} limit
     */
    constructor(it, limit) {
        /** @type {Iterator.<T>} */
        this._iterator = it[Symbol.iterator] ? it[Symbol.iterator]() : it;
        /** @type {number} */
        this._limit = limit;
    }

    /**
     * @returns {{next: function():object}}
     */
    [Symbol.iterator]() {
        return LimitIterable.iterator(this._iterator, this._limit);
    }

    /**
     * @template V
     * @param {Iterator.<V>} iterator
     * @param {number} limit
     * @returns {{next: function():object}}
     */
    static iterator(iterator, limit) {
        let count = 0;
        return {
            next: () => {
                const done = count++ >= limit;
                const next = iterator.next();
                return {
                    value: done ? undefined : next.value,
                    done: done || next.done
                };
            }
        };
    }
}
Class.register(LimitIterable);

/**
 * @typedef {{next: ?LinkedListEntry, prev: ?LinkedListEntry, value: V|*}} LinkedListEntry
 */

/**
 * @template V
 * @implements {Iterable.<V>}
 */
class LinkedList {
    /**
     * @param {...*} args
     */
    constructor(...args) {
        /** @type {number} */
        this._length = 0;
        /** @type {LinkedListEntry} */
        this._head = null;
        /** @type {LinkedListEntry} */
        this._tail = null;

        const values = args.length === 1 && Array.isArray(args[0]) ? args[0] : args;
        for (const value of values) {
            this.push(value);
        }
    }

    /**
     * @param {V|*} value
     * @returns {void}
     */
    push(value) {
        const entry = {
            next: null,
            prev: this._head,
            value: value
        };
        this._push(entry);
    }

    /**
     * @param {LinkedListEntry} entry
     * @returns {void}
     * @protected
     */
    _push(entry) {
        this._length++;

        if (!this._head) {
            this._head = entry;
            this._tail = entry;
            return;
        }

        this._head.next = entry;
        this._head = entry;
    }

    /**
     * @param {V|*} value
     */
    unshift(value) {
        const entry = {
            next: this._tail,
            prev: null,
            value: value
        };
        this._unshift(entry);
    }

    /**
     * @param {LinkedListEntry} entry
     * @returns {void}
     * @protected
     */
    _unshift(entry) {
        this._length++;

        if (!this._head) {
            this._head = entry;
            this._tail = entry;
            return;
        }

        this._tail.prev = entry;
        this._tail = entry;
    }

    /**
     * @returns {V|*}
     */
    pop() {
        if (!this._head) {
            return null;
        }

        this._length--;

        const entry = this._head;
        const prev = entry.prev;
        if (!prev) {
            this._head = null;
            this._tail = null;
            return entry.value;
        }

        prev.next = null;
        this._head = prev;
        return entry.value;
    }

    /**
     * @returns {V|*}
     */
    shift() {
        if (!this._head) {
            return null;
        }

        this._length--;

        const entry = this._tail;
        const next = entry.next;
        if (!next) {
            this._head = null;
            this._tail = null;
            return entry.value;
        }

        next.prev = null;
        this._tail = next;
        return entry.value;
    }

    /**
     * @param {LinkedListEntry} entry
     * @returns {void}
     * @protected
     */
    _remove(entry) {
        if (entry === this._head) {
            this.pop();
        } else if (entry === this._tail) {
            this.shift();
        } else {
            this._length--;
            entry.prev.next = entry.next;
            entry.next.prev = entry.prev;
        }
    }

    /**
     * @returns {void}
     */
    clear() {
        this._length = 0;
        this._head = null;
        this._tail = null;
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    [Symbol.iterator]() {
        return this.iterator();
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    *iterator() {
        let entry = this._tail;
        while (entry) {
            yield entry.value;
            entry = entry.next;
        }
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._length === 0;
    }

    /** @type {V|*} */
    get first() {
        return this._tail ? this._tail.value : null;
    }

    /** @type {V|*} */
    get last() {
        return this._head ? this._head.value : null;
    }

    /** @type {number} */
    get length() {
        return this._length;
    }
}
Class.register(LinkedList);

class UniqueLinkedList extends LinkedList {
    /**
     * @param {function(o: object): string} [fnHash]
     */
    constructor(fnHash) {
        super();
        this._map = new HashMap(fnHash);
    }

    /**
     * @param {V|*} value
     * @param {boolean} moveBack
     * @returns {void}
     * @override
     */
    push(value, moveBack = false) {
        const entry = this._map.get(value);
        if (!entry) {
            super.push(value);
        } else {
            entry.value = value;
            if (moveBack) {
                this._moveBack(entry);
            }
        }
    }

    /**
     * @param {LinkedListEntry} entry
     * @returns {void}
     * @protected
     * @override
     */
    _push(entry) {
        super._push(entry);
        this._map.put(entry.value, entry);
    }

    /**
     * @param {V|*} value
     * @returns {void}
     */
    unshift(value) {
        if (!this._map.contains(value)) {
            super.unshift(value);
        }
    }

    /**
     * @param {LinkedListEntry} entry
     * @returns {void}
     * @protected
     */
    _unshift(entry) {
        super._unshift(entry);
        this._map.put(entry.value, entry);
    }

    /**
     * @returns {V|*}
     */
    pop() {
        const value = super.pop();
        this._map.remove(value);
        return value;
    }

    /**
     * @returns {V|*}
     */
    shift() {
        const value = super.shift();
        this._map.remove(value);
        return value;
    }

    /**
     * @returns {void}
     */
    clear() {
        super.clear();
        this._map.clear();
    }

    /**
     * @param {V|*} value
     * @returns {V|*}
     */
    get(value) {
        const entry = this._map.get(value);
        return entry && entry.value;
    }

    /**
     * @param {V|*} value
     * @returns {boolean}
     */
    contains(value) {
        return this._map.contains(value);
    }

    /**
     * @param {V|*} value
     * @returns {void}
     */
    remove(value) {
        const entry = this._map.get(value);
        if (entry) {
            super._remove(entry);
            this._map.remove(value);
        }
    }

    /**
     * @param {V|*} value
     * @returns {void}
     */
    moveBack(value) {
        /*
         * Just removing and inserting the key again may take seconds (yes, seconds!).
         * This is due to the JavaScript Map implementation as illustrated in this benchmark:
         * https://gist.github.com/paberr/1d916343631c0e42f8311a6f2782f30d
         *
         * 100,000 accesses using Map remove/insert: ~4s
         * 100,000 accesses using optimised version: ~9ms
         */
        const entry = this._map.get(value);
        if (entry) {
            this._moveBack(entry);
        } else {
            // Do not check again for presence in the map.
            super.push(value);
        }
    }

    /**
     * @param {LinkedListEntry} entry
     * @returns {void}
     * @protected
     */
    _moveBack(entry) {
        if (entry === this._head) {
            return;
        } else if (entry === this._tail) {
            entry.next.prev = null;
            this._tail = entry.next;
        } else {
            entry.prev.next = entry.next;
            entry.next.prev = entry.prev;
        }
        entry.next = null;
        entry.prev = this._head;
        this._head.next = entry;
        this._head = entry;
    }
}
Class.register(UniqueLinkedList);

/**
 * @template V
 */
class Queue {
    /**
     * @param {...*} args
     */
    constructor(...args) {
        /**
         * @type {LinkedList.<V|*>}
         * @protected
         */
        this._queue = this._newQueue(...args);
    }

    /**
     * @param {...*} args
     * @returns {LinkedList.<V|*>}
     * @protected
     */
    _newQueue(...args) {
        return new LinkedList(...args);
    }

    /**
     * @param {V|*} value
     * @returns {void}
     */
    enqueue(value) {
        this._queue.push(value);
    }

    /**
     * @param {Array.<V|*>} values
     * @returns {void}
     */
    enqueueAll(values) {
        for (const value of values) {
            this.enqueue(value);
        }
    }

    /**
     * @returns {V|*}
     */
    dequeue() {
        return this._queue.shift();
    }

    /**
     * @param {number} count
     * @returns {Array.<V|*>}
     */
    dequeueMulti(count) {
        count = Math.min(this._queue.length, count);
        const values = [];
        for (let i = 0; i < count; i++) {
            values.push(this.dequeue());
        }
        return values;
    }

    /**
     * @returns {V|*}
     */
    peek() {
        return this._queue.first;
    }

    /**
     * @returns {void}
     */
    clear() {
        this._queue.clear();
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._queue.isEmpty();
    }

    /** @type {number} */
    get length() {
        return this._queue.length;
    }
}
Class.register(Queue);

/**
 * @template V
 */
class UniqueQueue extends Queue {
    /**
     * @param {function(o: object): string} [fnHash]
     */
    constructor(fnHash) {
        super(fnHash);
    }

    /**
     * @param {...*} args
     * @returns {LinkedList.<V|*>}
     * @protected
     * @override
     */
    _newQueue(...args) {
        return new UniqueLinkedList(...args);
    }

    /**
     * @param {V|*} value
     * @returns {boolean}
     */
    contains(value) {
        return this._queue.contains(value);
    }

    /**
     * @param {V|*} value
     * @returns {void}
     * @override
     */
    remove(value) {
        this._queue.remove(value);
    }

    /**
     * @param {V|*} value
     * @returns {void}
     */
    requeue(value) {
        this._queue.moveBack(value);
    }
}
Class.register(UniqueQueue);

/**
 * @template V
 */
class ThrottledQueue extends UniqueQueue {
    /**
     * @param {number} [maxAtOnce]
     * @param {number} [allowanceNum]
     * @param {number} [allowanceInterval]
     * @param {number} [maxSize]
     * @param {function} [allowanceCallback]
     */
    constructor(maxAtOnce = Number.POSITIVE_INFINITY, allowanceNum = maxAtOnce, allowanceInterval = 1000, maxSize = Number.POSITIVE_INFINITY, allowanceCallback) {
        super();
        this._maxSize = maxSize;
        this._maxAtOnce = maxAtOnce;
        this._availableNow = this._maxAtOnce;

        this._timers = new Timers();
        this._timers.setInterval('allowance', () => {
            this._availableNow = Math.min(this._maxAtOnce, this._availableNow + allowanceNum);
            if (typeof allowanceCallback === 'function' && this.isAvailable()) allowanceCallback();
        }, allowanceInterval);
    }

    /**
     * @returns {void}
     */
    stop() {
        this._timers.clearAll();
    }

    /**
     * @param {V|*} value
     * @returns {void}
     * @override
     */
    enqueue(value) {
        if (this.length >= this._maxSize) {
            super.dequeue();
        }
        super.enqueue(value);
    }

    /**
     * @returns {V|*}
     * @override
     */
    dequeue() {
        if (this.available > 0) {
            this._availableNow--;
            return super.dequeue();
        }
        return null;
    }

    /**
     * @param {number} count
     * @returns {Array.<V|*>}
     * @override
     */
    dequeueMulti(count) {
        count = Math.min(this.available, count);
        return super.dequeueMulti(count);
    }

    /**
     * @returns {boolean}
     */
    isAvailable() {
        return this.available > 0;
    }

    /** @type {number} */
    get available() {
        return Math.min(this._availableNow, this.length);
    }
}
Class.register(ThrottledQueue);

class SortedList {
    constructor(sortedList = [], compare) {
        this._list = sortedList;
        this._compare = compare || SortedList._compare;
    }

    static _compare(a, b) {
        return a.compare ? a.compare(b) : (a > b ? 1 : (a < b ? -1 : 0));
    }

    indexOf(o) {
        let a = 0, b = this._list.length - 1;
        let currentIndex = null;
        let currentElement = null;

        while (a <= b) {
            currentIndex = Math.round((a + b) / 2);
            currentElement = this._list[currentIndex];

            if (this._compare(currentElement, o) < 0) {
                a = currentIndex + 1;
            }
            else if (this._compare(currentElement, o) > 0) {
                b = currentIndex - 1;
            }
            else {
                return currentIndex;
            }
        }

        return -1;
    }

    _insertionIndex(o) {
        let a = 0, b = this._list.length - 1;
        let currentIndex = null;
        let currentElement = null;

        while (a <= b) {
            currentIndex = Math.round((a + b) / 2);
            currentElement = this._list[currentIndex];

            if (this._compare(currentElement, o) < 0) {
                a = currentIndex + 1;
            }
            else if (this._compare(currentElement, o) > 0) {
                b = currentIndex - 1;
            }
            else {
                break;
            }
        }

        return a;
    }

    add(value) {
        this._list.splice(this._insertionIndex(value), 0, value);
    }

    shift() {
        return this._list.shift();
    }

    pop() {
        return this._list.pop();
    }

    peekFirst() {
        return this._list[0];
    }

    peekLast() {
        return this._list[this._list.length - 1];
    }

    remove(value) {
        const index = this.indexOf(value);
        if (index > -1) {
            this._list.splice(index, 1);
        }
    }

    clear() {
        this._list = [];
    }

    values() {
        return this._list;
    }

    /**
     * @returns {Iterator.<V|*>}
     */
    [Symbol.iterator]() {
        return this._list[Symbol.iterator]();
    }

    copy() {
        return new SortedList(this._list.slice(), this._compare);
    }

    /** @type {number} */
    get length() {
        return this._list.length;
    }
}
Class.register(SortedList);

class Assert {
    /**
     * @param {boolean} condition
     * @param {string} [message]
     * @returns {void}
     */
    static that(condition, message = 'Assertion failed') {
        if (!condition) {
            throw new Error(message);
        }
    }
}
Class.register(Assert);

class BufferUtils {
    /**
     * @param {*} buffer
     * @return {string}
     */
    static toAscii(buffer) {
        const chunkSize = 0x2000;
        const buf = BufferUtils._toUint8View(buffer);

        let ascii = '';
        for (let i = 0; i < buf.length; i += chunkSize) {
            ascii += String.fromCharCode.apply(null, buf.subarray(i, i + chunkSize));
        }
        return ascii;
    }

    /**
     * @param {string} string
     * @return {Uint8Array}
     */
    static fromAscii(string) {
        const buf = new Uint8Array(string.length);
        for (let i = 0; i < string.length; ++i) {
            buf[i] = string.charCodeAt(i);
        }
        return buf;
    }

    static _codePointTextDecoder(buffer) {
        if (typeof TextDecoder === 'undefined') throw new Error('TextDecoder not supported');
        if (BufferUtils._ISO_8859_15_DECODER === null) throw new Error('TextDecoder does not support iso-8859-15');
        if (BufferUtils._ISO_8859_15_DECODER === undefined) {
            try {
                BufferUtils._ISO_8859_15_DECODER = new TextDecoder('iso-8859-15');
            } catch (e) {
                BufferUtils._ISO_8859_15_DECODER = null;
                throw new Error('TextDecoder does not support iso-8859-15');
            }
        }
        const uint8View = BufferUtils._toUint8View(buffer);
        return BufferUtils._ISO_8859_15_DECODER.decode(uint8View)
            .replace('', '').replace('', '').replace('', '').replace('', '')
            .replace('', '').replace('', '').replace('', '').replace('', '');
    }

    static _tripletToBase64(num) {
        return BufferUtils._BASE64_LOOKUP[num >> 18 & 0x3F] + BufferUtils._BASE64_LOOKUP[num >> 12 & 0x3F] + BufferUtils._BASE64_LOOKUP[num >> 6 & 0x3F] + BufferUtils._BASE64_LOOKUP[num & 0x3F];
    }

    static _base64encodeChunk(u8, start, end) {
        let tmp;
        const output = [];
        for (let i = start; i < end; i += 3) {
            tmp = ((u8[i] << 16) & 0xFF0000) + ((u8[i + 1] << 8) & 0xFF00) + (u8[i + 2] & 0xFF);
            output.push(BufferUtils._tripletToBase64(tmp));
        }
        return output.join('');
    }

    static _base64fromByteArray(u8) {
        let tmp;
        const len = u8.length;
        const extraBytes = len % 3; // if we have 1 byte left, pad 2 bytes
        let output = '';
        const parts = [];
        const maxChunkLength = 16383; // must be multiple of 3

        // go through the array every three bytes, we'll deal with trailing stuff later
        for (let i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
            parts.push(BufferUtils._base64encodeChunk(u8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)));
        }

        // pad the end with zeros, but make sure to not forget the extra bytes
        if (extraBytes === 1) {
            tmp = u8[len - 1];
            output += BufferUtils._BASE64_LOOKUP[tmp >> 2];
            output += BufferUtils._BASE64_LOOKUP[(tmp << 4) & 0x3F];
            output += '==';
        } else if (extraBytes === 2) {
            tmp = (u8[len - 2] << 8) + (u8[len - 1]);
            output += BufferUtils._BASE64_LOOKUP[tmp >> 10];
            output += BufferUtils._BASE64_LOOKUP[(tmp >> 4) & 0x3F];
            output += BufferUtils._BASE64_LOOKUP[(tmp << 2) & 0x3F];
            output += '=';
        }

        parts.push(output);

        return parts.join('');
    }

    /**
     * @param {*} buffer
     * @return {string}
     */
    static toBase64(buffer) {
        if (PlatformUtils.isNodeJs()) {
            return Buffer.from(buffer).toString('base64');
        } else if (typeof TextDecoder !== 'undefined' && BufferUtils._ISO_8859_15_DECODER !== null) {
            try {
                return btoa(BufferUtils._codePointTextDecoder(buffer));
            } catch (e) {
                // Disabled itself
            }
        }

        return BufferUtils._base64fromByteArray(BufferUtils._toUint8View(buffer));
    }

    /**
     * @param {string} base64
     * @param {number} [length]
     * @return {SerialBuffer}
     */
    static fromBase64(base64, length) {
        const arr = Uint8Array.from(atob(base64), c => c.charCodeAt(0));
        if (length !== undefined && arr.length !== length) throw new Error('Decoded length does not match expected length');
        return new SerialBuffer(arr);
    }

    /**
     * @param {*} buffer
     * @return {string}
     */
    static toBase64Url(buffer) {
        return BufferUtils.toBase64(buffer).replace(/\//g, '_').replace(/\+/g, '-').replace(/=/g, '.');
    }

    /**
     * @param {string} base64
     * @param {number} [length]
     * @return {SerialBuffer}
     */
    static fromBase64Url(base64, length) {
        return BufferUtils.fromBase64(base64.replace(/_/g, '/').replace(/-/g, '+').replace(/\./g, '='), length);
    }

    /**
     * @param {Uint8Array} buf
     * @param {string} [alphabet] Alphabet to use
     * @return {string}
     */
    static toBase32(buf, alphabet = BufferUtils.BASE32_ALPHABET.NIMIQ) {
        let shift = 3, carry = 0, byte, symbol, i, res = '';

        for (i = 0; i < buf.length; i++) {
            byte = buf[i];
            symbol = carry | (byte >> shift);
            res += alphabet[symbol & 0x1f];

            if (shift > 5) {
                shift -= 5;
                symbol = byte >> shift;
                res += alphabet[symbol & 0x1f];
            }

            shift = 5 - shift;
            carry = byte << shift;
            shift = 8 - shift;
        }

        if (shift !== 3) {
            res += alphabet[carry & 0x1f];
        }

        while (res.length % 8 !== 0 && alphabet.length === 33) {
            res += alphabet[32];
        }

        return res;
    }

    /**
     * @param {string} base32
     * @param {string} [alphabet] Alphabet to use
     * @return {Uint8Array}
     */
    static fromBase32(base32, alphabet = BufferUtils.BASE32_ALPHABET.NIMIQ) {
        const charmap = [];
        alphabet.toUpperCase().split('').forEach((c, i) => {
            if (!(c in charmap)) charmap[c] = i;
        });

        let symbol, shift = 8, carry = 0, buf = [];
        base32.toUpperCase().split('').forEach((char) => {
            // ignore padding
            if (alphabet.length === 33 && char === alphabet[32]) return;

            symbol = charmap[char] & 0xff;

            shift -= 5;
            if (shift > 0) {
                carry |= symbol << shift;
            } else if (shift < 0) {
                buf.push(carry | (symbol >> -shift));
                shift += 8;
                carry = (symbol << shift) & 0xff;
            } else {
                buf.push(carry | symbol);
                shift = 8;
                carry = 0;
            }
        });

        if (shift !== 8 && carry !== 0) {
            buf.push(carry);
        }

        return new Uint8Array(buf);
    }

    /**
     * @param {*} buffer
     * @return {string}
     */
    static toHex(buffer) {
        let hex = '';
        for (let i = 0; i < buffer.length; i++) {
            const code = buffer[i];
            hex += BufferUtils.HEX_ALPHABET[code >>> 4];
            hex += BufferUtils.HEX_ALPHABET[code & 0x0F];
        }
        return hex;
    }

    /**
     * @param {string} hex
     * @param {number} [length]
     * @return {SerialBuffer}
     */
    static fromHex(hex, length) {
        hex = hex.trim();
        if (!StringUtils.isHexBytes(hex, length)) throw new Error('String is not an hex string (of matching length)');
        return new SerialBuffer(Uint8Array.from(hex.match(/.{2}/g) || [], byte => parseInt(byte, 16)));
    }

    /**
     * @param {*} bytes
     * @return {string}
     */
    static toBinary(buffer) {
        let bin = '';
        for (let i = 0; i < buffer.length; i++) {
            const code = buffer[i];
            bin += StringUtils.lpad(code.toString(2), '0', 8);
        }
        return bin;
    }

    /**
     * Taken from https://github.com/google/closure-library/blob/master/closure/goog/crypt/crypt.js.
     *
     * @param {string} str
     * @returns {Uint8Array}
     * @private
     */
    static _strToUint8Array(str) {
        const out = [];
        let p = 0;
        for (let i = 0; i < str.length; i++) {
            let c = str.charCodeAt(i);
            if (c < 128) {
                out[p++] = c;
            } else if (c < 2048) {
                out[p++] = (c >> 6) | 192;
                out[p++] = (c & 63) | 128;
            } else if (
                ((c & 0xFC00) === 0xD800) && (i + 1) < str.length &&
                ((str.charCodeAt(i + 1) & 0xFC00) === 0xDC00)) {
                // Surrogate Pair
                c = 0x10000 + ((c & 0x03FF) << 10) + (str.charCodeAt(++i) & 0x03FF);
                out[p++] = (c >> 18) | 240;
                out[p++] = ((c >> 12) & 63) | 128;
                out[p++] = ((c >> 6) & 63) | 128;
                out[p++] = (c & 63) | 128;
            } else {
                out[p++] = (c >> 12) | 224;
                out[p++] = ((c >> 6) & 63) | 128;
                out[p++] = (c & 63) | 128;
            }
        }
        return new Uint8Array(out);
    }

    /**
     * @param {string} str
     * @returns {Uint8Array}
     * @private
     */
    static _utf8TextEncoder(str) {
        if (typeof TextEncoder === 'undefined') throw new Error('TextEncoder not supported');
        if (BufferUtils._UTF8_ENCODER === null) throw new Error('TextEncoder does not support utf8');
        if (BufferUtils._UTF8_ENCODER === undefined) {
            try {
                BufferUtils._UTF8_ENCODER = new TextEncoder();
            } catch (e) {
                BufferUtils._UTF8_ENCODER = null;
                throw new Error('TextEncoder does not support utf8');
            }
        }
        return BufferUtils._UTF8_ENCODER.encode(str);
    }

    /**
     * @param {string} str
     * @returns {Uint8Array}
     */
    static fromUtf8(str) {
        if (PlatformUtils.isNodeJs()) {
            return Buffer.from(str);
        } else if (typeof TextEncoder !== 'undefined' && BufferUtils._UTF8_ENCODER !== null) {
            try {
                return BufferUtils._utf8TextEncoder(str);
            } catch (e) {
                // Disabled itself
            }
        }
        return BufferUtils._strToUint8Array(str);
    }

    /**
     * @param {Uint8Array|string} o
     * @param {number} [length]
     * @return {SerialBuffer}
     */
    static fromAny(o, length) {
        if (o === '') return SerialBuffer.EMPTY;
        if (!o) throw new Error('Invalid buffer format');
        if (o instanceof Uint8Array) return new SerialBuffer(o);
        try {
            return BufferUtils.fromHex(o, length);
        } catch (e) {
            // Ignore
        }
        try {
            return BufferUtils.fromBase64(o, length);
        } catch (e) {
            // Ignore
        }
        throw new Error('Invalid buffer format');
    }


    /**
     * @template T
     * @param {T} a
     * @param {*} b
     * @return {T}
     */
    static concatTypedArrays(a, b) {
        const c = new (a.constructor)(a.length + b.length);
        c.set(a, 0);
        c.set(b, a.length);
        return c;
    }

    /**
     * @param {*} a
     * @param {*} b
     * @return {boolean}
     */
    static equals(a, b) {
        if ((a.byteLength || a.length) !== (b.byteLength || b.length)) return false;
        const viewA = BufferUtils._toUint8View(a);
        const viewB = BufferUtils._toUint8View(b);
        for (let i = 0; i < viewA.length; i++) {
            if (viewA[i] !== viewB[i]) return false;
        }
        return true;
    }

    /**
     * @param {*} a
     * @param {*} b
     * @return {number} -1 if a is smaller than b, 1 if a is larger than b, 0 if a equals b.
     */
    static compare(a, b) {
        if (a.length < b.length) return -1;
        if (a.length > b.length) return 1;
        for (let i = 0; i < a.length; i++) {
            if (a[i] < b[i]) return -1;
            if (a[i] > b[i]) return 1;
        }
        return 0;
    }

    /**
     * @param {Uint8Array} a
     * @param {Uint8Array} b
     * @return {Uint8Array}
     */
    static xor(a, b) {
        const res = new Uint8Array(a.byteLength);
        for (let i = 0; i < a.byteLength; ++i) {
            res[i] = a[i] ^ b[i];
        }
        return res;
    }

    /**
     * @param {*} arrayLike
     * @return {Uint8Array}
     * @private
     */
    static _toUint8View(arrayLike) {
        if (arrayLike instanceof Uint8Array) {
            return arrayLike;
        } if (arrayLike instanceof ArrayBuffer) {
            return new Uint8Array(arrayLike);
        } else if (arrayLike.buffer instanceof ArrayBuffer) {
            return new Uint8Array(arrayLike.buffer);
        } else {
            return Uint8Array.from(arrayLike);
        }
    }
}
BufferUtils.BASE64_ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
BufferUtils.BASE32_ALPHABET = {
    RFC4648: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
    RFC4648_HEX: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
    NIMIQ: '0123456789ABCDEFGHJKLMNPQRSTUVXY'
};
BufferUtils.HEX_ALPHABET = '0123456789abcdef';
BufferUtils._BASE64_LOOKUP = [];
for (let i = 0, len = BufferUtils.BASE64_ALPHABET.length; i < len; ++i) {
    BufferUtils._BASE64_LOOKUP[i] = BufferUtils.BASE64_ALPHABET[i];
}

Class.register(BufferUtils);

class SerialBuffer extends Uint8Array {
    /**
     * @param {*} bufferOrArrayOrLength
     */
    constructor(bufferOrArrayOrLength) {
        super(bufferOrArrayOrLength);
        this._view = new DataView(this.buffer);
        this._readPos = 0;
        this._writePos = 0;
    }

    /**
     * @param {number} start
     * @param {number} end
     * @return {Uint8Array}
     */
    subarray(start, end) {
        return ArrayUtils.subarray(this, start, end);
    }

    /** @type {number} */
    get readPos() {
        return this._readPos;
    }

    /** @type {number} */
    set readPos(value) {
        if (value < 0 || value > this.byteLength) throw `Invalid readPos ${value}`;
        this._readPos = value;
    }

    /** @type {number} */
    get writePos() {
        return this._writePos;
    }

    /** @type {number} */
    set writePos(value) {
        if (value < 0 || value > this.byteLength) throw `Invalid writePos ${value}`;
        this._writePos = value;
    }

    /**
     * Resets the read and write position of the buffer to zero.
     * @returns {void}
     */
    reset() {
        this._readPos = 0;
        this._writePos = 0;
    }

    /**
     * @param {number} length
     * @return {Uint8Array}
     */
    read(length) {
        const value = this.subarray(this._readPos, this._readPos + length);
        this._readPos += length;
        return new Uint8Array(value);
    }

    /**
     * @param {*} array
     */
    write(array) {
        this.set(array, this._writePos);
        this._writePos += array.byteLength;
    }

    /**
     * @return {number}
     */
    readUint8() {
        return this._view.getUint8(this._readPos++);
    }

    /**
     * @param {number} value
     */
    writeUint8(value) {
        this._view.setUint8(this._writePos++, value);
    }

    /**
     * @return {number}
     */
    readUint16() {
        const value = this._view.getUint16(this._readPos);
        this._readPos += 2;
        return value;
    }

    /**
     * @param {number} value
     */
    writeUint16(value) {
        this._view.setUint16(this._writePos, value);
        this._writePos += 2;
    }

    /**
     * @return {number}
     */
    readUint32() {
        const value = this._view.getUint32(this._readPos);
        this._readPos += 4;
        return value;
    }

    /**
     * @param {number} value
     */
    writeUint32(value) {
        this._view.setUint32(this._writePos, value);
        this._writePos += 4;
    }

    /**
     * @return {number}
     */
    readUint64() {
        const value = this._view.getUint32(this._readPos) * Math.pow(2, 32) + this._view.getUint32(this._readPos + 4);
        if (!NumberUtils.isUint64(value)) throw new Error('Malformed value');
        this._readPos += 8;
        return value;
    }

    /**
     * @param {number} value
     */
    writeUint64(value) {
        if (!NumberUtils.isUint64(value)) throw new Error('Malformed value');
        this._view.setUint32(this._writePos, Math.floor(value / Math.pow(2, 32)));
        this._view.setUint32(this._writePos + 4, value);
        this._writePos += 8;
    }

    /**
     * @return {number}
     */
    readVarUint() {
        const value = this.readUint8();
        if (value < 0xFD) {
            return value;
        } else if (value === 0xFD) {
            return this.readUint16();
        } else if (value === 0xFE) {
            return this.readUint32();
        } else /*if (value === 0xFF)*/ {
            return this.readUint64();
        }
    }

    /**
     * @param {number} value
     */
    writeVarUint(value) {
        if (!NumberUtils.isUint64(value)) throw new Error('Malformed value');
        if (value < 0xFD) {
            this.writeUint8(value);
        } else if (value <= 0xFFFF) {
            this.writeUint8(0xFD);
            this.writeUint16(value);
        } else if (value <= 0xFFFFFFFF) {
            this.writeUint8(0xFE);
            this.writeUint32(value);
        } else {
            this.writeUint8(0xFF);
            this.writeUint64(value);
        }
    }

    /**
     * @param {number} value
     * @returns {number}
     */
    static varUintSize(value) {
        if (!NumberUtils.isUint64(value)) throw new Error('Malformed value');
        if (value < 0xFD) {
            return 1;
        } else if (value <= 0xFFFF) {
            return 3;
        } else if (value <= 0xFFFFFFFF) {
            return 5;
        } else {
            return 9;
        }
    }

    /**
     * @return {number}
     */
    readFloat64() {
        const value = this._view.getFloat64(this._readPos);
        this._readPos += 8;
        return value;
    }

    /**
     * @param {number} value
     */
    writeFloat64(value) {
        this._view.setFloat64(this._writePos, value);
        this._writePos += 8;
    }

    /**
     * @param {number} length
     * @return {string}
     */
    readString(length) {
        const bytes = this.read(length);
        return BufferUtils.toAscii(bytes);
    }

    /**
     * @param {string} value
     * @param {number} length
     */
    writeString(value, length) {
        if (StringUtils.isMultibyte(value) || value.length !== length) throw new Error('Malformed value/length');
        const bytes = BufferUtils.fromAscii(value);
        this.write(bytes);
    }

    /**
     * @param {number} length
     * @return {string}
     */
    readPaddedString(length) {
        const bytes = this.read(length);
        let i = 0;
        while (i < length && bytes[i] !== 0x0) i++;
        const view = new Uint8Array(bytes.buffer, bytes.byteOffset, i);
        return BufferUtils.toAscii(view);
    }

    /**
     * @param {string} value
     * @param {number} length
     */
    writePaddedString(value, length) {
        if (StringUtils.isMultibyte(value) || value.length > length) throw new Error('Malformed value/length');
        const bytes = BufferUtils.fromAscii(value);
        this.write(bytes);
        const padding = length - bytes.byteLength;
        this.write(new Uint8Array(padding));
    }

    /**
     * @return {string}
     */
    readVarLengthString() {
        const length = this.readUint8();
        if (this._readPos + length > this.length) throw new Error('Malformed length');
        const bytes = this.read(length);
        return BufferUtils.toAscii(bytes);
    }

    /**
     * @param {string} value
     */
    writeVarLengthString(value) {
        if (StringUtils.isMultibyte(value) || !NumberUtils.isUint8(value.length)) throw new Error('Malformed value');
        const bytes = BufferUtils.fromAscii(value);
        this.writeUint8(bytes.byteLength);
        this.write(bytes);
    }

    /**
     * @param {string} value
     * @returns {number}
     */
    static varLengthStringSize(value) {
        if (StringUtils.isMultibyte(value) || !NumberUtils.isUint8(value.length)) throw new Error('Malformed value');
        return /*length*/ 1 + value.length;
    }
}
SerialBuffer.EMPTY = new SerialBuffer(0);
Class.register(SerialBuffer);

class Synchronizer extends Observable {
    /**
     * @param {number} [throttleAfter]
     * @param {number} [throttleWait]
     */
    constructor(throttleAfter, throttleWait) {
        super();

        /** @type {LinkedList.<object>} */
        this._queue = new LinkedList();
        /** @type {boolean} */
        this._working = false;
        /** @type {?number} */
        this._throttleAfter = throttleAfter;
        /** @type {?number} */
        this._throttleWait = throttleWait;
        /** @type {number} */
        this._elapsed = 0;
        /** @type {number} */
        this._totalElapsed = 0;
        /** @type {number} */
        this._totalJobs = 0;
        /** @type {number} */
        this._totalThrottles = 0;
    }

    /**
     * Push function to the Synchronizer for later, synchronous execution
     * @template T
     * @param {function():T} fn Function to be invoked later by this Synchronizer
     * @returns {Promise.<T>}
     */
    push(fn) {
        return new Promise((resolve, reject) => {
            this._queue.push({fn: fn, resolve: resolve, reject: reject});
            if (!this._working) {
                this.fire('work-start', this);
                this._doWork().catch(Log.w.tag(Synchronizer));
            }
        });
    }

    /**
     * Reject all jobs in the queue and clear it.
     * @returns {void}
     */
    clear() {
        for (const job of this._queue) {
            if (job.reject) job.reject();
        }
        this._queue.clear();
    }

    async _doWork() {
        this._working = true;

        while (this._queue.length > 0) {
            const start = Date.now();

            const job = this._queue.shift();
            try {
                const result = await job.fn();
                job.resolve(result);
            } catch (e) {
                if (job.reject) job.reject(e);
            }

            this._totalJobs++;

            if (this._throttleAfter !== undefined) {
                this._elapsed += Date.now() - start;
                if (this._elapsed >= this._throttleAfter) {
                    this._totalElapsed += this._elapsed;
                    this._totalThrottles++;
                    this._elapsed = 0;
                    setTimeout(this._doWork.bind(this), this._throttleWait);
                    return;
                }
            }
        }

        this._working = false;
        this._totalElapsed += this._elapsed;
        this._elapsed = 0;
        this.fire('work-end', this);
    }

    /** @type {boolean} */
    get working() {
        return this._working;
    }

    /** @type {number} */
    get length() {
        return this._queue.length;
    }

    /** @type {number} */
    get totalElapsed() {
        return this._totalElapsed;
    }

    /** @type {number} */
    get totalJobs() {
        return this._totalJobs;
    }

    /** @type {number} */
    get totalThrottles() {
        return this._totalThrottles;
    }
}
Class.register(Synchronizer);

class MultiSynchronizer extends Observable {
    /**
     * @param {number} [throttleAfter]
     * @param {number} [throttleWait]
     */
    constructor(throttleAfter, throttleWait) {
        super();
        /** @type {Map.<string, Synchronizer>} */
        this._synchronizers = new Map();
        /** @type {number} */
        this._throttleAfter = throttleAfter;
        /** @type {number} */
        this._throttleWait = throttleWait;
    }

    /**
     * Push function to the Synchronizer for later, synchronous execution
     * @template T
     * @param {string} tag
     * @param {function():T} fn Function to be invoked later by this Synchronizer
     * @returns {Promise.<T>}
     */
    push(tag, fn) {
        let synchonizer = this._synchronizers.get(tag);
        if (!synchonizer) {
            synchonizer = new Synchronizer(this._throttleAfter, this._throttleWait);
            synchonizer.on('work-start', () => this.fire('work-start', synchonizer, tag, this));
            synchonizer.on('work-end', () => this.fire('work-end', synchonizer, tag, this));
            this._synchronizers.set(tag, synchonizer);
        }
        return synchonizer.push(fn);
    }

    /**
     * Reject all jobs in the queue and clear it.
     * @returns {void}
     */
    clear() {
        for (const synchronizer of this._synchronizers.values()) {
            synchronizer.clear();
        }
        this._synchronizers.clear();
    }

    /**
     * @param {string} tag
     * @returns {boolean}
     */
    isWorking(tag) {
        const synchonizer = this._synchronizers.get(tag);
        return !!synchonizer && synchonizer.working;
    }
}
Class.register(MultiSynchronizer);

class PrioritySynchronizer extends Observable {
    /**
     * @param {number} numPriorities
     * @param {?number} [throttleAfter]
     * @param {?number} [throttleWait]
     */
    constructor(numPriorities, throttleAfter, throttleWait) {
        super();

        /** @type {Array.<LinkedList.<object>>} */
        this._queues = [];
        for (let i = 0; i < numPriorities; i++) {
            this._queues[i] = new LinkedList();
        }

        /** @type {boolean} */
        this._working = false;
        /** @type {?number} */
        this._throttleAfter = throttleAfter;
        /** @type {?number} */
        this._throttleWait = throttleWait;
        /** @type {number} */
        this._elapsed = 0;
        /** @type {number} */
        this._totalElapsed = 0;
        /** @type {number} */
        this._totalJobs = 0;
        /** @type {number} */
        this._totalThrottles = 0;
    }

    /**
     * Push function to the Synchronizer for later, synchronous execution
     * @template T
     * @param {number} priority A discrete priority, 0 being highest.
     * @param {function():T} fn Function to be invoked later by this Synchronizer
     * @returns {Promise.<T>}
     */
    push(priority, fn) {
        Assert.that(priority >= 0 && priority < this._queues.length && Number.isInteger(priority), 'Invalid priority');

        return new Promise((resolve, reject) => {
            this._queues[priority].push({fn: fn, resolve: resolve, reject: reject});
            if (!this._working) {
                this.fire('work-start', this);
                this._doWork().catch(Log.w.tag(PrioritySynchronizer));
            }
        });
    }

    /**
     * Reject all jobs in the queue and clear it.
     * @returns {void}
     */
    clear() {
        for (const queue of this._queues) {
            for (const job of queue) {
                if (job.reject) job.reject();
            }
            queue.clear();
        }
    }

    async _doWork() {
        this._working = true;

        for (const queue of this._queues) {
            while (queue.length > 0) {
                const start = Date.now();

                const job = queue.shift();
                try {
                    const result = await job.fn();
                    job.resolve(result);
                } catch (e) {
                    if (job.reject) job.reject(e);
                }

                this._totalJobs++;

                if (this._throttleAfter !== undefined) {
                    this._elapsed += Date.now() - start;
                    if (this._elapsed >= this._throttleAfter) {
                        this._totalElapsed += this._elapsed;
                        this._totalThrottles++;
                        this._elapsed = 0;
                        setTimeout(this._doWork.bind(this), this._throttleWait);
                        return;
                    }
                }
            }
        }

        this._working = false;
        this._totalElapsed += this._elapsed;
        this._elapsed = 0;
        this.fire('work-end', this);
    }

    /** @type {boolean} */
    get working() {
        return this._working;
    }

    /** @type {number} */
    get length() {
        return this._queues.reduce((sum, q) => sum + q.length, 0);
    }

    /** @type {number} */
    get totalElapsed() {
        return this._totalElapsed;
    }

    /** @type {number} */
    get totalJobs() {
        return this._totalJobs;
    }

    /** @type {number} */
    get totalThrottles() {
        return this._totalThrottles;
    }
}
Class.register(PrioritySynchronizer);

class RateLimit {
    /**
     * @param {number} allowedOccurrences Occurences per timeRange (default 1min)
     * @param {number} [timeRange=60000]
     */
    constructor(allowedOccurrences, timeRange = 60000) {
        /** @type {number} */
        this._allowedOccurrences = allowedOccurrences;
        /** @type {number} */
        this._timeRange = timeRange;

        /** @type {number} */
        this._lastReset = 0;
        /** @type {number} */
        this._counter = 0;
    }

    /**
     * @param {number} [number=1]
     * @returns {boolean}
     */
    note(number = 1) {
        const now = Date.now();
        if (this._lastReset < now - this._timeRange) {
            this._lastReset = now;
            this._counter = 0;
        }
        return (this._counter += number) <= this._allowedOccurrences;
    }

    /** @type {number} */
    get lastReset() {
        return this._lastReset;
    }
}

Class.register(RateLimit);

/**
 * @interface
 */
class IWorker {
    static async createProxy(clazz, name, worker) {
        return new (IWorker.Proxy(clazz))(worker, name);
    }

    static async startWorkerForProxy(clazz, name, workerScript) {
        if (!IWorker._workersSupported) {
            await IWorker._workerImplementation[clazz.name].init(name);
            return IWorker._workerImplementation[clazz.name];
        } else {
            if (!workerScript) {
                workerScript = `${Nimiq._path}worker.js`;
            }
            return IWorker.createProxy(clazz, name, new Worker(URL.createObjectURL(new Blob([`Nimiq = {_path: '${Nimiq._path}'}; importScripts('${workerScript.replace(/'/g, '')}');`]))));
        }
    }

    static async startWorkerPoolForProxy(clazz, name, size, workerScript) {
        return (new (IWorker.Pool(clazz))((name) => IWorker.startWorkerForProxy(clazz, name, workerScript), name, size)).start();
    }

    static async stubBaseOnMessage(msg) {
        try {
            if (msg.data.command === 'init') {
                if (IWorker._workerImplementation[msg.data.args[0]]) {
                    const res = await IWorker._workerImplementation[msg.data.args[0]].init(msg.data.args[1]);
                    self.postMessage({status: 'OK', result: res, id: msg.data.id});
                } else {
                    self.postMessage({status: 'error', result: 'Unknown worker!', id: msg.data.id});
                }
            } else {
                self.postMessage({status: 'error', result: 'Worker not yet initialized!', id: msg.data.id});
            }
        } catch (e) {
            self.postMessage({status: 'error', result: e, id: msg.data.id});
        }
    }

    static get _workersSupported() {
        return typeof Worker !== 'undefined';
    }

    static get areWorkersAsync() {
        return IWorker._workersSupported;
    }

    static get _insideWebWorker() {
        return typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope;
    }

    static get _global() {
        return typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : null;
    }

    static prepareForWorkerUse(baseClazz, impl) {
        if (IWorker._insideWebWorker) {
            // Only inside WebWorker
            self.onmessage = IWorker.stubBaseOnMessage;
        }
        IWorker._workerImplementation = IWorker._workerImplementation || {};
        IWorker._workerImplementation[baseClazz.name] = impl;
    }

    static _loadBrowserScript(url, resolve) {
        // Adding the script tag to the head as suggested before
        const head = document.getElementsByTagName('head')[0];
        const script = document.createElement('script');
        script.type = 'text/javascript';
        script.src = url;

        // Then bind the event to the callback function.
        // There are several events for cross browser compatibility.
        // These events might occur before processing, so delay them a bit.
        const ret = () => setTimeout(resolve, 100);
        script.onreadystatechange = ret;
        script.onload = ret;

        // Fire the loading
        head.appendChild(script);
    }

    static Proxy(clazz) {
        const proxyClass = class extends clazz {
            /**
             * @param {Worker} worker
             * @param {string} [name]
             */
            constructor(worker, name) {
                super();
                this._name = name;
                this._messageId = 0;
                this._worker = worker;
                this._worker.onmessage = this._receive.bind(this);
                /** @type {Map.<number,{resolve:Function,error:Function}>} */
                this._waiting = new Map();
                return this._invoke('init', [clazz.name, name]).then(() => { return this; });
            }

            _receive(msg) {
                const cb = this._waiting.get(msg.data.id);
                if (!cb) {
                    Log.w(WorkerProxy, 'Unknown reply', msg);
                } else {
                    this._waiting.delete(msg.data.id);
                    if (msg.data.status === 'OK') {
                        cb.resolve(msg.data.result);
                    } else if (msg.data.status === 'error') {
                        cb.error(msg.data.result);
                    }
                }
            }

            /**
             * @param {string} command
             * @param {object[]} [args]
             * @returns {Promise}
             * @private
             */
            _invoke(command, args = []) {
                return new Promise((resolve, error) => {
                    const obj = {command: command, args: args, id: this._messageId++};
                    this._waiting.set(obj.id, {resolve, error});
                    this._worker.postMessage(obj);
                });
            }

            destroy() {
                return this._invoke('destroy');
            }
        };
        for (const funcName of Object.getOwnPropertyNames(clazz.prototype)) {
            if (typeof clazz.prototype[funcName] === 'function' && funcName !== 'constructor') {
                proxyClass.prototype[funcName] = function (...args) {
                    return this._invoke(funcName, args);
                };
            }
        }
        return proxyClass;
    }

    /**
     * @param {object} clazz
     * @return {Stub}
     * @constructor
     */
    static Stub(clazz) {
        const Stub = class extends clazz {
            constructor() {
                super();
            }

            _result(msg, status, result) {
                self.postMessage({status, result, id: msg.data.id});
            }

            _onmessage(msg) {
                try {
                    const res = this._invoke(msg.data.command, msg.data.args);
                    if (res instanceof Promise) {
                        res.then((finalRes) => { this._result(msg, 'OK', finalRes); });
                    } else {
                        this._result(msg, 'OK', res);
                    }
                } catch (e) {
                    this._result(msg, 'error', e.message || e);
                }
            }

            init(name) {
                this._name = name;
                if (IWorker._insideWebWorker) {
                    self.name = name;
                    self.onmessage = (msg) => this._onmessage(msg);
                }
            }

            _invoke(command, args) {
                return this[command].apply(this, args);
            }

            destroy() {
                if (IWorker._insideWebWorker) {
                    self.close();
                }
            }
        };
        for (const funcName of Object.getOwnPropertyNames(clazz.prototype)) {
            if (typeof clazz.prototype[funcName] === 'function' && funcName !== 'constructor') {
                Stub.prototype[funcName] = function () {
                    throw `Not implemented in IWorker Stub: ${funcName}`;
                };
            }
        }
        return Stub;
    }

    static Pool(clazz) {
        const poolClass = class extends clazz {
            /**
             *
             * @param {function(string):Promise} proxyInitializer
             * @param {string} [name]
             * @param {number} [size] Number of workers in this pool.
             */
            constructor(proxyInitializer, name = 'pool', size = 1) {
                super();
                /** @type {function(string):Promise} */
                this._proxyInitializer = proxyInitializer;
                /** @type {string} */
                this._name = name;
                /** @type {number} */
                this._poolSize = size;
                /** @type {Array} */
                this._workers = [];
                /** @type {Array} */
                this._freeWorkers = [];
                /** @type {Array.<{name:string, args:Array, resolve:function, error:function}>} */
                this._waitingCalls = [];
            }

            async start() {
                await this._updateToSize();

                return this;
            }

            get poolSize() {
                return this._poolSize;
            }

            set poolSize(_size) {
                this._poolSize = _size;
                this._updateToSize().catch(Log.w.tag(IWorker));
            }

            destroy() {
                this._poolSize = 0;
                return this._updateToSize();
            }

            /**
             * @param {string} name Name of the function to call on a worker
             * @param {Array} args Arguments to pass to the function
             * @returns {Promise}
             */
            _invoke(name, args) {
                if (IWorker._workersSupported) {
                    return new Promise((resolve, error) => {
                        this._waitingCalls.push({name, args, resolve, error});
                        const worker = this._freeWorkers.shift();
                        if (worker) {
                            this._step(worker).catch(Log.w.tag(IWorker));
                        }
                    });
                } else {
                    return this._workers[0][name].apply(this._workers[0], args);
                }
            }

            /**
             * @param worker
             * @returns {Promise.<void>}
             * @private
             */
            async _step(worker) {
                let call = this._waitingCalls.shift();
                while (call) {
                    try {
                        // eslint-disable-next-line no-await-in-loop
                        call.resolve(await worker[call.name].apply(worker, call.args));
                    } catch (e) {
                        call.error(e);
                    }
                    if (this._workers.indexOf(worker) === -1) {
                        worker.destroy();
                        return;
                    }
                    call = this._waitingCalls.shift();
                }
                this._freeWorkers.push(worker);
            }

            async _updateToSize() {
                if (typeof Worker === 'undefined' && this._poolSize > 1) {
                    Log.d(IWorker, 'Pool of size larger than 1 requires WebWorker support.');
                    this._poolSize = 1;
                }

                const workerPromises = [];
                while (this._workers.length + workerPromises.length < this._poolSize) {
                    workerPromises.push(this._proxyInitializer(`${this._name}#${this._workers.length + workerPromises.length}`));
                }
                const createdWorkers = await Promise.all(workerPromises);
                for (const worker of createdWorkers) {
                    this._workers.push(worker);
                    this._step(worker).catch(Log.w.tag(IWorker));
                }

                while (this._workers.length > this._poolSize) {
                    const worker = this._freeWorkers.shift() || this._workers.pop();
                    const idx = this._workers.indexOf(worker);
                    if (idx >= 0) {
                        // This was a free worker, also remove it from the worker list and destroy it now.
                        this._workers.splice(idx, 1);
                        worker.destroy();
                    }
                }
                return this;
            }
        };
        for (const funcName of Object.getOwnPropertyNames(clazz.prototype)) {
            if (typeof clazz.prototype[funcName] === 'function' && funcName !== 'constructor') {
                poolClass.prototype[funcName] = function (...args) {
                    return this._invoke(funcName, args);
                };
            }
        }
        return poolClass;
    }
}

IWorker._moduleLoadedCallbacks = {};
IWorker._workerImplementation = {};
Class.register(IWorker);

/**
 * @interface
 */
class CryptoWorker {
    static get lib() { return CryptoLib.instance; }

    /**
     * @returns {Promise.<CryptoWorker>}
     */
    static async getInstanceAsync() {
        if (!CryptoWorker._workerAsync) {
            CryptoWorker._workerAsync = await IWorker.startWorkerPoolForProxy(CryptoWorker, 'crypto', 4);
        }
        return CryptoWorker._workerAsync;
    }
    /**
     * @param {Uint8Array} input
     * @returns {Promise.<Uint8Array>}
     */
    async computeArgon2d(input) {}

    /**
     * @param {Array.<Uint8Array>} inputs
     * @returns {Promise.<Array.<Uint8Array>>}
     */
    async computeArgon2dBatch(inputs) {}

    /**
     * @param {Uint8Array} key
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @param {number} outputSize
     * @returns {Promise.<Uint8Array>}
     * @deprecated
     */
    async kdfLegacy(key, salt, iterations, outputSize) {}

    /**
     * @param {Uint8Array} key
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @param {number} outputSize
     * @returns {Promise.<Uint8Array>}
     */
    async kdf(key, salt, iterations, outputSize) {}

    /**
     * @param {Uint8Array} block
     * @param {Array.<bool>} transactionValid
     * @param {number} timeNow
     * @param {Uint8Array} genesisHash
     * @param {number} networkId
     * @returns {Promise.<{valid: boolean, pow: SerialBuffer, interlinkHash: SerialBuffer, bodyHash: SerialBuffer}>}
     */
    async blockVerify(block, transactionValid, timeNow, genesisHash, networkId) {}
}
/** @type {CryptoWorker} */
CryptoWorker._workerAsync = null;

Class.register(CryptoWorker);

class CryptoWorkerImpl extends IWorker.Stub(CryptoWorker) {
    constructor() {
        super();
        // FIXME: This is needed for Babel to work correctly. Can be removed as soon as we updated to Babel v7.
        this._superInit = super.init;
    }

    async init(name) {
        await this._superInit.call(this, name);
        if (PlatformUtils.isBrowser()) await WasmHelper.doImportBrowser();
        CryptoWorker._workerAsync = this;
    }

    /**
     * @param {Uint8Array} input
     * @returns {Uint8Array}
     */
    computeArgon2d(input) {
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(Hash.getSize(Hash.Algorithm.ARGON2D));
            const res = NodeNative.node_argon2(out, new Uint8Array(input), 512);
            if (res !== 0) {
                throw res;
            }
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const hashSize = Hash.getSize(Hash.Algorithm.ARGON2D);
                const wasmOut = Module.stackAlloc(hashSize);
                const wasmIn = Module.stackAlloc(input.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, input.length).set(input);
                const res = Module._nimiq_argon2(wasmOut, wasmIn, input.length, 512);
                if (res !== 0) {
                    throw res;
                }
                const hash = new Uint8Array(hashSize);
                hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hashSize));
                return hash;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Array.<Uint8Array>} inputs
     * @returns {Array.<Uint8Array>}
     */
    computeArgon2dBatch(inputs) {
        const hashes = [];
        if (PlatformUtils.isNodeJs()) {
            for(const input of inputs) {
                const out = new Uint8Array(Hash.getSize(Hash.Algorithm.ARGON2D));
                const res = NodeNative.node_argon2(out, new Uint8Array(input), 512);
                if (res !== 0) {
                    throw res;
                }
                hashes.push(out);
            }
            return hashes;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const hashSize = Hash.getSize(Hash.Algorithm.ARGON2D);
                const wasmOut = Module.stackAlloc(hashSize);
                const stackTmp = Module.stackSave();
                for (const input of inputs) {
                    Module.stackRestore(stackTmp);
                    const wasmIn = Module.stackAlloc(input.length);
                    new Uint8Array(Module.HEAPU8.buffer, wasmIn, input.length).set(input);
                    const res = Module._nimiq_argon2(wasmOut, wasmIn, input.length, 512);
                    if (res !== 0) {
                        throw res;
                    }
                    const hash = new Uint8Array(hashSize);
                    hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hashSize));
                    hashes.push(hash);
                }
                return hashes;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} key
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @param {number} outputSize
     * @returns {Uint8Array}
     * @deprecated
     */
    kdfLegacy(key, salt, iterations, outputSize = Hash.getSize(Hash.Algorithm.ARGON2D)) {
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(outputSize);
            const res = NodeNative.node_kdf_legacy(out, new Uint8Array(key), new Uint8Array(salt), 512, iterations);
            if (res !== 0) {
                throw res;
            }
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(outputSize);
                const wasmIn = Module.stackAlloc(key.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, key.length).set(key);
                const wasmSalt = Module.stackAlloc(salt.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmSalt, salt.length).set(salt);
                const res = Module._nimiq_kdf_legacy(wasmOut, outputSize, wasmIn, key.length, wasmSalt, salt.length, 512, iterations);
                if (res !== 0) {
                    throw res;
                }
                const hash = new Uint8Array(outputSize);
                hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, outputSize));
                return hash;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} key
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @param {number} outputSize
     * @returns {Uint8Array}
     */
    kdf(key, salt, iterations, outputSize = Hash.getSize(Hash.Algorithm.ARGON2D)) {
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(outputSize);
            const res = NodeNative.node_kdf(out, new Uint8Array(key), new Uint8Array(salt), 512, iterations);
            if (res !== 0) {
                throw res;
            }
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(outputSize);
                const wasmIn = Module.stackAlloc(key.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, key.length).set(key);
                const wasmSalt = Module.stackAlloc(salt.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmSalt, salt.length).set(salt);
                const res = Module._nimiq_kdf(wasmOut, outputSize, wasmIn, key.length, wasmSalt, salt.length, 512, iterations);
                if (res !== 0) {
                    throw res;
                }
                const hash = new Uint8Array(outputSize);
                hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, outputSize));
                return hash;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} blockSerialized
     * @param {Array.<boolean|undefined>} transactionValid
     * @param {number} timeNow
     * @param {Uint8Array} genesisHash
     * @param {number} networkId
     * @returns {Promise.<{valid: boolean, pow: SerialBuffer, interlinkHash: SerialBuffer, bodyHash: SerialBuffer}>}
     */
    async blockVerify(blockSerialized, transactionValid, timeNow, genesisHash, networkId) {
        // The worker only uses a stub genesis config.
        GenesisConfig = {
            GENESIS_HASH: Hash.unserialize(new SerialBuffer(genesisHash)),
            NETWORK_ID: networkId
        };

        const block = Block.unserialize(new SerialBuffer(blockSerialized));
        for (let i = 0; i < transactionValid.length; i++) {
            block.body.transactions[i]._valid = transactionValid[i];
        }

        const valid = await block._verify(timeNow);
        const pow = await block.header.pow();
        const interlinkHash = block.interlink.hash();
        const bodyHash = block.body.hash();
        return { valid: valid, pow: pow.serialize(), interlinkHash: interlinkHash.serialize(), bodyHash: bodyHash.serialize() };
    }
}

IWorker.prepareForWorkerUse(CryptoWorker, new CryptoWorkerImpl());

class CryptoUtils {
    /**
     * @param {Uint8Array} key
     * @param {Uint8Array} data
     * @return {Uint8Array}
     */
    static computeHmacSha512(key, data) {
        if (key.length > CryptoUtils.SHA512_BLOCK_SIZE) {
            key = new SerialBuffer(Hash.computeSha512(key));
        }

        const iKey = new SerialBuffer(CryptoUtils.SHA512_BLOCK_SIZE);
        const oKey = new SerialBuffer(CryptoUtils.SHA512_BLOCK_SIZE);
        for (let i = 0; i < CryptoUtils.SHA512_BLOCK_SIZE; ++i) {
            const byte = key[i] || 0;
            iKey[i] = 0x36 ^ byte;
            oKey[i] = 0x5c ^ byte;
        }

        const innerHash = Hash.computeSha512(BufferUtils.concatTypedArrays(iKey, data));
        return Hash.computeSha512(BufferUtils.concatTypedArrays(oKey, innerHash));
    }

    /**
     * @param {Uint8Array} password
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @param {number} derivedKeyLength
     * @return {Uint8Array}
     */
    static computePBKDF2sha512(password, salt, iterations, derivedKeyLength) {
        // Following https://www.ietf.org/rfc/rfc2898.txt
        const hashLength = Hash.SIZE.get(Hash.Algorithm.SHA512);

        if (derivedKeyLength > (Math.pow(2, 32) - 1) * hashLength) {
            throw new Error('Derived key too long');
        }

        const l = Math.ceil(derivedKeyLength / hashLength);
        const r = derivedKeyLength - (l - 1) * hashLength;

        const derivedKey = new SerialBuffer(derivedKeyLength);
        for (let i = 1; i <= l; i++) {
            let u = new SerialBuffer(salt.length + 4);
            u.write(salt);
            u.writeUint32(i);

            u = CryptoUtils.computeHmacSha512(password, u);
            const t = u;
            for (let j = 1; j < iterations; j++) {
                u = CryptoUtils.computeHmacSha512(password, u);
                for (let k = 0; k < t.length; k++) {
                    t[k] ^= u[k];
                }
            }

            if (i < l) {
                derivedKey.write(t);
            } else {
                derivedKey.write(t.slice(0, r));
            }
        }
        return derivedKey;
    }

    /**
     * @param {Uint8Array} message
     * @param {Uint8Array} key
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @return {Promise.<Uint8Array>}
     * @deprecated
     */
    static async otpKdfLegacy(message, key, salt, iterations) {
        const worker = await CryptoWorker.getInstanceAsync();
        const derivedKey = await worker.kdfLegacy(key, salt, iterations, message.byteLength);
        return BufferUtils.xor(message, derivedKey);
    }

    /**
     * @param {Uint8Array} message
     * @param {Uint8Array} key
     * @param {Uint8Array} salt
     * @param {number} iterations
     * @return {Promise.<Uint8Array>}
     */
    static async otpKdf(message, key, salt, iterations) {
        const worker = await CryptoWorker.getInstanceAsync();
        const derivedKey = await worker.kdf(key, salt, iterations, message.byteLength);
        return BufferUtils.xor(message, derivedKey);
    }

}
CryptoUtils.SHA512_BLOCK_SIZE = 128;

Class.register(CryptoUtils);

class CRC8 {
    // Adapted from https://github.com/mode80/crc8js
    static _createTable() {
        // Create a lookup table byte array
        const table = []; // 256 max len byte array

        for (let i = 0; i < 256; ++i) {
            let curr = i;
            for (let j = 0; j < 8; ++j) {
                if ((curr & 0x80) !== 0) {
                    curr = ((curr << 1) ^ 0x97) % 256; // Polynomial C2 by Baicheva98
                } else {
                    curr = (curr << 1) % 256;
                }
            }
            table[i] = curr;
        }
        return table;
    }

    /**
     * @param {Uint8Array} buf
     * @return {number}
     */
    static compute(buf) {
        if (!CRC8._table) CRC8._table = CRC8._createTable();
        // Calculate the 8-bit checksum given an array of byte-sized numbers
        let c = 0;
        for (let i = 0; i < buf.length; i++) {
            c = CRC8._table[(c ^ buf[i]) % 256];
        }
        return c;
    }
}
CRC8._table = null;
Class.register(CRC8);

class CRC32 {
    static _createTable () {
        let b;
        const table = [];

        for (let j = 0; j < 256; ++j) {
            b = j;
            for (let k = 0; k < 8; ++k) {
                b = b & 1 ? CRC32._POLYNOMIAL ^ (b >>> 1) : b >>> 1;
            }
            table[j] = b >>> 0;
        }
        return table;
    }

    /**
     * @param {Uint8Array} buf
     * @return {number}
     */
    static compute(buf) {
        if (!CRC32._table) CRC32._table = CRC32._createTable();
        if (!CRC32._hex_chars) CRC32._hex_chars = '0123456789abcdef'.split('');

        const message = new Uint8Array(buf);
        const initialValue = -1;

        let crc = initialValue;
        let hex = '';

        for (let i = 0; i < message.length; ++i) {
            crc = CRC32._table[(crc ^ message[i]) & 0xFF] ^ (crc >>> 8);
        }
        crc ^= initialValue;

        hex += CRC32._hex_chars[(crc >> 28) & 0x0F] + CRC32._hex_chars[(crc >> 24) & 0x0F] +
            CRC32._hex_chars[(crc >> 20) & 0x0F] + CRC32._hex_chars[(crc >> 16) & 0x0F] +
            CRC32._hex_chars[(crc >> 12) & 0x0F] + CRC32._hex_chars[(crc >> 8) & 0x0F] +
            CRC32._hex_chars[(crc >> 4) & 0x0F] + CRC32._hex_chars[crc & 0x0F];

        return parseInt(hex, 16);
    }
}
CRC32._table = null;
CRC32._hex_chars = null;
CRC32._POLYNOMIAL = 0xEDB88320;
Class.register(CRC32);

;(function (globalObject) {
    'use strict';

    /*
     *      bignumber.js v7.0.1
     *      A JavaScript library for arbitrary-precision arithmetic.
     *      https://github.com/MikeMcl/bignumber.js
     *      Copyright (c) 2018 Michael Mclaughlin <M8ch88l@gmail.com>
     *      MIT Licensed.
     *
     *      BigNumber.prototype methods     |  BigNumber methods
     *                                      |
     *      absoluteValue            abs    |  clone
     *      comparedTo                      |  config               set
     *      decimalPlaces            dp     |      DECIMAL_PLACES
     *      dividedBy                div    |      ROUNDING_MODE
     *      dividedToIntegerBy       idiv   |      EXPONENTIAL_AT
     *      exponentiatedBy          pow    |      RANGE
     *      integerValue                    |      CRYPTO
     *      isEqualTo                eq     |      MODULO_MODE
     *      isFinite                        |      POW_PRECISION
     *      isGreaterThan            gt     |      FORMAT
     *      isGreaterThanOrEqualTo   gte    |      ALPHABET
     *      isInteger                       |  isBigNumber
     *      isLessThan               lt     |  maximum              max
     *      isLessThanOrEqualTo      lte    |  minimum              min
     *      isNaN                           |  random
     *      isNegative                      |
     *      isPositive                      |
     *      isZero                          |
     *      minus                           |
     *      modulo                   mod    |
     *      multipliedBy             times  |
     *      negated                         |
     *      plus                            |
     *      precision                sd     |
     *      shiftedBy                       |
     *      squareRoot               sqrt   |
     *      toExponential                   |
     *      toFixed                         |
     *      toFormat                        |
     *      toFraction                      |
     *      toJSON                          |
     *      toNumber                        |
     *      toPrecision                     |
     *      toString                        |
     *      valueOf                         |
     *
     */


    var BigNumber,
        isNumeric = /^-?(?:\d+(?:\.\d*)?|\.\d+)(?:e[+-]?\d+)?$/i,

        mathceil = Math.ceil,
        mathfloor = Math.floor,

        bignumberError = '[BigNumber Error] ',
        tooManyDigits = bignumberError + 'Number primitive has more than 15 significant digits: ',

        BASE = 1e14,
        LOG_BASE = 14,
        MAX_SAFE_INTEGER = 0x1fffffffffffff,         // 2^53 - 1
        // MAX_INT32 = 0x7fffffff,                   // 2^31 - 1
        POWS_TEN = [1, 10, 100, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9, 1e10, 1e11, 1e12, 1e13],
        SQRT_BASE = 1e7,

        // EDITABLE
        // The limit on the value of DECIMAL_PLACES, TO_EXP_NEG, TO_EXP_POS, MIN_EXP, MAX_EXP, and
        // the arguments to toExponential, toFixed, toFormat, and toPrecision.
        MAX = 1E9;                                   // 0 to MAX_INT32


    /*
     * Create and return a BigNumber constructor.
     */
    function clone(configObject) {
        var div, convertBase, parseNumeric,
            P = BigNumber.prototype = { constructor: BigNumber, toString: null, valueOf: null },
            ONE = new BigNumber(1),


            //----------------------------- EDITABLE CONFIG DEFAULTS -------------------------------


            // The default values below must be integers within the inclusive ranges stated.
            // The values can also be changed at run-time using BigNumber.set.

            // The maximum number of decimal places for operations involving division.
            DECIMAL_PLACES = 20,                     // 0 to MAX

            // The rounding mode used when rounding to the above decimal places, and when using
            // toExponential, toFixed, toFormat and toPrecision, and round (default value).
            // UP         0 Away from zero.
            // DOWN       1 Towards zero.
            // CEIL       2 Towards +Infinity.
            // FLOOR      3 Towards -Infinity.
            // HALF_UP    4 Towards nearest neighbour. If equidistant, up.
            // HALF_DOWN  5 Towards nearest neighbour. If equidistant, down.
            // HALF_EVEN  6 Towards nearest neighbour. If equidistant, towards even neighbour.
            // HALF_CEIL  7 Towards nearest neighbour. If equidistant, towards +Infinity.
            // HALF_FLOOR 8 Towards nearest neighbour. If equidistant, towards -Infinity.
            ROUNDING_MODE = 4,                       // 0 to 8

            // EXPONENTIAL_AT : [TO_EXP_NEG , TO_EXP_POS]

            // The exponent value at and beneath which toString returns exponential notation.
            // Number type: -7
            TO_EXP_NEG = -7,                         // 0 to -MAX

            // The exponent value at and above which toString returns exponential notation.
            // Number type: 21
            TO_EXP_POS = 21,                         // 0 to MAX

            // RANGE : [MIN_EXP, MAX_EXP]

            // The minimum exponent value, beneath which underflow to zero occurs.
            // Number type: -324  (5e-324)
            MIN_EXP = -1e7,                          // -1 to -MAX

            // The maximum exponent value, above which overflow to Infinity occurs.
            // Number type:  308  (1.7976931348623157e+308)
            // For MAX_EXP > 1e7, e.g. new BigNumber('1e100000000').plus(1) may be slow.
            MAX_EXP = 1e7,                           // 1 to MAX

            // Whether to use cryptographically-secure random number generation, if available.
            CRYPTO = false,                          // true or false

            // The modulo mode used when calculating the modulus: a mod n.
            // The quotient (q = a / n) is calculated according to the corresponding rounding mode.
            // The remainder (r) is calculated as: r = a - n * q.
            //
            // UP        0 The remainder is positive if the dividend is negative, else is negative.
            // DOWN      1 The remainder has the same sign as the dividend.
            //             This modulo mode is commonly known as 'truncated division' and is
            //             equivalent to (a % n) in JavaScript.
            // FLOOR     3 The remainder has the same sign as the divisor (Python %).
            // HALF_EVEN 6 This modulo mode implements the IEEE 754 remainder function.
            // EUCLID    9 Euclidian division. q = sign(n) * floor(a / abs(n)).
            //             The remainder is always positive.
            //
            // The truncated division, floored division, Euclidian division and IEEE 754 remainder
            // modes are commonly used for the modulus operation.
            // Although the other rounding modes can also be used, they may not give useful results.
            MODULO_MODE = 1,                         // 0 to 9

            // The maximum number of significant digits of the result of the exponentiatedBy operation.
            // If POW_PRECISION is 0, there will be unlimited significant digits.
            POW_PRECISION = 0,                    // 0 to MAX

            // The format specification used by the BigNumber.prototype.toFormat method.
            FORMAT = {
                decimalSeparator: '.',
                groupSeparator: ',',
                groupSize: 3,
                secondaryGroupSize: 0,
                fractionGroupSeparator: '\xA0',      // non-breaking space
                fractionGroupSize: 0
            },

            // The alphabet used for base conversion.
            // It must be at least 2 characters long, with no '.' or repeated character.
            // '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ$_'
            ALPHABET = '0123456789abcdefghijklmnopqrstuvwxyz';


        //------------------------------------------------------------------------------------------


        // CONSTRUCTOR


        /*
         * The BigNumber constructor and exported function.
         * Create and return a new instance of a BigNumber object.
         *
         * n {number|string|BigNumber} A numeric value.
         * [b] {number} The base of n. Integer, 2 to ALPHABET.length inclusive.
         */
        function BigNumber(n, b) {
            var alphabet, c, e, i, isNum, len, str,
                x = this;

            // Enable constructor usage without new.
            if (!(x instanceof BigNumber)) {

                // Don't throw on constructor call without new (#81).
                // '[BigNumber Error] Constructor call without new: {n}'
                //throw Error(bignumberError + ' Constructor call without new: ' + n);
                return new BigNumber(n, b);
            }

            if (b == null) {

                // Duplicate.
                if (n instanceof BigNumber) {
                    x.s = n.s;
                    x.e = n.e;
                    x.c = (n = n.c) ? n.slice() : n;
                    return;
                }

                isNum = typeof n == 'number';

                if (isNum && n * 0 == 0) {

                    // Use `1 / n` to handle minus zero also.
                    x.s = 1 / n < 0 ? (n = -n, -1) : 1;

                    // Faster path for integers.
                    if (n === ~~n) {
                        for (e = 0, i = n; i >= 10; i /= 10, e++);
                        x.e = e;
                        x.c = [n];
                        return;
                    }

                    str = n + '';
                } else {
                    if (!isNumeric.test(str = n + '')) return parseNumeric(x, str, isNum);
                    x.s = str.charCodeAt(0) == 45 ? (str = str.slice(1), -1) : 1;
                }

            } else {

                // '[BigNumber Error] Base {not a primitive number|not an integer|out of range}: {b}'
                intCheck(b, 2, ALPHABET.length, 'Base');
                str = n + '';

                // Allow exponential notation to be used with base 10 argument, while
                // also rounding to DECIMAL_PLACES as with other bases.
                if (b == 10) {
                    x = new BigNumber(n instanceof BigNumber ? n : str);
                    return round(x, DECIMAL_PLACES + x.e + 1, ROUNDING_MODE);
                }

                isNum = typeof n == 'number';

                if (isNum) {

                    // Avoid potential interpretation of Infinity and NaN as base 44+ values.
                    if (n * 0 != 0) return parseNumeric(x, str, isNum, b);

                    x.s = 1 / n < 0 ? (str = str.slice(1), -1) : 1;

                    // '[BigNumber Error] Number primitive has more than 15 significant digits: {n}'
                    if (BigNumber.DEBUG && str.replace(/^0\.0*|\./, '').length > 15) {
                        throw Error
                        (tooManyDigits + n);
                    }

                    // Prevent later check for length on converted number.
                    isNum = false;
                } else {
                    x.s = str.charCodeAt(0) === 45 ? (str = str.slice(1), -1) : 1;

                    // Allow e.g. hexadecimal 'FF' as well as 'ff'.
                    if (b > 10 && b < 37) str = str.toLowerCase();
                }

                alphabet = ALPHABET.slice(0, b);
                e = i = 0;

                // Check that str is a valid base b number.
                // Don't use RegExp so alphabet can contain special characters.
                for (len = str.length; i < len; i++) {
                    if (alphabet.indexOf(c = str.charAt(i)) < 0) {
                        if (c == '.') {

                            // If '.' is not the first character and it has not be found before.
                            if (i > e) {
                                e = len;
                                continue;
                            }
                        }

                        return parseNumeric(x, n + '', isNum, b);
                    }
                }

                str = convertBase(str, b, 10, x.s);
            }

            // Decimal point?
            if ((e = str.indexOf('.')) > -1) str = str.replace('.', '');

            // Exponential form?
            if ((i = str.search(/e/i)) > 0) {

                // Determine exponent.
                if (e < 0) e = i;
                e += +str.slice(i + 1);
                str = str.substring(0, i);
            } else if (e < 0) {

                // Integer.
                e = str.length;
            }

            // Determine leading zeros.
            for (i = 0; str.charCodeAt(i) === 48; i++);

            // Determine trailing zeros.
            for (len = str.length; str.charCodeAt(--len) === 48;);

            str = str.slice(i, ++len);

            if (str) {
                len -= i;

                // '[BigNumber Error] Number primitive has more than 15 significant digits: {n}'
                if (isNum && BigNumber.DEBUG &&
                    len > 15 && (n > MAX_SAFE_INTEGER || n !== mathfloor(n))) {
                    throw Error
                    (tooManyDigits + (x.s * n));
                }

                e = e - i - 1;

                // Overflow?
                if (e > MAX_EXP) {

                    // Infinity.
                    x.c = x.e = null;

                    // Underflow?
                } else if (e < MIN_EXP) {

                    // Zero.
                    x.c = [x.e = 0];
                } else {
                    x.e = e;
                    x.c = [];

                    // Transform base

                    // e is the base 10 exponent.
                    // i is where to slice str to get the first element of the coefficient array.
                    i = (e + 1) % LOG_BASE;
                    if (e < 0) i += LOG_BASE;

                    if (i < len) {
                        if (i) x.c.push(+str.slice(0, i));

                        for (len -= LOG_BASE; i < len;) {
                            x.c.push(+str.slice(i, i += LOG_BASE));
                        }

                        str = str.slice(i);
                        i = LOG_BASE - str.length;
                    } else {
                        i -= len;
                    }

                    for (; i--; str += '0');
                    x.c.push(+str);
                }
            } else {

                // Zero.
                x.c = [x.e = 0];
            }
        }


        // CONSTRUCTOR PROPERTIES


        BigNumber.clone = clone;

        BigNumber.ROUND_UP = 0;
        BigNumber.ROUND_DOWN = 1;
        BigNumber.ROUND_CEIL = 2;
        BigNumber.ROUND_FLOOR = 3;
        BigNumber.ROUND_HALF_UP = 4;
        BigNumber.ROUND_HALF_DOWN = 5;
        BigNumber.ROUND_HALF_EVEN = 6;
        BigNumber.ROUND_HALF_CEIL = 7;
        BigNumber.ROUND_HALF_FLOOR = 8;
        BigNumber.EUCLID = 9;


        /*
         * Configure infrequently-changing library-wide settings.
         *
         * Accept an object with the following optional properties (if the value of a property is
         * a number, it must be an integer within the inclusive range stated):
         *
         *   DECIMAL_PLACES   {number}           0 to MAX
         *   ROUNDING_MODE    {number}           0 to 8
         *   EXPONENTIAL_AT   {number|number[]}  -MAX to MAX  or  [-MAX to 0, 0 to MAX]
         *   RANGE            {number|number[]}  -MAX to MAX (not zero)  or  [-MAX to -1, 1 to MAX]
         *   CRYPTO           {boolean}          true or false
         *   MODULO_MODE      {number}           0 to 9
         *   POW_PRECISION       {number}           0 to MAX
         *   ALPHABET         {string}           A string of two or more unique characters, and not
         *                                       containing '.'. The empty string, null or undefined
         *                                       resets the alphabet to its default value.
         *   FORMAT           {object}           An object with some of the following properties:
         *      decimalSeparator       {string}
         *      groupSeparator         {string}
         *      groupSize              {number}
         *      secondaryGroupSize     {number}
         *      fractionGroupSeparator {string}
         *      fractionGroupSize      {number}
         *
         * (The values assigned to the above FORMAT object properties are not checked for validity.)
         *
         * E.g.
         * BigNumber.config({ DECIMAL_PLACES : 20, ROUNDING_MODE : 4 })
         *
         * Ignore properties/parameters set to null or undefined, except for ALPHABET.
         *
         * Return an object with the properties current values.
         */
        BigNumber.config = BigNumber.set = function (obj) {
            var p, v;

            if (obj != null) {

                if (typeof obj == 'object') {

                    // DECIMAL_PLACES {number} Integer, 0 to MAX inclusive.
                    // '[BigNumber Error] DECIMAL_PLACES {not a primitive number|not an integer|out of range}: {v}'
                    if (obj.hasOwnProperty(p = 'DECIMAL_PLACES')) {
                        v = obj[p];
                        intCheck(v, 0, MAX, p);
                        DECIMAL_PLACES = v;
                    }

                    // ROUNDING_MODE {number} Integer, 0 to 8 inclusive.
                    // '[BigNumber Error] ROUNDING_MODE {not a primitive number|not an integer|out of range}: {v}'
                    if (obj.hasOwnProperty(p = 'ROUNDING_MODE')) {
                        v = obj[p];
                        intCheck(v, 0, 8, p);
                        ROUNDING_MODE = v;
                    }

                    // EXPONENTIAL_AT {number|number[]}
                    // Integer, -MAX to MAX inclusive or
                    // [integer -MAX to 0 inclusive, 0 to MAX inclusive].
                    // '[BigNumber Error] EXPONENTIAL_AT {not a primitive number|not an integer|out of range}: {v}'
                    if (obj.hasOwnProperty(p = 'EXPONENTIAL_AT')) {
                        v = obj[p];
                        if (isArray(v)) {
                            intCheck(v[0], -MAX, 0, p);
                            intCheck(v[1], 0, MAX, p);
                            TO_EXP_NEG = v[0];
                            TO_EXP_POS = v[1];
                        } else {
                            intCheck(v, -MAX, MAX, p);
                            TO_EXP_NEG = -(TO_EXP_POS = v < 0 ? -v : v);
                        }
                    }

                    // RANGE {number|number[]} Non-zero integer, -MAX to MAX inclusive or
                    // [integer -MAX to -1 inclusive, integer 1 to MAX inclusive].
                    // '[BigNumber Error] RANGE {not a primitive number|not an integer|out of range|cannot be zero}: {v}'
                    if (obj.hasOwnProperty(p = 'RANGE')) {
                        v = obj[p];
                        if (isArray(v)) {
                            intCheck(v[0], -MAX, -1, p);
                            intCheck(v[1], 1, MAX, p);
                            MIN_EXP = v[0];
                            MAX_EXP = v[1];
                        } else {
                            intCheck(v, -MAX, MAX, p);
                            if (v) {
                                MIN_EXP = -(MAX_EXP = v < 0 ? -v : v);
                            } else {
                                throw Error
                                (bignumberError + p + ' cannot be zero: ' + v);
                            }
                        }
                    }

                    // CRYPTO {boolean} true or false.
                    // '[BigNumber Error] CRYPTO not true or false: {v}'
                    // '[BigNumber Error] crypto unavailable'
                    if (obj.hasOwnProperty(p = 'CRYPTO')) {
                        v = obj[p];
                        if (v === !!v) {
                            if (v) {
                                if (typeof crypto != 'undefined' && crypto &&
                                    (crypto.getRandomValues || crypto.randomBytes)) {
                                    CRYPTO = v;
                                } else {
                                    CRYPTO = !v;
                                    throw Error
                                    (bignumberError + 'crypto unavailable');
                                }
                            } else {
                                CRYPTO = v;
                            }
                        } else {
                            throw Error
                            (bignumberError + p + ' not true or false: ' + v);
                        }
                    }

                    // MODULO_MODE {number} Integer, 0 to 9 inclusive.
                    // '[BigNumber Error] MODULO_MODE {not a primitive number|not an integer|out of range}: {v}'
                    if (obj.hasOwnProperty(p = 'MODULO_MODE')) {
                        v = obj[p];
                        intCheck(v, 0, 9, p);
                        MODULO_MODE = v;
                    }

                    // POW_PRECISION {number} Integer, 0 to MAX inclusive.
                    // '[BigNumber Error] POW_PRECISION {not a primitive number|not an integer|out of range}: {v}'
                    if (obj.hasOwnProperty(p = 'POW_PRECISION')) {
                        v = obj[p];
                        intCheck(v, 0, MAX, p);
                        POW_PRECISION = v;
                    }

                    // FORMAT {object}
                    // '[BigNumber Error] FORMAT not an object: {v}'
                    if (obj.hasOwnProperty(p = 'FORMAT')) {
                        v = obj[p];
                        if (typeof v == 'object') FORMAT = v;
                        else throw Error
                        (bignumberError + p + ' not an object: ' + v);
                    }

                    // ALPHABET {string}
                    // '[BigNumber Error] ALPHABET invalid: {v}'
                    if (obj.hasOwnProperty(p = 'ALPHABET')) {
                        v = obj[p];

                        // Disallow if only one character, or contains '.' or a repeated character.
                        if (typeof v == 'string' && !/^.$|\.|(.).*\1/.test(v)) {
                            ALPHABET = v;
                        } else {
                            throw Error
                            (bignumberError + p + ' invalid: ' + v);
                        }
                    }

                } else {

                    // '[BigNumber Error] Object expected: {v}'
                    throw Error
                    (bignumberError + 'Object expected: ' + obj);
                }
            }

            return {
                DECIMAL_PLACES: DECIMAL_PLACES,
                ROUNDING_MODE: ROUNDING_MODE,
                EXPONENTIAL_AT: [TO_EXP_NEG, TO_EXP_POS],
                RANGE: [MIN_EXP, MAX_EXP],
                CRYPTO: CRYPTO,
                MODULO_MODE: MODULO_MODE,
                POW_PRECISION: POW_PRECISION,
                FORMAT: FORMAT,
                ALPHABET: ALPHABET
            };
        };


        /*
         * Return true if v is a BigNumber instance, otherwise return false.
         *
         * v {any}
         */
        BigNumber.isBigNumber = function (v) {
            return v instanceof BigNumber || v && v._isBigNumber === true || false;
        };


        /*
         * Return a new BigNumber whose value is the maximum of the arguments.
         *
         * arguments {number|string|BigNumber}
         */
        BigNumber.maximum = BigNumber.max = function () {
            return maxOrMin(arguments, P.lt);
        };


        /*
         * Return a new BigNumber whose value is the minimum of the arguments.
         *
         * arguments {number|string|BigNumber}
         */
        BigNumber.minimum = BigNumber.min = function () {
            return maxOrMin(arguments, P.gt);
        };


        /*
         * Return a new BigNumber with a random value equal to or greater than 0 and less than 1,
         * and with dp, or DECIMAL_PLACES if dp is omitted, decimal places (or less if trailing
         * zeros are produced).
         *
         * [dp] {number} Decimal places. Integer, 0 to MAX inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {dp}'
         * '[BigNumber Error] crypto unavailable'
         */
        BigNumber.random = (function () {
            var pow2_53 = 0x20000000000000;

            // Return a 53 bit integer n, where 0 <= n < 9007199254740992.
            // Check if Math.random() produces more than 32 bits of randomness.
            // If it does, assume at least 53 bits are produced, otherwise assume at least 30 bits.
            // 0x40000000 is 2^30, 0x800000 is 2^23, 0x1fffff is 2^21 - 1.
            var random53bitInt = (Math.random() * pow2_53) & 0x1fffff
                ? function () { return mathfloor(Math.random() * pow2_53); }
                : function () { return ((Math.random() * 0x40000000 | 0) * 0x800000) +
                    (Math.random() * 0x800000 | 0); };

            return function (dp) {
                var a, b, e, k, v,
                    i = 0,
                    c = [],
                    rand = new BigNumber(ONE);

                if (dp == null) dp = DECIMAL_PLACES;
                else intCheck(dp, 0, MAX);

                k = mathceil(dp / LOG_BASE);

                if (CRYPTO) {

                    // Browsers supporting crypto.getRandomValues.
                    if (crypto.getRandomValues) {

                        a = crypto.getRandomValues(new Uint32Array(k *= 2));

                        for (; i < k;) {

                            // 53 bits:
                            // ((Math.pow(2, 32) - 1) * Math.pow(2, 21)).toString(2)
                            // 11111 11111111 11111111 11111111 11100000 00000000 00000000
                            // ((Math.pow(2, 32) - 1) >>> 11).toString(2)
                            //                                     11111 11111111 11111111
                            // 0x20000 is 2^21.
                            v = a[i] * 0x20000 + (a[i + 1] >>> 11);

                            // Rejection sampling:
                            // 0 <= v < 9007199254740992
                            // Probability that v >= 9e15, is
                            // 7199254740992 / 9007199254740992 ~= 0.0008, i.e. 1 in 1251
                            if (v >= 9e15) {
                                b = crypto.getRandomValues(new Uint32Array(2));
                                a[i] = b[0];
                                a[i + 1] = b[1];
                            } else {

                                // 0 <= v <= 8999999999999999
                                // 0 <= (v % 1e14) <= 99999999999999
                                c.push(v % 1e14);
                                i += 2;
                            }
                        }
                        i = k / 2;

                        // Node.js supporting crypto.randomBytes.
                    } else if (crypto.randomBytes) {

                        // buffer
                        a = crypto.randomBytes(k *= 7);

                        for (; i < k;) {

                            // 0x1000000000000 is 2^48, 0x10000000000 is 2^40
                            // 0x100000000 is 2^32, 0x1000000 is 2^24
                            // 11111 11111111 11111111 11111111 11111111 11111111 11111111
                            // 0 <= v < 9007199254740992
                            v = ((a[i] & 31) * 0x1000000000000) + (a[i + 1] * 0x10000000000) +
                                (a[i + 2] * 0x100000000) + (a[i + 3] * 0x1000000) +
                                (a[i + 4] << 16) + (a[i + 5] << 8) + a[i + 6];

                            if (v >= 9e15) {
                                crypto.randomBytes(7).copy(a, i);
                            } else {

                                // 0 <= (v % 1e14) <= 99999999999999
                                c.push(v % 1e14);
                                i += 7;
                            }
                        }
                        i = k / 7;
                    } else {
                        CRYPTO = false;
                        throw Error
                        (bignumberError + 'crypto unavailable');
                    }
                }

                // Use Math.random.
                if (!CRYPTO) {

                    for (; i < k;) {
                        v = random53bitInt();
                        if (v < 9e15) c[i++] = v % 1e14;
                    }
                }

                k = c[--i];
                dp %= LOG_BASE;

                // Convert trailing digits to zeros according to dp.
                if (k && dp) {
                    v = POWS_TEN[LOG_BASE - dp];
                    c[i] = mathfloor(k / v) * v;
                }

                // Remove trailing elements which are zero.
                for (; c[i] === 0; c.pop(), i--);

                // Zero?
                if (i < 0) {
                    c = [e = 0];
                } else {

                    // Remove leading elements which are zero and adjust exponent accordingly.
                    for (e = -1 ; c[0] === 0; c.splice(0, 1), e -= LOG_BASE);

                    // Count the digits of the first element of c to determine leading zeros, and...
                    for (i = 1, v = c[0]; v >= 10; v /= 10, i++);

                    // adjust the exponent accordingly.
                    if (i < LOG_BASE) e -= LOG_BASE - i;
                }

                rand.e = e;
                rand.c = c;
                return rand;
            };
        })();


        // PRIVATE FUNCTIONS


        // Called by BigNumber and BigNumber.prototype.toString.
        convertBase = (function () {
            var decimal = '0123456789';

            /*
             * Convert string of baseIn to an array of numbers of baseOut.
             * Eg. toBaseOut('255', 10, 16) returns [15, 15].
             * Eg. toBaseOut('ff', 16, 10) returns [2, 5, 5].
             */
            function toBaseOut(str, baseIn, baseOut, alphabet) {
                var j,
                    arr = [0],
                    arrL,
                    i = 0,
                    len = str.length;

                for (; i < len;) {
                    for (arrL = arr.length; arrL--; arr[arrL] *= baseIn);

                    arr[0] += alphabet.indexOf(str.charAt(i++));

                    for (j = 0; j < arr.length; j++) {

                        if (arr[j] > baseOut - 1) {
                            if (arr[j + 1] == null) arr[j + 1] = 0;
                            arr[j + 1] += arr[j] / baseOut | 0;
                            arr[j] %= baseOut;
                        }
                    }
                }

                return arr.reverse();
            }

            // Convert a numeric string of baseIn to a numeric string of baseOut.
            // If the caller is toString, we are converting from base 10 to baseOut.
            // If the caller is BigNumber, we are converting from baseIn to base 10.
            return function (str, baseIn, baseOut, sign, callerIsToString) {
                var alphabet, d, e, k, r, x, xc, y,
                    i = str.indexOf('.'),
                    dp = DECIMAL_PLACES,
                    rm = ROUNDING_MODE;

                // Non-integer.
                if (i >= 0) {
                    k = POW_PRECISION;

                    // Unlimited precision.
                    POW_PRECISION = 0;
                    str = str.replace('.', '');
                    y = new BigNumber(baseIn);
                    x = y.pow(str.length - i);
                    POW_PRECISION = k;

                    // Convert str as if an integer, then restore the fraction part by dividing the
                    // result by its base raised to a power.

                    y.c = toBaseOut(toFixedPoint(coeffToString(x.c), x.e, '0'),
                        10, baseOut, decimal);
                    y.e = y.c.length;
                }

                // Convert the number as integer.

                xc = toBaseOut(str, baseIn, baseOut, callerIsToString
                    ? (alphabet = ALPHABET, decimal)
                    : (alphabet = decimal, ALPHABET));

                // xc now represents str as an integer and converted to baseOut. e is the exponent.
                e = k = xc.length;

                // Remove trailing zeros.
                for (; xc[--k] == 0; xc.pop());

                // Zero?
                if (!xc[0]) return alphabet.charAt(0);

                // Does str represent an integer? If so, no need for the division.
                if (i < 0) {
                    --e;
                } else {
                    x.c = xc;
                    x.e = e;

                    // The sign is needed for correct rounding.
                    x.s = sign;
                    x = div(x, y, dp, rm, baseOut);
                    xc = x.c;
                    r = x.r;
                    e = x.e;
                }

                // xc now represents str converted to baseOut.

                // THe index of the rounding digit.
                d = e + dp + 1;

                // The rounding digit: the digit to the right of the digit that may be rounded up.
                i = xc[d];

                // Look at the rounding digits and mode to determine whether to round up.

                k = baseOut / 2;
                r = r || d < 0 || xc[d + 1] != null;

                r = rm < 4 ? (i != null || r) && (rm == 0 || rm == (x.s < 0 ? 3 : 2))
                    : i > k || i == k &&(rm == 4 || r || rm == 6 && xc[d - 1] & 1 ||
                    rm == (x.s < 0 ? 8 : 7));

                // If the index of the rounding digit is not greater than zero, or xc represents
                // zero, then the result of the base conversion is zero or, if rounding up, a value
                // such as 0.00001.
                if (d < 1 || !xc[0]) {

                    // 1^-dp or 0
                    str = r ? toFixedPoint(alphabet.charAt(1), -dp, alphabet.charAt(0))
                        : alphabet.charAt(0);
                } else {

                    // Truncate xc to the required number of decimal places.
                    xc.length = d;

                    // Round up?
                    if (r) {

                        // Rounding up may mean the previous digit has to be rounded up and so on.
                        for (--baseOut; ++xc[--d] > baseOut;) {
                            xc[d] = 0;

                            if (!d) {
                                ++e;
                                xc = [1].concat(xc);
                            }
                        }
                    }

                    // Determine trailing zeros.
                    for (k = xc.length; !xc[--k];);

                    // E.g. [4, 11, 15] becomes 4bf.
                    for (i = 0, str = ''; i <= k; str += alphabet.charAt(xc[i++]));

                    // Add leading zeros, decimal point and trailing zeros as required.
                    str = toFixedPoint(str, e, alphabet.charAt(0));
                }

                // The caller will add the sign.
                return str;
            };
        })();


        // Perform division in the specified base. Called by div and convertBase.
        div = (function () {

            // Assume non-zero x and k.
            function multiply(x, k, base) {
                var m, temp, xlo, xhi,
                    carry = 0,
                    i = x.length,
                    klo = k % SQRT_BASE,
                    khi = k / SQRT_BASE | 0;

                for (x = x.slice(); i--;) {
                    xlo = x[i] % SQRT_BASE;
                    xhi = x[i] / SQRT_BASE | 0;
                    m = khi * xlo + xhi * klo;
                    temp = klo * xlo + ((m % SQRT_BASE) * SQRT_BASE) + carry;
                    carry = (temp / base | 0) + (m / SQRT_BASE | 0) + khi * xhi;
                    x[i] = temp % base;
                }

                if (carry) x = [carry].concat(x);

                return x;
            }

            function compare(a, b, aL, bL) {
                var i, cmp;

                if (aL != bL) {
                    cmp = aL > bL ? 1 : -1;
                } else {

                    for (i = cmp = 0; i < aL; i++) {

                        if (a[i] != b[i]) {
                            cmp = a[i] > b[i] ? 1 : -1;
                            break;
                        }
                    }
                }

                return cmp;
            }

            function subtract(a, b, aL, base) {
                var i = 0;

                // Subtract b from a.
                for (; aL--;) {
                    a[aL] -= i;
                    i = a[aL] < b[aL] ? 1 : 0;
                    a[aL] = i * base + a[aL] - b[aL];
                }

                // Remove leading zeros.
                for (; !a[0] && a.length > 1; a.splice(0, 1));
            }

            // x: dividend, y: divisor.
            return function (x, y, dp, rm, base) {
                var cmp, e, i, more, n, prod, prodL, q, qc, rem, remL, rem0, xi, xL, yc0,
                    yL, yz,
                    s = x.s == y.s ? 1 : -1,
                    xc = x.c,
                    yc = y.c;

                // Either NaN, Infinity or 0?
                if (!xc || !xc[0] || !yc || !yc[0]) {

                    return new BigNumber(

                        // Return NaN if either NaN, or both Infinity or 0.
                        !x.s || !y.s || (xc ? yc && xc[0] == yc[0] : !yc) ? NaN :

                            // Return 0 if x is 0 or y is Infinity, or return Infinity as y is 0.
                            xc && xc[0] == 0 || !yc ? s * 0 : s / 0
                    );
                }

                q = new BigNumber(s);
                qc = q.c = [];
                e = x.e - y.e;
                s = dp + e + 1;

                if (!base) {
                    base = BASE;
                    e = bitFloor(x.e / LOG_BASE) - bitFloor(y.e / LOG_BASE);
                    s = s / LOG_BASE | 0;
                }

                // Result exponent may be one less then the current value of e.
                // The coefficients of the BigNumbers from convertBase may have trailing zeros.
                for (i = 0; yc[i] == (xc[i] || 0); i++);

                if (yc[i] > (xc[i] || 0)) e--;

                if (s < 0) {
                    qc.push(1);
                    more = true;
                } else {
                    xL = xc.length;
                    yL = yc.length;
                    i = 0;
                    s += 2;

                    // Normalise xc and yc so highest order digit of yc is >= base / 2.

                    n = mathfloor(base / (yc[0] + 1));

                    // Not necessary, but to handle odd bases where yc[0] == (base / 2) - 1.
                    // if (n > 1 || n++ == 1 && yc[0] < base / 2) {
                    if (n > 1) {
                        yc = multiply(yc, n, base);
                        xc = multiply(xc, n, base);
                        yL = yc.length;
                        xL = xc.length;
                    }

                    xi = yL;
                    rem = xc.slice(0, yL);
                    remL = rem.length;

                    // Add zeros to make remainder as long as divisor.
                    for (; remL < yL; rem[remL++] = 0);
                    yz = yc.slice();
                    yz = [0].concat(yz);
                    yc0 = yc[0];
                    if (yc[1] >= base / 2) yc0++;
                    // Not necessary, but to prevent trial digit n > base, when using base 3.
                    // else if (base == 3 && yc0 == 1) yc0 = 1 + 1e-15;

                    do {
                        n = 0;

                        // Compare divisor and remainder.
                        cmp = compare(yc, rem, yL, remL);

                        // If divisor < remainder.
                        if (cmp < 0) {

                            // Calculate trial digit, n.

                            rem0 = rem[0];
                            if (yL != remL) rem0 = rem0 * base + (rem[1] || 0);

                            // n is how many times the divisor goes into the current remainder.
                            n = mathfloor(rem0 / yc0);

                            //  Algorithm:
                            //  product = divisor multiplied by trial digit (n).
                            //  Compare product and remainder.
                            //  If product is greater than remainder:
                            //    Subtract divisor from product, decrement trial digit.
                            //  Subtract product from remainder.
                            //  If product was less than remainder at the last compare:
                            //    Compare new remainder and divisor.
                            //    If remainder is greater than divisor:
                            //      Subtract divisor from remainder, increment trial digit.

                            if (n > 1) {

                                // n may be > base only when base is 3.
                                if (n >= base) n = base - 1;

                                // product = divisor * trial digit.
                                prod = multiply(yc, n, base);
                                prodL = prod.length;
                                remL = rem.length;

                                // Compare product and remainder.
                                // If product > remainder then trial digit n too high.
                                // n is 1 too high about 5% of the time, and is not known to have
                                // ever been more than 1 too high.
                                while (compare(prod, rem, prodL, remL) == 1) {
                                    n--;

                                    // Subtract divisor from product.
                                    subtract(prod, yL < prodL ? yz : yc, prodL, base);
                                    prodL = prod.length;
                                    cmp = 1;
                                }
                            } else {

                                // n is 0 or 1, cmp is -1.
                                // If n is 0, there is no need to compare yc and rem again below,
                                // so change cmp to 1 to avoid it.
                                // If n is 1, leave cmp as -1, so yc and rem are compared again.
                                if (n == 0) {

                                    // divisor < remainder, so n must be at least 1.
                                    cmp = n = 1;
                                }

                                // product = divisor
                                prod = yc.slice();
                                prodL = prod.length;
                            }

                            if (prodL < remL) prod = [0].concat(prod);

                            // Subtract product from remainder.
                            subtract(rem, prod, remL, base);
                            remL = rem.length;

                            // If product was < remainder.
                            if (cmp == -1) {

                                // Compare divisor and new remainder.
                                // If divisor < new remainder, subtract divisor from remainder.
                                // Trial digit n too low.
                                // n is 1 too low about 5% of the time, and very rarely 2 too low.
                                while (compare(yc, rem, yL, remL) < 1) {
                                    n++;

                                    // Subtract divisor from remainder.
                                    subtract(rem, yL < remL ? yz : yc, remL, base);
                                    remL = rem.length;
                                }
                            }
                        } else if (cmp === 0) {
                            n++;
                            rem = [0];
                        } // else cmp === 1 and n will be 0

                        // Add the next digit, n, to the result array.
                        qc[i++] = n;

                        // Update the remainder.
                        if (rem[0]) {
                            rem[remL++] = xc[xi] || 0;
                        } else {
                            rem = [xc[xi]];
                            remL = 1;
                        }
                    } while ((xi++ < xL || rem[0] != null) && s--);

                    more = rem[0] != null;

                    // Leading zero?
                    if (!qc[0]) qc.splice(0, 1);
                }

                if (base == BASE) {

                    // To calculate q.e, first get the number of digits of qc[0].
                    for (i = 1, s = qc[0]; s >= 10; s /= 10, i++);

                    round(q, dp + (q.e = i + e * LOG_BASE - 1) + 1, rm, more);

                    // Caller is convertBase.
                } else {
                    q.e = e;
                    q.r = +more;
                }

                return q;
            };
        })();


        /*
         * Return a string representing the value of BigNumber n in fixed-point or exponential
         * notation rounded to the specified decimal places or significant digits.
         *
         * n: a BigNumber.
         * i: the index of the last digit required (i.e. the digit that may be rounded up).
         * rm: the rounding mode.
         * id: 1 (toExponential) or 2 (toPrecision).
         */
        function format(n, i, rm, id) {
            var c0, e, ne, len, str;

            if (rm == null) rm = ROUNDING_MODE;
            else intCheck(rm, 0, 8);

            if (!n.c) return n.toString();

            c0 = n.c[0];
            ne = n.e;

            if (i == null) {
                str = coeffToString(n.c);
                str = id == 1 || id == 2 && ne <= TO_EXP_NEG
                    ? toExponential(str, ne)
                    : toFixedPoint(str, ne, '0');
            } else {
                n = round(new BigNumber(n), i, rm);

                // n.e may have changed if the value was rounded up.
                e = n.e;

                str = coeffToString(n.c);
                len = str.length;

                // toPrecision returns exponential notation if the number of significant digits
                // specified is less than the number of digits necessary to represent the integer
                // part of the value in fixed-point notation.

                // Exponential notation.
                if (id == 1 || id == 2 && (i <= e || e <= TO_EXP_NEG)) {

                    // Append zeros?
                    for (; len < i; str += '0', len++);
                    str = toExponential(str, e);

                    // Fixed-point notation.
                } else {
                    i -= ne;
                    str = toFixedPoint(str, e, '0');

                    // Append zeros?
                    if (e + 1 > len) {
                        if (--i > 0) for (str += '.'; i--; str += '0');
                    } else {
                        i += e - len;
                        if (i > 0) {
                            if (e + 1 == len) str += '.';
                            for (; i--; str += '0');
                        }
                    }
                }
            }

            return n.s < 0 && c0 ? '-' + str : str;
        }


        // Handle BigNumber.max and BigNumber.min.
        function maxOrMin(args, method) {
            var m, n,
                i = 0;

            if (isArray(args[0])) args = args[0];
            m = new BigNumber(args[0]);

            for (; ++i < args.length;) {
                n = new BigNumber(args[i]);

                // If any number is NaN, return NaN.
                if (!n.s) {
                    m = n;
                    break;
                } else if (method.call(m, n)) {
                    m = n;
                }
            }

            return m;
        }


        /*
         * Strip trailing zeros, calculate base 10 exponent and check against MIN_EXP and MAX_EXP.
         * Called by minus, plus and times.
         */
        function normalise(n, c, e) {
            var i = 1,
                j = c.length;

            // Remove trailing zeros.
            for (; !c[--j]; c.pop());

            // Calculate the base 10 exponent. First get the number of digits of c[0].
            for (j = c[0]; j >= 10; j /= 10, i++);

            // Overflow?
            if ((e = i + e * LOG_BASE - 1) > MAX_EXP) {

                // Infinity.
                n.c = n.e = null;

                // Underflow?
            } else if (e < MIN_EXP) {

                // Zero.
                n.c = [n.e = 0];
            } else {
                n.e = e;
                n.c = c;
            }

            return n;
        }


        // Handle values that fail the validity test in BigNumber.
        parseNumeric = (function () {
            var basePrefix = /^(-?)0([xbo])(?=\w[\w.]*$)/i,
                dotAfter = /^([^.]+)\.$/,
                dotBefore = /^\.([^.]+)$/,
                isInfinityOrNaN = /^-?(Infinity|NaN)$/,
                whitespaceOrPlus = /^\s*\+(?=[\w.])|^\s+|\s+$/g;

            return function (x, str, isNum, b) {
                var base,
                    s = isNum ? str : str.replace(whitespaceOrPlus, '');

                // No exception on Infinity or NaN.
                if (isInfinityOrNaN.test(s)) {
                    x.s = isNaN(s) ? null : s < 0 ? -1 : 1;
                    x.c = x.e = null;
                } else {
                    if (!isNum) {

                        // basePrefix = /^(-?)0([xbo])(?=\w[\w.]*$)/i
                        s = s.replace(basePrefix, function (m, p1, p2) {
                            base = (p2 = p2.toLowerCase()) == 'x' ? 16 : p2 == 'b' ? 2 : 8;
                            return !b || b == base ? p1 : m;
                        });

                        if (b) {
                            base = b;

                            // E.g. '1.' to '1', '.1' to '0.1'
                            s = s.replace(dotAfter, '$1').replace(dotBefore, '0.$1');
                        }

                        if (str != s) return new BigNumber(s, base);
                    }

                    // '[BigNumber Error] Not a number: {n}'
                    // '[BigNumber Error] Not a base {b} number: {n}'
                    if (BigNumber.DEBUG) {
                        throw Error
                        (bignumberError + 'Not a' + (b ? ' base ' + b : '') + ' number: ' + str);
                    }

                    // NaN
                    x.c = x.e = x.s = null;
                }
            }
        })();


        /*
         * Round x to sd significant digits using rounding mode rm. Check for over/under-flow.
         * If r is truthy, it is known that there are more digits after the rounding digit.
         */
        function round(x, sd, rm, r) {
            var d, i, j, k, n, ni, rd,
                xc = x.c,
                pows10 = POWS_TEN;

            // if x is not Infinity or NaN...
            if (xc) {

                // rd is the rounding digit, i.e. the digit after the digit that may be rounded up.
                // n is a base 1e14 number, the value of the element of array x.c containing rd.
                // ni is the index of n within x.c.
                // d is the number of digits of n.
                // i is the index of rd within n including leading zeros.
                // j is the actual index of rd within n (if < 0, rd is a leading zero).
                out: {

                    // Get the number of digits of the first element of xc.
                    for (d = 1, k = xc[0]; k >= 10; k /= 10, d++);
                    i = sd - d;

                    // If the rounding digit is in the first element of xc...
                    if (i < 0) {
                        i += LOG_BASE;
                        j = sd;
                        n = xc[ni = 0];

                        // Get the rounding digit at index j of n.
                        rd = n / pows10[d - j - 1] % 10 | 0;
                    } else {
                        ni = mathceil((i + 1) / LOG_BASE);

                        if (ni >= xc.length) {

                            if (r) {

                                // Needed by sqrt.
                                for (; xc.length <= ni; xc.push(0));
                                n = rd = 0;
                                d = 1;
                                i %= LOG_BASE;
                                j = i - LOG_BASE + 1;
                            } else {
                                break out;
                            }
                        } else {
                            n = k = xc[ni];

                            // Get the number of digits of n.
                            for (d = 1; k >= 10; k /= 10, d++);

                            // Get the index of rd within n.
                            i %= LOG_BASE;

                            // Get the index of rd within n, adjusted for leading zeros.
                            // The number of leading zeros of n is given by LOG_BASE - d.
                            j = i - LOG_BASE + d;

                            // Get the rounding digit at index j of n.
                            rd = j < 0 ? 0 : n / pows10[d - j - 1] % 10 | 0;
                        }
                    }

                    r = r || sd < 0 ||

                        // Are there any non-zero digits after the rounding digit?
                        // The expression  n % pows10[d - j - 1]  returns all digits of n to the right
                        // of the digit at j, e.g. if n is 908714 and j is 2, the expression gives 714.
                        xc[ni + 1] != null || (j < 0 ? n : n % pows10[d - j - 1]);

                    r = rm < 4
                        ? (rd || r) && (rm == 0 || rm == (x.s < 0 ? 3 : 2))
                        : rd > 5 || rd == 5 && (rm == 4 || r || rm == 6 &&

                        // Check whether the digit to the left of the rounding digit is odd.
                        ((i > 0 ? j > 0 ? n / pows10[d - j] : 0 : xc[ni - 1]) % 10) & 1 ||
                        rm == (x.s < 0 ? 8 : 7));

                    if (sd < 1 || !xc[0]) {
                        xc.length = 0;

                        if (r) {

                            // Convert sd to decimal places.
                            sd -= x.e + 1;

                            // 1, 0.1, 0.01, 0.001, 0.0001 etc.
                            xc[0] = pows10[(LOG_BASE - sd % LOG_BASE) % LOG_BASE];
                            x.e = -sd || 0;
                        } else {

                            // Zero.
                            xc[0] = x.e = 0;
                        }

                        return x;
                    }

                    // Remove excess digits.
                    if (i == 0) {
                        xc.length = ni;
                        k = 1;
                        ni--;
                    } else {
                        xc.length = ni + 1;
                        k = pows10[LOG_BASE - i];

                        // E.g. 56700 becomes 56000 if 7 is the rounding digit.
                        // j > 0 means i > number of leading zeros of n.
                        xc[ni] = j > 0 ? mathfloor(n / pows10[d - j] % pows10[j]) * k : 0;
                    }

                    // Round up?
                    if (r) {

                        for (; ;) {

                            // If the digit to be rounded up is in the first element of xc...
                            if (ni == 0) {

                                // i will be the length of xc[0] before k is added.
                                for (i = 1, j = xc[0]; j >= 10; j /= 10, i++);
                                j = xc[0] += k;
                                for (k = 1; j >= 10; j /= 10, k++);

                                // if i != k the length has increased.
                                if (i != k) {
                                    x.e++;
                                    if (xc[0] == BASE) xc[0] = 1;
                                }

                                break;
                            } else {
                                xc[ni] += k;
                                if (xc[ni] != BASE) break;
                                xc[ni--] = 0;
                                k = 1;
                            }
                        }
                    }

                    // Remove trailing zeros.
                    for (i = xc.length; xc[--i] === 0; xc.pop());
                }

                // Overflow? Infinity.
                if (x.e > MAX_EXP) {
                    x.c = x.e = null;

                    // Underflow? Zero.
                } else if (x.e < MIN_EXP) {
                    x.c = [x.e = 0];
                }
            }

            return x;
        }


        // PROTOTYPE/INSTANCE METHODS


        /*
         * Return a new BigNumber whose value is the absolute value of this BigNumber.
         */
        P.absoluteValue = P.abs = function () {
            var x = new BigNumber(this);
            if (x.s < 0) x.s = 1;
            return x;
        };


        /*
         * Return
         *   1 if the value of this BigNumber is greater than the value of BigNumber(y, b),
         *   -1 if the value of this BigNumber is less than the value of BigNumber(y, b),
         *   0 if they have the same value,
         *   or null if the value of either is NaN.
         */
        P.comparedTo = function (y, b) {
            return compare(this, new BigNumber(y, b));
        };


        /*
         * If dp is undefined or null or true or false, return the number of decimal places of the
         * value of this BigNumber, or null if the value of this BigNumber is Infinity or NaN.
         *
         * Otherwise, if dp is a number, return a new BigNumber whose value is the value of this
         * BigNumber rounded to a maximum of dp decimal places using rounding mode rm, or
         * ROUNDING_MODE if rm is omitted.
         *
         * [dp] {number} Decimal places: integer, 0 to MAX inclusive.
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {dp|rm}'
         */
        P.decimalPlaces = P.dp = function (dp, rm) {
            var c, n, v,
                x = this;

            if (dp != null) {
                intCheck(dp, 0, MAX);
                if (rm == null) rm = ROUNDING_MODE;
                else intCheck(rm, 0, 8);

                return round(new BigNumber(x), dp + x.e + 1, rm);
            }

            if (!(c = x.c)) return null;
            n = ((v = c.length - 1) - bitFloor(this.e / LOG_BASE)) * LOG_BASE;

            // Subtract the number of trailing zeros of the last number.
            if (v = c[v]) for (; v % 10 == 0; v /= 10, n--);
            if (n < 0) n = 0;

            return n;
        };


        /*
         *  n / 0 = I
         *  n / N = N
         *  n / I = 0
         *  0 / n = 0
         *  0 / 0 = N
         *  0 / N = N
         *  0 / I = 0
         *  N / n = N
         *  N / 0 = N
         *  N / N = N
         *  N / I = N
         *  I / n = I
         *  I / 0 = I
         *  I / N = N
         *  I / I = N
         *
         * Return a new BigNumber whose value is the value of this BigNumber divided by the value of
         * BigNumber(y, b), rounded according to DECIMAL_PLACES and ROUNDING_MODE.
         */
        P.dividedBy = P.div = function (y, b) {
            return div(this, new BigNumber(y, b), DECIMAL_PLACES, ROUNDING_MODE);
        };


        /*
         * Return a new BigNumber whose value is the integer part of dividing the value of this
         * BigNumber by the value of BigNumber(y, b).
         */
        P.dividedToIntegerBy = P.idiv = function (y, b) {
            return div(this, new BigNumber(y, b), 0, 1);
        };


        /*
         * Return a BigNumber whose value is the value of this BigNumber exponentiated by n.
         *
         * If m is present, return the result modulo m.
         * If n is negative round according to DECIMAL_PLACES and ROUNDING_MODE.
         * If POW_PRECISION is non-zero and m is not present, round to POW_PRECISION using ROUNDING_MODE.
         *
         * The modular power operation works efficiently when x, n, and m are integers, otherwise it
         * is equivalent to calculating x.exponentiatedBy(n).modulo(m) with a POW_PRECISION of 0.
         *
         * n {number|string|BigNumber} The exponent. An integer.
         * [m] {number|string|BigNumber} The modulus.
         *
         * '[BigNumber Error] Exponent not an integer: {n}'
         */
        P.exponentiatedBy = P.pow = function (n, m) {
            var half, isModExp, k, more, nIsBig, nIsNeg, nIsOdd, y,
                x = this;

            n = new BigNumber(n);

            // Allow NaN and Infinity, but not other non-integers.
            if (n.c && !n.isInteger()) {
                throw Error
                (bignumberError + 'Exponent not an integer: ' + n);
            }

            if (m != null) m = new BigNumber(m);

            // Exponent of MAX_SAFE_INTEGER is 15.
            nIsBig = n.e > 14;

            // If x is NaN, Infinity, 0 or 1, or n is Infinity, NaN or 0.
            if (!x.c || !x.c[0] || x.c[0] == 1 && !x.e && x.c.length == 1 || !n.c || !n.c[0]) {

                // The sign of the result of pow when x is negative depends on the evenness of n.
                // If +n overflows to Infinity, the evenness of n would be not be known.
                y = new BigNumber(Math.pow(+x.valueOf(), nIsBig ? 2 - isOdd(n) : +n));
                return m ? y.mod(m) : y;
            }

            nIsNeg = n.s < 0;

            if (m) {

                // x % m returns NaN if abs(m) is zero, or m is NaN.
                if (m.c ? !m.c[0] : !m.s) return new BigNumber(NaN);

                isModExp = !nIsNeg && x.isInteger() && m.isInteger();

                if (isModExp) x = x.mod(m);

                // Overflow to Infinity: >=2**1e10 or >=1.0000024**1e15.
                // Underflow to 0: <=0.79**1e10 or <=0.9999975**1e15.
            } else if (n.e > 9 && (x.e > 0 || x.e < -1 || (x.e == 0
                // [1, 240000000]
                ? x.c[0] > 1 || nIsBig && x.c[1] >= 24e7
                // [80000000000000]  [99999750000000]
                : x.c[0] < 8e13 || nIsBig && x.c[0] <= 9999975e7))) {

                // If x is negative and n is odd, k = -0, else k = 0.
                k = x.s < 0 && isOdd(n) ? -0 : 0;

                // If x >= 1, k = Infinity.
                if (x.e > -1) k = 1 / k;

                // If n is negative return 0, else return Infinity.
                return new BigNumber(nIsNeg ? 1 / k : k);

            } else if (POW_PRECISION) {

                // Truncating each coefficient array to a length of k after each multiplication
                // equates to truncating significant digits to POW_PRECISION + [28, 41],
                // i.e. there will be a minimum of 28 guard digits retained.
                k = mathceil(POW_PRECISION / LOG_BASE + 2);
            }

            if (nIsBig) {
                half = new BigNumber(0.5);
                nIsOdd = isOdd(n);
            } else {
                nIsOdd = n % 2;
            }

            if (nIsNeg) n.s = 1;

            y = new BigNumber(ONE);

            // Performs 54 loop iterations for n of 9007199254740991.
            for (; ;) {

                if (nIsOdd) {
                    y = y.times(x);
                    if (!y.c) break;

                    if (k) {
                        if (y.c.length > k) y.c.length = k;
                    } else if (isModExp) {
                        y = y.mod(m);    //y = y.minus(div(y, m, 0, MODULO_MODE).times(m));
                    }
                }

                if (nIsBig) {
                    n = n.times(half);
                    round(n, n.e + 1, 1);
                    if (!n.c[0]) break;
                    nIsBig = n.e > 14;
                    nIsOdd = isOdd(n);
                } else {
                    n = mathfloor(n / 2);
                    if (!n) break;
                    nIsOdd = n % 2;
                }

                x = x.times(x);

                if (k) {
                    if (x.c && x.c.length > k) x.c.length = k;
                } else if (isModExp) {
                    x = x.mod(m);    //x = x.minus(div(x, m, 0, MODULO_MODE).times(m));
                }
            }

            if (isModExp) return y;
            if (nIsNeg) y = ONE.div(y);

            return m ? y.mod(m) : k ? round(y, POW_PRECISION, ROUNDING_MODE, more) : y;
        };


        /*
         * Return a new BigNumber whose value is the value of this BigNumber rounded to an integer
         * using rounding mode rm, or ROUNDING_MODE if rm is omitted.
         *
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {rm}'
         */
        P.integerValue = function (rm) {
            var n = new BigNumber(this);
            if (rm == null) rm = ROUNDING_MODE;
            else intCheck(rm, 0, 8);
            return round(n, n.e + 1, rm);
        };


        /*
         * Return true if the value of this BigNumber is equal to the value of BigNumber(y, b),
         * otherwise return false.
         */
        P.isEqualTo = P.eq = P.equals = function (y, b) {
            return compare(this, new BigNumber(y, b)) === 0;
        };


        /*
         * Return true if the value of this BigNumber is a finite number, otherwise return false.
         */
        P.isFinite = function () {
            return !!this.c;
        };


        /*
         * Return true if the value of this BigNumber is greater than the value of BigNumber(y, b),
         * otherwise return false.
         */
        P.isGreaterThan = P.gt = function (y, b) {
            return compare(this, new BigNumber(y, b)) > 0;
        };


        /*
         * Return true if the value of this BigNumber is greater than or equal to the value of
         * BigNumber(y, b), otherwise return false.
         */
        P.isGreaterThanOrEqualTo = P.gte = function (y, b) {
            return (b = compare(this, new BigNumber(y, b))) === 1 || b === 0;

        };


        /*
         * Return true if the value of this BigNumber is an integer, otherwise return false.
         */
        P.isInteger = function () {
            return !!this.c && bitFloor(this.e / LOG_BASE) > this.c.length - 2;
        };


        /*
         * Return true if the value of this BigNumber is less than the value of BigNumber(y, b),
         * otherwise return false.
         */
        P.isLessThan = P.lt = function (y, b) {
            return compare(this, new BigNumber(y, b)) < 0;
        };


        /*
         * Return true if the value of this BigNumber is less than or equal to the value of
         * BigNumber(y, b), otherwise return false.
         */
        P.isLessThanOrEqualTo = P.lte = function (y, b) {
            return (b = compare(this, new BigNumber(y, b))) === -1 || b === 0;
        };


        /*
         * Return true if the value of this BigNumber is NaN, otherwise return false.
         */
        P.isNaN = function () {
            return !this.s;
        };


        /*
         * Return true if the value of this BigNumber is negative, otherwise return false.
         */
        P.isNegative = function () {
            return this.s < 0;
        };


        /*
         * Return true if the value of this BigNumber is positive, otherwise return false.
         */
        P.isPositive = function () {
            return this.s > 0;
        };


        /*
         * Return true if the value of this BigNumber is 0 or -0, otherwise return false.
         */
        P.isZero = function () {
            return !!this.c && this.c[0] == 0;
        };


        /*
         *  n - 0 = n
         *  n - N = N
         *  n - I = -I
         *  0 - n = -n
         *  0 - 0 = 0
         *  0 - N = N
         *  0 - I = -I
         *  N - n = N
         *  N - 0 = N
         *  N - N = N
         *  N - I = N
         *  I - n = I
         *  I - 0 = I
         *  I - N = N
         *  I - I = N
         *
         * Return a new BigNumber whose value is the value of this BigNumber minus the value of
         * BigNumber(y, b).
         */
        P.minus = function (y, b) {
            var i, j, t, xLTy,
                x = this,
                a = x.s;

            y = new BigNumber(y, b);
            b = y.s;

            // Either NaN?
            if (!a || !b) return new BigNumber(NaN);

            // Signs differ?
            if (a != b) {
                y.s = -b;
                return x.plus(y);
            }

            var xe = x.e / LOG_BASE,
                ye = y.e / LOG_BASE,
                xc = x.c,
                yc = y.c;

            if (!xe || !ye) {

                // Either Infinity?
                if (!xc || !yc) return xc ? (y.s = -b, y) : new BigNumber(yc ? x : NaN);

                // Either zero?
                if (!xc[0] || !yc[0]) {

                    // Return y if y is non-zero, x if x is non-zero, or zero if both are zero.
                    return yc[0] ? (y.s = -b, y) : new BigNumber(xc[0] ? x :

                        // IEEE 754 (2008) 6.3: n - n = -0 when rounding to -Infinity
                        ROUNDING_MODE == 3 ? -0 : 0);
                }
            }

            xe = bitFloor(xe);
            ye = bitFloor(ye);
            xc = xc.slice();

            // Determine which is the bigger number.
            if (a = xe - ye) {

                if (xLTy = a < 0) {
                    a = -a;
                    t = xc;
                } else {
                    ye = xe;
                    t = yc;
                }

                t.reverse();

                // Prepend zeros to equalise exponents.
                for (b = a; b--; t.push(0));
                t.reverse();
            } else {

                // Exponents equal. Check digit by digit.
                j = (xLTy = (a = xc.length) < (b = yc.length)) ? a : b;

                for (a = b = 0; b < j; b++) {

                    if (xc[b] != yc[b]) {
                        xLTy = xc[b] < yc[b];
                        break;
                    }
                }
            }

            // x < y? Point xc to the array of the bigger number.
            if (xLTy) t = xc, xc = yc, yc = t, y.s = -y.s;

            b = (j = yc.length) - (i = xc.length);

            // Append zeros to xc if shorter.
            // No need to add zeros to yc if shorter as subtract only needs to start at yc.length.
            if (b > 0) for (; b--; xc[i++] = 0);
            b = BASE - 1;

            // Subtract yc from xc.
            for (; j > a;) {

                if (xc[--j] < yc[j]) {
                    for (i = j; i && !xc[--i]; xc[i] = b);
                    --xc[i];
                    xc[j] += BASE;
                }

                xc[j] -= yc[j];
            }

            // Remove leading zeros and adjust exponent accordingly.
            for (; xc[0] == 0; xc.splice(0, 1), --ye);

            // Zero?
            if (!xc[0]) {

                // Following IEEE 754 (2008) 6.3,
                // n - n = +0  but  n - n = -0  when rounding towards -Infinity.
                y.s = ROUNDING_MODE == 3 ? -1 : 1;
                y.c = [y.e = 0];
                return y;
            }

            // No need to check for Infinity as +x - +y != Infinity && -x - -y != Infinity
            // for finite x and y.
            return normalise(y, xc, ye);
        };


        /*
         *   n % 0 =  N
         *   n % N =  N
         *   n % I =  n
         *   0 % n =  0
         *  -0 % n = -0
         *   0 % 0 =  N
         *   0 % N =  N
         *   0 % I =  0
         *   N % n =  N
         *   N % 0 =  N
         *   N % N =  N
         *   N % I =  N
         *   I % n =  N
         *   I % 0 =  N
         *   I % N =  N
         *   I % I =  N
         *
         * Return a new BigNumber whose value is the value of this BigNumber modulo the value of
         * BigNumber(y, b). The result depends on the value of MODULO_MODE.
         */
        P.modulo = P.mod = function (y, b) {
            var q, s,
                x = this;

            y = new BigNumber(y, b);

            // Return NaN if x is Infinity or NaN, or y is NaN or zero.
            if (!x.c || !y.s || y.c && !y.c[0]) {
                return new BigNumber(NaN);

                // Return x if y is Infinity or x is zero.
            } else if (!y.c || x.c && !x.c[0]) {
                return new BigNumber(x);
            }

            if (MODULO_MODE == 9) {

                // Euclidian division: q = sign(y) * floor(x / abs(y))
                // r = x - qy    where  0 <= r < abs(y)
                s = y.s;
                y.s = 1;
                q = div(x, y, 0, 3);
                y.s = s;
                q.s *= s;
            } else {
                q = div(x, y, 0, MODULO_MODE);
            }

            y = x.minus(q.times(y));

            // To match JavaScript %, ensure sign of zero is sign of dividend.
            if (!y.c[0] && MODULO_MODE == 1) y.s = x.s;

            return y;
        };


        /*
         *  n * 0 = 0
         *  n * N = N
         *  n * I = I
         *  0 * n = 0
         *  0 * 0 = 0
         *  0 * N = N
         *  0 * I = N
         *  N * n = N
         *  N * 0 = N
         *  N * N = N
         *  N * I = N
         *  I * n = I
         *  I * 0 = N
         *  I * N = N
         *  I * I = I
         *
         * Return a new BigNumber whose value is the value of this BigNumber multiplied by the value
         * of BigNumber(y, b).
         */
        P.multipliedBy = P.times = function (y, b) {
            var c, e, i, j, k, m, xcL, xlo, xhi, ycL, ylo, yhi, zc,
                base, sqrtBase,
                x = this,
                xc = x.c,
                yc = (y = new BigNumber(y, b)).c;

            // Either NaN, Infinity or 0?
            if (!xc || !yc || !xc[0] || !yc[0]) {

                // Return NaN if either is NaN, or one is 0 and the other is Infinity.
                if (!x.s || !y.s || xc && !xc[0] && !yc || yc && !yc[0] && !xc) {
                    y.c = y.e = y.s = null;
                } else {
                    y.s *= x.s;

                    // Return Infinity if either is Infinity.
                    if (!xc || !yc) {
                        y.c = y.e = null;

                        // Return 0 if either is 0.
                    } else {
                        y.c = [0];
                        y.e = 0;
                    }
                }

                return y;
            }

            e = bitFloor(x.e / LOG_BASE) + bitFloor(y.e / LOG_BASE);
            y.s *= x.s;
            xcL = xc.length;
            ycL = yc.length;

            // Ensure xc points to longer array and xcL to its length.
            if (xcL < ycL) zc = xc, xc = yc, yc = zc, i = xcL, xcL = ycL, ycL = i;

            // Initialise the result array with zeros.
            for (i = xcL + ycL, zc = []; i--; zc.push(0));

            base = BASE;
            sqrtBase = SQRT_BASE;

            for (i = ycL; --i >= 0;) {
                c = 0;
                ylo = yc[i] % sqrtBase;
                yhi = yc[i] / sqrtBase | 0;

                for (k = xcL, j = i + k; j > i;) {
                    xlo = xc[--k] % sqrtBase;
                    xhi = xc[k] / sqrtBase | 0;
                    m = yhi * xlo + xhi * ylo;
                    xlo = ylo * xlo + ((m % sqrtBase) * sqrtBase) + zc[j] + c;
                    c = (xlo / base | 0) + (m / sqrtBase | 0) + yhi * xhi;
                    zc[j--] = xlo % base;
                }

                zc[j] = c;
            }

            if (c) {
                ++e;
            } else {
                zc.splice(0, 1);
            }

            return normalise(y, zc, e);
        };


        /*
         * Return a new BigNumber whose value is the value of this BigNumber negated,
         * i.e. multiplied by -1.
         */
        P.negated = function () {
            var x = new BigNumber(this);
            x.s = -x.s || null;
            return x;
        };


        /*
         *  n + 0 = n
         *  n + N = N
         *  n + I = I
         *  0 + n = n
         *  0 + 0 = 0
         *  0 + N = N
         *  0 + I = I
         *  N + n = N
         *  N + 0 = N
         *  N + N = N
         *  N + I = N
         *  I + n = I
         *  I + 0 = I
         *  I + N = N
         *  I + I = I
         *
         * Return a new BigNumber whose value is the value of this BigNumber plus the value of
         * BigNumber(y, b).
         */
        P.plus = function (y, b) {
            var t,
                x = this,
                a = x.s;

            y = new BigNumber(y, b);
            b = y.s;

            // Either NaN?
            if (!a || !b) return new BigNumber(NaN);

            // Signs differ?
            if (a != b) {
                y.s = -b;
                return x.minus(y);
            }

            var xe = x.e / LOG_BASE,
                ye = y.e / LOG_BASE,
                xc = x.c,
                yc = y.c;

            if (!xe || !ye) {

                // Return Infinity if either Infinity.
                if (!xc || !yc) return new BigNumber(a / 0);

                // Either zero?
                // Return y if y is non-zero, x if x is non-zero, or zero if both are zero.
                if (!xc[0] || !yc[0]) return yc[0] ? y : new BigNumber(xc[0] ? x : a * 0);
            }

            xe = bitFloor(xe);
            ye = bitFloor(ye);
            xc = xc.slice();

            // Prepend zeros to equalise exponents. Faster to use reverse then do unshifts.
            if (a = xe - ye) {
                if (a > 0) {
                    ye = xe;
                    t = yc;
                } else {
                    a = -a;
                    t = xc;
                }

                t.reverse();
                for (; a--; t.push(0));
                t.reverse();
            }

            a = xc.length;
            b = yc.length;

            // Point xc to the longer array, and b to the shorter length.
            if (a - b < 0) t = yc, yc = xc, xc = t, b = a;

            // Only start adding at yc.length - 1 as the further digits of xc can be ignored.
            for (a = 0; b;) {
                a = (xc[--b] = xc[b] + yc[b] + a) / BASE | 0;
                xc[b] = BASE === xc[b] ? 0 : xc[b] % BASE;
            }

            if (a) {
                xc = [a].concat(xc);
                ++ye;
            }

            // No need to check for zero, as +x + +y != 0 && -x + -y != 0
            // ye = MAX_EXP + 1 possible
            return normalise(y, xc, ye);
        };


        /*
         * If sd is undefined or null or true or false, return the number of significant digits of
         * the value of this BigNumber, or null if the value of this BigNumber is Infinity or NaN.
         * If sd is true include integer-part trailing zeros in the count.
         *
         * Otherwise, if sd is a number, return a new BigNumber whose value is the value of this
         * BigNumber rounded to a maximum of sd significant digits using rounding mode rm, or
         * ROUNDING_MODE if rm is omitted.
         *
         * sd {number|boolean} number: significant digits: integer, 1 to MAX inclusive.
         *                     boolean: whether to count integer-part trailing zeros: true or false.
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {sd|rm}'
         */
        P.precision = P.sd = function (sd, rm) {
            var c, n, v,
                x = this;

            if (sd != null && sd !== !!sd) {
                intCheck(sd, 1, MAX);
                if (rm == null) rm = ROUNDING_MODE;
                else intCheck(rm, 0, 8);

                return round(new BigNumber(x), sd, rm);
            }

            if (!(c = x.c)) return null;
            v = c.length - 1;
            n = v * LOG_BASE + 1;

            if (v = c[v]) {

                // Subtract the number of trailing zeros of the last element.
                for (; v % 10 == 0; v /= 10, n--);

                // Add the number of digits of the first element.
                for (v = c[0]; v >= 10; v /= 10, n++);
            }

            if (sd && x.e + 1 > n) n = x.e + 1;

            return n;
        };


        /*
         * Return a new BigNumber whose value is the value of this BigNumber shifted by k places
         * (powers of 10). Shift to the right if n > 0, and to the left if n < 0.
         *
         * k {number} Integer, -MAX_SAFE_INTEGER to MAX_SAFE_INTEGER inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {k}'
         */
        P.shiftedBy = function (k) {
            intCheck(k, -MAX_SAFE_INTEGER, MAX_SAFE_INTEGER);
            return this.times('1e' + k);
        };


        /*
         *  sqrt(-n) =  N
         *  sqrt(N) =  N
         *  sqrt(-I) =  N
         *  sqrt(I) =  I
         *  sqrt(0) =  0
         *  sqrt(-0) = -0
         *
         * Return a new BigNumber whose value is the square root of the value of this BigNumber,
         * rounded according to DECIMAL_PLACES and ROUNDING_MODE.
         */
        P.squareRoot = P.sqrt = function () {
            var m, n, r, rep, t,
                x = this,
                c = x.c,
                s = x.s,
                e = x.e,
                dp = DECIMAL_PLACES + 4,
                half = new BigNumber('0.5');

            // Negative/NaN/Infinity/zero?
            if (s !== 1 || !c || !c[0]) {
                return new BigNumber(!s || s < 0 && (!c || c[0]) ? NaN : c ? x : 1 / 0);
            }

            // Initial estimate.
            s = Math.sqrt(+x);

            // Math.sqrt underflow/overflow?
            // Pass x to Math.sqrt as integer, then adjust the exponent of the result.
            if (s == 0 || s == 1 / 0) {
                n = coeffToString(c);
                if ((n.length + e) % 2 == 0) n += '0';
                s = Math.sqrt(n);
                e = bitFloor((e + 1) / 2) - (e < 0 || e % 2);

                if (s == 1 / 0) {
                    n = '1e' + e;
                } else {
                    n = s.toExponential();
                    n = n.slice(0, n.indexOf('e') + 1) + e;
                }

                r = new BigNumber(n);
            } else {
                r = new BigNumber(s + '');
            }

            // Check for zero.
            // r could be zero if MIN_EXP is changed after the this value was created.
            // This would cause a division by zero (x/t) and hence Infinity below, which would cause
            // coeffToString to throw.
            if (r.c[0]) {
                e = r.e;
                s = e + dp;
                if (s < 3) s = 0;

                // Newton-Raphson iteration.
                for (; ;) {
                    t = r;
                    r = half.times(t.plus(div(x, t, dp, 1)));

                    if (coeffToString(t.c  ).slice(0, s) === (n =
                        coeffToString(r.c)).slice(0, s)) {

                        // The exponent of r may here be one less than the final result exponent,
                        // e.g 0.0009999 (e-4) --> 0.001 (e-3), so adjust s so the rounding digits
                        // are indexed correctly.
                        if (r.e < e) --s;
                        n = n.slice(s - 3, s + 1);

                        // The 4th rounding digit may be in error by -1 so if the 4 rounding digits
                        // are 9999 or 4999 (i.e. approaching a rounding boundary) continue the
                        // iteration.
                        if (n == '9999' || !rep && n == '4999') {

                            // On the first iteration only, check to see if rounding up gives the
                            // exact result as the nines may infinitely repeat.
                            if (!rep) {
                                round(t, t.e + DECIMAL_PLACES + 2, 0);

                                if (t.times(t).eq(x)) {
                                    r = t;
                                    break;
                                }
                            }

                            dp += 4;
                            s += 4;
                            rep = 1;
                        } else {

                            // If rounding digits are null, 0{0,4} or 50{0,3}, check for exact
                            // result. If not, then there are further digits and m will be truthy.
                            if (!+n || !+n.slice(1) && n.charAt(0) == '5') {

                                // Truncate to the first rounding digit.
                                round(r, r.e + DECIMAL_PLACES + 2, 1);
                                m = !r.times(r).eq(x);
                            }

                            break;
                        }
                    }
                }
            }

            return round(r, r.e + DECIMAL_PLACES + 1, ROUNDING_MODE, m);
        };


        /*
         * Return a string representing the value of this BigNumber in exponential notation and
         * rounded using ROUNDING_MODE to dp fixed decimal places.
         *
         * [dp] {number} Decimal places. Integer, 0 to MAX inclusive.
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {dp|rm}'
         */
        P.toExponential = function (dp, rm) {
            if (dp != null) {
                intCheck(dp, 0, MAX);
                dp++;
            }
            return format(this, dp, rm, 1);
        };


        /*
         * Return a string representing the value of this BigNumber in fixed-point notation rounding
         * to dp fixed decimal places using rounding mode rm, or ROUNDING_MODE if rm is omitted.
         *
         * Note: as with JavaScript's number type, (-0).toFixed(0) is '0',
         * but e.g. (-0.00001).toFixed(0) is '-0'.
         *
         * [dp] {number} Decimal places. Integer, 0 to MAX inclusive.
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {dp|rm}'
         */
        P.toFixed = function (dp, rm) {
            if (dp != null) {
                intCheck(dp, 0, MAX);
                dp = dp + this.e + 1;
            }
            return format(this, dp, rm);
        };


        /*
         * Return a string representing the value of this BigNumber in fixed-point notation rounded
         * using rm or ROUNDING_MODE to dp decimal places, and formatted according to the properties
         * of the FORMAT object (see BigNumber.set).
         *
         * FORMAT = {
         *      decimalSeparator : '.',
         *      groupSeparator : ',',
         *      groupSize : 3,
         *      secondaryGroupSize : 0,
         *      fractionGroupSeparator : '\xA0',    // non-breaking space
         *      fractionGroupSize : 0
         * };
         *
         * [dp] {number} Decimal places. Integer, 0 to MAX inclusive.
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {dp|rm}'
         */
        P.toFormat = function (dp, rm) {
            var str = this.toFixed(dp, rm);

            if (this.c) {
                var i,
                    arr = str.split('.'),
                    g1 = +FORMAT.groupSize,
                    g2 = +FORMAT.secondaryGroupSize,
                    groupSeparator = FORMAT.groupSeparator,
                    intPart = arr[0],
                    fractionPart = arr[1],
                    isNeg = this.s < 0,
                    intDigits = isNeg ? intPart.slice(1) : intPart,
                    len = intDigits.length;

                if (g2) i = g1, g1 = g2, g2 = i, len -= i;

                if (g1 > 0 && len > 0) {
                    i = len % g1 || g1;
                    intPart = intDigits.substr(0, i);

                    for (; i < len; i += g1) {
                        intPart += groupSeparator + intDigits.substr(i, g1);
                    }

                    if (g2 > 0) intPart += groupSeparator + intDigits.slice(i);
                    if (isNeg) intPart = '-' + intPart;
                }

                str = fractionPart
                    ? intPart + FORMAT.decimalSeparator + ((g2 = +FORMAT.fractionGroupSize)
                    ? fractionPart.replace(new RegExp('\\d{' + g2 + '}\\B', 'g'),
                        '$&' + FORMAT.fractionGroupSeparator)
                    : fractionPart)
                    : intPart;
            }

            return str;
        };


        /*
         * Return a string array representing the value of this BigNumber as a simple fraction with
         * an integer numerator and an integer denominator. The denominator will be a positive
         * non-zero value less than or equal to the specified maximum denominator. If a maximum
         * denominator is not specified, the denominator will be the lowest value necessary to
         * represent the number exactly.
         *
         * [md] {number|string|BigNumber} Integer >= 1, or Infinity. The maximum denominator.
         *
         * '[BigNumber Error] Argument {not an integer|out of range} : {md}'
         */
        P.toFraction = function (md) {
            var arr, d, d0, d1, d2, e, exp, n, n0, n1, q, s,
                x = this,
                xc = x.c;

            if (md != null) {
                n = new BigNumber(md);

                // Throw if md is less than one or is not an integer, unless it is Infinity.
                if (!n.isInteger() && (n.c || n.s !== 1) || n.lt(ONE)) {
                    throw Error
                    (bignumberError + 'Argument ' +
                        (n.isInteger() ? 'out of range: ' : 'not an integer: ') + md);
                }
            }

            if (!xc) return x.toString();

            d = new BigNumber(ONE);
            n1 = d0 = new BigNumber(ONE);
            d1 = n0 = new BigNumber(ONE);
            s = coeffToString(xc);

            // Determine initial denominator.
            // d is a power of 10 and the minimum max denominator that specifies the value exactly.
            e = d.e = s.length - x.e - 1;
            d.c[0] = POWS_TEN[(exp = e % LOG_BASE) < 0 ? LOG_BASE + exp : exp];
            md = !md || n.comparedTo(d) > 0 ? (e > 0 ? d : n1) : n;

            exp = MAX_EXP;
            MAX_EXP = 1 / 0;
            n = new BigNumber(s);

            // n0 = d1 = 0
            n0.c[0] = 0;

            for (; ;)  {
                q = div(n, d, 0, 1);
                d2 = d0.plus(q.times(d1));
                if (d2.comparedTo(md) == 1) break;
                d0 = d1;
                d1 = d2;
                n1 = n0.plus(q.times(d2 = n1));
                n0 = d2;
                d = n.minus(q.times(d2 = d));
                n = d2;
            }

            d2 = div(md.minus(d0), d1, 0, 1);
            n0 = n0.plus(d2.times(n1));
            d0 = d0.plus(d2.times(d1));
            n0.s = n1.s = x.s;
            e *= 2;

            // Determine which fraction is closer to x, n0/d0 or n1/d1
            arr = div(n1, d1, e, ROUNDING_MODE).minus(x).abs().comparedTo(
                div(n0, d0, e, ROUNDING_MODE).minus(x).abs()) < 1
                ? [n1.toString(), d1.toString()]
                : [n0.toString(), d0.toString()];

            MAX_EXP = exp;
            return arr;
        };


        /*
         * Return the value of this BigNumber converted to a number primitive.
         */
        P.toNumber = function () {
            return +this;
        };


        /*
         * Return a string representing the value of this BigNumber rounded to sd significant digits
         * using rounding mode rm or ROUNDING_MODE. If sd is less than the number of digits
         * necessary to represent the integer part of the value in fixed-point notation, then use
         * exponential notation.
         *
         * [sd] {number} Significant digits. Integer, 1 to MAX inclusive.
         * [rm] {number} Rounding mode. Integer, 0 to 8 inclusive.
         *
         * '[BigNumber Error] Argument {not a primitive number|not an integer|out of range}: {sd|rm}'
         */
        P.toPrecision = function (sd, rm) {
            if (sd != null) intCheck(sd, 1, MAX);
            return format(this, sd, rm, 2);
        };


        /*
         * Return a string representing the value of this BigNumber in base b, or base 10 if b is
         * omitted. If a base is specified, including base 10, round according to DECIMAL_PLACES and
         * ROUNDING_MODE. If a base is not specified, and this BigNumber has a positive exponent
         * that is equal to or greater than TO_EXP_POS, or a negative exponent equal to or less than
         * TO_EXP_NEG, return exponential notation.
         *
         * [b] {number} Integer, 2 to ALPHABET.length inclusive.
         *
         * '[BigNumber Error] Base {not a primitive number|not an integer|out of range}: {b}'
         */
        P.toString = function (b) {
            var str,
                n = this,
                s = n.s,
                e = n.e;

            // Infinity or NaN?
            if (e === null) {

                if (s) {
                    str = 'Infinity';
                    if (s < 0) str = '-' + str;
                } else {
                    str = 'NaN';
                }
            } else {
                str = coeffToString(n.c);

                if (b == null) {
                    str = e <= TO_EXP_NEG || e >= TO_EXP_POS
                        ? toExponential(str, e)
                        : toFixedPoint(str, e, '0');
                } else {
                    intCheck(b, 2, ALPHABET.length, 'Base');
                    str = convertBase(toFixedPoint(str, e, '0'), 10, b, s, true);
                }

                if (s < 0 && n.c[0]) str = '-' + str;
            }

            return str;
        };


        /*
         * Return as toString, but do not accept a base argument, and include the minus sign for
         * negative zero.
         */
        P.valueOf = P.toJSON = function () {
            var str,
                n = this,
                e = n.e;

            if (e === null) return n.toString();

            str = coeffToString(n.c);

            str = e <= TO_EXP_NEG || e >= TO_EXP_POS
                ? toExponential(str, e)
                : toFixedPoint(str, e, '0');

            return n.s < 0 ? '-' + str : str;
        };


        P._isBigNumber = true;

        if (configObject != null) BigNumber.set(configObject);

        return BigNumber;
    }


    // PRIVATE HELPER FUNCTIONS


    function bitFloor(n) {
        var i = n | 0;
        return n > 0 || n === i ? i : i - 1;
    }


    // Return a coefficient array as a string of base 10 digits.
    function coeffToString(a) {
        var s, z,
            i = 1,
            j = a.length,
            r = a[0] + '';

        for (; i < j;) {
            s = a[i++] + '';
            z = LOG_BASE - s.length;
            for (; z--; s = '0' + s);
            r += s;
        }

        // Determine trailing zeros.
        for (j = r.length; r.charCodeAt(--j) === 48;);
        return r.slice(0, j + 1 || 1);
    }


    // Compare the value of BigNumbers x and y.
    function compare(x, y) {
        var a, b,
            xc = x.c,
            yc = y.c,
            i = x.s,
            j = y.s,
            k = x.e,
            l = y.e;

        // Either NaN?
        if (!i || !j) return null;

        a = xc && !xc[0];
        b = yc && !yc[0];

        // Either zero?
        if (a || b) return a ? b ? 0 : -j : i;

        // Signs differ?
        if (i != j) return i;

        a = i < 0;
        b = k == l;

        // Either Infinity?
        if (!xc || !yc) return b ? 0 : !xc ^ a ? 1 : -1;

        // Compare exponents.
        if (!b) return k > l ^ a ? 1 : -1;

        j = (k = xc.length) < (l = yc.length) ? k : l;

        // Compare digit by digit.
        for (i = 0; i < j; i++) if (xc[i] != yc[i]) return xc[i] > yc[i] ^ a ? 1 : -1;

        // Compare lengths.
        return k == l ? 0 : k > l ^ a ? 1 : -1;
    }


    /*
     * Check that n is a primitive number, an integer, and in range, otherwise throw.
     */
    function intCheck(n, min, max, name) {
        if (n < min || n > max || n !== (n < 0 ? mathceil(n) : mathfloor(n))) {
            throw Error
            (bignumberError + (name || 'Argument') + (typeof n == 'number'
                ? n < min || n > max ? ' out of range: ' : ' not an integer: '
                : ' not a primitive number: ') + n);
        }
    }


    function isArray(obj) {
        return Object.prototype.toString.call(obj) == '[object Array]';
    }


    // Assumes finite n.
    function isOdd(n) {
        var k = n.c.length - 1;
        return bitFloor(n.e / LOG_BASE) == k && n.c[k] % 2 != 0;
    }


    function toExponential(str, e) {
        return (str.length > 1 ? str.charAt(0) + '.' + str.slice(1) : str) +
            (e < 0 ? 'e' : 'e+') + e;
    }


    function toFixedPoint(str, e, z) {
        var len, zs;

        // Negative exponent?
        if (e < 0) {

            // Prepend zeros.
            for (zs = z + '.'; ++e; zs += z);
            str = zs + str;

            // Positive exponent
        } else {
            len = str.length;

            // Append zeros.
            if (++e > len) {
                for (zs = z, e -= len; --e; zs += z);
                str += zs;
            } else if (e < len) {
                str = str.slice(0, e) + '.' + str.slice(e);
            }
        }

        return str;
    }


    // EXPORT


    BigNumber = clone();
    BigNumber['default'] = BigNumber.BigNumber = BigNumber;
    globalObject.BigNumber = BigNumber;
})(Class.scope);
const BigNumber = Class.scope.BigNumber;
BigNumber.config({ DECIMAL_PLACES: 10 });

class NumberUtils {
    /**
     * @param {number} val
     * @return {boolean}
     */
    static isUint8(val) {
        return Number.isInteger(val)
            && val >= 0 && val <= NumberUtils.UINT8_MAX;
    }

    /**
     * @param {number} val
     * @return {boolean}
     */
    static isUint16(val) {
        return Number.isInteger(val)
            && val >= 0 && val <= NumberUtils.UINT16_MAX;
    }

    /**
     * @param {number} val
     * @return {boolean}
     */
    static isUint32(val) {
        return Number.isInteger(val)
            && val >= 0 && val <= NumberUtils.UINT32_MAX;
    }

    /**
     * @param {number} val
     * @return {boolean}
     */
    static isUint64(val) {
        return Number.isInteger(val)
            && val >= 0 && val <= NumberUtils.UINT64_MAX;
    }

    /**
     * @return {number}
     */
    static randomUint32() {
        return Math.floor(Math.random() * (NumberUtils.UINT32_MAX + 1));
    }

    /**
     * @return {number}
     */
    static randomUint64() {
        return Math.floor(Math.random() * (NumberUtils.UINT64_MAX + 1));
    }

    /**
     * @param {string} bin
     * @return {number}
     */
    static fromBinary(bin) {
        return parseInt(bin, 2);
    }
}

NumberUtils.UINT8_MAX = 255;
NumberUtils.UINT16_MAX = 65535;
NumberUtils.UINT32_MAX = 4294967295;
NumberUtils.UINT64_MAX = Number.MAX_SAFE_INTEGER;
//Object.freeze(NumberUtils);
Class.register(NumberUtils);

class MerkleTree {
    /**
     * @param {Array} values
     * @param {function(o: *):Hash} [fnHash]
     * @returns {Hash}
     */
    static computeRoot(values, fnHash = MerkleTree._hash) {
        return MerkleTree._computeRoot(values, fnHash);
    }

    /**
     * @param {Array} values
     * @param {function(o: *):Hash} fnHash
     * @returns {Hash}
     * @private
     */
    static _computeRoot(values, fnHash) {
        const len = values.length;
        if (len === 0) {
            return Hash.light(new Uint8Array(0));
        }
        if (len === 1) {
            return fnHash(values[0]);
        }

        const mid = Math.round(len / 2);
        const left = values.slice(0, mid);
        const right = values.slice(mid);
        const leftHash = MerkleTree._computeRoot(left, fnHash);
        const rightHash = MerkleTree._computeRoot(right, fnHash);
        return Hash.light(BufferUtils.concatTypedArrays(leftHash.serialize(), rightHash.serialize()));
    }

    /**
     * @param {Hash|Uint8Array|{hash: function():Hash}|{serialize: function():Uint8Array}} o
     * @returns {Hash}
     * @private
     */
    static _hash(o) {
        if (o instanceof Hash) {
            return o;
        }
        if (typeof o.hash === 'function') {
            return o.hash();
        }
        if (typeof o.serialize === 'function') {
            return Hash.light(o.serialize());
        }
        if (o instanceof Uint8Array) {
            return Hash.light(o);
        }
        throw new Error('MerkleTree objects must be Uint8Array or have a .hash()/.serialize() method');
    }
}
Class.register(MerkleTree);

class MerklePath {
    /**
     * @param {Array.<MerklePathNode>} nodes
     */
    constructor(nodes) {
        if (!Array.isArray(nodes) || !NumberUtils.isUint8(nodes.length)
            || nodes.some(it => !(it instanceof MerklePathNode))) throw new Error('Malformed nodes');
        /**
         * @type {Array.<MerklePathNode>}
         * @private
         */
        this._nodes = nodes;
    }

    /**
     * @param {Array} values
     * @param {*} leafValue
     * @param {function(o: *):Hash} [fnHash]
     * @returns {MerklePath}
     */
    static compute(values, leafValue, fnHash = MerkleTree._hash) {
        const leafHash = fnHash(leafValue);
        const path = [];
        MerklePath._compute(values, leafHash, path, fnHash);
        return new MerklePath(path);
    }

    /**
     * @param {Array} values
     * @param {Hash} leafHash
     * @param {Array.<MerklePathNode>} path
     * @param {function(o: *):Hash} fnHash
     * @returns {{containsLeaf:boolean, inner:Hash}}
     * @private
     */
    static _compute(values, leafHash, path, fnHash) {
        const len = values.length;
        let hash;
        if (len === 0) {
            hash = Hash.light(new Uint8Array(0));
            return {containsLeaf: false, inner: hash};
        }
        if (len === 1) {
            hash = fnHash(values[0]);
            return {containsLeaf: hash.equals(leafHash), inner: hash};
        }

        const mid = Math.round(len / 2);
        const left = values.slice(0, mid);
        const right = values.slice(mid);
        const {containsLeaf: leftLeaf, inner: leftHash} = MerklePath._compute(left, leafHash, path, fnHash);
        const {containsLeaf: rightLeaf, inner: rightHash} = MerklePath._compute(right, leafHash, path, fnHash);
        hash = Hash.light(BufferUtils.concatTypedArrays(leftHash.serialize(), rightHash.serialize()));

        if (leftLeaf) {
            path.push(new MerklePathNode(rightHash, false));
            return {containsLeaf: true, inner: hash};
        } else if (rightLeaf) {
            path.push(new MerklePathNode(leftHash, true));
            return {containsLeaf: true, inner: hash};
        }

        return {containsLeaf: false, inner: hash};
    }

    /**
     * @param {*} leafValue
     * @param {function(o: *):Hash} [fnHash]
     * @returns {Hash}
     */
    computeRoot(leafValue, fnHash = MerkleTree._hash) {
        /** @type {Hash} */
        let root = fnHash(leafValue);
        for (const node of this._nodes) {
            const left = node.left;
            const hash = node.hash;
            const concat = new SerialBuffer(hash.serializedSize * 2);
            if (left) hash.serialize(concat);
            root.serialize(concat);
            if (!left) hash.serialize(concat);
            root = Hash.light(concat);
        }
        return root;
    }

    /**
     * @param {Array.<MerklePathNode>} nodes
     * @returns {Uint8Array}
     * @private
     */
    static _compress(nodes) {
        const count = nodes.length;
        const leftBitsSize = Math.ceil(count / 8);
        const leftBits = new Uint8Array(leftBitsSize);

        for (let i = 0; i < count; i++) {
            if (nodes[i].left) {
                leftBits[Math.floor(i / 8)] |= 0x80 >>> (i % 8);
            }
        }

        return leftBits;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {MerklePath}
     */
    static unserialize(buf) {
        const count = buf.readUint8();
        const leftBitsSize = Math.ceil(count / 8);
        const leftBits = buf.read(leftBitsSize);

        const nodes = [];
        for (let i = 0; i < count; i++) {
            const left = (leftBits[Math.floor(i / 8)] & (0x80 >>> (i % 8))) !== 0;
            const hash = Hash.unserialize(buf);
            nodes.push(new MerklePathNode(hash, left));
        }
        return new MerklePath(nodes);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._nodes.length);
        buf.write(MerklePath._compress(this._nodes));

        for (const node of this._nodes) {
            node.hash.serialize(buf);
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        const leftBitsSize = Math.ceil(this._nodes.length / 8);
        return /*count*/ 1
            + leftBitsSize
            + this._nodes.reduce((sum, node) => sum + node.hash.serializedSize, 0);
    }

    /**
     * @param {MerklePath} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof MerklePath
            && this._nodes.length === o._nodes.length
            && this._nodes.every((node, i) => node.equals(o._nodes[i]));
    }

    /** @type {Array.<MerklePathNode>} */
    get nodes() {
        return this._nodes;
    }
}
Class.register(MerklePath);

class MerklePathNode {
    /**
     * @param {Hash} hash
     * @param {boolean} left
     */
    constructor(hash, left) {
        this._hash = hash;
        this._left = left;
    }

    /** @type {Hash} */
    get hash() {
        return this._hash;
    }

    /** @type {boolean} */
    get left() {
        return this._left;
    }

    /**
     * @param {MerklePathNode} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof MerklePathNode
            && this._hash.equals(o.hash)
            && this._left === o.left;
    }
}
Class.register(MerklePathNode);

class MerkleProof {
    /**
     * @param {Array.<*>} hashes
     * @param {Array.<MerkleProof.Operation>} operations
     */
    constructor(hashes, operations) {
        if (!Array.isArray(hashes) || !NumberUtils.isUint16(hashes.length)) throw new Error('Malformed nodes');
        if (!Array.isArray(operations) || !NumberUtils.isUint16(operations.length)) throw new Error('Malformed operations');
        /**
         * @type {Array.<*>}
         * @private
         */
        this._nodes = hashes;
        this._operations = operations;
    }

    /**
     * @param {Array} values
     * @param {Array.<*>} leafValues
     * @param {function(o: *):Hash} [fnHash]
     * @returns {MerkleProof}
     */
    static compute(values, leafValues, fnHash = MerkleTree._hash) {
        const leafHashes = leafValues.map(fnHash);
        const {containsLeaf, operations, path, inner} = MerkleProof._compute(values, leafHashes, fnHash);
        return new MerkleProof(path, operations);
    }

    /**
     * Assumes ordered array of values.
     * @param {Array} values
     * @param {Array.<*>} leafValues
     * @param {function(a: *, b: *):number} fnCompare
     * @param {function(o: *):Hash} [fnHash]
     * @returns {MerkleProof}
     */
    static computeWithAbsence(values, leafValues, fnCompare, fnHash = MerkleTree._hash) {
        const leaves = new Set();
        leafValues = leafValues.slice();
        leafValues.sort(fnCompare);
        // Find missing leaves and include neighbours instead.
        let leafIndex = 0, valueIndex = 0;
        while (valueIndex < values.length && leafIndex < leafValues.length) {
            const value = values[valueIndex];
            const comparisonResult = fnCompare(value, leafValues[leafIndex]);
            // Leave is included.
            if (comparisonResult === 0) {
                leaves.add(leafValues[leafIndex]);
                ++leafIndex;
            }
            // Leave should already have been there, so it is missing.
            else if (comparisonResult > 0) {
                // Use both, prevValue and value, as a proof of absence.
                // Special case: prevValue unknown as we're at the first value.
                if (valueIndex > 0) {
                    leaves.add(values[valueIndex - 1]);
                }
                leaves.add(value);
                ++leafIndex;
            }
            // This value is not interesting for us, skip it.
            else {
                ++valueIndex;
            }
        }
        // If we processed all values but not all leaves, these are missing. Add last value as proof.
        if (leafIndex < leafValues.length && values.length > 0) {
            leaves.add(values[values.length - 1]);
        }

        return MerkleProof.compute(values, Array.from(leaves), fnHash);
    }

    /**
     * @param {Array} values
     * @param {Array.<Hash>} leafHashes
     * @param {function(o: *):Hash} fnHash
     * @returns {{containsLeaf:boolean, inner:Hash}}
     * @private
     */
    static _compute(values, leafHashes, fnHash) {
        const len = values.length;
        let hash;
        if (len === 0) {
            hash = Hash.light(new Uint8Array(0));
            return {containsLeaf: false, operations: [MerkleProof.Operation.CONSUME_PROOF], path: [hash], inner: hash};
        }
        if (len === 1) {
            hash = fnHash(values[0]);
            const isLeaf = leafHashes.some(h => hash.equals(h));
            return {
                containsLeaf: isLeaf,
                operations: [isLeaf ? MerkleProof.Operation.CONSUME_INPUT : MerkleProof.Operation.CONSUME_PROOF],
                path: isLeaf ? [] : [hash],
                inner: hash
            };
        }

        const mid = Math.round(len / 2);
        const left = values.slice(0, mid);
        const right = values.slice(mid);
        const {containsLeaf: leftLeaf, operations: leftOps, path: leftPath, inner: leftHash} = MerkleProof._compute(left, leafHashes, fnHash);
        const {containsLeaf: rightLeaf, operations: rightOps, path: rightPath, inner: rightHash} = MerkleProof._compute(right, leafHashes, fnHash);
        hash = Hash.light(BufferUtils.concatTypedArrays(leftHash.serialize(), rightHash.serialize()));

        // If a branch does not contain a leaf, we can directly use its hash and discard any inner operations.
        if (!leftLeaf && !rightLeaf) {
            return {containsLeaf: false, operations: [MerkleProof.Operation.CONSUME_PROOF], path: [hash], inner: hash};
        }

        // At least one branch contains a leaf, so execute all operations.
        let operations = leftOps;
        operations = operations.concat(rightOps);
        let path = leftPath;
        path = path.concat(rightPath);

        operations.push(MerkleProof.Operation.HASH);

        return {containsLeaf: true, operations: operations, path: path, inner: hash};
    }

    /**
     * @param {Array.<*>} leafValues
     * @param {function(o: *):Hash} [fnHash]
     * @returns {Hash}
     */
    computeRoot(leafValues, fnHash = MerkleTree._hash) {
        /** @type {Array.<Hash>} */
        const inputs = leafValues.map(fnHash);
        const stack = [];
        const proofNodes = this._nodes.slice();
        for (const op of this._operations) {
            switch (op) {
                case MerkleProof.Operation.CONSUME_PROOF:
                    if (proofNodes.length === 0) {
                        throw new Error('Invalid operation.');
                    }
                    stack.push(proofNodes.shift());
                    break;
                case MerkleProof.Operation.CONSUME_INPUT:
                    if (inputs.length === 0) {
                        throw new Error('Invalid operation.');
                    }
                    stack.push(inputs.shift());
                    break;
                case MerkleProof.Operation.HASH: {
                    if (stack.length < 2) {
                        throw new Error('Invalid operation.');
                    }
                    const hashStack = stack.splice(-2, 2);
                    const concat = new SerialBuffer(hashStack.reduce((size, hash) => size + hash.serializedSize, 0));
                    const [left, right] = hashStack;
                    left.serialize(concat);
                    right.serialize(concat);
                    stack.push(Hash.light(concat));
                    break;
                }
                default:
                    throw new Error('Invalid operation.');
            }
        }

        // Everything but the root needs to be consumed.
        if (stack.length !== 1 || proofNodes.length !== 0 || inputs.length !== 0) {
            throw Error('Did not consume all nodes.');
        }

        return stack[0];
    }

    /**
     * @param {Array.<MerkleProof.Operation>} operations
     * @returns {Uint8Array}
     * @private
     */
    static _compress(operations) {
        const count = operations.length;
        const opBitsSize = Math.ceil(count / 4);
        const opBits = new Uint8Array(opBitsSize);

        for (let i = 0; i < count; i++) {
            const op = operations[i] & 0x3;
            opBits[Math.floor(i / 4)] |= op << (i % 4) * 2;
        }

        return opBits;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {MerkleProof}
     */
    static unserialize(buf) {
        const opCount = buf.readUint16();
        const opBitsSize = Math.ceil(opCount / 4);
        const opBits = buf.read(opBitsSize);

        const operations = [];
        for (let i = 0; i < opCount; i++) {
            const op = ((opBits[Math.floor(i / 4)] >>> (i % 4) * 2) & 0x3);
            operations.push(op);
        }

        const countNodes = buf.readUint16();
        const hashes = [];
        for (let i = 0; i < countNodes; i++) {
            hashes.push(Hash.unserialize(buf));
        }
        return new MerkleProof(hashes, operations);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._operations.length);
        buf.write(MerkleProof._compress(this._operations));
        buf.writeUint16(this._nodes.length);
        for (const hash of this._nodes) {
            hash.serialize(buf);
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        const opBitsSize = Math.ceil(this._operations.length / 4);
        return /*counts*/ 4
            + opBitsSize
            + this._nodes.reduce((sum, node) => sum + node.serializedSize, 0);
    }

    /**
     * @param {MerkleProof} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof MerkleProof
            && this._nodes.length === o._nodes.length
            && this._nodes.every((node, i) => node.equals(o._nodes[i]))
            && this._operations.length === o._operations.length
            && this._operations.every((op, i) => op === o._operations[i]);
    }

    /** @type {Array.<Hash>} */
    get nodes() {
        return this._nodes;
    }
}
/** @enum {number} */
MerkleProof.Operation = {
    CONSUME_PROOF: 0,
    CONSUME_INPUT: 1,
    HASH: 2
};
Class.register(MerkleProof);

class MnemonicUtils {
    // Adapted from https://github.com/bitcoinjs/bip39, see license below.

    /**
     * @param {Uint8Array} entropy
     * @returns {string}
     * @private
     */
    static _crcChecksum(entropy) {
        const ENT = entropy.length * 8;
        const CS = ENT / 32;
        const hash = CRC8.compute(entropy);

        return BufferUtils.toBinary([hash]).slice(0, CS);
    }

    /**
     * @param {Uint8Array} entropy
     * @returns {string}
     * @private
     */
    static _sha256Checksum(entropy) {
        const ENT = entropy.length * 8;
        const CS = ENT / 32;
        const hash = Hash.computeSha256(entropy);

        return BufferUtils.toBinary(hash).slice(0, CS);
    }

    /**
     * @param {Uint8Array} entropy
     * @returns {string}
     * @private
     */
    static _entropyToBits(entropy) {
        // 128 <= ENT <= 256
        if (entropy.length < 16) throw new Error('Invalid key, length < 16');
        if (entropy.length > 32) throw new Error('Invalid key, length > 32');
        if (entropy.length % 4 !== 0) throw new Error('Invalid key, length % 4 != 0');

        return BufferUtils.toBinary(entropy);
    }

    /**
     * @param {string|ArrayBuffer|Uint8Array|Entropy} entropy
     * @returns {Uint8Array}
     * @private
     */
    static _normalizeEntropy(entropy) {
        if (typeof entropy === 'string') entropy = BufferUtils.fromHex(entropy);
        if (entropy instanceof Entropy) entropy = entropy.serialize();
        if (entropy instanceof ArrayBuffer) entropy = new Uint8Array(entropy);
        return entropy;
    }

    /**
     * @param {string} bits
     * @param {Array.<string>} wordlist
     * @returns {Array.<string>}
     */
    static _bitsToMnemonic(bits, wordlist) {
        const chunks = bits.match(/(.{11})/g);
        const words = chunks.map(chunk => {
            const index = NumberUtils.fromBinary(chunk);
            return wordlist[index];
        });

        return words;
    }

    /**
     * @param {Array.<string>} mnemonic
     * @param {Array.<string>} wordlist
     * @returns {string}
     */
    static _mnemonicToBits(mnemonic, wordlist) {
        const words = mnemonic;
        if (words.length < 12) throw new Error('Invalid mnemonic, less than 12 words');
        if (words.length > 24) throw new Error('Invalid mnemonic, more than 24 words');
        if (words.length % 3 !== 0) throw new Error('Invalid mnemonic, words % 3 != 0');

        // Convert word indices to 11 bit binary strings
        const bits = words.map(function (word) {
            const index = wordlist.indexOf(word.toLowerCase());
            if (index === -1) throw new Error(`Invalid mnemonic, word >${word}< is not in wordlist`);

            return StringUtils.lpad(index.toString(2), '0', 11);
        }).join('');

        return bits;
    }

    /**
     * @param {string} bits
     * @param {boolean} legacy
     * @returns {Uint8Array}
     */
    static _bitsToEntropy(bits, legacy = false) {
        // Split the binary string into ENT/CS
        const dividerIndex = bits.length - (bits.length % 8 || 8);
        const entropyBits = bits.slice(0, dividerIndex);
        const checksumBits = bits.slice(dividerIndex);

        // Calculate the checksum and compare
        const entropyBytes = entropyBits.match(/(.{8})/g).map(NumberUtils.fromBinary);

        if (entropyBytes.length < 16) throw new Error('Invalid generated key, length < 16');
        if (entropyBytes.length > 32) throw new Error('Invalid generated key, length > 32');
        if (entropyBytes.length % 4 !== 0) throw new Error('Invalid generated key, length % 4 != 0');

        const entropy = new Uint8Array(entropyBytes);
        const checksum = legacy ? MnemonicUtils._crcChecksum(entropy) : MnemonicUtils._sha256Checksum(entropy);
        if (checksum !== checksumBits) throw new Error('Invalid checksum');

        return entropy;
    }

    /**
     * @param {string|ArrayBuffer|Uint8Array|Entropy} entropy
     * @param {Array.<string>} [wordlist]
     * @returns {Array.<string>}
     */
    static entropyToMnemonic(entropy, wordlist) {
        wordlist = wordlist || MnemonicUtils.DEFAULT_WORDLIST;
        entropy = MnemonicUtils._normalizeEntropy(entropy);

        const entropyBits = MnemonicUtils._entropyToBits(entropy);
        const checksumBits = MnemonicUtils._sha256Checksum(entropy);

        const bits = entropyBits + checksumBits;
        return MnemonicUtils._bitsToMnemonic(bits, wordlist);
    }

    /**
     * @param {string|ArrayBuffer|Uint8Array|Entropy} entropy
     * @param {Array.<string>} [wordlist]
     * @returns {Array.<string>}
     * @deprecated
     */
    static entropyToLegacyMnemonic(entropy, wordlist) {
        wordlist = wordlist || MnemonicUtils.DEFAULT_WORDLIST;
        entropy = MnemonicUtils._normalizeEntropy(entropy);

        const entropyBits = MnemonicUtils._entropyToBits(entropy);
        const checksumBits = MnemonicUtils._crcChecksum(entropy);

        const bits = entropyBits + checksumBits;
        return MnemonicUtils._bitsToMnemonic(bits, wordlist);
    }

    /**
     * @param {Array.<string>|string} mnemonic
     * @param {Array.<string>} [wordlist]
     * @returns {Entropy}
     */
    static mnemonicToEntropy(mnemonic, wordlist) {
        if (!Array.isArray(mnemonic)) mnemonic = mnemonic.trim().split(/\s+/g);
        wordlist = wordlist || MnemonicUtils.DEFAULT_WORDLIST;

        const bits = MnemonicUtils._mnemonicToBits(mnemonic, wordlist);
        return new Entropy(MnemonicUtils._bitsToEntropy(bits, false));
    }

    /**
     * @param {Array.<string>|string} mnemonic
     * @param {Array.<string>} [wordlist]
     * @returns {Entropy}
     * @deprecated
     */
    static legacyMnemonicToEntropy(mnemonic, wordlist) {
        if (!Array.isArray(mnemonic)) mnemonic = mnemonic.trim().split(/\s+/g);
        wordlist = wordlist || MnemonicUtils.DEFAULT_WORDLIST;

        const bits = MnemonicUtils._mnemonicToBits(mnemonic, wordlist);
        return new Entropy(MnemonicUtils._bitsToEntropy(bits, true));
    }

    /**
     * @param {string} password
     * @returns {string}
     * @private
     */
    static _salt(password) {
        return `mnemonic${password || ''}`;
    }

    /**
     * @param {string|Array.<string>} mnemonic
     * @param {string} [password]
     * @returns {Uint8Array}
     */
    static mnemonicToSeed(mnemonic, password) {
        if (Array.isArray(mnemonic)) mnemonic = mnemonic.join(' ');

        const mnemonicBuffer = BufferUtils.fromAscii(mnemonic);
        const saltBuffer = BufferUtils.fromAscii(MnemonicUtils._salt(password));

        return CryptoUtils.computePBKDF2sha512(mnemonicBuffer, saltBuffer, 2048, 64);
    }

    /**
     * @param {string|Array.<string>} mnemonic
     * @param {string} [password]
     * @returns {ExtendedPrivateKey}
     */
    static mnemonicToExtendedPrivateKey(mnemonic, password) {
        const seed = MnemonicUtils.mnemonicToSeed(mnemonic, password);
        return ExtendedPrivateKey.generateMasterKey(seed);
    }

    /**
     * @param {Entropy} entropy
     * @returns {boolean}
     */
    static isCollidingChecksum(entropy) {
        const normalizedEntropy = MnemonicUtils._normalizeEntropy(entropy);
        return MnemonicUtils._crcChecksum(normalizedEntropy) === MnemonicUtils._sha256Checksum(normalizedEntropy);
    }

    /**
     * @param {string|Array.<string>} mnemonic
     * @param {Array.<string>} [wordlist]
     * @returns {MnemonicUtils.MnemonicType}
     */
    static getMnemonicType(mnemonic, wordlist) {
        if (!Array.isArray(mnemonic)) mnemonic = mnemonic.trim().split(/\s+/g);

        wordlist = wordlist || MnemonicUtils.DEFAULT_WORDLIST;

        const bits = MnemonicUtils._mnemonicToBits(mnemonic, wordlist);

        let isBIP39 = true;
        try { MnemonicUtils._bitsToEntropy(bits, false); } catch (e) { isBIP39 = false; }
        let isLegacy = true;
        try { MnemonicUtils._bitsToEntropy(bits, true); } catch (e) { isLegacy = false; }

        if (isBIP39 && isLegacy) return MnemonicUtils.MnemonicType.UNKNOWN;
        if (!isBIP39 && !isLegacy) throw new Error('Invalid checksum');
        return isBIP39 ? MnemonicUtils.MnemonicType.BIP39 : MnemonicUtils.MnemonicType.LEGACY;
    }
}

MnemonicUtils.ENGLISH_WORDLIST = ['abandon', 'ability', 'able', 'about', 'above', 'absent', 'absorb', 'abstract', 'absurd', 'abuse', 'access', 'accident', 'account', 'accuse', 'achieve', 'acid', 'acoustic', 'acquire', 'across', 'act', 'action', 'actor', 'actress', 'actual', 'adapt', 'add', 'addict', 'address', 'adjust', 'admit', 'adult', 'advance', 'advice', 'aerobic', 'affair', 'afford', 'afraid', 'again', 'age', 'agent', 'agree', 'ahead', 'aim', 'air', 'airport', 'aisle', 'alarm', 'album', 'alcohol', 'alert', 'alien', 'all', 'alley', 'allow', 'almost', 'alone', 'alpha', 'already', 'also', 'alter', 'always', 'amateur', 'amazing', 'among', 'amount', 'amused', 'analyst', 'anchor', 'ancient', 'anger', 'angle', 'angry', 'animal', 'ankle', 'announce', 'annual', 'another', 'answer', 'antenna', 'antique', 'anxiety', 'any', 'apart', 'apology', 'appear', 'apple', 'approve', 'april', 'arch', 'arctic', 'area', 'arena', 'argue', 'arm', 'armed', 'armor', 'army', 'around', 'arrange', 'arrest', 'arrive', 'arrow', 'art', 'artefact', 'artist', 'artwork', 'ask', 'aspect', 'assault', 'asset', 'assist', 'assume', 'asthma', 'athlete', 'atom', 'attack', 'attend', 'attitude', 'attract', 'auction', 'audit', 'august', 'aunt', 'author', 'auto', 'autumn', 'average', 'avocado', 'avoid', 'awake', 'aware', 'away', 'awesome', 'awful', 'awkward', 'axis', 'baby', 'bachelor', 'bacon', 'badge', 'bag', 'balance', 'balcony', 'ball', 'bamboo', 'banana', 'banner', 'bar', 'barely', 'bargain', 'barrel', 'base', 'basic', 'basket', 'battle', 'beach', 'bean', 'beauty', 'because', 'become', 'beef', 'before', 'begin', 'behave', 'behind', 'believe', 'below', 'belt', 'bench', 'benefit', 'best', 'betray', 'better', 'between', 'beyond', 'bicycle', 'bid', 'bike', 'bind', 'biology', 'bird', 'birth', 'bitter', 'black', 'blade', 'blame', 'blanket', 'blast', 'bleak', 'bless', 'blind', 'blood', 'blossom', 'blouse', 'blue', 'blur', 'blush', 'board', 'boat', 'body', 'boil', 'bomb', 'bone', 'bonus', 'book', 'boost', 'border', 'boring', 'borrow', 'boss', 'bottom', 'bounce', 'box', 'boy', 'bracket', 'brain', 'brand', 'brass', 'brave', 'bread', 'breeze', 'brick', 'bridge', 'brief', 'bright', 'bring', 'brisk', 'broccoli', 'broken', 'bronze', 'broom', 'brother', 'brown', 'brush', 'bubble', 'buddy', 'budget', 'buffalo', 'build', 'bulb', 'bulk', 'bullet', 'bundle', 'bunker', 'burden', 'burger', 'burst', 'bus', 'business', 'busy', 'butter', 'buyer', 'buzz', 'cabbage', 'cabin', 'cable', 'cactus', 'cage', 'cake', 'call', 'calm', 'camera', 'camp', 'can', 'canal', 'cancel', 'candy', 'cannon', 'canoe', 'canvas', 'canyon', 'capable', 'capital', 'captain', 'car', 'carbon', 'card', 'cargo', 'carpet', 'carry', 'cart', 'case', 'cash', 'casino', 'castle', 'casual', 'cat', 'catalog', 'catch', 'category', 'cattle', 'caught', 'cause', 'caution', 'cave', 'ceiling', 'celery', 'cement', 'census', 'century', 'cereal', 'certain', 'chair', 'chalk', 'champion', 'change', 'chaos', 'chapter', 'charge', 'chase', 'chat', 'cheap', 'check', 'cheese', 'chef', 'cherry', 'chest', 'chicken', 'chief', 'child', 'chimney', 'choice', 'choose', 'chronic', 'chuckle', 'chunk', 'churn', 'cigar', 'cinnamon', 'circle', 'citizen', 'city', 'civil', 'claim', 'clap', 'clarify', 'claw', 'clay', 'clean', 'clerk', 'clever', 'click', 'client', 'cliff', 'climb', 'clinic', 'clip', 'clock', 'clog', 'close', 'cloth', 'cloud', 'clown', 'club', 'clump', 'cluster', 'clutch', 'coach', 'coast', 'coconut', 'code', 'coffee', 'coil', 'coin', 'collect', 'color', 'column', 'combine', 'come', 'comfort', 'comic', 'common', 'company', 'concert', 'conduct', 'confirm', 'congress', 'connect', 'consider', 'control', 'convince', 'cook', 'cool', 'copper', 'copy', 'coral', 'core', 'corn', 'correct', 'cost', 'cotton', 'couch', 'country', 'couple', 'course', 'cousin', 'cover', 'coyote', 'crack', 'cradle', 'craft', 'cram', 'crane', 'crash', 'crater', 'crawl', 'crazy', 'cream', 'credit', 'creek', 'crew', 'cricket', 'crime', 'crisp', 'critic', 'crop', 'cross', 'crouch', 'crowd', 'crucial', 'cruel', 'cruise', 'crumble', 'crunch', 'crush', 'cry', 'crystal', 'cube', 'culture', 'cup', 'cupboard', 'curious', 'current', 'curtain', 'curve', 'cushion', 'custom', 'cute', 'cycle', 'dad', 'damage', 'damp', 'dance', 'danger', 'daring', 'dash', 'daughter', 'dawn', 'day', 'deal', 'debate', 'debris', 'decade', 'december', 'decide', 'decline', 'decorate', 'decrease', 'deer', 'defense', 'define', 'defy', 'degree', 'delay', 'deliver', 'demand', 'demise', 'denial', 'dentist', 'deny', 'depart', 'depend', 'deposit', 'depth', 'deputy', 'derive', 'describe', 'desert', 'design', 'desk', 'despair', 'destroy', 'detail', 'detect', 'develop', 'device', 'devote', 'diagram', 'dial', 'diamond', 'diary', 'dice', 'diesel', 'diet', 'differ', 'digital', 'dignity', 'dilemma', 'dinner', 'dinosaur', 'direct', 'dirt', 'disagree', 'discover', 'disease', 'dish', 'dismiss', 'disorder', 'display', 'distance', 'divert', 'divide', 'divorce', 'dizzy', 'doctor', 'document', 'dog', 'doll', 'dolphin', 'domain', 'donate', 'donkey', 'donor', 'door', 'dose', 'double', 'dove', 'draft', 'dragon', 'drama', 'drastic', 'draw', 'dream', 'dress', 'drift', 'drill', 'drink', 'drip', 'drive', 'drop', 'drum', 'dry', 'duck', 'dumb', 'dune', 'during', 'dust', 'dutch', 'duty', 'dwarf', 'dynamic', 'eager', 'eagle', 'early', 'earn', 'earth', 'easily', 'east', 'easy', 'echo', 'ecology', 'economy', 'edge', 'edit', 'educate', 'effort', 'egg', 'eight', 'either', 'elbow', 'elder', 'electric', 'elegant', 'element', 'elephant', 'elevator', 'elite', 'else', 'embark', 'embody', 'embrace', 'emerge', 'emotion', 'employ', 'empower', 'empty', 'enable', 'enact', 'end', 'endless', 'endorse', 'enemy', 'energy', 'enforce', 'engage', 'engine', 'enhance', 'enjoy', 'enlist', 'enough', 'enrich', 'enroll', 'ensure', 'enter', 'entire', 'entry', 'envelope', 'episode', 'equal', 'equip', 'era', 'erase', 'erode', 'erosion', 'error', 'erupt', 'escape', 'essay', 'essence', 'estate', 'eternal', 'ethics', 'evidence', 'evil', 'evoke', 'evolve', 'exact', 'example', 'excess', 'exchange', 'excite', 'exclude', 'excuse', 'execute', 'exercise', 'exhaust', 'exhibit', 'exile', 'exist', 'exit', 'exotic', 'expand', 'expect', 'expire', 'explain', 'expose', 'express', 'extend', 'extra', 'eye', 'eyebrow', 'fabric', 'face', 'faculty', 'fade', 'faint', 'faith', 'fall', 'false', 'fame', 'family', 'famous', 'fan', 'fancy', 'fantasy', 'farm', 'fashion', 'fat', 'fatal', 'father', 'fatigue', 'fault', 'favorite', 'feature', 'february', 'federal', 'fee', 'feed', 'feel', 'female', 'fence', 'festival', 'fetch', 'fever', 'few', 'fiber', 'fiction', 'field', 'figure', 'file', 'film', 'filter', 'final', 'find', 'fine', 'finger', 'finish', 'fire', 'firm', 'first', 'fiscal', 'fish', 'fit', 'fitness', 'fix', 'flag', 'flame', 'flash', 'flat', 'flavor', 'flee', 'flight', 'flip', 'float', 'flock', 'floor', 'flower', 'fluid', 'flush', 'fly', 'foam', 'focus', 'fog', 'foil', 'fold', 'follow', 'food', 'foot', 'force', 'forest', 'forget', 'fork', 'fortune', 'forum', 'forward', 'fossil', 'foster', 'found', 'fox', 'fragile', 'frame', 'frequent', 'fresh', 'friend', 'fringe', 'frog', 'front', 'frost', 'frown', 'frozen', 'fruit', 'fuel', 'fun', 'funny', 'furnace', 'fury', 'future', 'gadget', 'gain', 'galaxy', 'gallery', 'game', 'gap', 'garage', 'garbage', 'garden', 'garlic', 'garment', 'gas', 'gasp', 'gate', 'gather', 'gauge', 'gaze', 'general', 'genius', 'genre', 'gentle', 'genuine', 'gesture', 'ghost', 'giant', 'gift', 'giggle', 'ginger', 'giraffe', 'girl', 'give', 'glad', 'glance', 'glare', 'glass', 'glide', 'glimpse', 'globe', 'gloom', 'glory', 'glove', 'glow', 'glue', 'goat', 'goddess', 'gold', 'good', 'goose', 'gorilla', 'gospel', 'gossip', 'govern', 'gown', 'grab', 'grace', 'grain', 'grant', 'grape', 'grass', 'gravity', 'great', 'green', 'grid', 'grief', 'grit', 'grocery', 'group', 'grow', 'grunt', 'guard', 'guess', 'guide', 'guilt', 'guitar', 'gun', 'gym', 'habit', 'hair', 'half', 'hammer', 'hamster', 'hand', 'happy', 'harbor', 'hard', 'harsh', 'harvest', 'hat', 'have', 'hawk', 'hazard', 'head', 'health', 'heart', 'heavy', 'hedgehog', 'height', 'hello', 'helmet', 'help', 'hen', 'hero', 'hidden', 'high', 'hill', 'hint', 'hip', 'hire', 'history', 'hobby', 'hockey', 'hold', 'hole', 'holiday', 'hollow', 'home', 'honey', 'hood', 'hope', 'horn', 'horror', 'horse', 'hospital', 'host', 'hotel', 'hour', 'hover', 'hub', 'huge', 'human', 'humble', 'humor', 'hundred', 'hungry', 'hunt', 'hurdle', 'hurry', 'hurt', 'husband', 'hybrid', 'ice', 'icon', 'idea', 'identify', 'idle', 'ignore', 'ill', 'illegal', 'illness', 'image', 'imitate', 'immense', 'immune', 'impact', 'impose', 'improve', 'impulse', 'inch', 'include', 'income', 'increase', 'index', 'indicate', 'indoor', 'industry', 'infant', 'inflict', 'inform', 'inhale', 'inherit', 'initial', 'inject', 'injury', 'inmate', 'inner', 'innocent', 'input', 'inquiry', 'insane', 'insect', 'inside', 'inspire', 'install', 'intact', 'interest', 'into', 'invest', 'invite', 'involve', 'iron', 'island', 'isolate', 'issue', 'item', 'ivory', 'jacket', 'jaguar', 'jar', 'jazz', 'jealous', 'jeans', 'jelly', 'jewel', 'job', 'join', 'joke', 'journey', 'joy', 'judge', 'juice', 'jump', 'jungle', 'junior', 'junk', 'just', 'kangaroo', 'keen', 'keep', 'ketchup', 'key', 'kick', 'kid', 'kidney', 'kind', 'kingdom', 'kiss', 'kit', 'kitchen', 'kite', 'kitten', 'kiwi', 'knee', 'knife', 'knock', 'know', 'lab', 'label', 'labor', 'ladder', 'lady', 'lake', 'lamp', 'language', 'laptop', 'large', 'later', 'latin', 'laugh', 'laundry', 'lava', 'law', 'lawn', 'lawsuit', 'layer', 'lazy', 'leader', 'leaf', 'learn', 'leave', 'lecture', 'left', 'leg', 'legal', 'legend', 'leisure', 'lemon', 'lend', 'length', 'lens', 'leopard', 'lesson', 'letter', 'level', 'liar', 'liberty', 'library', 'license', 'life', 'lift', 'light', 'like', 'limb', 'limit', 'link', 'lion', 'liquid', 'list', 'little', 'live', 'lizard', 'load', 'loan', 'lobster', 'local', 'lock', 'logic', 'lonely', 'long', 'loop', 'lottery', 'loud', 'lounge', 'love', 'loyal', 'lucky', 'luggage', 'lumber', 'lunar', 'lunch', 'luxury', 'lyrics', 'machine', 'mad', 'magic', 'magnet', 'maid', 'mail', 'main', 'major', 'make', 'mammal', 'man', 'manage', 'mandate', 'mango', 'mansion', 'manual', 'maple', 'marble', 'march', 'margin', 'marine', 'market', 'marriage', 'mask', 'mass', 'master', 'match', 'material', 'math', 'matrix', 'matter', 'maximum', 'maze', 'meadow', 'mean', 'measure', 'meat', 'mechanic', 'medal', 'media', 'melody', 'melt', 'member', 'memory', 'mention', 'menu', 'mercy', 'merge', 'merit', 'merry', 'mesh', 'message', 'metal', 'method', 'middle', 'midnight', 'milk', 'million', 'mimic', 'mind', 'minimum', 'minor', 'minute', 'miracle', 'mirror', 'misery', 'miss', 'mistake', 'mix', 'mixed', 'mixture', 'mobile', 'model', 'modify', 'mom', 'moment', 'monitor', 'monkey', 'monster', 'month', 'moon', 'moral', 'more', 'morning', 'mosquito', 'mother', 'motion', 'motor', 'mountain', 'mouse', 'move', 'movie', 'much', 'muffin', 'mule', 'multiply', 'muscle', 'museum', 'mushroom', 'music', 'must', 'mutual', 'myself', 'mystery', 'myth', 'naive', 'name', 'napkin', 'narrow', 'nasty', 'nation', 'nature', 'near', 'neck', 'need', 'negative', 'neglect', 'neither', 'nephew', 'nerve', 'nest', 'net', 'network', 'neutral', 'never', 'news', 'next', 'nice', 'night', 'noble', 'noise', 'nominee', 'noodle', 'normal', 'north', 'nose', 'notable', 'note', 'nothing', 'notice', 'novel', 'now', 'nuclear', 'number', 'nurse', 'nut', 'oak', 'obey', 'object', 'oblige', 'obscure', 'observe', 'obtain', 'obvious', 'occur', 'ocean', 'october', 'odor', 'off', 'offer', 'office', 'often', 'oil', 'okay', 'old', 'olive', 'olympic', 'omit', 'once', 'one', 'onion', 'online', 'only', 'open', 'opera', 'opinion', 'oppose', 'option', 'orange', 'orbit', 'orchard', 'order', 'ordinary', 'organ', 'orient', 'original', 'orphan', 'ostrich', 'other', 'outdoor', 'outer', 'output', 'outside', 'oval', 'oven', 'over', 'own', 'owner', 'oxygen', 'oyster', 'ozone', 'pact', 'paddle', 'page', 'pair', 'palace', 'palm', 'panda', 'panel', 'panic', 'panther', 'paper', 'parade', 'parent', 'park', 'parrot', 'party', 'pass', 'patch', 'path', 'patient', 'patrol', 'pattern', 'pause', 'pave', 'payment', 'peace', 'peanut', 'pear', 'peasant', 'pelican', 'pen', 'penalty', 'pencil', 'people', 'pepper', 'perfect', 'permit', 'person', 'pet', 'phone', 'photo', 'phrase', 'physical', 'piano', 'picnic', 'picture', 'piece', 'pig', 'pigeon', 'pill', 'pilot', 'pink', 'pioneer', 'pipe', 'pistol', 'pitch', 'pizza', 'place', 'planet', 'plastic', 'plate', 'play', 'please', 'pledge', 'pluck', 'plug', 'plunge', 'poem', 'poet', 'point', 'polar', 'pole', 'police', 'pond', 'pony', 'pool', 'popular', 'portion', 'position', 'possible', 'post', 'potato', 'pottery', 'poverty', 'powder', 'power', 'practice', 'praise', 'predict', 'prefer', 'prepare', 'present', 'pretty', 'prevent', 'price', 'pride', 'primary', 'print', 'priority', 'prison', 'private', 'prize', 'problem', 'process', 'produce', 'profit', 'program', 'project', 'promote', 'proof', 'property', 'prosper', 'protect', 'proud', 'provide', 'public', 'pudding', 'pull', 'pulp', 'pulse', 'pumpkin', 'punch', 'pupil', 'puppy', 'purchase', 'purity', 'purpose', 'purse', 'push', 'put', 'puzzle', 'pyramid', 'quality', 'quantum', 'quarter', 'question', 'quick', 'quit', 'quiz', 'quote', 'rabbit', 'raccoon', 'race', 'rack', 'radar', 'radio', 'rail', 'rain', 'raise', 'rally', 'ramp', 'ranch', 'random', 'range', 'rapid', 'rare', 'rate', 'rather', 'raven', 'raw', 'razor', 'ready', 'real', 'reason', 'rebel', 'rebuild', 'recall', 'receive', 'recipe', 'record', 'recycle', 'reduce', 'reflect', 'reform', 'refuse', 'region', 'regret', 'regular', 'reject', 'relax', 'release', 'relief', 'rely', 'remain', 'remember', 'remind', 'remove', 'render', 'renew', 'rent', 'reopen', 'repair', 'repeat', 'replace', 'report', 'require', 'rescue', 'resemble', 'resist', 'resource', 'response', 'result', 'retire', 'retreat', 'return', 'reunion', 'reveal', 'review', 'reward', 'rhythm', 'rib', 'ribbon', 'rice', 'rich', 'ride', 'ridge', 'rifle', 'right', 'rigid', 'ring', 'riot', 'ripple', 'risk', 'ritual', 'rival', 'river', 'road', 'roast', 'robot', 'robust', 'rocket', 'romance', 'roof', 'rookie', 'room', 'rose', 'rotate', 'rough', 'round', 'route', 'royal', 'rubber', 'rude', 'rug', 'rule', 'run', 'runway', 'rural', 'sad', 'saddle', 'sadness', 'safe', 'sail', 'salad', 'salmon', 'salon', 'salt', 'salute', 'same', 'sample', 'sand', 'satisfy', 'satoshi', 'sauce', 'sausage', 'save', 'say', 'scale', 'scan', 'scare', 'scatter', 'scene', 'scheme', 'school', 'science', 'scissors', 'scorpion', 'scout', 'scrap', 'screen', 'script', 'scrub', 'sea', 'search', 'season', 'seat', 'second', 'secret', 'section', 'security', 'seed', 'seek', 'segment', 'select', 'sell', 'seminar', 'senior', 'sense', 'sentence', 'series', 'service', 'session', 'settle', 'setup', 'seven', 'shadow', 'shaft', 'shallow', 'share', 'shed', 'shell', 'sheriff', 'shield', 'shift', 'shine', 'ship', 'shiver', 'shock', 'shoe', 'shoot', 'shop', 'short', 'shoulder', 'shove', 'shrimp', 'shrug', 'shuffle', 'shy', 'sibling', 'sick', 'side', 'siege', 'sight', 'sign', 'silent', 'silk', 'silly', 'silver', 'similar', 'simple', 'since', 'sing', 'siren', 'sister', 'situate', 'six', 'size', 'skate', 'sketch', 'ski', 'skill', 'skin', 'skirt', 'skull', 'slab', 'slam', 'sleep', 'slender', 'slice', 'slide', 'slight', 'slim', 'slogan', 'slot', 'slow', 'slush', 'small', 'smart', 'smile', 'smoke', 'smooth', 'snack', 'snake', 'snap', 'sniff', 'snow', 'soap', 'soccer', 'social', 'sock', 'soda', 'soft', 'solar', 'soldier', 'solid', 'solution', 'solve', 'someone', 'song', 'soon', 'sorry', 'sort', 'soul', 'sound', 'soup', 'source', 'south', 'space', 'spare', 'spatial', 'spawn', 'speak', 'special', 'speed', 'spell', 'spend', 'sphere', 'spice', 'spider', 'spike', 'spin', 'spirit', 'split', 'spoil', 'sponsor', 'spoon', 'sport', 'spot', 'spray', 'spread', 'spring', 'spy', 'square', 'squeeze', 'squirrel', 'stable', 'stadium', 'staff', 'stage', 'stairs', 'stamp', 'stand', 'start', 'state', 'stay', 'steak', 'steel', 'stem', 'step', 'stereo', 'stick', 'still', 'sting', 'stock', 'stomach', 'stone', 'stool', 'story', 'stove', 'strategy', 'street', 'strike', 'strong', 'struggle', 'student', 'stuff', 'stumble', 'style', 'subject', 'submit', 'subway', 'success', 'such', 'sudden', 'suffer', 'sugar', 'suggest', 'suit', 'summer', 'sun', 'sunny', 'sunset', 'super', 'supply', 'supreme', 'sure', 'surface', 'surge', 'surprise', 'surround', 'survey', 'suspect', 'sustain', 'swallow', 'swamp', 'swap', 'swarm', 'swear', 'sweet', 'swift', 'swim', 'swing', 'switch', 'sword', 'symbol', 'symptom', 'syrup', 'system', 'table', 'tackle', 'tag', 'tail', 'talent', 'talk', 'tank', 'tape', 'target', 'task', 'taste', 'tattoo', 'taxi', 'teach', 'team', 'tell', 'ten', 'tenant', 'tennis', 'tent', 'term', 'test', 'text', 'thank', 'that', 'theme', 'then', 'theory', 'there', 'they', 'thing', 'this', 'thought', 'three', 'thrive', 'throw', 'thumb', 'thunder', 'ticket', 'tide', 'tiger', 'tilt', 'timber', 'time', 'tiny', 'tip', 'tired', 'tissue', 'title', 'toast', 'tobacco', 'today', 'toddler', 'toe', 'together', 'toilet', 'token', 'tomato', 'tomorrow', 'tone', 'tongue', 'tonight', 'tool', 'tooth', 'top', 'topic', 'topple', 'torch', 'tornado', 'tortoise', 'toss', 'total', 'tourist', 'toward', 'tower', 'town', 'toy', 'track', 'trade', 'traffic', 'tragic', 'train', 'transfer', 'trap', 'trash', 'travel', 'tray', 'treat', 'tree', 'trend', 'trial', 'tribe', 'trick', 'trigger', 'trim', 'trip', 'trophy', 'trouble', 'truck', 'true', 'truly', 'trumpet', 'trust', 'truth', 'try', 'tube', 'tuition', 'tumble', 'tuna', 'tunnel', 'turkey', 'turn', 'turtle', 'twelve', 'twenty', 'twice', 'twin', 'twist', 'two', 'type', 'typical', 'ugly', 'umbrella', 'unable', 'unaware', 'uncle', 'uncover', 'under', 'undo', 'unfair', 'unfold', 'unhappy', 'uniform', 'unique', 'unit', 'universe', 'unknown', 'unlock', 'until', 'unusual', 'unveil', 'update', 'upgrade', 'uphold', 'upon', 'upper', 'upset', 'urban', 'urge', 'usage', 'use', 'used', 'useful', 'useless', 'usual', 'utility', 'vacant', 'vacuum', 'vague', 'valid', 'valley', 'valve', 'van', 'vanish', 'vapor', 'various', 'vast', 'vault', 'vehicle', 'velvet', 'vendor', 'venture', 'venue', 'verb', 'verify', 'version', 'very', 'vessel', 'veteran', 'viable', 'vibrant', 'vicious', 'victory', 'video', 'view', 'village', 'vintage', 'violin', 'virtual', 'virus', 'visa', 'visit', 'visual', 'vital', 'vivid', 'vocal', 'voice', 'void', 'volcano', 'volume', 'vote', 'voyage', 'wage', 'wagon', 'wait', 'walk', 'wall', 'walnut', 'want', 'warfare', 'warm', 'warrior', 'wash', 'wasp', 'waste', 'water', 'wave', 'way', 'wealth', 'weapon', 'wear', 'weasel', 'weather', 'web', 'wedding', 'weekend', 'weird', 'welcome', 'west', 'wet', 'whale', 'what', 'wheat', 'wheel', 'when', 'where', 'whip', 'whisper', 'wide', 'width', 'wife', 'wild', 'will', 'win', 'window', 'wine', 'wing', 'wink', 'winner', 'winter', 'wire', 'wisdom', 'wise', 'wish', 'witness', 'wolf', 'woman', 'wonder', 'wood', 'wool', 'word', 'work', 'world', 'worry', 'worth', 'wrap', 'wreck', 'wrestle', 'wrist', 'write', 'wrong', 'yard', 'year', 'yellow', 'you', 'young', 'youth', 'zebra', 'zero', 'zone', 'zoo'];
MnemonicUtils.DEFAULT_WORDLIST = MnemonicUtils.ENGLISH_WORDLIST;

/**
 * @enum {number}
 */
MnemonicUtils.MnemonicType = {
    UNKNOWN: -1,
    LEGACY: 0,
    BIP39: 1,
};

Object.freeze(MnemonicUtils);

Class.register(MnemonicUtils);

/*
bitcoinjs/bip39 LICENSE
Copyright (c) 2014, Wei Lu <luwei.here@gmail.com> and Daniel Cousens <email@dcousens.com>
Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.
THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
*/

class StringUtils {
    /**
     * @param {string} str
     * @returns {boolean}
     */
    static isMultibyte(str) {
        return /[\uD800-\uDFFF]/.test(str);
    }

    /**
     * @param {string} str
     * @returns {boolean}
     */
    static isHex(str) {
        return /^[0-9A-Fa-f]*$/.test(str);
    }

    /**
     * @param {string} str
     * @param {number} [length]
     * @returns {boolean}
     */
    static isHexBytes(str, length) {
        if (!StringUtils.isHex(str)) return false;
        if (str.length % 2 !== 0) return false;
        if (typeof length === 'number' && str.length / 2 !== length) return false;
        return true;
    }

    /**
     * @param {string} str1
     * @param {string} str2
     * @returns {string}
     */
    static commonPrefix(str1, str2) {
        let i = 0;
        for (; i < str1.length; ++i) {
            if (str1[i] !== str2[i]) break;
        }
        return str1.substr(0, i);
    }

    /**
     * @param {string} str
     * @param {string} padString
     * @param {number} length
     * @return {string}
     */
    static lpad(str, padString, length) {
        while (str.length < length) str = padString + str;
        return str;
    }

}
Class.register(StringUtils);

class Policy {
    /**
     * Convert Nimiq decimal to Number of Satoshis.
     * @param {number} coins Nimiq count in decimal
     * @return {number} Number of Lunas
     */
    static coinsToLunas(coins) {
        return Math.round(coins * Policy.LUNAS_PER_COIN);
    }

    /**
     * Convert Number of Satoshis to Nimiq decimal.
     * @param {number} lunas Number of Lunas.
     * @return {number} Nimiq count in decimal.
     */
    static lunasToCoins(lunas) {
        return lunas / Policy.LUNAS_PER_COIN;
    }

    /**
     * @deprecated Use coinsToLunas instead
     * @param {number} coins Nimiq count in decimal
     * @return {number} Number of Satoshis (Lunas)
     */
    static coinsToSatoshis(coins) {
        return Policy.coinsToLunas(coins);
    }

    /**
     * @deprecated Use lunasToCoins instead
     * @param {number} lunas Number of Lunas.
     * @return {number} Nimiq count in decimal.
     */
    static satoshisToCoins(satoshis) {
        return Policy.lunasToCoins(satoshis);
    }

    /**
     * @deprecated Use LUNAS_PER_COIN instead
     * @type {number}
     * @constant
     */
    static get SATOSHIS_PER_COIN() {
        return Policy.LUNAS_PER_COIN;
    }

    /**
     * Circulating supply after block.
     * @param {number} blockHeight
     * @return {number}
     */
    static supplyAfter(blockHeight) {
        // Calculate last entry in supply cache that is below blockHeight.
        let startHeight = Math.floor(blockHeight / Policy._supplyCacheInterval) * Policy._supplyCacheInterval;
        startHeight = Math.max(0, Math.min(startHeight, Policy._supplyCacheMax));

        // Calculate respective block for the last entry of the cache and the targeted height.
        const startI = startHeight / Policy._supplyCacheInterval;
        const endI = Math.floor(blockHeight / Policy._supplyCacheInterval);

        // The starting supply is the initial supply at the beginning and a cached value afterwards.
        let supply = startHeight === 0 ? Policy.INITIAL_SUPPLY : Policy._supplyCache.get(startHeight);
        // Use and update cache.
        for (let i = startI; i < endI; ++i) {
            startHeight = i * Policy._supplyCacheInterval;
            // Since the cache stores the supply *before* a certain block, subtract one.
            const endHeight = (i + 1) * Policy._supplyCacheInterval - 1;
            supply = Policy._supplyAfter(supply, endHeight, startHeight);
            // Don't forget to add one again.
            Policy._supplyCache.set(endHeight + 1, supply);
            Policy._supplyCacheMax = endHeight + 1;
        }

        // Calculate remaining supply (this also adds the block reward for endI*interval).
        return Policy._supplyAfter(supply, blockHeight, endI * Policy._supplyCacheInterval);
    }

    /**
     * Circulating supply after block.
     * @param {number} initialSupply
     * @param {number} blockHeight
     * @param {number} [startHeight]
     * @return {number}
     */
    static _supplyAfter(initialSupply, blockHeight, startHeight=0) {
        let supply = initialSupply;
        for (let i = startHeight; i <= blockHeight; ++i) {
            supply += Policy._blockRewardAt(supply, i);
        }
        return supply;
    }

    /**
     * Miner reward per block.
     * @param {number} blockHeight
     * @return {number}
     */
    static blockRewardAt(blockHeight) {
        const currentSupply = Policy.supplyAfter(blockHeight - 1);
        return Policy._blockRewardAt(currentSupply, blockHeight);
    }

    /**
     * Miner reward per block.
     * @param {number} currentSupply
     * @param {number} blockHeight
     * @return {number}
     */
    static _blockRewardAt(currentSupply, blockHeight) {
        if (blockHeight <= 0) return 0;
        const remaining = Policy.TOTAL_SUPPLY - currentSupply;
        if (blockHeight >= Policy.EMISSION_TAIL_START && remaining >= Policy.EMISSION_TAIL_REWARD) {
            return Policy.EMISSION_TAIL_REWARD;
        }
        const remainder = remaining % Policy.EMISSION_SPEED;
        return (remaining - remainder) / Policy.EMISSION_SPEED;
    }
}

/**
 * Targeted block time in seconds.
 * @type {number}
 * @constant
 */
Policy.BLOCK_TIME = 60;

/**
 * Maximum block size in bytes.
 * @type {number}
 * @constant
 */
Policy.BLOCK_SIZE_MAX = 1e5; // 100 kb

/**
 * The highest (easiest) block PoW target.
 * @type {BigNumber}
 * @constant
 */
Policy.BLOCK_TARGET_MAX = new BigNumber(2).pow(240);

/**
 * Number of blocks we take into account to calculate next difficulty.
 * @type {number}
 * @constant
 */
Policy.DIFFICULTY_BLOCK_WINDOW = 120;

/**
 * Limits the rate at which the difficulty is adjusted min/max.
 * @type {number}
 * @constant
 */
Policy.DIFFICULTY_MAX_ADJUSTMENT_FACTOR = 2;

/**
 * Number of blocks a transaction is valid.
 * @type {number}
 * @constant
 */
Policy.TRANSACTION_VALIDITY_WINDOW = 120;


/* Supply & Emission Parameters */

/**
 * Number of Satoshis per Nimiq.
 * @type {number}
 * @constant
 */
Policy.LUNAS_PER_COIN = 1e5;

/**
 * Targeted total supply in lunas.
 * @type {number}
 * @constant
 */
Policy.TOTAL_SUPPLY = 21e14;

/**
 * Initial supply before genesis block in lunas.
 * @type {number}
 * @constant
 */
Policy.INITIAL_SUPPLY = 252000000000000;

/**
 * Emission speed.
 * @type {number}
 * @constant
 */
Policy.EMISSION_SPEED = Math.pow(2, 22);

/**
 * First block using constant tail emission until total supply is reached.
 * @type {number}
 * @constant
 */
Policy.EMISSION_TAIL_START = 48692960;

/**
 * Constant tail emission in lunas until total supply is reached.
 * @type {number}
 * @constant
 */
Policy.EMISSION_TAIL_REWARD = 4000;

/* Security parameters */

/**
 * NIPoPoW Security parameter M
 * FIXME naming
 * @type {number}
 * @constant
 */
Policy.M = 240;

/**
 * NIPoPoW Security parameter K
 * FIXME naming
 * @type {number}
 * @constant
 */
Policy.K = 120;

/**
 * NIPoPoW Security parameter DELTA
 * FIXME naming
 * @type {number}
 * @constant
 */
Policy.DELTA = 0.15;

/**
 * Number of blocks the light client downloads to verify the AccountsTree construction.
 * FIXME naming
 * @type {number}
 * @constant
 */
Policy.NUM_BLOCKS_VERIFICATION = 250;


/* Snapshot Parameters */

/**
 * Maximum number of snapshots.
 * @type {number}
 * @constant
 */
Policy.NUM_SNAPSHOTS_MAX = 20;


/**
 * Stores the circulating supply before the given block.
 * @type {Map.<number, number>}
 * @private
 */
Policy._supplyCache = new Map();
Policy._supplyCacheMax = 0; // blocks
Policy._supplyCacheInterval = 5000; // blocks
Class.register(Policy);

/**
 * @abstract
 */
class Serializable {
    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof Serializable && BufferUtils.equals(this.serialize(), o.serialize());
    }

    /**
     * @param {Serializable} o
     * @return {number} negative if this is smaller than o, positive if this is larger than o, zero if equal.
     */
    compare(o) {
        return BufferUtils.compare(this.serialize(), o.serialize());
    }

    hashCode() {
        return this.toBase64();
    }

    /**
     * @abstract
     * @param {SerialBuffer} [buf]
     */
    serialize(buf) {}

    /**
     * @return {string}
     */
    toString() {
        return this.toBase64();
    }

    /**
     * @return {string}
     */
    toBase64() {
        return BufferUtils.toBase64(this.serialize());
    }

    /**
     * @return {string}
     */
    toHex() {
        return BufferUtils.toHex(this.serialize());
    }
}

Class.register(Serializable);

class Hash extends Serializable {
    /**
     * @param {?Uint8Array} arg
     * @param {Hash.Algorithm} [algorithm]
     * @private
     */
    constructor(arg, algorithm = Hash.Algorithm.BLAKE2B) {
        if (arg === null) {
            arg = new Uint8Array(Hash.getSize(algorithm));
        } else {
            if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
            if (arg.length !== Hash.getSize(algorithm)) throw new Error('Primitive: Invalid length');
        }
        super();
        this._obj = arg;
        /** @type {Hash.Algorithm} */
        this._algorithm = algorithm;
    }

    /**
     * @deprecated
     * @param {Uint8Array} arr
     * @returns {Hash}
     */
    static light(arr) {
        return Hash.blake2b(arr);
    }

    /**
     * @param {Uint8Array} arr
     * @returns {Hash}
     */
    static blake2b(arr) {
        return new Hash(Hash.computeBlake2b(arr), Hash.Algorithm.BLAKE2B);
    }

    /**
     * @param {Uint8Array} arr
     * @deprecated
     * @returns {Promise.<Hash>}
     */
    static hard(arr) {
        return Hash.argon2d(arr);
    }

    /**
     * @param {Uint8Array} arr
     * @returns {Promise.<Hash>}
     */
    static async argon2d(arr) {
        return new Hash(await (await CryptoWorker.getInstanceAsync()).computeArgon2d(arr), Hash.Algorithm.ARGON2D);
    }

    /**
     * @param {Uint8Array} arr
     * @returns {Hash}
     */
    static sha256(arr) {
        return new Hash(Hash.computeSha256(arr), Hash.Algorithm.SHA256);
    }

    /**
     * @param {Uint8Array} arr
     * @returns {Hash}
     */
    static sha512(arr) {
        return new Hash(Hash.computeSha512(arr), Hash.Algorithm.SHA512);
    }

    /**
     * @param {Uint8Array} arr
     * @param {Hash.Algorithm} algorithm
     * @returns {Hash}
     */
    static compute(arr, algorithm) {
        // !! The algorithms supported by this function are the allowed hash algorithms for HTLCs !!
        switch (algorithm) {
            case Hash.Algorithm.BLAKE2B: return Hash.blake2b(arr);
            case Hash.Algorithm.SHA256: return Hash.sha256(arr);
            // Hash.Algorithm.SHA512 postponed until hard-fork
            // Hash.Algorithm.ARGON2 intentionally omitted
            default: throw new Error('Invalid hash algorithm');
        }
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Hash.Algorithm} [algorithm]
     * @returns {Hash}
     */
    static unserialize(buf, algorithm = Hash.Algorithm.BLAKE2B) {
        return new Hash(buf.read(Hash.getSize(algorithm)), algorithm);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /**
     * @param {number} begin
     * @param {number} end
     * @returns {Uint8Array}
     */
    subarray(begin, end) {
        return this._obj.subarray(begin, end);
    }

    /** @type {number} */
    get serializedSize() {
        return Hash.SIZE.get(this._algorithm);
    }

    /** @type {Uint8Array} */
    get array() {
        return this._obj;
    }

    /** @type {Hash.Algorithm} */
    get algorithm() {
        return this._algorithm;
    }

    /**
     * @param {Serializable} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof Hash && o._algorithm === this._algorithm && super.equals(o);
    }

    /**
     * @param {Hash|Uint8Array|string} hash
     * @param {Hash.Algorithm} algorithm
     * @return {Hash}
     */
    static fromAny(hash, algorithm = Hash.Algorithm.BLAKE2B) {
        if (hash instanceof Hash) return hash;
        try {
            return new Hash(BufferUtils.fromAny(hash, Hash.SIZE.get(algorithm)), algorithm);
        } catch (e) {
            throw new Error('Invalid hash format');
        }
    }

    /**
     * @returns {string}
     */
    toPlain() {
        return this.toHex();
    }

    /**
     * @param {string} base64
     * @returns {Hash}
     */
    static fromBase64(base64) {
        return new Hash(BufferUtils.fromBase64(base64));
    }

    /**
     * @param {string} hex
     * @returns {Hash}
     */
    static fromHex(hex) {
        return new Hash(BufferUtils.fromHex(hex));
    }

    /**
     * @param {string} str
     * @returns {Hash}
     */
    static fromPlain(str) {
        return Hash.fromString(str);
    }

    /**
     * @param {string} str
     * @returns {Hash}
     */
    static fromString(str) {
        try {
            return Hash.fromHex(str);
        } catch (e) {
            // Ignore
        }

        try {
            return Hash.fromBase64(str);
        } catch (e) {
            // Ignore
        }

        throw new Error('Invalid hash format');
    }

    /**
     * @param {Hash} o
     * @returns {boolean}
     */
    static isHash(o) {
        return o instanceof Hash;
    }

    /**
     * @param {Hash.Algorithm} algorithm
     * @returns {number}
     */
    static getSize(algorithm) {
        const size = Hash.SIZE.get(algorithm);
        if (typeof size !== 'number') throw new Error('Invalid hash algorithm');
        return size;
    }

    /**
     * @param {Uint8Array} input
     * @returns {Uint8Array}
     */
    static computeBlake2b(input) {
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(Hash.getSize(Hash.Algorithm.BLAKE2B));
            NodeNative.node_blake2(out, new Uint8Array(input));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const hashSize = Hash.getSize(Hash.Algorithm.BLAKE2B);
                const wasmOut = Module.stackAlloc(hashSize);
                const wasmIn = Module.stackAlloc(input.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, input.length).set(input);
                const res = Module._nimiq_blake2(wasmOut, wasmIn, input.length);
                if (res !== 0) {
                    throw res;
                }
                const hash = new Uint8Array(hashSize);
                hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hashSize));
                return hash;
            } catch (e) {
                Log.w(Hash, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} input
     * @returns {Uint8Array}
     */
    static computeSha256(input) {
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(Hash.getSize(Hash.Algorithm.SHA256));
            NodeNative.node_sha256(out, new Uint8Array(input));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const hashSize = Hash.getSize(Hash.Algorithm.SHA256);
                const wasmOut = Module.stackAlloc(hashSize);
                const wasmIn = Module.stackAlloc(input.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, input.length).set(input);
                Module._nimiq_sha256(wasmOut, wasmIn, input.length);
                const hash = new Uint8Array(hashSize);
                hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hashSize));
                return hash;
            } catch (e) {
                Log.w(Hash, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} input
     * @returns {Uint8Array}
     */
    static computeSha512(input) {
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(Hash.getSize(Hash.Algorithm.SHA512));
            NodeNative.node_sha512(out, new Uint8Array(input));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const hashSize = Hash.getSize(Hash.Algorithm.SHA512);
                const wasmOut = Module.stackAlloc(hashSize);
                const wasmIn = Module.stackAlloc(input.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, input.length).set(input);
                Module._nimiq_sha512(wasmOut, wasmIn, input.length);
                const hash = new Uint8Array(hashSize);
                hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hashSize));
                return hash;
            } catch (e) {
                Log.w(Hash, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

/**
 * @enum {number}
 */
Hash.Algorithm = {
    BLAKE2B: 1,
    ARGON2D: 2,
    SHA256: 3,
    SHA512: 4
};
/**
 * @param {Hash.Algorithm} hashAlgorithm
 * @return {string}
 */
Hash.Algorithm.toString = function(hashAlgorithm) {
    switch (hashAlgorithm) {
        case Hash.Algorithm.BLAKE2B: return 'blake2b';
        case Hash.Algorithm.ARGON2D: return 'argon2d';
        case Hash.Algorithm.SHA256: return 'sha256';
        case Hash.Algorithm.SHA512: return 'sha512';
    }
    throw new Error('Invalid hash algorithm');
};

/**
 * @type {Map<Hash.Algorithm, number>}
 */
Hash.SIZE = new Map();
Hash.SIZE.set(Hash.Algorithm.BLAKE2B, 32);
Hash.SIZE.set(Hash.Algorithm.ARGON2D, 32);
Hash.SIZE.set(Hash.Algorithm.SHA256, 32);
Hash.SIZE.set(Hash.Algorithm.SHA512, 64);

Hash.NULL = new Hash(new Uint8Array(32));
Class.register(Hash);

class Secret extends Serializable {
    /**
     * @param {Secret.Type} type
     * @param {number} purposeId
     */
    constructor(type, purposeId) {
        super();
        this._type = type;
        this._purposeId = purposeId;
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Uint8Array} key
     * @return {Promise.<PrivateKey|Entropy>}
     */
    static fromEncrypted(buf, key) {
        const version = buf.readUint8();

        const roundsLog = buf.readUint8();
        if (roundsLog > 32) throw new Error('Rounds out-of-bounds');
        const rounds = Math.pow(2, roundsLog);

        switch (version) {
            case 1:
                return Secret._decryptV1(buf, key, rounds);
            case 2:
                return Secret._decryptV2(buf, key, rounds);
            case 3:
                return Secret._decryptV3(buf, key, rounds);
            default:
                throw new Error('Unsupported version');
        }
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Uint8Array} key
     * @param {number} rounds
     * @returns {Promise.<PrivateKey>}
     * @private
     */
    static async _decryptV1(buf, key, rounds) {
        const ciphertext = buf.read(Secret.SIZE);
        const salt = buf.read(Secret.ENCRYPTION_SALT_SIZE);
        const check = buf.read(Secret.ENCRYPTION_CHECKSUM_SIZE);
        const plaintext = await CryptoUtils.otpKdfLegacy(ciphertext, key, salt, rounds);

        const privateKey = new PrivateKey(plaintext);
        const publicKey = PublicKey.derive(privateKey);
        const checksum = publicKey.hash().subarray(0, Secret.ENCRYPTION_CHECKSUM_SIZE);
        if (!BufferUtils.equals(check, checksum)) {
            throw new Error('Invalid key');
        }

        return privateKey;
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Uint8Array} key
     * @param {number} rounds
     * @returns {Promise.<PrivateKey>}
     * @private
     */
    static async _decryptV2(buf, key, rounds) {
        const ciphertext = buf.read(Secret.SIZE);
        const salt = buf.read(Secret.ENCRYPTION_SALT_SIZE);
        const check = buf.read(Secret.ENCRYPTION_CHECKSUM_SIZE);
        const plaintext = await CryptoUtils.otpKdfLegacy(ciphertext, key, salt, rounds);

        const checksum = Hash.computeBlake2b(plaintext).subarray(0, Secret.ENCRYPTION_CHECKSUM_SIZE);
        if (!BufferUtils.equals(check, checksum)) {
            throw new Error('Invalid key');
        }

        return new PrivateKey(plaintext);
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Uint8Array} key
     * @param {number} rounds
     * @returns {Promise.<PrivateKey|Entropy>}
     * @private
     */
    static async _decryptV3(buf, key, rounds) {
        const salt = buf.read(Secret.ENCRYPTION_SALT_SIZE);
        const ciphertext = buf.read(Secret.ENCRYPTION_CHECKSUM_SIZE_V3 + /*purposeId*/ 4 + Secret.SIZE);
        const plaintext = await CryptoUtils.otpKdf(ciphertext, key, salt, rounds);

        const check = plaintext.subarray(0, Secret.ENCRYPTION_CHECKSUM_SIZE_V3);
        const payload = plaintext.subarray(Secret.ENCRYPTION_CHECKSUM_SIZE_V3);
        const checksum = Hash.computeBlake2b(payload).subarray(0, Secret.ENCRYPTION_CHECKSUM_SIZE_V3);
        if (!BufferUtils.equals(check, checksum)) {
            throw new Error('Invalid key');
        }

        const purposeId = payload[0] << 24 | payload[1] << 16 | payload[2] << 8 | payload[3];
        const secret = payload.subarray(4);
        switch (purposeId) {
            case PrivateKey.PURPOSE_ID:
                return new PrivateKey(secret);
            case Entropy.PURPOSE_ID:
            default:
                return new Entropy(secret);
        }
    }

    /**
     * @param {Uint8Array} key
     * @return {Promise.<SerialBuffer>}
     */
    async exportEncrypted(key) {
        const salt = new Uint8Array(Secret.ENCRYPTION_SALT_SIZE);
        CryptoWorker.lib.getRandomValues(salt);

        const data = new SerialBuffer(/*purposeId*/ 4 + Secret.SIZE);
        data.writeUint32(this._purposeId);
        data.write(this.serialize());

        const checksum = Hash.computeBlake2b(data).subarray(0, Secret.ENCRYPTION_CHECKSUM_SIZE_V3);
        const plaintext = new SerialBuffer(checksum.byteLength + data.byteLength);
        plaintext.write(checksum);
        plaintext.write(data);
        const ciphertext = await CryptoUtils.otpKdf(plaintext, key, salt, Secret.ENCRYPTION_KDF_ROUNDS);

        const buf = new SerialBuffer(/*version*/ 1 + /*kdf rounds*/ 1 + salt.byteLength + ciphertext.byteLength);
        buf.writeUint8(3); // version
        buf.writeUint8(Math.log2(Secret.ENCRYPTION_KDF_ROUNDS));
        buf.write(salt);
        buf.write(ciphertext);

        return buf;
    }

    /** @type {number} */
    get encryptedSize() {
        return /*version*/ 1
            + /*kdf rounds*/ 1
            + Secret.ENCRYPTION_SALT_SIZE
            + Secret.ENCRYPTION_CHECKSUM_SIZE_V3
            + /*purposeId*/ 4
            + Secret.SIZE;
    }

    /** @type {Secret.Type} */
    get type() {
        return this._type;
    }
}

Secret.Type = {
    PRIVATE_KEY: 1,
    ENTROPY: 2
};
Secret.SIZE = 32;

Secret.ENCRYPTION_SALT_SIZE = 16;
Secret.ENCRYPTION_KDF_ROUNDS = 256;
Secret.ENCRYPTION_CHECKSUM_SIZE = 4;
Secret.ENCRYPTION_CHECKSUM_SIZE_V3 = 2;

Class.register(Secret);

class PrivateKey extends Secret {
    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super(Secret.Type.PRIVATE_KEY, PrivateKey.PURPOSE_ID);
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== PrivateKey.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @return {PrivateKey}
     */
    static generate() {
        const privateKey = new Uint8Array(PrivateKey.SIZE);
        CryptoWorker.lib.getRandomValues(privateKey);
        return new PrivateKey(privateKey);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {PrivateKey}
     */
    static unserialize(buf) {
        return new PrivateKey(buf.read(PrivateKey.SIZE));
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return PrivateKey.SIZE;
    }

    /**
     * Overwrite this private key with a replacement in-memory
     * @param {PrivateKey} privateKey
     */
    overwrite(privateKey) {
        this._obj.set(privateKey._obj);
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof PrivateKey && super.equals(o);
    }

    /**
     * @param {Uint8Array} privateKey
     * @param {Uint8Array} publicKey
     * @param {Uint8Array} publicKeysHash
     * @returns {Uint8Array}
     */
    static _privateKeyDelinearize(privateKey, publicKey, publicKeysHash) {
        if (privateKey.byteLength !== PrivateKey.SIZE
            || publicKey.byteLength !== PublicKey.SIZE
            || publicKeysHash.byteLength !== Hash.getSize(Hash.Algorithm.SHA512)) {
            throw Error('Wrong buffer size.');
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PublicKey.SIZE);
            NodeNative.node_ed25519_derive_delinearized_private_key(out, new Uint8Array(publicKeysHash), new Uint8Array(publicKey), new Uint8Array(privateKey));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(PublicKey.SIZE);
                const wasmInPrivateKey = Module.stackAlloc(privateKey.length);
                const wasmInPublicKey = Module.stackAlloc(publicKey.length);
                const wasmInPublicKeysHash = Module.stackAlloc(publicKeysHash.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPrivateKey, privateKey.length).set(privateKey);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKey, publicKey.length).set(publicKey);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKeysHash, publicKeysHash.length).set(publicKeysHash);
                Module._ed25519_derive_delinearized_private_key(wasmOut, wasmInPublicKeysHash, wasmInPublicKey, wasmInPrivateKey);
                const delinearizedPrivateKey = new Uint8Array(PrivateKey.SIZE);
                delinearizedPrivateKey.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, PrivateKey.SIZE));
                return delinearizedPrivateKey;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

PrivateKey.SIZE = Secret.SIZE;
PrivateKey.PURPOSE_ID = 0x42000001;

Class.register(PrivateKey);

class PublicKey extends Serializable {
    /**
     * @param {PublicKey} o
     * @returns {PublicKey}
     */
    static copy(o) {
        if (!o) return o;
        return new PublicKey(new Uint8Array(o._obj));
    }

    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== PublicKey.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @param {PrivateKey} privateKey
     * @return {PublicKey}
     */
    static derive(privateKey) {
        return new PublicKey(PublicKey._publicKeyDerive(privateKey._obj));
    }

    /**
     * @param {Array.<PublicKey>} publicKeys
     * @return {PublicKey}
     */
    static sum(publicKeys) {
        publicKeys = publicKeys.slice();
        publicKeys.sort((a, b) => a.compare(b));
        return PublicKey._delinearizeAndAggregatePublicKeys(publicKeys);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {PublicKey}
     */
    static unserialize(buf) {
        return new PublicKey(buf.read(PublicKey.SIZE));
    }

    /**
     * @param {PublicKey|Uint8Array|string} o
     * @return {PublicKey}
     */
    static fromAny(o) {
        if (!o) throw new Error('Invalid public key format');
        if (o instanceof PublicKey) return o;
        try {
            return new PublicKey(BufferUtils.fromAny(o, PublicKey.SIZE));
        } catch (e) {
            throw new Error('Invalid public key format');
        }
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return PublicKey.SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof PublicKey && super.equals(o);
    }

    /**
     * @return {Hash}
     */
    hash() {
        return Hash.light(this.serialize());
    }

    /**
     * @param {PublicKey} o
     * @return {number}
     */
    compare(o) {
        return BufferUtils.compare(this._obj, o._obj);
    }

    /**
     * @return {Address}
     */
    toAddress() {
        return Address.fromHash(this.hash());
    }

    /**
     * @return {PeerId}
     */
    toPeerId() {
        return new PeerId(this.hash().subarray(0, 16));
    }

    /**
     * @param {Array.<PublicKey>} publicKeys
     * @returns {PublicKey}
     */
    static _delinearizeAndAggregatePublicKeys(publicKeys) {
        const publicKeysObj = publicKeys.map(k => k.serialize());
        const publicKeysHash = PublicKey._publicKeysHash(publicKeysObj);
        const raw = PublicKey._publicKeysDelinearizeAndAggregate(publicKeysObj, publicKeysHash);
        return new PublicKey(raw);
    }

    /**
     * @param {Uint8Array} privateKey
     * @returns {Uint8Array}
     */
    static _publicKeyDerive(privateKey) {
        if (privateKey.byteLength !== PrivateKey.SIZE) {
            throw Error('Wrong buffer size.');
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PublicKey.SIZE);
            NodeNative.node_ed25519_public_key_derive(out, new Uint8Array(privateKey));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(PublicKey.SIZE);
                const pubKeyBuffer = new Uint8Array(Module.HEAP8.buffer, wasmOut, PrivateKey.SIZE);
                pubKeyBuffer.set(privateKey);
                const wasmIn = Module.stackAlloc(privateKey.length);
                const privKeyBuffer = new Uint8Array(Module.HEAP8.buffer, wasmIn, PrivateKey.SIZE);
                privKeyBuffer.set(privateKey);

                Module._ed25519_public_key_derive(wasmOut, wasmIn);
                privKeyBuffer.fill(0);
                const publicKey = new Uint8Array(PublicKey.SIZE);
                publicKey.set(pubKeyBuffer);
                return publicKey;
            } catch (e) {
                Log.w(PublicKey, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Array.<Uint8Array>} publicKeys
     * @returns {Uint8Array}
     */
    static _publicKeysHash(publicKeys) {
        if (publicKeys.some(publicKey => publicKey.byteLength !== PublicKey.SIZE)) {
            throw Error('Wrong buffer size.');
        }
        const concatenatedPublicKeys = new Uint8Array(publicKeys.length * PublicKey.SIZE);
        for (let i = 0; i < publicKeys.length; ++i) {
            concatenatedPublicKeys.set(publicKeys[i], i * PublicKey.SIZE);
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(Hash.getSize(Hash.Algorithm.SHA512));
            NodeNative.node_ed25519_hash_public_keys(out, concatenatedPublicKeys, publicKeys.length);
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const hashSize = Hash.getSize(Hash.Algorithm.SHA512);
                const wasmOut = Module.stackAlloc(hashSize);
                const wasmInPublicKeys = Module.stackAlloc(concatenatedPublicKeys.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKeys, concatenatedPublicKeys.length).set(concatenatedPublicKeys);
                Module._ed25519_hash_public_keys(wasmOut, wasmInPublicKeys, publicKeys.length);
                const hashedPublicKey = new Uint8Array(hashSize);
                hashedPublicKey.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hashSize));
                return hashedPublicKey;
            } catch (e) {
                Log.w(PublicKey, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} publicKey
     * @param {Uint8Array} publicKeysHash
     * @returns {Uint8Array}
     */
    static _publicKeyDelinearize(publicKey, publicKeysHash) {
        if (publicKey.byteLength !== PublicKey.SIZE
            || publicKeysHash.byteLength !== Hash.getSize(Hash.Algorithm.SHA512)) {
            throw Error('Wrong buffer size.');
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PublicKey.SIZE);
            NodeNative.node_ed25519_delinearize_public_key(out, new Uint8Array(publicKeysHash), new Uint8Array(publicKey));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(PublicKey.SIZE);
                const wasmInPublicKey = Module.stackAlloc(publicKey.length);
                const wasmInPublicKeysHash = Module.stackAlloc(publicKeysHash.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKey, publicKey.length).set(publicKey);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKeysHash, publicKeysHash.length).set(publicKeysHash);
                Module._ed25519_delinearize_public_key(wasmOut, wasmInPublicKeysHash, wasmInPublicKey);
                const delinearizedPublicKey = new Uint8Array(PublicKey.SIZE);
                delinearizedPublicKey.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, PublicKey.SIZE));
                return delinearizedPublicKey;
            } catch (e) {
                Log.w(PublicKey, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Array.<Uint8Array>} publicKeys
     * @param {Uint8Array} publicKeysHash
     * @returns {Uint8Array}
     */
    static _publicKeysDelinearizeAndAggregate(publicKeys, publicKeysHash) {
        if (publicKeys.some(publicKey => publicKey.byteLength !== PublicKey.SIZE)
            || publicKeysHash.byteLength !== Hash.getSize(Hash.Algorithm.SHA512)) {
            throw Error('Wrong buffer size.');
        }
        const concatenatedPublicKeys = new Uint8Array(publicKeys.length * PublicKey.SIZE);
        for (let i = 0; i < publicKeys.length; ++i) {
            concatenatedPublicKeys.set(publicKeys[i], i * PublicKey.SIZE);
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PublicKey.SIZE);
            NodeNative.node_ed25519_aggregate_delinearized_public_keys(out, new Uint8Array(publicKeysHash), concatenatedPublicKeys, publicKeys.length);
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(PublicKey.SIZE);
                const wasmInPublicKeys = Module.stackAlloc(concatenatedPublicKeys.length);
                const wasmInPublicKeysHash = Module.stackAlloc(publicKeysHash.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKeys, concatenatedPublicKeys.length).set(concatenatedPublicKeys);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKeysHash, publicKeysHash.length).set(publicKeysHash);
                Module._ed25519_aggregate_delinearized_public_keys(wasmOut, wasmInPublicKeysHash, wasmInPublicKeys, publicKeys.length);
                const aggregatePublicKey = new Uint8Array(PublicKey.SIZE);
                aggregatePublicKey.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, PublicKey.SIZE));
                return aggregatePublicKey;
            } catch (e) {
                Log.w(PublicKey, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

PublicKey.SIZE = 32;

Class.register(PublicKey);

class KeyPair extends Serializable {
    /**
     * @param {PrivateKey} privateKey
     * @param {PublicKey} publicKey
     * @param {boolean} locked
     * @param {Uint8Array} lockSalt
     * @private
     */
    constructor(privateKey, publicKey, locked = false, lockSalt = null) {
        if (!(privateKey instanceof Object)) throw new Error('Primitive: Invalid type');
        if (!(publicKey instanceof Object)) throw new Error('Primitive: Invalid type');
        super();

        /** @type {boolean} */
        this._locked = locked;
        /** @type {boolean} */
        this._lockedInternally = locked;
        /** @type {Uint8Array} */
        this._lockSalt = lockSalt;
        /** @type {PublicKey} */
        this._publicKey = publicKey;
        /** @type {PrivateKey} */
        this._internalPrivateKey = new PrivateKey(privateKey.serialize());
    }

    /**
     * @return {KeyPair}
     */
    static generate() {
        const privateKey = PrivateKey.generate();
        return new KeyPair(privateKey, PublicKey.derive(privateKey));
    }

    /**
     * @param {PrivateKey} privateKey
     * @return {KeyPair}
     */
    static derive(privateKey) {
        return new KeyPair(privateKey, PublicKey.derive(privateKey));
    }

    /**
     * @param {string} hexBuf
     * @return {KeyPair}
     */
    static fromHex(hexBuf) {
        return KeyPair.unserialize(BufferUtils.fromHex(hexBuf));
    }

    /**
     * @param {SerialBuffer} buf
     * @return {KeyPair}
     */
    static unserialize(buf) {
        const privateKey = PrivateKey.unserialize(buf);
        const publicKey = PublicKey.unserialize(buf);
        let locked = false;
        let lockSalt = null;
        if (buf.readPos < buf.byteLength) {
            const extra = buf.readUint8();
            if (extra === 1) {
                locked = true;
                lockSalt = buf.read(32);
            }
        }
        return new KeyPair(privateKey, publicKey, locked, lockSalt);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._privateKey.serialize(buf);
        this.publicKey.serialize(buf);
        if (this._locked) {
            buf.writeUint8(1);
            buf.write(this._lockSalt);
        } else {
            buf.writeUint8(0);
        }
        return buf;
    }

    /**
     * The unlocked private key.
     * @type {PrivateKey}
     */
    get privateKey() {
        if (this.isLocked) throw new Error('KeyPair is locked');
        return this._privateKey;
    }

    /**
     * The private key in its current state, i.e., depending on this._locked.
     * If this._locked, it is the internally locked private key.
     * If !this._locked, it is either the internally unlocked private key (if !this._lockedInternally)
     * or this._unlockedPrivateKey.
     * @type {PrivateKey}
     */
    get _privateKey() {
        return this._unlockedPrivateKey || this._internalPrivateKey;
    }

    /** @type {PublicKey} */
    get publicKey() {
        return this._publicKey || (this._publicKey = new PublicKey(this._obj.publicKey));
    }

    /** @type {number} */
    get serializedSize() {
        return this._privateKey.serializedSize + this.publicKey.serializedSize + (this._locked ? this._lockSalt.byteLength + 1 : 1);
    }

    /**
     * @param {Uint8Array} key
     * @param {Uint8Array} [lockSalt]
     */
    async lock(key, lockSalt) {
        if (this._locked) throw new Error('KeyPair already locked');

        if (lockSalt) this._lockSalt = lockSalt;
        if (!this._lockSalt || this._lockSalt.length === 0) {
            this._lockSalt = new Uint8Array(32);
            CryptoWorker.lib.getRandomValues(this._lockSalt);
        }

        this._internalPrivateKey.overwrite(await this._otpPrivateKey(key));
        this._clearUnlockedPrivateKey();
        this._locked = true;
        this._lockedInternally = true;
    }

    /**
     * @param {Uint8Array} key
     */
    async unlock(key) {
        if (!this._locked) throw new Error('KeyPair not locked');

        const privateKey = await this._otpPrivateKey(key);
        const verifyPub = PublicKey.derive(privateKey);
        if (verifyPub.equals(this.publicKey)) {
            // Only set this._internalPrivateKey, but keep this._obj locked.
            this._unlockedPrivateKey = privateKey;
            this._locked = false;
        } else {
            throw new Error('Invalid key');
        }
    }

    /**
     * Destroy cached unlocked private key if the internal key is in locked state.
     */
    relock() {
        if (this._locked) throw new Error('KeyPair already locked');
        if (!this._lockedInternally) throw new Error('KeyPair was never locked');
        this._clearUnlockedPrivateKey();
        this._locked = true;
    }

    _clearUnlockedPrivateKey() {
        // If this wallet is not locked internally and unlocked, this method does not have any effect.
        if (!this._lockedInternally || this._locked) return;

        // Overwrite cached key in this._unlockedPrivateKey with 0s.
        this._unlockedPrivateKey.overwrite(PrivateKey.unserialize(new SerialBuffer(this._unlockedPrivateKey.serializedSize)));
        // Then, reset it.
        this._unlockedPrivateKey = null;
    }

    /**
     * @param {Uint8Array} key
     * @return {Promise<PrivateKey>}
     * @private
     */
    async _otpPrivateKey(key) {
        return new PrivateKey(await CryptoUtils.otpKdfLegacy(this._privateKey.serialize(), key, this._lockSalt, KeyPair.LOCK_KDF_ROUNDS));
    }

    get isLocked() {
        return this._locked;
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Uint8Array} key
     * @return {Promise.<KeyPair>}
     */
    static async fromEncrypted(buf, key) {
        const privateKey = await Secret.fromEncrypted(buf, key);
        if (privateKey.type !== Secret.Type.PRIVATE_KEY) throw new Error('Expected privateKey, got Entropy');
        return KeyPair.derive(privateKey);
    }

    /**
     * @param {Uint8Array} key
     * @return {Promise.<SerialBuffer>}
     */
    exportEncrypted(key) {
        return this._privateKey.exportEncrypted(key);
    }

    /** @type {number} */
    get encryptedSize() {
        return this._privateKey.encryptedSize;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof KeyPair && super.equals(o);
    }
}
KeyPair.LOCK_KDF_ROUNDS = 256;


Class.register(KeyPair);

class Entropy extends Secret {
    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super(Secret.Type.ENTROPY, Entropy.PURPOSE_ID);
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== Entropy.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @return {Entropy}
     */
    static generate() {
        const entropy = new Uint8Array(Entropy.SIZE);
        CryptoWorker.lib.getRandomValues(entropy);
        return new Entropy(entropy);
    }

    /**
     * @param {string} [password]
     * @param {Array.<string>} [wordlist]
     * @return {ExtendedPrivateKey}
     */
    toExtendedPrivateKey(password, wordlist) {
        return MnemonicUtils.mnemonicToExtendedPrivateKey(this.toMnemonic(wordlist), password);
    }

    /**
     * @param {Array.<string>} [wordlist]
     * @return {Array.<string>}
     */
    toMnemonic(wordlist) {
        return MnemonicUtils.entropyToMnemonic(this, wordlist);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Entropy}
     */
    static unserialize(buf) {
        return new Entropy(buf.read(Entropy.SIZE));
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return Entropy.SIZE;
    }

    /**
     * Overwrite this entropy with a replacement in-memory
     * @param {Entropy} entropy
     */
    overwrite(entropy) {
        this._obj.set(entropy._obj);
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof Entropy && super.equals(o);
    }
}

Entropy.SIZE = Secret.SIZE;
Entropy.PURPOSE_ID = 0x42000002;

Class.register(Entropy);

class ExtendedPrivateKey extends Serializable {
    /**
     * @param {PrivateKey} key
     * @param {Uint8Array} chainCode
     * @private
     */
    constructor(key, chainCode) {
        super();
        if (!(key instanceof PrivateKey)) throw new Error('ExtendedPrivateKey: Invalid key');
        if (!(chainCode instanceof Uint8Array)) throw new Error('ExtendedPrivateKey: Invalid chainCode');
        if (chainCode.length !== ExtendedPrivateKey.CHAIN_CODE_SIZE) throw new Error('ExtendedPrivateKey: Invalid chainCode length');
        this._key = key;
        this._chainCode = chainCode;
    }

    /**
     * @param {Uint8Array} seed
     * @return {ExtendedPrivateKey}
     */
    static generateMasterKey(seed) {
        const bCurve = BufferUtils.fromAscii('ed25519 seed');
        const hash = CryptoUtils.computeHmacSha512(bCurve, seed);
        return new ExtendedPrivateKey(new PrivateKey(hash.slice(0, 32)), hash.slice(32));
    }

    /**
     * @param {number} index
     * @return {ExtendedPrivateKey}
     */
    derive(index) {
        // Only hardened derivation is allowed for ed25519.
        if (index < 0x80000000) index += 0x80000000;

        const data = new SerialBuffer(1 + PrivateKey.SIZE + 4);
        data.writeUint8(0);
        this._key.serialize(data);
        data.writeUint32(index);

        const hash = CryptoUtils.computeHmacSha512(this._chainCode, data);
        return new ExtendedPrivateKey(new PrivateKey(hash.slice(0, 32)), hash.slice(32));
    }

    /**
     * @param {string} path
     * @return {boolean}
     */
    static isValidPath(path) {
        if (path.match(/^m(\/[0-9]+')*$/) === null) return false;

        // Overflow check.
        const segments = path.split('/');
        for (let i = 1; i < segments.length; i++) {
            if (!NumberUtils.isUint32(parseInt(segments[i]))) return false;
        }

        return true;
    }

    /**
     * @param {string} path
     * @return {ExtendedPrivateKey}
     */
    derivePath(path) {
        if (!ExtendedPrivateKey.isValidPath(path)) throw new Error('Invalid path');

        let extendedKey = this;
        const segments = path.split('/');
        for (let i = 1; i < segments.length; i++) {
            const index = parseInt(segments[i]);
            extendedKey = extendedKey.derive(index);
        }
        return extendedKey;
    }

    /**
     * @param {string} path
     * @param {Uint8Array} seed
     * @return {ExtendedPrivateKey}
     */
    static derivePathFromSeed(path, seed) {
        let extendedKey = ExtendedPrivateKey.generateMasterKey(seed);
        return extendedKey.derivePath(path);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {ExtendedPrivateKey}
     */
    static unserialize(buf) {
        const privateKey = PrivateKey.unserialize(buf);
        const chainCode = buf.read(ExtendedPrivateKey.CHAIN_CODE_SIZE);
        return new ExtendedPrivateKey(privateKey, chainCode);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._key.serialize(buf);
        buf.write(this._chainCode);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return this._key.serializedSize + ExtendedPrivateKey.CHAIN_CODE_SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof ExtendedPrivateKey && super.equals(o);
    }

    /**
     * @type {PrivateKey}
     */
    get privateKey() {
        return this._key;
    }

    /**
     * @return {Address}
     */
    toAddress() {
        return PublicKey.derive(this._key).toAddress();
    }
}

ExtendedPrivateKey.CHAIN_CODE_SIZE = 32;

Class.register(ExtendedPrivateKey);

class RandomSecret extends Serializable {
    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== RandomSecret.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {RandomSecret}
     */
    static unserialize(buf) {
        return new RandomSecret(buf.read(RandomSecret.SIZE));
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return RandomSecret.SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof RandomSecret && super.equals(o);
    }
}

RandomSecret.SIZE = 32;

Class.register(RandomSecret);

class Signature extends Serializable {
    /**
     * @param {Signature} o
     * @returns {Signature}
     */
    static copy(o) {
        if (!o) return o;
        // FIXME Move this to Crypto class.
        const obj = new Uint8Array(o._obj);
        return new Signature(obj);
    }

    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== Signature.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @param {PrivateKey} privateKey
     * @param {PublicKey} publicKey
     * @param {Uint8Array} data
     * @return {Signature}
     */
    static create(privateKey, publicKey, data) {
        return new Signature(Signature._signatureCreate(privateKey._obj, publicKey._obj, data));
    }

    /**
     * @param {Commitment} commitment
     * @param {Array.<PartialSignature>} signatures
     * @return {Signature}
     */
    static fromPartialSignatures(commitment, signatures) {
        const raw = Signature._combinePartialSignatures(commitment.serialize(), signatures.map(s => s.serialize()));
        return new Signature(raw);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Signature}
     */
    static unserialize(buf) {
        return new Signature(buf.read(Signature.SIZE));
    }

    /**
     * @param {Signature|Uint8Array|string} o
     * @return {Signature}
     */
    static fromAny(o) {
        if (!o) throw new Error('Invalid signature format');
        if (o instanceof Signature) return o;
        try {
            return new Signature(BufferUtils.fromAny(o, Signature.SIZE));
        } catch (e) {
            throw new Error('Invalid signature format');
        }
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return Signature.SIZE;
    }

    /**
     * @param {PublicKey} publicKey
     * @param {Uint8Array} data
     * @return {boolean}
     */
    verify(publicKey, data) {
        return Signature._signatureVerify(publicKey._obj, data, this._obj);
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof Signature && super.equals(o);
    }

    /**
     * @param {Uint8Array} combinedCommitment
     * @param {Array.<Uint8Array>} partialSignatures
     * @returns {Uint8Array}
     */
    static _combinePartialSignatures(combinedCommitment, partialSignatures) {
        const combinedSignature = Signature._aggregatePartialSignatures(partialSignatures);
        return BufferUtils.concatTypedArrays(combinedCommitment, combinedSignature);
    }

    /**
     * @param {Array.<Uint8Array>} partialSignatures
     * @returns {Uint8Array}
     */
    static _aggregatePartialSignatures(partialSignatures) {
        return partialSignatures.reduce((sigA, sigB) => Signature._scalarsAdd(sigA, sigB));
    }

    /**
     * @param {Uint8Array} a
     * @param {Uint8Array} b
     * @returns {Uint8Array}
     */
    static _scalarsAdd(a, b) {
        if (a.byteLength !== PartialSignature.SIZE || b.byteLength !== PartialSignature.SIZE) {
            throw Error('Wrong buffer size.');
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PartialSignature.SIZE);
            NodeNative.node_ed25519_add_scalars(out, new Uint8Array(a), new Uint8Array(b));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOutSum = Module.stackAlloc(PartialSignature.SIZE);
                const wasmInA = Module.stackAlloc(a.length);
                const wasmInB = Module.stackAlloc(b.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInA, a.length).set(a);
                new Uint8Array(Module.HEAPU8.buffer, wasmInB, b.length).set(b);
                Module._ed25519_add_scalars(wasmOutSum, wasmInA, wasmInB);
                const sum = new Uint8Array(PartialSignature.SIZE);
                sum.set(new Uint8Array(Module.HEAPU8.buffer, wasmOutSum, PartialSignature.SIZE));
                return sum;
            } catch (e) {
                Log.w(Signature, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} privateKey
     * @param {Uint8Array} publicKey
     * @param {Uint8Array} message
     * @returns {Uint8Array}
     */
    static _signatureCreate(privateKey, publicKey, message) {
        if (publicKey.byteLength !== PublicKey.SIZE
            || privateKey.byteLength !== PrivateKey.SIZE) {
            throw Error('Wrong buffer size.');
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(Signature.SIZE);
            NodeNative.node_ed25519_sign(out, new Uint8Array(message), new Uint8Array(publicKey), new Uint8Array(privateKey));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOutSignature = Module.stackAlloc(Signature.SIZE);
                const signatureBuffer = new Uint8Array(Module.HEAP8.buffer, wasmOutSignature, Signature.SIZE);
                const wasmInMessage = Module.stackAlloc(message.length);
                new Uint8Array(Module.HEAP8.buffer, wasmInMessage, message.length).set(message);
                const wasmInPubKey = Module.stackAlloc(publicKey.length);
                new Uint8Array(Module.HEAP8.buffer, wasmInPubKey, publicKey.length).set(publicKey);
                const wasmInPrivKey = Module.stackAlloc(privateKey.length);
                const privKeyBuffer = new Uint8Array(Module.HEAP8.buffer, wasmInPrivKey, privateKey.length);
                privKeyBuffer.set(privateKey);

                Module._ed25519_sign(wasmOutSignature, wasmInMessage, message.byteLength, wasmInPubKey, wasmInPrivKey);
                privKeyBuffer.fill(0);

                const signature = new Uint8Array(Signature.SIZE);
                signature.set(signatureBuffer);
                return signature;
            } catch (e) {
                Log.w(Signature, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }

    /**
     * @param {Uint8Array} publicKey
     * @param {Uint8Array} message
     * @param {Uint8Array} signature
     * @returns {boolean}
     */
    static _signatureVerify(publicKey, message, signature) {
        if (PlatformUtils.isNodeJs()) {
            return !!NodeNative.node_ed25519_verify(new Uint8Array(signature), new Uint8Array(message), new Uint8Array(publicKey));
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmInPubKey = Module.stackAlloc(publicKey.length);
                new Uint8Array(Module.HEAP8.buffer, wasmInPubKey, publicKey.length).set(publicKey);
                const wasmInMessage = Module.stackAlloc(message.length);
                new Uint8Array(Module.HEAP8.buffer, wasmInMessage, message.length).set(message);
                const wasmInSignature = Module.stackAlloc(signature.length);
                new Uint8Array(Module.HEAP8.buffer, wasmInSignature, signature.length).set(signature);

                return !!Module._ed25519_verify(wasmInSignature, wasmInMessage, message.byteLength, wasmInPubKey);
            } catch (e) {
                Log.w(Signature, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

Signature.SIZE = 64;

Class.register(Signature);

class Commitment extends Serializable {
    /**
     * @param {Commitment} o
     * @returns {Commitment}
     */
    static copy(o) {
        if (!o) return o;
        return new Commitment(new Uint8Array(o._obj));
    }

    /**
     * @param {Array.<Commitment>} commitments
     * @return {Commitment}
     */
    static sum(commitments) {
        return new Commitment(Commitment._commitmentsAggregate(commitments.map(c => c._obj)));
    }

    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== Commitment.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Commitment}
     */
    static unserialize(buf) {
        return new Commitment(buf.read(Commitment.SIZE));
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return Commitment.SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof Commitment && super.equals(o);
    }

    /**
     * @param {Array.<Uint8Array>} commitments
     * @returns {Uint8Array}
     */
    static _commitmentsAggregate(commitments) {
        if (commitments.some(commitment => commitment.byteLength !== PublicKey.SIZE)) {
            throw Error('Wrong buffer size.');
        }
        const concatenatedCommitments = new Uint8Array(commitments.length * PublicKey.SIZE);
        for (let i = 0; i < commitments.length; ++i) {
            concatenatedCommitments.set(commitments[i], i * PublicKey.SIZE);
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PublicKey.SIZE);
            NodeNative.node_ed25519_aggregate_commitments(out, concatenatedCommitments, commitments.length);
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(PublicKey.SIZE);
                const wasmInCommitments = Module.stackAlloc(concatenatedCommitments.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInCommitments, concatenatedCommitments.length).set(concatenatedCommitments);
                Module._ed25519_aggregate_commitments(wasmOut, wasmInCommitments, commitments.length);
                const aggCommitments = new Uint8Array(PublicKey.SIZE);
                aggCommitments.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, PublicKey.SIZE));
                return aggCommitments;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

Commitment.SIZE = 32;

Class.register(Commitment);

class CommitmentPair extends Serializable {
    /**
     * @param {RandomSecret} secret
     * @param {Commitment} commitment
     * @private
     */
    constructor(secret, commitment) {
        super();
        if (!(secret instanceof RandomSecret)) throw new Error('Primitive: Invalid type');
        if (!(commitment instanceof Commitment)) throw new Error('Primitive: Invalid type');
        this._secret = secret;
        this._commitment = commitment;
    }

    /**
     * @return {CommitmentPair}
     */
    static generate() {
        const randomness = new Uint8Array(CommitmentPair.RANDOMNESS_SIZE);
        CryptoWorker.lib.getRandomValues(randomness);
        const raw = CommitmentPair._commitmentCreate(randomness);
        return new CommitmentPair(new RandomSecret(raw.secret), new Commitment(raw.commitment));
    }

    /**
     * @param {SerialBuffer} buf
     * @return {CommitmentPair}
     */
    static unserialize(buf) {
        const secret = RandomSecret.unserialize(buf);
        const commitment = Commitment.unserialize(buf);
        return new CommitmentPair(secret, commitment);
    }

    /**
     * @param {string} hexBuf
     * @return {CommitmentPair}
     */
    static fromHex(hexBuf) {
        return this.unserialize(BufferUtils.fromHex(hexBuf));
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this.secret.serialize(buf);
        this.commitment.serialize(buf);
        return buf;
    }

    /** @type {RandomSecret} */
    get secret() {
        return this._secret;
    }

    /** @type {Commitment} */
    get commitment() {
        return this._commitment;
    }

    /** @type {number} */
    get serializedSize() {
        return this.secret.serializedSize + this.commitment.serializedSize;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof CommitmentPair && super.equals(o);
    }

    /**
     * @param {Uint8Array} randomness
     * @returns {{commitment:Uint8Array, secret:Uint8Array}}
     */
    static _commitmentCreate(randomness) {
        if (PlatformUtils.isNodeJs()) {
            const commitment = new Uint8Array(PublicKey.SIZE);
            const secret = new Uint8Array(PrivateKey.SIZE);
            NodeNative.node_ed25519_create_commitment(secret, commitment, randomness);
            return {commitment, secret};
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOutCommitment = Module.stackAlloc(PublicKey.SIZE);
                const wasmOutSecret = Module.stackAlloc(PrivateKey.SIZE);
                const wasmIn = Module.stackAlloc(randomness.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmIn, randomness.length).set(randomness);
                const res = Module._ed25519_create_commitment(wasmOutSecret, wasmOutCommitment, wasmIn);
                if (res !== 1) {
                    throw new Error(`Secret must not be 0 or 1: ${res}`);
                }
                const commitment = new Uint8Array(PublicKey.SIZE);
                const secret = new Uint8Array(PrivateKey.SIZE);
                commitment.set(new Uint8Array(Module.HEAPU8.buffer, wasmOutCommitment, PublicKey.SIZE));
                secret.set(new Uint8Array(Module.HEAPU8.buffer, wasmOutSecret, PrivateKey.SIZE));
                return {commitment, secret};
            } catch (e) {
                Log.w(CommitmentPair, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

CommitmentPair.SERIALIZED_SIZE = RandomSecret.SIZE + Signature.SIZE;
CommitmentPair.RANDOMNESS_SIZE = 32;

Class.register(CommitmentPair);

class PartialSignature extends Serializable {
    /**
     * @param {Uint8Array} arg
     * @private
     */
    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== PartialSignature.SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * @param {PrivateKey} privateKey
     * @param {PublicKey} publicKey
     * @param {Array.<PublicKey>} publicKeys
     * @param {RandomSecret} secret
     * @param {Commitment} aggregateCommitment
     * @param {Uint8Array} data
     * @return {PartialSignature}
     */
    static create(privateKey, publicKey, publicKeys, secret, aggregateCommitment, data) {
        const raw = PartialSignature._delinearizedPartialSignatureCreate(publicKeys.map(o => o._obj), privateKey._obj,
            publicKey._obj, secret._obj, aggregateCommitment._obj, data);
        return new PartialSignature(raw);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {PartialSignature}
     */
    static unserialize(buf) {
        return new PartialSignature(buf.read(PartialSignature.SIZE));
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return PartialSignature.SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof PartialSignature && super.equals(o);
    }

    /**
     * @param {Array.<Uint8Array>} publicKeys
     * @param {Uint8Array} privateKey
     * @param {Uint8Array} publicKey
     * @param {Uint8Array} secret
     * @param {Uint8Array} aggregateCommitment
     * @param {Uint8Array} message
     * @returns {Uint8Array}
     */
    static _delinearizedPartialSignatureCreate(publicKeys, privateKey, publicKey, secret, aggregateCommitment, message) {
        if (publicKeys.some(publicKey => publicKey.byteLength !== PublicKey.SIZE)
            || privateKey.byteLength !== PrivateKey.SIZE
            || publicKey.byteLength !== PublicKey.SIZE
            || secret.byteLength !== RandomSecret.SIZE
            || aggregateCommitment.byteLength !== Commitment.SIZE) {
            throw Error('Wrong buffer size.');
        }
        const concatenatedPublicKeys = new Uint8Array(publicKeys.length * PublicKey.SIZE);
        for (let i = 0; i < publicKeys.length; ++i) {
            concatenatedPublicKeys.set(publicKeys[i], i * PublicKey.SIZE);
        }
        if (PlatformUtils.isNodeJs()) {
            const out = new Uint8Array(PartialSignature.SIZE);
            NodeNative.node_ed25519_delinearized_partial_sign(out, new Uint8Array(message), new Uint8Array(aggregateCommitment), new Uint8Array(secret), new Uint8Array(concatenatedPublicKeys), publicKeys.length, new Uint8Array(publicKey), new Uint8Array(privateKey));
            return out;
        } else {
            let stackPtr;
            try {
                stackPtr = Module.stackSave();
                const wasmOut = Module.stackAlloc(PartialSignature.SIZE);
                const wasmInPublicKeys = Module.stackAlloc(concatenatedPublicKeys.length);
                const wasmInPrivateKey = Module.stackAlloc(privateKey.length);
                const wasmInPublicKey = Module.stackAlloc(publicKey.length);
                const wasmInSecret = Module.stackAlloc(secret.length);
                const wasmInCommitment = Module.stackAlloc(aggregateCommitment.length);
                const wasmInMessage = Module.stackAlloc(message.length);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKeys, concatenatedPublicKeys.length).set(concatenatedPublicKeys);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPrivateKey, privateKey.length).set(privateKey);
                new Uint8Array(Module.HEAPU8.buffer, wasmInPublicKey, publicKey.length).set(publicKey);
                new Uint8Array(Module.HEAPU8.buffer, wasmInSecret, secret.length).set(secret);
                new Uint8Array(Module.HEAPU8.buffer, wasmInCommitment, aggregateCommitment.length).set(aggregateCommitment);
                new Uint8Array(Module.HEAPU8.buffer, wasmInMessage, message.length).set(message);
                Module._ed25519_delinearized_partial_sign(wasmOut, wasmInMessage, message.length, wasmInCommitment, wasmInSecret, wasmInPublicKeys, publicKeys.length, wasmInPublicKey, wasmInPrivateKey);
                const partialSignature = new Uint8Array(PartialSignature.SIZE);
                partialSignature.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, PartialSignature.SIZE));
                return partialSignature;
            } catch (e) {
                Log.w(CryptoWorkerImpl, e);
                throw e;
            } finally {
                if (stackPtr !== undefined) Module.stackRestore(stackPtr);
            }
        }
    }
}

PartialSignature.SIZE = 32;
Class.register(PartialSignature);

class Address extends Serializable {
    /**
     * @param {Address} o
     * @returns {Address}
     */
    static copy(o) {
        if (!o) return o;
        const obj = new Uint8Array(o._obj);
        return new Address(obj);
    }

    /**
     * @param {Hash} hash
     * @returns {Address}
     */
    static fromHash(hash) {
        return new Address(hash.subarray(0, Address.SERIALIZED_SIZE));
    }

    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== Address.SERIALIZED_SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * Create Address object from binary form.
     * @param {SerialBuffer} buf Buffer to read from.
     * @return {Address} Newly created Account object.
     */
    static unserialize(buf) {
        return new Address(buf.read(Address.SERIALIZED_SIZE));
    }

    /**
     * Serialize this Address object into binary form.
     * @param {?SerialBuffer} [buf] Buffer to write to.
     * @return {SerialBuffer} Buffer from `buf` or newly generated one.
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    subarray(begin, end) {
        return this._obj.subarray(begin, end);
    }

    /**
     * @type {number}
     */
    get serializedSize() {
        return Address.SERIALIZED_SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof Address
            && super.equals(o);
    }

    /**
     * @param {Address|string} addr
     */
    static fromAny(addr) {
        if (addr instanceof Address) return addr;
        if (typeof addr === 'string') return Address.fromString(addr);
        throw new Error('Invalid address format');
    }

    /**
     * @returns {string}
     */
    toPlain() {
        return this.toUserFriendlyAddress();
    }

    static fromString(str) {
        try {
            return Address.fromUserFriendlyAddress(str);
        } catch (e) {
            // Ignore
        }

        try {
            return Address.fromHex(str);
        } catch (e) {
            // Ignore
        }

        try {
            return Address.fromBase64(str);
        } catch (e) {
            // Ignore
        }

        throw new Error('Invalid address format');
    }

    /**
     * @param {string} base64
     * @return {Address}
     */
    static fromBase64(base64) {
        return new Address(BufferUtils.fromBase64(base64));
    }

    /**
     * @param {string} hex
     * @return {Address}
     */
    static fromHex(hex) {
        return new Address(BufferUtils.fromHex(hex));
    }

    /**
     * @param {string} str
     * @return {Address}
     */
    static fromUserFriendlyAddress(str) {
        str = str.replace(/ /g, '');
        if (str.substr(0, 2).toUpperCase() !== Address.CCODE) {
            throw new Error('Invalid Address: Wrong country code');
        }
        if (str.length !== 36) {
            throw new Error('Invalid Address: Should be 36 chars (ignoring spaces)');
        }
        if (Address._ibanCheck(str.substr(4) + str.substr(0, 4)) !== 1) {
            throw new Error('Invalid Address: Checksum invalid');
        }
        return new Address(BufferUtils.fromBase32(str.substr(4)));
    }

    static _ibanCheck(str) {
        const num = str.split('').map((c) => {
            const code = c.toUpperCase().charCodeAt(0);
            return code >= 48 && code <= 57 ? c : (code - 55).toString();
        }).join('');
        let tmp = '';

        for (let i = 0; i < Math.ceil(num.length / 6); i++) {
            tmp = (parseInt(tmp + num.substr(i * 6, 6)) % 97).toString();
        }

        return parseInt(tmp);
    }

    /**
     * @param {boolean} [withSpaces]
     * @return {string}
     */
    toUserFriendlyAddress(withSpaces = true) {
        const base32 = BufferUtils.toBase32(this.serialize());
        // eslint-disable-next-line prefer-template
        const check = ('00' + (98 - Address._ibanCheck(base32 + Address.CCODE + '00'))).slice(-2);
        let res = Address.CCODE + check + base32;
        if (withSpaces) res = res.replace(/.{4}/g, '$& ').trim();
        return res;
    }
}
Address.CCODE = 'NQ';
Address.SERIALIZED_SIZE = 20;
Address.HEX_SIZE = 40;
Address.NULL = new Address(new Uint8Array(Address.SERIALIZED_SIZE));
Address.CONTRACT_CREATION = new Address(new Uint8Array(Address.SERIALIZED_SIZE));
Class.register(Address);

/**
 * @abstract
 */
class Account {
    /**
     * @param {Account.Type} type
     * @param {number} balance
     */
    constructor(type, balance) {
        if (!NumberUtils.isUint8(type)) throw new Error('Malformed type');
        if (!NumberUtils.isUint64(balance)) throw new Error('Malformed balance');

        /** @type {Account.Type} */
        this._type = type;
        /** @type {number} */
        this._balance = balance;
    }

    /**
     * Create Account object from binary form.
     * @param {SerialBuffer} buf Buffer to read from.
     * @return {Account} Newly created Account object.
     */
    static unserialize(buf) {
        const type = /** @type {Account.Type} */ buf.readUint8();
        buf.readPos--;

        if (!Account.TYPE_MAP.has(type)) {
            throw new Error('Unknown account type');
        }

        return Account.TYPE_MAP.get(type).unserialize(buf);
    }

    /**
     * Serialize this Account object into binary form.
     * @param {?SerialBuffer} [buf] Buffer to write to.
     * @return {SerialBuffer} Buffer from `buf` or newly generated one.
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._type);
        buf.writeUint64(this._balance);
        return buf;
    }

    /**
     * @return {number}
     */
    get serializedSize() {
        return /*type*/ 1
            + /*balance*/ 8;
    }

    /**
     * Check if two Accounts are the same.
     * @param {Account} o Object to compare with.
     * @return {boolean} Set if both objects describe the same data.
     */
    equals(o) {
        return BufferUtils.equals(this.serialize(), o.serialize());
    }

    toString() {
        return `Account{type=${this._type}, balance=${this._balance.toString()}`;
    }

    /**
     * @param {Account|object} o
     */
    static fromAny(o) {
        if (o instanceof Account) return o;
        return Account.fromPlain(o);
    }

    /**
     * @param {object} plain
     * @returns {Account}
     */
    static fromPlain(plain) {
        if (!plain || plain.type === undefined) throw new Error('Invalid account');
        const type = Account.Type.fromAny(plain.type);
        return Account.TYPE_MAP.get(type).fromPlain(plain);
    }

    /**
     * @returns {object}
     */
    toPlain() {
        return {
            type: Account.Type.toString(this.type),
            balance: this.balance
        };
    }

    /**
     * @type {number} Account balance
     */
    get balance() {
        return this._balance;
    }

    /** @type {Account.Type} */
    get type() {
        return this._type;
    }

    /**
     * @param {number} balance
     * @return {Account|*}
     */
    withBalance(balance) { throw new Error('Not yet implemented.'); }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {TransactionCache} transactionsCache
     * @param {boolean} [revert]
     * @return {Account}
     */
    withOutgoingTransaction(transaction, blockHeight, transactionsCache, revert = false) {
        if (!revert) {
            const newBalance = this._balance - transaction.value - transaction.fee;
            if (newBalance < 0) {
                throw new Account.BalanceError();
            }
            if (blockHeight < transaction.validityStartHeight
                || blockHeight >= transaction.validityStartHeight + Policy.TRANSACTION_VALIDITY_WINDOW) {
                throw new Account.ValidityError();
            }
            if (transactionsCache.containsTransaction(transaction)) {
                throw new Account.DoubleTransactionError();
            }
            return this.withBalance(newBalance);
        } else {
            if (blockHeight < transaction.validityStartHeight
                || blockHeight >= transaction.validityStartHeight + Policy.TRANSACTION_VALIDITY_WINDOW) {
                throw new Account.ValidityError();
            }
            return this.withBalance(this._balance + transaction.value + transaction.fee);
        }
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withIncomingTransaction(transaction, blockHeight, revert = false) {
        if (!revert) {
            return this.withBalance(this._balance + transaction.value);
        } else {
            const newBalance = this._balance - transaction.value;
            if (newBalance < 0) {
                throw new Account.BalanceError();
            }
            return this.withBalance(newBalance);
        }
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withContractCommand(transaction, blockHeight, revert = false) {
        throw new Error('Not yet implemented');
    }

    /**
     * @return {boolean}
     */
    isInitial() {
        return this === Account.INITIAL;
    }

    /**
     * @return {boolean}
     */
    isToBePruned() {
        return this._balance === 0 && !this.isInitial();
    }

    /**
     * @param {Uint8Array} data
     * @return {object}
     */
    static dataToPlain(data) {
        return {};
    }

    /**
     * @param {Uint8Array} proof
     * @return {object}
     */
    static proofToPlain(proof) {
        return {};
    }
}

/**
 * Enum for Account types.
 * Non-zero values are contracts.
 * @enum
 */
Account.Type = {
    /**
     * Basic account type.
     * @see {BasicAccount}
     */
    BASIC: 0,
    /**
     * Account with vesting functionality.
     * @see {VestingContract}
     */
    VESTING: 1,
    /**
     * Hashed Time-Locked Contract
     * @see {HashedTimeLockedContract}
     */
    HTLC: 2
};
/**
 * @param {Account.Type} type
 * @return {string}
 */
Account.Type.toString = function(type) {
    switch (type) {
        case Account.Type.BASIC: return 'basic';
        case Account.Type.VESTING: return 'vesting';
        case Account.Type.HTLC: return 'htlc';
    }
    throw new Error('Invalid account type');
};
/**
 * @param {Account.Type|string} type
 * @return {Account.Type}
 */
Account.Type.fromAny = function(type) {
    if (typeof type === 'number') return type;
    switch (type) {
        case 'basic': return Account.Type.BASIC;
        case 'vesting': return Account.Type.VESTING;
        case 'htlc': return Account.Type.HTLC;
    }
    throw new Error('Invalid account type');
};
/**
 * @type {Map.<Account.Type, {
 *  copy: function(o: *):Account,
 *  unserialize: function(buf: SerialBuffer):Account,
 *  create: function(balance: number, blockHeight: number, transaction: Transaction):Account,
 *  verifyOutgoingTransaction: function(transaction: Transaction):boolean,
 *  verifyIncomingTransaction: function(transaction: Transaction):boolean,
 *  fromPlain: function(o: object):Account,
 *  dataToPlain: function(data: Uint8Array):object,
 *  proofToPlain: function(proof: Uint8Array):object
 * }>}
 */
Account.TYPE_MAP = new Map();
Account.BalanceError = class extends Error { constructor() { super('Balance Error!'); }};
Account.DoubleTransactionError = class extends Error { constructor() { super('Double Transaction Error!'); }};
Account.ProofError = class extends Error { constructor() { super('Proof Error!'); }};
Account.ValidityError = class extends Error { constructor() { super('Validity Error!'); }};
Class.register(Account);

class PrunedAccount {
    /**
     * @param {Address} address
     * @param {Account} account
     */
    constructor(address, account) {
        if (!(address instanceof Address)) throw new Error('Malformed address');

        /** @type {Address} */
        this._address = address;
        /** @type {Account} */
        this._account = account;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {PrunedAccount}
     */
    static unserialize(buf) {
        return new PrunedAccount(Address.unserialize(buf), Account.unserialize(buf));
    }

    /**
     * @param {PrunedAccount|object} o
     * @returns {PrunedAccount}
     */
    static fromAny(o) {
        if (o instanceof PrunedAccount) return o;
        return PrunedAccount.fromPlain(o);
    }

    /**
     * @param {object} plain
     */
    static fromPlain(plain) {
        return new PrunedAccount(Address.fromAny(plain.address), Account.fromAny(plain.account));
    }

    /**
     * @param {PrunedAccount} o
     * @return {number} negative if this is smaller than o, positive if this is larger than o, zero if equal.
     */
    compare(o) {
        return this._address.compare(o._address);
    }

    /**
     * @returns {Address}
     */
    get address() {
        return this._address;
    }

    /**
     * @returns {Account}
     */
    get account() {
        return this._account;
    }

    /**
     * @param buf
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._address.serialize(buf);
        this._account.serialize(buf);
        return this;
    }

    /**
     * @returns {number}
     */
    get serializedSize() {
        return this._address.serializedSize + this._account.serializedSize;
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this._address.hashCode();
    }

    /**
     * @returns {object}
     */
    toPlain() {
        return {
            address: this.address.toPlain(),
            account: this.account.toPlain()
        };
    }
}

Class.register(PrunedAccount);

/**
 * This is a classic account that can send all his funds and receive any transaction.
 * All outgoing transactions are signed using the key corresponding to this address.
 */
class BasicAccount extends Account {
    /**
     * @param {BasicAccount} o
     * @returns {BasicAccount}
     */
    static copy(o) {
        if (!o) return o;
        return new BasicAccount(o._balance);
    }

    /**
     * @param {number} [balance]
     */
    constructor(balance = 0) {
        super(Account.Type.BASIC, balance);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {BasicAccount}
     */
    static unserialize(buf) {
        const type = buf.readUint8();
        if (type !== Account.Type.BASIC) throw new Error('Invalid account type');

        const balance = buf.readUint64();
        return new BasicAccount(balance);
    }

    /**
     * @param {object} o
     */
    static fromPlain(o) {
        if (!o) throw new Error('Invalid account');
        return new BasicAccount(o.balance);
    }

    /**
     * Check if two Accounts are the same.
     * @param {Account} o Object to compare with.
     * @return {boolean} Set if both objects describe the same data.
     */
    equals(o) {
        return o instanceof BasicAccount
            && this._type === o._type
            && this._balance === o._balance;
    }

    toString() {
        return `BasicAccount{balance=${this._balance}}`;
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyOutgoingTransaction(transaction) {
        return SignatureProof.verifyTransaction(transaction);
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyIncomingTransaction(transaction) {
        if (transaction.data.byteLength > 64) return false;
        return true;
    }

    /**
     * @param {number} balance
     * @return {Account|*}
     */
    withBalance(balance) {
        return new BasicAccount(balance);
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withIncomingTransaction(transaction, blockHeight, revert = false) {
        if (!revert) {
            const isContractCreation = transaction.hasFlag(Transaction.Flag.CONTRACT_CREATION);
            const isTypeChange = transaction.recipientType !== this._type;
            if (isContractCreation !== isTypeChange) {
                throw new Error('Data Error!');
            }
        }
        return super.withIncomingTransaction(transaction, blockHeight, revert);
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withContractCommand(transaction, blockHeight, revert = false) {
        if (!revert && transaction.recipientType !== this._type && transaction.hasFlag(Transaction.Flag.CONTRACT_CREATION)) {
            // Contract creation
            return Account.TYPE_MAP.get(transaction.recipientType).create(this._balance, blockHeight, transaction);
        }
        return this;
    }

    /**
     * @return {boolean}
     */
    isInitial() {
        return this._balance === 0;
    }

    /**
     * @param {Uint8Array} data
     * @return {object}
     */
    static dataToPlain(data) {
        return Account.dataToPlain(data);
    }

    /**
     * @param {Uint8Array} proof
     * @return {object}
     */
    static proofToPlain(proof) {
        try {
            const signatureProof = SignatureProof.unserialize(new SerialBuffer(proof));
            return {
                signature: signatureProof.signature.toHex(),
                publicKey: signatureProof.publicKey.toHex(),
                signer: signatureProof.publicKey.toAddress().toPlain(),
                pathLength: signatureProof.merklePath.nodes.length
            };
        } catch (e) {
            return Account.proofToPlain(proof);
        }
    }
}

Account.INITIAL = new BasicAccount(0);
Account.TYPE_MAP.set(Account.Type.BASIC, BasicAccount);
Class.register(BasicAccount);

class Contract extends Account {
    /**
     * @param {Account.Type} type
     * @param {number} balance
     */
    constructor(type, balance) {
        super(type, balance);
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyIncomingTransaction(transaction) {
        if (!transaction.recipient.equals(transaction.getContractCreationAddress())) {
            return false;
        }
        return true;
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withIncomingTransaction(transaction, blockHeight, revert = false) {
        if (!revert && transaction.hasFlag(Transaction.Flag.CONTRACT_CREATION)) {
            // Contract already created
            throw new Error('Data error');
        }
        return super.withIncomingTransaction(transaction, blockHeight, revert);
    }


    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withContractCommand(transaction, blockHeight, revert = false) {
        if (revert && transaction.hasFlag(Transaction.Flag.CONTRACT_CREATION)) {
            // Revert contract creation
            return new BasicAccount(this.balance);
        }
        return this;
    }
}

Class.register(Contract);

class HashedTimeLockedContract extends Contract {
    /**
     * @param {number} balance
     * @param {Address} sender
     * @param {Address} recipient
     * @param {Hash} hashRoot
     * @param {number} hashCount
     * @param {number} timeout
     * @param {number} totalAmount
     */
    constructor(balance = 0, sender = Address.NULL, recipient = Address.NULL, hashRoot = Hash.NULL, hashCount = 1, timeout = 0, totalAmount = balance) {
        super(Account.Type.HTLC, balance);
        if (!(sender instanceof Address)) throw new Error('Malformed address');
        if (!(recipient instanceof Address)) throw new Error('Malformed address');
        if (!(hashRoot instanceof Hash)) throw new Error('Malformed address');
        if (!NumberUtils.isUint8(hashCount) || hashCount === 0) throw new Error('Malformed hashCount');
        if (!NumberUtils.isUint32(timeout)) throw new Error('Malformed timeout');
        if (!NumberUtils.isUint64(totalAmount)) throw new Error('Malformed totalAmount');

        /** @type {Address} */
        this._sender = sender;
        /** @type {Address} */
        this._recipient = recipient;
        /** @type {Hash} */
        this._hashRoot = hashRoot;
        /** @type {number} */
        this._hashCount = hashCount;
        /** @type {number} */
        this._timeout = timeout;
        /** @type {number} */
        this._totalAmount = totalAmount;
    }

    /**
     * @param {number} balance
     * @param {number} blockHeight
     * @param {Transaction} transaction
     */
    static create(balance, blockHeight, transaction) {
        const buf = new SerialBuffer(transaction.data);

        const sender = Address.unserialize(buf);
        const recipient = Address.unserialize(buf);
        const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
        const hashRoot = Hash.unserialize(buf, hashAlgorithm);
        const hashCount = buf.readUint8();
        const timeout = buf.readUint32();

        return new HashedTimeLockedContract(balance, sender, recipient, hashRoot, hashCount, timeout);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {HashedTimeLockedContract}
     */
    static unserialize(buf) {
        const type = buf.readUint8();
        if (type !== Account.Type.HTLC) throw new Error('Invalid account type');

        const balance = buf.readUint64();
        const sender = Address.unserialize(buf);
        const recipient = Address.unserialize(buf);
        const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
        const hashRoot = Hash.unserialize(buf, hashAlgorithm);
        const hashCount = buf.readUint8();
        const timeout = buf.readUint32();
        const totalAmount = buf.readUint64();
        return new HashedTimeLockedContract(balance, sender, recipient, hashRoot, hashCount, timeout, totalAmount);
    }

    /**
     * @param {object} plain
     */
    static fromPlain(plain) {
        if (!plain) throw new Error('Invalid account');
        return new HashedTimeLockedContract(plain.balance, Address.fromAny(plain.sender), Address.fromAny(plain.recipient), Hash.fromAny(plain.hashRoot), plain.hashCount, plain.timeout, plain.totalAmount);
    }


    /**
     * Serialize this HTLC object into binary form.
     * @param {?SerialBuffer} [buf] Buffer to write to.
     * @return {SerialBuffer} Buffer from `buf` or newly generated one.
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._sender.serialize(buf);
        this._recipient.serialize(buf);
        buf.writeUint8(this._hashRoot.algorithm);
        this._hashRoot.serialize(buf);
        buf.writeUint8(this._hashCount);
        buf.writeUint32(this._timeout);
        buf.writeUint64(this._totalAmount);
        return buf;
    }

    /**
     * @return {number}
     */
    get serializedSize() {
        return super.serializedSize
            + this._sender.serializedSize
            + this._recipient.serializedSize
            + /*hashAlgorithm*/ 1
            + this._hashRoot.serializedSize
            + /*hashCount*/ 1
            + /*timeout*/ 4
            + /*totalAmount*/ 8;
    }

    /** @type {Address} */
    get sender() {
        return this._sender;
    }

    /** @type {Address} */
    get recipient() {
        return this._recipient;
    }

    /** @type {Hash} */
    get hashRoot() {
        return this._hashRoot;
    }

    /** @type {number} */
    get hashCount() {
        return this._hashCount;
    }

    /** @type {number} */
    get timeout() {
        return this._timeout;
    }

    /** @type {number} */
    get totalAmount() {
        return this._totalAmount;
    }

    toString() {
        return `HashedTimeLockedContract{balance=${this._balance}, sender=${this._sender.toUserFriendlyAddress(false)}, recipient=${this._sender.toUserFriendlyAddress(false)}, amount=${this._totalAmount}/${this._hashCount}, timeout=${this._timeout}}`;
    }

    /**
     * @returns {object}
     */
    toPlain() {
        const plain = super.toPlain();
        plain.sender = this.sender.toPlain();
        plain.recipient = this.recipient.toPlain();
        plain.hashRoot = this.hashRoot.toPlain();
        plain.hashCount = this.hashCount;
        plain.timeout = this.timeout;
        plain.totalAmount = this.totalAmount;
        return plain;
    }

    /**
     * Check if two Accounts are the same.
     * @param {Account} o Object to compare with.
     * @return {boolean} Set if both objects describe the same data.
     */
    equals(o) {
        return o instanceof HashedTimeLockedContract
            && this._type === o._type
            && this._balance === o._balance
            && this._sender.equals(o._sender)
            && this._recipient.equals(o._recipient)
            && this._hashRoot.equals(o._hashRoot)
            && this._hashCount === o._hashCount
            && this._timeout === o._timeout
            && this._totalAmount === o._totalAmount;
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyOutgoingTransaction(transaction) {
        try {
            const buf = new SerialBuffer(transaction.proof);
            const type = buf.readUint8();
            switch (type) {
                case HashedTimeLockedContract.ProofType.REGULAR_TRANSFER: {
                    const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
                    const hashDepth = buf.readUint8();
                    const hashRoot = Hash.unserialize(buf, hashAlgorithm);
                    let preImage = Hash.unserialize(buf, hashAlgorithm);

                    // Verify that the preImage hashed hashDepth times matches the _provided_ hashRoot.
                    for (let i = 0; i < hashDepth; ++i) {
                        preImage = Hash.compute(preImage.array, hashAlgorithm);
                    }
                    if (!hashRoot.equals(preImage)) {
                        return false;
                    }

                    // Signature proof of the HTLC recipient
                    if (!SignatureProof.unserialize(buf).verify(null, transaction.serializeContent())) {
                        return false;
                    }
                    break;
                }
                case HashedTimeLockedContract.ProofType.EARLY_RESOLVE: {
                    // Signature proof of the HTLC recipient
                    if (!SignatureProof.unserialize(buf).verify(null, transaction.serializeContent())) {
                        return false;
                    }

                    // Signature proof of the HTLC creator
                    if (!SignatureProof.unserialize(buf).verify(null, transaction.serializeContent())) {
                        return false;
                    }
                    break;
                }
                case HashedTimeLockedContract.ProofType.TIMEOUT_RESOLVE:
                    // Signature proof of the HTLC creator
                    if (!SignatureProof.unserialize(buf).verify(null, transaction.serializeContent())) {
                        return false;
                    }
                    break;
                default:
                    return false;
            }

            // Reject overlong proof.
            if (buf.readPos !== buf.byteLength) {
                return false;
            }

            return true; // Accept
        } catch (e) {
            return false;
        }
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyIncomingTransaction(transaction) {
        try {
            const buf = new SerialBuffer(transaction.data);

            Address.unserialize(buf); // sender address
            Address.unserialize(buf); // recipient address
            const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
            Hash.unserialize(buf, hashAlgorithm);
            buf.readUint8(); // hash count
            buf.readUint32(); // timeout

            // Blacklist Argon2 hash function.
            if (hashAlgorithm === Hash.Algorithm.ARGON2D) {
                return false;
            }

            if (buf.readPos !== buf.byteLength) {
                return false;
            }

            return Contract.verifyIncomingTransaction(transaction);
        } catch (e) {
            return false;
        }
    }

    /**
     * @param {number} balance
     * @return {Account|*}
     */
    withBalance(balance) {
        return new HashedTimeLockedContract(balance, this._sender, this._recipient, this._hashRoot, this._hashCount, this._timeout, this._totalAmount);
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {TransactionCache} transactionsCache
     * @param {boolean} [revert]
     * @return {Account|*}
     */
    withOutgoingTransaction(transaction, blockHeight, transactionsCache, revert = false) {
        const buf = new SerialBuffer(transaction.proof);
        const type = buf.readUint8();
        let minCap = 0;
        switch (type) {
            case HashedTimeLockedContract.ProofType.REGULAR_TRANSFER: {
                // Check that the contract has not expired yet.
                if (this._timeout < blockHeight) {
                    throw new Account.ProofError();
                }

                // Check that the provided hashRoot is correct.
                const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
                const hashDepth = buf.readUint8();
                const hashRoot = Hash.unserialize(buf, hashAlgorithm);
                if (!hashRoot.equals(this._hashRoot)) {
                    throw new Account.ProofError();
                }

                // Ignore the preImage.
                Hash.unserialize(buf, hashAlgorithm);

                // Verify that the transaction is signed by the authorized recipient.
                if (!SignatureProof.unserialize(buf).isSignedBy(this._recipient)) {
                    throw new Account.ProofError();
                }

                minCap = Math.max(0, Math.floor((1 - (hashDepth / this._hashCount)) * this._totalAmount));

                break;
            }
            case HashedTimeLockedContract.ProofType.EARLY_RESOLVE: {
                if (!SignatureProof.unserialize(buf).isSignedBy(this._recipient)) {
                    throw new Account.ProofError();
                }

                if (!SignatureProof.unserialize(buf).isSignedBy(this._sender)) {
                    throw new Account.ProofError();
                }

                break;
            }
            case HashedTimeLockedContract.ProofType.TIMEOUT_RESOLVE: {
                if (this._timeout >= blockHeight) {
                    throw new Account.ProofError();
                }

                if (!SignatureProof.unserialize(buf).isSignedBy(this._sender)) {
                    throw new Account.ProofError();
                }

                break;
            }
            default:
                throw new Account.ProofError();
        }

        if (!revert) {
            const newBalance = this._balance - transaction.value - transaction.fee;
            if (newBalance < minCap) {
                throw new Account.BalanceError();
            }
        }

        return super.withOutgoingTransaction(transaction, blockHeight, transactionsCache, revert);
    }


    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withIncomingTransaction(transaction, blockHeight, revert = false) {
        throw new Error('Illegal incoming transaction');
    }

    /**
     * @param {Uint8Array} data
     * @return {object}
     */
    static dataToPlain(data) {
        try {
            const buf = new SerialBuffer(proof);

            const sender = Address.unserialize(buf);
            const recipient = Address.unserialize(buf);
            const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
            const hashRoot = Hash.unserialize(buf, hashAlgorithm);
            const hashCount = buf.readUint8();
            const timeout = buf.readUint32();

            return {
                sender: sender.toPlain(),
                recipient: recipient.toPlain(),
                hashAlgorithm: Hash.Algorithm.toString(hashAlgorithm),
                hashRoot: hashRoot.toPlain(),
                hashCount,
                timeout
            };
        } catch (e) {
            return Account.dataToPlain(data);
        }
    }

    /**
     * @param {Uint8Array} proof
     * @return {object}
     */
    static proofToPlain(proof) {
        try {
            const buf = new SerialBuffer(proof);
            const type = buf.readUint8();
            switch (type) {
                case HashedTimeLockedContract.ProofType.REGULAR_TRANSFER: {
                    const hashAlgorithm = /** @type {Hash.Algorithm} */ buf.readUint8();
                    const hashDepth = buf.readUint8();
                    const hashRoot = Hash.unserialize(buf, hashAlgorithm);
                    const preImage = Hash.unserialize(buf, hashAlgorithm);
                    const signatureProof = SignatureProof.unserialize(buf);

                    return {
                        type: HashedTimeLockedContract.ProofType.toString(type),
                        hashAlgorithm: Hash.Algorithm.toString(hashAlgorithm),
                        hashDepth,
                        hashRoot: hashRoot.toPlain(),
                        preImage: preImage.toPlain(),
                        signer: signatureProof.publicKey.toAddress().toPlain(),
                        signature: signatureProof.signature.toHex(),
                        publicKey: signatureProof.publicKey.toHex(),
                        pathLength: signatureProof.merklePath.nodes.length
                    };
                }
                case HashedTimeLockedContract.ProofType.EARLY_RESOLVE: {
                    const signatureProof = SignatureProof.unserialize(buf);
                    const creatorSignatureProof = SignatureProof.unserialize(buf);
                    return {
                        type: HashedTimeLockedContract.ProofType.toString(type),
                        signer: signatureProof.publicKey.toAddress().toPlain(),
                        signature: signatureProof.signature.toHex(),
                        publicKey: signatureProof.publicKey.toHex(),
                        pathLength: signatureProof.merklePath.nodes.length,
                        creator: creatorSignatureProof.publicKey.toAddress().toPlain(),
                        creatorSignature: creatorSignatureProof.signature.toHex(),
                        creatorPublicKey: creatorSignatureProof.publicKey.toHex(),
                        creatorPathLength: creatorSignatureProof.merklePath.nodes.length
                    };
                }
                case HashedTimeLockedContract.ProofType.TIMEOUT_RESOLVE: {
                    const creatorSignatureProof = SignatureProof.unserialize(buf);
                    return {
                        type: HashedTimeLockedContract.ProofType.toString(type),
                        creator: creatorSignatureProof.publicKey.toAddress().toPlain(),
                        creatorSignature: creatorSignatureProof.signature.toHex(),
                        creatorPublicKey: creatorSignatureProof.publicKey.toHex(),
                        creatorPathLength: creatorSignatureProof.merklePath.nodes.length
                    };
                }
                default:
                    return false;
            }
        } catch (e) {
            return Account.proofToPlain(proof);
        }
    }
}

HashedTimeLockedContract.ProofType = {
    REGULAR_TRANSFER: 1,
    EARLY_RESOLVE: 2,
    TIMEOUT_RESOLVE: 3
};

/**
 * @param {HashedTimeLockedContract.ProofType} proofType
 * @return {string}
 */
HashedTimeLockedContract.ProofType.toString = function(proofType) {
    switch (proofType) {
        case HashedTimeLockedContract.ProofType.REGULAR_TRANSFER: return 'regular-transfer';
        case HashedTimeLockedContract.ProofType.EARLY_RESOLVE: return 'early-resolve';
        case HashedTimeLockedContract.ProofType.TIMEOUT_RESOLVE: return 'timeout-resolve';
    }
    throw new Error('Invalid proof type');
};

Account.TYPE_MAP.set(Account.Type.HTLC, HashedTimeLockedContract);
Class.register(HashedTimeLockedContract);

class VestingContract extends Contract {
    /**
     * @param {number} [balance]
     * @param {Address} [owner]
     * @param {number} [vestingStart]
     * @param {number} [vestingStepBlocks]
     * @param {number} [vestingStepAmount]
     * @param {number} [vestingTotalAmount]
     */
    constructor(balance = 0, owner = Address.NULL, vestingStart = 0, vestingStepBlocks = 0, vestingStepAmount = balance, vestingTotalAmount = balance) {
        super(Account.Type.VESTING, balance);
        if (!(owner instanceof Address)) throw new Error('Malformed address');
        if (!NumberUtils.isUint32(vestingStart)) throw new Error('Malformed vestingStart');
        if (!NumberUtils.isUint32(vestingStepBlocks)) throw new Error('Malformed vestingStepBlocks');
        if (!NumberUtils.isUint64(vestingStepAmount)) throw new Error('Malformed vestingStepAmount');
        if (!NumberUtils.isUint64(vestingTotalAmount)) throw new Error('Malformed lowerCap');

        /** @type {Address} */
        this._owner = owner;
        /** @type {number} */
        this._vestingStart = vestingStart;
        /** @type {number} */
        this._vestingStepBlocks = vestingStepBlocks;
        /** @type {number} */
        this._vestingStepAmount = vestingStepAmount;
        /** @type {number} */
        this._vestingTotalAmount = vestingTotalAmount;
    }

    /**
     * @param {number} balance
     * @param {number} blockHeight
     * @param {Transaction} transaction
     */
    static create(balance, blockHeight, transaction) {
        /** @type {number} */
        let vestingStart, vestingStepBlocks, vestingStepAmount, vestingTotalAmount;
        const buf = new SerialBuffer(transaction.data);
        const owner = Address.unserialize(buf);
        vestingTotalAmount = transaction.value;
        switch (transaction.data.length) {
            case Address.SERIALIZED_SIZE + 4:
                // Only block number: vest full amount at that block
                vestingStart = 0;
                vestingStepBlocks = buf.readUint32();
                vestingStepAmount = vestingTotalAmount;
                break;
            case Address.SERIALIZED_SIZE + 16:
                vestingStart = buf.readUint32();
                vestingStepBlocks = buf.readUint32();
                vestingStepAmount = buf.readUint64();
                break;
            case Address.SERIALIZED_SIZE + 24:
                // Create a vesting account with some instantly vested funds or additional funds considered.
                vestingStart = buf.readUint32();
                vestingStepBlocks = buf.readUint32();
                vestingStepAmount = buf.readUint64();
                vestingTotalAmount = buf.readUint64();
                break;
            default:
                throw new Error('Invalid transaction data');
        }
        return new VestingContract(balance, owner, vestingStart, vestingStepBlocks, vestingStepAmount, vestingTotalAmount);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {VestingContract}
     */
    static unserialize(buf) {
        const type = buf.readUint8();
        if (type !== Account.Type.VESTING) throw new Error('Invalid account type');

        const balance = buf.readUint64();
        const owner = Address.unserialize(buf);
        const vestingStart = buf.readUint32();
        const vestingStepBlocks = buf.readUint32();
        const vestingStepAmount = buf.readUint64();
        const vestingTotalAmount = buf.readUint64();
        return new VestingContract(balance, owner, vestingStart, vestingStepBlocks, vestingStepAmount, vestingTotalAmount);
    }

    /**
     * @param {object} plain
     */
    static fromPlain(plain) {
        if (!plain) throw new Error('Invalid account');
        return new VestingContract(plain.balance, Address.fromAny(plain.owner), plain.vestingStart, plain.vestingStepBlocks, plain.vestingStepAmount, plain.vestingTotalAmount);
    }

    /**
     * Serialize this VestingContract object into binary form.
     * @param {?SerialBuffer} [buf] Buffer to write to.
     * @return {SerialBuffer} Buffer from `buf` or newly generated one.
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._owner.serialize(buf);
        buf.writeUint32(this._vestingStart);
        buf.writeUint32(this._vestingStepBlocks);
        buf.writeUint64(this._vestingStepAmount);
        buf.writeUint64(this._vestingTotalAmount);
        return buf;
    }

    /**
     * @return {number}
     */
    get serializedSize() {
        return super.serializedSize
            + this._owner.serializedSize
            + /*vestingStart*/ 4
            + /*vestingStepBlocks*/ 4
            + /*vestingStepAmount*/ 8
            + /*vestingTotalAmount*/ 8;
    }

    /** @type {Address} */
    get owner() {
        return this._owner;
    }

    /** @type {number} */
    get vestingStart() {
        return this._vestingStart;
    }

    /** @type {number} */
    get vestingStepBlocks() {
        return this._vestingStepBlocks;
    }

    /** @type {number} */
    get vestingStepAmount() {
        return this._vestingStepAmount;
    }

    /** @type {number} */
    get vestingTotalAmount() {
        return this._vestingTotalAmount;
    }

    toString() {
        return `VestingAccount{balance=${this._balance}, owner=${this._owner.toUserFriendlyAddress()}`;
    }

    /**
     * @returns {object}
     */
    toPlain() {
        const plain = super.toPlain();
        plain.owner = this.owner.toPlain();
        plain.vestingStart = this.vestingStart;
        plain.vestingStepBlocks = this.vestingStepBlocks;
        plain.vestingStepAmount = this.vestingStepAmount;
        plain.vestingTotalAmount = this.vestingTotalAmount;
        return plain;
    }

    /**
     * Check if two Accounts are the same.
     * @param {Account} o Object to compare with.
     * @return {boolean} Set if both objects describe the same data.
     */
    equals(o) {
        return o instanceof VestingContract
            && this._type === o._type
            && this._balance === o._balance
            && this._owner.equals(o._owner)
            && this._vestingStart === o._vestingStart
            && this._vestingStepBlocks === o._vestingStepBlocks
            && this._vestingStepAmount === o._vestingStepAmount
            && this._vestingTotalAmount === o._vestingTotalAmount;
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyOutgoingTransaction(transaction) {
        const buf = new SerialBuffer(transaction.proof);

        if (!SignatureProof.unserialize(buf).verify(null, transaction.serializeContent())) {
            return false;
        }

        if (buf.readPos !== buf.byteLength) {
            return false;
        }

        return true;
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    static verifyIncomingTransaction(transaction) {
        switch (transaction.data.length) {
            case Address.SERIALIZED_SIZE + 4:
            case Address.SERIALIZED_SIZE + 16:
            case Address.SERIALIZED_SIZE + 24:
                return Contract.verifyIncomingTransaction(transaction);
            default:
                return false;
        }
    }

    /**
     * @param {number} balance
     * @return {Account|*}
     */
    withBalance(balance) {
        return new VestingContract(balance, this._owner, this._vestingStart, this._vestingStepBlocks, this._vestingStepAmount, this._vestingTotalAmount);
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {TransactionCache} transactionsCache
     * @param {boolean} [revert]
     * @return {Account|*}
     */
    withOutgoingTransaction(transaction, blockHeight, transactionsCache, revert = false) {
        if (!revert) {
            const minCap = this.getMinCap(blockHeight);
            const newBalance = this._balance - transaction.value - transaction.fee;
            if (newBalance < minCap) {
                throw new Account.BalanceError();
            }

            const buf = new SerialBuffer(transaction.proof);
            if (!SignatureProof.unserialize(buf).isSignedBy(this._owner)) {
                throw new Account.ProofError();
            }
        }
        return super.withOutgoingTransaction(transaction, blockHeight, transactionsCache, revert);
    }

    /**
     * @param {Transaction} transaction
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @return {Account}
     */
    withIncomingTransaction(transaction, blockHeight, revert = false) {
        throw new Error('Illegal incoming transaction');
    }

    /**
     * @param {number} blockHeight
     * @returns {number}
     */
    getMinCap(blockHeight) {
        return this._vestingStepBlocks && this._vestingStepAmount > 0
            ? Math.max(0, this._vestingTotalAmount - Math.floor((blockHeight - this._vestingStart) / this._vestingStepBlocks) * this._vestingStepAmount)
            : 0;
    }


    /**
     * @param {Uint8Array} data
     * @return {object}
     */
    static dataToPlain(data) {
        try {
            let vestingStart, vestingStepBlocks, vestingStepAmount, vestingTotalAmount;
            const buf = new SerialBuffer(data);
            const owner = Address.unserialize(buf);
            switch (transaction.data.length) {
                case Address.SERIALIZED_SIZE + 4:
                    vestingStart = 0;
                    vestingStepBlocks = buf.readUint32();
                    break;
                case Address.SERIALIZED_SIZE + 16:
                    vestingStart = buf.readUint32();
                    vestingStepBlocks = buf.readUint32();
                    vestingStepAmount = buf.readUint64();
                    break;
                case Address.SERIALIZED_SIZE + 24:
                    vestingStart = buf.readUint32();
                    vestingStepBlocks = buf.readUint32();
                    vestingStepAmount = buf.readUint64();
                    vestingTotalAmount = buf.readUint64();
                    break;
                default:
                    throw new Error('Invalid transaction data');
            }
            return {
                owner: owner.toPlain(),
                vestingStart,
                vestingStepBlocks,
                vestingStepAmount,
                vestingTotalAmount
            };
        } catch (e) {
            return Account.dataToPlain(data);
        }
    }

    /**
     * @param {Uint8Array} proof
     * @return {object}
     */
    static proofToPlain(proof) {
        try {
            const signatureProof = SignatureProof.unserialize(new SerialBuffer(proof));
            return {
                signature: signatureProof.signature.toHex(),
                publicKey: signatureProof.publicKey.toHex(),
                signer: signatureProof.publicKey.toAddress().toPlain(),
                pathLength: signatureProof.merklePath.nodes.length
            };
        } catch (e) {
            return Account.proofToPlain(proof);
        }
    }
}

Account.TYPE_MAP.set(Account.Type.VESTING, VestingContract);
Class.register(VestingContract);

class AccountsTreeNode {
    /**
     * @param {string} prefix
     * @param {Account} account
     * @returns {AccountsTreeNode}
     */
    static terminalNode(prefix, account) {
        return new AccountsTreeNode(AccountsTreeNode.TERMINAL, prefix, account);
    }

    /**
     * @param {string} prefix
     * @param {Array.<string>} childrenSuffixes
     * @param {Array.<Hash>} childrenHashes
     * @returns {AccountsTreeNode}
     */
    static branchNode(prefix, childrenSuffixes = [], childrenHashes = []) {
        if (childrenSuffixes.length !== childrenHashes.length) {
            throw new Error('Invalid list of children for branch node');
        }
        return new AccountsTreeNode(AccountsTreeNode.BRANCH, prefix, childrenSuffixes, childrenHashes);
    }

    /**
     * @param type
     * @param {string} prefix
     * @param {Account|Array.<string>} arg
     * @param {Array.<Hash>} [arg2]
     */
    constructor(type, prefix = '', arg, arg2 = []) {
        this._type = type;
        /** @type {string} */
        this._prefix = prefix;
        if (this.isBranch()) {
            /** @type {Array.<string>} */
            this._childrenSuffixes = arg;
            /** @type {Array.<Hash>} */
            this._childrenHashes = arg2;
        } else if (this.isTerminal()) {
            /** @type {Account} */
            this._account = arg;
        } else {
            throw `Invalid AccountsTreeNode type: ${type}`;
        }
    }

    /**
     * @param type
     * @returns {boolean}
     */
    static isTerminalType(type) {
        return type === AccountsTreeNode.TERMINAL;
    }

    /**
     * @param type
     * @returns {boolean}
     */
    static isBranchType(type) {
        return type === AccountsTreeNode.BRANCH;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {AccountsTreeNode}
     */
    static unserialize(buf) {
        const type = buf.readUint8();
        const prefix = buf.readVarLengthString();

        if (AccountsTreeNode.isTerminalType(type)) {
            // Terminal node
            const account = Account.unserialize(buf);
            return AccountsTreeNode.terminalNode(prefix, account);
        } else if (AccountsTreeNode.isBranchType(type)) {
            // Branch node
            const childrenSuffixes = [], childrenHashes = [];
            const childCount = buf.readUint8();
            for (let i = 0; i < childCount; ++i) {
                const childSuffix = buf.readVarLengthString();
                const childHash = Hash.unserialize(buf);
                const childIndex = parseInt(childSuffix[0], 16);
                childrenSuffixes[childIndex] = childSuffix;
                childrenHashes[childIndex] = childHash;
            }
            return AccountsTreeNode.branchNode(prefix, childrenSuffixes, childrenHashes);
        } else {
            throw `Invalid AccountsTreeNode type: ${type}`;
        }
    }

    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._type);
        buf.writeVarLengthString(this._prefix);
        if (this.isTerminal()) {
            // Terminal node
            this._account.serialize(buf);
        } else {
            // Branch node
            const childCount = this._childrenSuffixes.reduce((count, child) => count + !!child, 0);
            buf.writeUint8(childCount);
            for (let i = 0; i < this._childrenSuffixes.length; ++i) {
                if (this._childrenHashes[i]) {
                    buf.writeVarLengthString(this._childrenSuffixes[i]);
                    this._childrenHashes[i].serialize(buf);
                }
            }
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let payloadSize;
        if (this.isTerminal()) {
            payloadSize = this._account.serializedSize;
        } else {
            // The children array contains undefined values for non existing children.
            // Only count existing ones.
            const childrenSize = this._childrenHashes.reduce((sum, child, i) => {
                return sum + (child ? child.serializedSize + SerialBuffer.varLengthStringSize(this._childrenSuffixes[i]) : 0);
            }, 0);
            payloadSize = /*childCount*/ 1 + childrenSize;
        }

        return /*type*/ 1
            + SerialBuffer.varLengthStringSize(this._prefix)
            + payloadSize;
    }

    /**
     * @param {string} prefix
     * @returns {?Hash}
     */
    getChildHash(prefix) {
        return this._childrenHashes && this._childrenHashes[this._getChildIndex(prefix)];
    }

    /**
     * @param {string} prefix
     * @returns {?string}
     */
    getChild(prefix) {
        const suffix = this._childrenSuffixes && this._childrenSuffixes[this._getChildIndex(prefix)];
        if (suffix) {
            return this.prefix + suffix;
        }
        return suffix;
    }

    /**
     * @param {string} prefix
     * @param {Hash} childHash
     * @returns {AccountsTreeNode}
     */
    withChild(prefix, childHash) {
        const childrenSuffixes = this._childrenSuffixes.slice() || [];
        const childrenHashes = this._childrenHashes.slice() || [];
        childrenSuffixes[this._getChildIndex(prefix)] = prefix.substr(this.prefix.length);
        childrenHashes[this._getChildIndex(prefix)] = childHash;
        return AccountsTreeNode.branchNode(this._prefix, childrenSuffixes, childrenHashes);
    }

    /**
     * @param {string} prefix
     * @returns {AccountsTreeNode}
     */
    withoutChild(prefix) {
        const childrenSuffixes = this._childrenSuffixes.slice() || [];
        const childrenHashes = this._childrenHashes.slice() || [];
        delete childrenSuffixes[this._getChildIndex(prefix)];
        delete childrenHashes[this._getChildIndex(prefix)];
        return AccountsTreeNode.branchNode(this._prefix, childrenSuffixes, childrenHashes);
    }

    /**
     * @returns {boolean}
     */
    hasChildren() {
        return this._childrenSuffixes && this._childrenSuffixes.some(child => !!child);
    }

    /**
     * @returns {boolean}
     */
    hasSingleChild() {
        return this._childrenSuffixes && this._childrenSuffixes.reduce((count, child) => count + !!child, 0) === 1;
    }

    /**
     * @returns {?string}
     */
    getFirstChild() {
        if (!this._childrenSuffixes) {
            return undefined;
        }
        const suffix = this._childrenSuffixes.find(child => !!child);
        return suffix ? this.prefix + suffix : undefined;
    }

    /**
     * @returns {?string}
     */
    getLastChild() {
        if (!this._childrenSuffixes) {
            return undefined;
        }
        for (let i = this._childrenSuffixes.length - 1; i >= 0; --i) {
            if (this._childrenSuffixes[i]) {
                return this.prefix + this._childrenSuffixes[i];
            }
        }
        return undefined;
    }

    /**
     * @returns {?Array.<string>}
     */
    getChildren() {
        if (!this._childrenSuffixes) {
            return undefined;
        }
        return this._childrenSuffixes.filter(child => !!child).map(child => this.prefix + child);
    }

    /** @type {Account} */
    get account() {
        return this._account;
    }

    /** @type {string} */
    get prefix() {
        return this._prefix;
    }

    /** @type {string} */
    set prefix(value) {
        this._prefix = value;
        this._hash = undefined;
    }

    /**
     * @param {Account} account
     * @returns {AccountsTreeNode}
     */
    withAccount(account) {
        return AccountsTreeNode.terminalNode(this._prefix, account);
    }

    /**
     * @returns {Hash}
     */
    hash() {
        if (!this._hash) {
            this._hash = Hash.light(this.serialize());
        }
        return this._hash;
    }

    /**
     * Tests if this node is a child of some other node.
     * @param {AccountsTreeNode} parent
     * @returns {boolean}
     */
    isChildOf(parent) {
        return parent.getChildren() && parent.getChildren().includes(this._prefix);
    }

    /**
     * @returns {boolean}
     */
    isTerminal() {
        return AccountsTreeNode.isTerminalType(this._type);
    }

    /**
     * @returns {boolean}
     */
    isBranch() {
        return AccountsTreeNode.isBranchType(this._type);
    }

    /**
     * @param {string} prefix
     * @returns {number}
     * @private
     */
    _getChildIndex(prefix) {
        Assert.that(prefix.substr(0, this.prefix.length) === this.prefix, `Prefix ${prefix} is not a child of the current node ${this.prefix}`);
        return parseInt(prefix[this.prefix.length], 16);
    }

    /**
     * @param {AccountsTreeNode} o
     * @returns {boolean}
     */
    equals(o) {
        if (!(o instanceof AccountsTreeNode)) return false;
        if (!Object.is(this.prefix, o.prefix)) return false;
        if (this.isTerminal()) {
            return o.isTerminal() && o._account.equals(this._account);
        } else {
            if (!o.isBranch()) return false;
            if (this._childrenSuffixes.length !== o._childrenSuffixes.length) return false;
            if (o._childrenSuffixes.length !== o._childrenHashes.length) return false;
            for (let i = 0; i < this._childrenSuffixes.length; ++i) {
                // hashes of child nodes
                const ourChild = this._childrenHashes[i];
                const otherChild = o._childrenHashes[i];
                if (ourChild) {
                    if (!otherChild || !ourChild.equals(otherChild)) return false;
                } else {
                    if (otherChild) return false;
                }
                if (this._childrenSuffixes[i] !== o._childrenSuffixes[i]) return false;
            }
        }
        return true;
    }
}
AccountsTreeNode.BRANCH = 0x00;
AccountsTreeNode.TERMINAL = 0xff;
Class.register(AccountsTreeNode);

class AccountsTreeStore {
    /**
     * @param {JungleDB} jdb
     */
    static initPersistent(jdb) {
        jdb.createObjectStore('Accounts', { codec: new AccountsTreeStoreCodec() });
    }

    /**
     * @param {JungleDB} jdb
     * @returns {AccountsTreeStore}
     */
    static getPersistent(jdb) {
        return new AccountsTreeStore(jdb.getObjectStore('Accounts'));
    }

    /**
     * @returns {AccountsTreeStore}
     */
    static createVolatile() {
        const store = JDB.JungleDB.createVolatileObjectStore();
        return new AccountsTreeStore(store);
    }

    /**
     * @param {IObjectStore} store
     */
    constructor(store) {
        this._store = store;
    }

    /**
     * @override
     * @param {string} key
     * @returns {Promise.<AccountsTreeNode>}
     */
    get(key) {
        return this._store.get(key);
    }

    /**
     * @override
     * @param {AccountsTreeNode} node
     * @returns {Promise.<string>}
     */
    async put(node) {
        const key = node.prefix;
        await this._store.put(key, node);
        return key;
    }

    /**
     * @override
     * @param {AccountsTreeNode} node
     * @returns {Promise.<string>}
     */
    async remove(node) {
        const key = node.prefix;
        await this._store.remove(key);
        return key;
    }

    /**
     * @returns {Promise.<AccountsTreeNode>}
     */
    getRootNode() {
        return this.get('');
    }

    /**
     * @param startPrefix This prefix will *not* be included.
     * @param size
     * @returns {Promise.<Array.<AccountsTreeNode>>}
     */
    async getTerminalNodes(startPrefix, size) {
        const relevantKeys = [];
        await this._store.keyStream(key => {
            if (key.length === Address.HEX_SIZE) {
                relevantKeys.push(key);
                if (relevantKeys.length === size) {
                    return false;
                }
            }
            return true;
        }, true, JDB.KeyRange.lowerBound(startPrefix, true));
        const nodes = [];
        for (const key of relevantKeys) {
            nodes.push(this._store.get(key));
        }
        return Promise.all(nodes);
    }

    /**
     * @param {AccountsTreeStore} [tx]
     * @returns {AccountsTreeStore}
     */
    snapshot(tx) {
        const snapshot = this._store.snapshot();
        if (tx) {
            snapshot.inherit(tx._store);
        }
        return new AccountsTreeStore(snapshot);
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {AccountsTreeStore}
     */
    transaction(enableWatchdog = true) {
        const tx = this._store.transaction(enableWatchdog);
        return new AccountsTreeStore(tx);
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {SynchronousAccountsTreeStore}
     */
    synchronousTransaction(enableWatchdog = true) {
        const tx = this._store.synchronousTransaction(enableWatchdog);
        return new SynchronousAccountsTreeStore(tx);
    }

    /**
     * @returns {Promise}
     */
    truncate() {
        return this._store.truncate();
    }

    /**
     * @returns {Promise.<boolean>}
     */
    commit() {
        return this._store.commit();
    }

    /**
     * @returns {Promise}
     */
    abort() {
        return this._store.abort();
    }

    /** @type {Transaction} */
    get tx() {
        if (this._store instanceof JDB.Transaction) {
            return this._store;
        }
        return undefined;
    }
}
Class.register(AccountsTreeStore);

/**
 * @implements {ICodec}
 */
class AccountsTreeStoreCodec {
    /**
     * @param {*} obj The object to encode before storing it.
     * @returns {*} Encoded object.
     */
    encode(obj) {
        return obj.serialize();
    }

    /**
     * @param {*} obj The object to decode.
     * @param {string} key The object's primary key.
     * @returns {*} Decoded object.
     */
    decode(obj, key) {
        return AccountsTreeNode.unserialize(new SerialBuffer(obj));
    }

    /**
     * @type {{encode: function(val:*):*, decode: function(val:*):*, buffer: boolean, type: string}|void}
     */
    get valueEncoding() {
        return JDB.JungleDB.BINARY_ENCODING;
    }
}

class SynchronousAccountsTreeStore extends AccountsTreeStore {
    /**
     * @param {SynchronousTransaction} store
     */
    constructor(store) {
        super(store);
        this._syncStore = store;
    }

    /**
     * @param {Array.<string>} keys
     */
    async preload(keys) {
        await this._syncStore.preload(keys);
    }

    /**
     * @param {string} key
     * @param {boolean} [expectedToBePresent]
     * @returns {AccountsTreeNode}
     */
    getSync(key, expectedToBePresent = true) {
        return this._syncStore.getSync(key, { expectPresence: expectedToBePresent });
    }

    /**
     * @param {AccountsTreeNode} node
     * @returns {string}
     */
    putSync(node) {
        const key = node.prefix;
        this._syncStore.putSync(key, node);
        return key;
    }

    /**
     * @param {AccountsTreeNode} node
     * @returns {string}
     */
    removeSync(node) {
        const key = node.prefix;
        this._syncStore.removeSync(key);
        return key;
    }

    /**
     * @returns {AccountsTreeNode}
     */
    getRootNodeSync() {
        return this.getSync('');
    }
}
Class.register(SynchronousAccountsTreeStore);

class AccountsProof {
    /**
     * @param {Array.<AccountsTreeNode>} nodes
     */
    constructor(nodes) {
        if (!nodes || !Array.isArray(nodes) || !NumberUtils.isUint16(nodes.length)
            || nodes.some(it => !(it instanceof AccountsTreeNode))) throw new Error('Malformed nodes');

        /** @type {Array.<AccountsTreeNode>} */
        this._nodes = nodes;
        /** @type {HashMap.<Hash,AccountsTreeNode>} */
        this._index = null;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {AccountsProof}
     */
    static unserialize(buf) {
        const count = buf.readUint16();
        const nodes = [];
        for (let i = 0; i < count; i++) {
            nodes.push(AccountsTreeNode.unserialize(buf));
        }
        return new AccountsProof(nodes);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._nodes.length);
        for (const node of this._nodes) {
            node.serialize(buf);
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let size = /*count*/ 2;
        for (const node of this._nodes) {
            size += node.serializedSize;
        }
        return size;
    }

    /**
     * Assumes nodes to be in post order and hashes nodes to check internal consistency of proof.
     * XXX Abuse this method to index the nodes contained in the proof. This forces callers to explicitly verify()
     * the proof before retrieving accounts.
     * @returns {boolean}
     */
    verify() {
        /** @type {Array.<AccountsTreeNode>} */
        const children = [];
        this._index = new HashMap();
        for (const node of this._nodes) {
            // If node is a branch node, validate its children.
            if (node.isBranch()) {
                let child;
                while (child = children.pop()) { // eslint-disable-line no-cond-assign
                    if (child.isChildOf(node)) {
                        const hash = child.hash();
                        // If the child is not valid, return false.
                        if (!node.getChildHash(child.prefix).equals(hash) || node.getChild(child.prefix) !== child.prefix) {
                            return false;
                        }
                        this._index.put(hash, child);
                    } else {
                        children.push(child);
                        break;
                    }
                }
            }

            // Append child.
            children.push(node);
        }

        // The last element must be the root node.
        return children.length === 1 && children[0].prefix === '' && children[0].isBranch();
    }

    /**
     * @param {Address} address
     * @returns {Account}
     */
    getAccount(address) {
        if (!this._index) {
            throw new Error('AccountsProof must be verified before retrieving accounts. Call verify() first.');
        }

        const rootNode = this._nodes[this._nodes.length - 1];
        const prefix = address.toHex();
        return this._getAccount(rootNode, prefix);
    }

    /**
     * @param {AccountsTreeNode} node
     * @param {string} prefix
     * @returns {Account}
     * @private
     */
    _getAccount(node, prefix) {
        // Find common prefix between node and requested address.
        const commonPrefix = StringUtils.commonPrefix(node.prefix, prefix);

        // If the prefix does not fully match, the requested account does not exist.
        if (commonPrefix.length !== node.prefix.length) return Account.INITIAL;

        // If the remaining address is empty, we have found the requested node.
        if (commonPrefix === prefix) return node.account;

        // Descend into the matching child node if one exists.
        const childKey = node.getChildHash(prefix);
        if (childKey) {
            const childNode = this._index.get(childKey);

            // If the child exists but is not part of the proof, fail.
            if (!childNode) {
                throw new Error('Requested address not part of AccountsProof');
            }

            return this._getAccount(childNode, prefix);
        }

        // No matching child exists, the requested account does not exist.
        return Account.INITIAL;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `AccountsProof{length=${this.length}}`;
    }

    /**
     * @returns {Hash}
     */
    root() {
        return this._nodes[this._nodes.length - 1].hash();
    }

    /** @type {number} */
    get length() {
        return this._nodes.length;
    }

    /** @type {Array.<AccountsTreeNode>} */
    get nodes() {
        return this._nodes;
    }
}
Class.register(AccountsProof);

class AccountsTreeChunk {
    /**
     * @param {Array.<AccountsTreeNode>} nodes
     * @param {AccountsProof} proof
     */
    constructor(nodes, proof) {
        if (!nodes || !NumberUtils.isUint16(nodes.length)
            || nodes.some(it => !(it instanceof AccountsTreeNode) || !it.isTerminal())) throw new Error('Malformed nodes');

        /** @type {Array.<AccountsTreeNode>} */
        this._nodes = nodes;
        this._proof = proof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {AccountsTreeChunk}
     */
    static unserialize(buf) {
        const count = buf.readUint16();
        const nodes = [];
        for (let i = 0; i < count; i++) {
            nodes.push(AccountsTreeNode.unserialize(buf));
        }
        const proof = AccountsProof.unserialize(buf);
        return new AccountsTreeChunk(nodes, proof);
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._nodes.length);
        for (const node of this._nodes) {
            node.serialize(buf);
        }
        this._proof.serialize(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let size = /*count*/ 2;
        for (const node of this._nodes) {
            size += node.serializedSize;
        }
        size += this._proof.serializedSize;
        return size;
    }

    /**
     * @returns {boolean}
     */
    verify() {
        if (!this._proof.verify()) {
            return false;
        }

        let lastPrefix = null;
        for (let i = 0; i <= this._nodes.length; ++i) {
            const node = i < this._nodes.length ? this._nodes[i] : this.tail;
            if (lastPrefix && lastPrefix >= node.prefix) {
                return false;
            }
            lastPrefix = node.prefix;
        }
        return true;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `AccountsTreeChunk{length=${this.length}}`;
    }

    /**
     * @returns {Hash}
     */
    root() {
        return this._proof.root();
    }

    /** @type {Array.<AccountsTreeNode>} */
    get terminalNodes() {
        return this._nodes.concat([this.tail]);
    }

    /** @type {AccountsProof} */
    get proof() {
        return this._proof;
    }

    /** @type {AccountsTreeNode} */
    get head() {
        return this._nodes.length > 0 ? this._nodes[0] : this.tail;
    }

    /** @type {AccountsTreeNode} */
    get tail() {
        return this._proof.nodes[0];
    }

    /** @type {number} */
    get length() {
        return this._nodes.length + 1;
    }
}
AccountsTreeChunk.SIZE_MAX = 5000;
AccountsTreeChunk.EMPTY = new AccountsTreeChunk([], new AccountsProof([]));
Class.register(AccountsTreeChunk);

class AccountsTree extends Observable {
    /**
     * @returns {Promise.<AccountsTree>}
     */
    static async getPersistent(jdb) {
        const store = AccountsTreeStore.getPersistent(jdb);
        const tree = new AccountsTree(store);
        return tree._init();
    }

    /**
     * @returns {Promise.<AccountsTree>}
     */
    static async createVolatile() {
        const store = AccountsTreeStore.createVolatile();
        const tree = new AccountsTree(store);
        return tree._init();
    }

    /**
     * @private
     * @param {AccountsTreeStore} store
     * @returns {AccountsTree}
     */
    constructor(store) {
        super();
        /** @type {AccountsTreeStore} */
        this._store = store;
        this._synchronizer = new Synchronizer();
    }

    /**
     * @returns {Promise.<AccountsTree>}
     * @protected
     */
    async _init() {
        let rootNode = await this._store.getRootNode();
        if (!rootNode) {
            rootNode = AccountsTreeNode.branchNode(/*prefix*/ '', /*childrenSuffixes*/ [], /*childrenHashes*/ []);
            await this._store.put(rootNode);
        }
        return this;
    }

    /**
     * @param {Address} address
     * @param {Account} account
     * @returns {Promise}
     */
    put(address, account) {
        return this._synchronizer.push(() => {
            return this._put(address, account);
        });
    }

    /**
     * @param {Address} address
     * @param {Account} account
     * @returns {Promise}
     * @private
     */
    async _put(address, account) {
        if (account.isInitial() && !(await this.get(address))) {
            return;
        }

        // Fetch the root node.
        const rootNode = await this._store.getRootNode();
        Assert.that(!!rootNode, 'Corrupted store: Failed to fetch AccountsTree root node');

        // Insert account into the tree at address.
        const prefix = address.toHex();
        await this._insert(rootNode, prefix, account, []);
    }

    /**
     * @param {AccountsTreeNode} node
     * @param {string} prefix
     * @param {Account} account
     * @param {Array.<AccountsTreeNode>} rootPath
     * @returns {Promise}
     * @private
     */
    async _insert(node, prefix, account, rootPath) {
        // Find common prefix between node and new address.
        const commonPrefix = StringUtils.commonPrefix(node.prefix, prefix);

        // If the node prefix does not fully match the new address, split the node.
        if (commonPrefix.length !== node.prefix.length) {
            // Insert the new account node.
            const newChild = AccountsTreeNode.terminalNode(prefix, account);
            const newChildHash = newChild.hash();
            await this._store.put(newChild);

            // Insert the new parent node.
            const newParent = AccountsTreeNode.branchNode(commonPrefix)
                .withChild(node.prefix, node.hash())
                .withChild(newChild.prefix, newChildHash);
            const newParentHash = newParent.hash();
            await this._store.put(newParent);

            return this._updateKeys(newParent.prefix, newParentHash, rootPath);
        }

        // If the commonPrefix is the specified address, we have found an (existing) node
        // with the given address. Update the account.
        if (commonPrefix === prefix) {
            // XXX How does this generalize to more than one account type?
            // Special case: If the new balance is the initial balance
            // (i.e. balance=0, nonce=0), it is like the account never existed
            // in the first place. Delete the node in this case.
            if (account.isInitial()) {
                await this._store.remove(node);
                // We have already deleted the node, remove the subtree it was on.
                return this._prune(node.prefix, rootPath);
            }

            // Update the account.
            node = node.withAccount(account);
            const nodeHash = node.hash();
            await this._store.put(node);

            return this._updateKeys(node.prefix, nodeHash, rootPath);
        }

        // If the node prefix matches and there are address bytes left, descend into
        // the matching child node if one exists.
        const childPrefix = node.getChild(prefix);
        if (childPrefix) {
            const childNode = await this._store.get(childPrefix);
            rootPath.push(node);
            return this._insert(childNode, prefix, account, rootPath);
        }

        // If no matching child exists, add a new child account node to the current node.
        const newChild = AccountsTreeNode.terminalNode(prefix, account);
        const newChildHash = newChild.hash();
        await this._store.put(newChild);

        node = node.withChild(newChild.prefix, newChildHash);
        const nodeHash = node.hash();
        await this._store.put(node);

        return this._updateKeys(node.prefix, nodeHash, rootPath);
    }

    /**
     * @param {string} prefix
     * @param {Array.<AccountsTreeNode>} rootPath
     * @returns {Promise}
     * @private
     */
    async _prune(prefix, rootPath) {
        // Walk along the rootPath towards the root node starting with the
        // immediate predecessor of the node specified by 'prefix'.
        let i = rootPath.length - 1;
        for (; i >= 0; --i) {
            let node = rootPath[i];

            node = node.withoutChild(prefix);

            // If the node has only a single child, merge it with the next node.
            if (node.hasSingleChild() && node.prefix !== '') {
                await this._store.remove(node); // eslint-disable-line no-await-in-loop

                const childPrefix = node.getFirstChild();
                const childNode = await this._store.get(childPrefix); // eslint-disable-line no-await-in-loop

                await this._store.put(childNode); // eslint-disable-line no-await-in-loop
                const childHash = childNode.hash();
                return this._updateKeys(childNode.prefix, childHash, rootPath.slice(0, i));
            }
            // Otherwise, if the node has children left, update it and all keys on the
            // remaining root path. Pruning finished.
            // XXX Special case: We start with an empty root node. Don't delete it.
            else if (node.hasChildren() || node.prefix === '') {
                const nodeHash = node.hash();
                await this._store.put(node); // eslint-disable-line no-await-in-loop
                return this._updateKeys(node.prefix, nodeHash, rootPath.slice(0, i));
            }

            // The node has no children left, continue pruning.
            prefix = node.prefix;
        }

        // XXX This should never be reached.
        return undefined;
    }

    /**
     * @param {string} prefix
     * @param {Hash} nodeHash
     * @param {Array.<AccountsTreeNode>} rootPath
     * @returns {Promise}
     * @private
     */
    async _updateKeys(prefix, nodeHash, rootPath) {
        // Walk along the rootPath towards the root node starting with the
        // immediate predecessor of the node specified by 'prefix'.
        let i = rootPath.length - 1;
        for (; i >= 0; --i) {
            let node = rootPath[i];

            node = node.withChild(prefix, nodeHash);
            await this._store.put(node); // eslint-disable-line no-await-in-loop
            nodeHash = node.hash();
            prefix = node.prefix;
        }

        return nodeHash;
    }

    /**
     * @param {Address} address
     * @returns {Promise.<?Account>}
     */
    async get(address) {
        const node = await this._store.get(address.toHex());
        return node !== undefined ? node.account : null;
    }

    /**
     * @param {Array.<Address>} addresses
     * @returns {Promise.<AccountsProof>}
     */
    async getAccountsProof(addresses) {
        const rootNode = await this._store.getRootNode();
        Assert.that(!!rootNode, 'Corrupted store: Failed to fetch AccountsTree root node');

        const prefixes = [];
        for (const address of addresses) {
            prefixes.push(address.toHex());
        }
        // We sort the addresses to simplify traversal in post order (leftmost addresses first).
        prefixes.sort();

        const nodes = [];
        await this._getAccountsProof(rootNode, prefixes, nodes);
        return new AccountsProof(nodes);
    }

    /**
     * Constructs the accounts proof in post-order.
     * @param {AccountsTreeNode} node
     * @param {Array.<string>} prefixes
     * @param {Array.<AccountsTreeNode>} nodes
     * @returns {Promise.<*>}
     * @private
     */
    async _getAccountsProof(node, prefixes, nodes) {
        // For each prefix, descend the tree individually.
        let includeNode = false;
        for (let i = 0; i < prefixes.length; ) {
            let prefix = prefixes[i];

            // Find common prefix between node and the current requested prefix.
            const commonPrefix = StringUtils.commonPrefix(node.prefix, prefix);

            // If the prefix fully matches, we have found the requested node.
            // If the prefix does not fully match, the requested address is not part of this node.
            // Include the node in the proof nevertheless to prove that the account doesn't exist.
            if (commonPrefix.length !== node.prefix.length || node.prefix === prefix) {
                includeNode = true;
                i++;
                continue;
            }

            // Descend into the matching child node if one exists.
            const childKey = node.getChild(prefix);
            if (childKey) {
                const childNode = await this._store.get(childKey); // eslint-disable-line no-await-in-loop

                // Group addresses with same prefix:
                // Because of our ordering, they have to be located next to the current prefix.
                // Hence, we iterate over the next prefixes, until we don't find commonalities anymore.
                // In the next main iteration we can skip those we already requested here.
                const subPrefixes = [prefix];
                // Find other prefixes to descend into this tree as well.
                let j = i + 1;
                for (; j < prefixes.length; ++j) {
                    // Since we ordered prefixes, there can't be any other prefixes with commonalities.
                    if (!prefixes[j].startsWith(childNode.prefix)) break;
                    // But if there is a commonality, add it to the list.
                    subPrefixes.push(prefixes[j]);
                }
                // Now j is the last index which doesn't have commonalities,
                // we continue from there in the next iteration.
                i = j;

                includeNode = (await this._getAccountsProof(childNode, subPrefixes, nodes)) || includeNode; // eslint-disable-line no-await-in-loop
            }
            // No child node exists with the requested prefix. Include the current node to prove the absence of the requested account.
            else {
                includeNode = true;
                i++;
            }
        }

        // If this branch contained at least one account, we add this node.
        if (includeNode) {
            nodes.push(node);
        }

        return includeNode;
    }

    /**
     * @param {string} startPrefix The prefix to start with.
     * @param {number} size The maximum number of terminal nodes to include.
     * @returns {Promise.<AccountsTreeChunk>}
     */
    async getChunk(startPrefix, size) {
        const chunk = await this._store.getTerminalNodes(startPrefix, size);
        const lastNode = chunk.pop();
        let /** @type {AccountsProof} */ proof;
        if (lastNode) {
            proof = await this.getAccountsProof([Address.fromHex(lastNode.prefix)]);
        } else {
            // The proof that the last address does not exist is sufficient to prove that there is no such chunk.
            proof = await this.getAccountsProof([Address.fromHex('ffffffffffffffffffffffffffffffffffffffff')]);
        }
        return new AccountsTreeChunk(chunk, proof);
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {Promise.<AccountsTree>}
     */
    transaction(enableWatchdog = true) {
        const tree = new AccountsTree(this._store.transaction(enableWatchdog));
        return tree._init();
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {Promise.<SynchronousAccountsTree>}
     */
    synchronousTransaction(enableWatchdog = true) {
        const tx = this._store.synchronousTransaction(enableWatchdog);
        const tree = new SynchronousAccountsTree(tx);
        return tree._init();
    }

    /**
     * @returns {Promise.<PartialAccountsTree>}
     */
    async partialTree() {
        const tx = this._store.synchronousTransaction(false);
        await tx.truncate();
        const tree = new PartialAccountsTree(tx);
        return tree._init();
    }

    /**
     * @param {AccountsTree} [tx]
     * @returns {Promise.<AccountsTree>}
     */
    snapshot(tx) {
        const tree = new AccountsTree(this._store.snapshot(tx ? tx._store : undefined));
        return tree._init();
    }

    /**
     * @returns {Promise}
     */
    async commit() {
        Assert.that(!(await this.root()).equals(new Hash(null)));
        return this._store.commit();
    }

    /**
     * @returns {Promise}
     */
    abort() {
        return this._store.abort();
    }

    /**
     * @returns {Promise.<Hash>}
     */
    async root() {
        const rootNode = await this._store.getRootNode();
        return rootNode && rootNode.hash();
    }

    /** @type {Transaction} */
    get tx() {
        return this._store.tx;
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async isEmpty() {
        const rootNode = await this._store.getRootNode();
        return !rootNode.hasChildren();
    }
}
Class.register(AccountsTree);


class SynchronousAccountsTree extends AccountsTree {
    /**
     * @private
     * @param {SynchronousAccountsTreeStore} store
     * @returns {SynchronousAccountsTree}
     */
    constructor(store) {
        super(store);
        /** @type {SynchronousAccountsTreeStore} */
        this._syncStore = store;
    }

    /**
     * @param {Array.<Address>} addresses
     * @returns {Promise}
     */
    async preloadAddresses(addresses) {
        const rootNode = await this._syncStore.getRootNode();
        Assert.that(!!rootNode, 'Corrupted store: Failed to fetch AccountsTree root node');

        const prefixes = [];
        for (const address of addresses) {
            prefixes.push(address.toHex());
        }
        // We sort the addresses to simplify traversal in post order (leftmost addresses first).
        prefixes.sort();

        await this._preloadAddresses(rootNode, prefixes);
    }

    /**
     * @param {AccountsTreeNode} node
     * @param {Array.<string>} prefixes
     * @private
     */
    async _preloadAddresses(node, prefixes) {
        if (node.hasChildren()) {
            await this._syncStore.preload(node.getChildren());
        }
        
        // For each prefix, descend the tree individually.
        for (let i = 0; i < prefixes.length; ) {
            const prefix = prefixes[i];

            // Find common prefix between node and the current requested prefix.
            const commonPrefix = StringUtils.commonPrefix(node.prefix, prefix);

            // If the prefix fully matches, we have found the requested node.
            // If the prefix does not fully match, the requested address is not part of this node.
            // Include the node in the proof nevertheless to prove that the account doesn't exist.
            if (commonPrefix.length !== node.prefix.length || node.prefix === prefix) {
                i++;
                continue;
            }

            // Descend into the matching child node if one exists.
            const childKey = node.getChild(prefix);
            if (childKey) {
                const childNode = this._syncStore.getSync(childKey);

                // Group addresses with same prefix:
                // Because of our ordering, they have to be located next to the current prefix.
                // Hence, we iterate over the next prefixes, until we don't find commonalities anymore.
                // In the next main iteration we can skip those we already requested here.
                const subPrefixes = [prefix];
                // Find other prefixes to descend into this tree as well.
                let j = i + 1;
                for (; j < prefixes.length; ++j) {
                    // Since we ordered prefixes, there can't be any other prefixes with commonalities.
                    if (!prefixes[j].startsWith(childNode.prefix)) break;
                    // But if there is a commonality, add it to the list.
                    subPrefixes.push(prefixes[j]);
                }
                // Now j is the last index which doesn't have commonalities,
                // we continue from there in the next iteration.
                i = j;

                await this._preloadAddresses(childNode, subPrefixes); // eslint-disable-line no-await-in-loop
            }
            // No child node exists with the requested prefix. Include the current node to prove the absence of the requested account.
            else {
                i++;
            }
        }
    }

    /**
     * @param {Address} address
     * @param {Account} account
     */
    putSync(address, account) {
        this.putBatch(address, account);
        this.finalizeBatch();
    }

    finalizeBatch() {
        const rootNode = this._syncStore.getRootNodeSync();
        this._updateHashes(rootNode);
    }

    /**
     * @param {Address} address
     * @param {Account} account
     */
    putBatch(address, account) {
        if (account.isInitial() && !this.getSync(address, false)) {
            return;
        }

        // Fetch the root node.
        const rootNode = this._syncStore.getRootNodeSync();
        Assert.that(!!rootNode, 'Corrupted store: Failed to fetch AccountsTree root node');

        // Insert account into the tree at address.
        const prefix = address.toHex();
        this._insertBatch(rootNode, prefix, account, []);
    }

    /**
     * @param {AccountsTreeNode} node
     * @param {string} prefix
     * @param {Account} account
     * @param {Array.<AccountsTreeNode>} rootPath
     * @protected
     */
    _insertBatch(node, prefix, account, rootPath) {
        // Find common prefix between node and new address.
        const commonPrefix = StringUtils.commonPrefix(node.prefix, prefix);

        // If the node prefix does not fully match the new address, split the node.
        if (commonPrefix.length !== node.prefix.length) {
            // Insert the new account node.
            const newChild = AccountsTreeNode.terminalNode(prefix, account);
            this._syncStore.putSync(newChild);

            // Insert the new parent node.
            const newParent = AccountsTreeNode.branchNode(commonPrefix)
                .withChild(node.prefix, new Hash(null))
                .withChild(newChild.prefix, new Hash(null));
            this._syncStore.putSync(newParent);

            return this._updateKeysBatch(newParent.prefix, rootPath);
        }

        // If the commonPrefix is the specified address, we have found an (existing) node
        // with the given address. Update the account.
        if (commonPrefix === prefix) {
            // XXX How does this generalize to more than one account type?
            // Special case: If the new balance is the initial balance
            // (i.e. balance=0, nonce=0), it is like the account never existed
            // in the first place. Delete the node in this case.
            if (account.isInitial()) {
                this._syncStore.removeSync(node);
                // We have already deleted the node, remove the subtree it was on.
                return this._pruneBatch(node.prefix, rootPath);
            }

            // Update the account.
            node = node.withAccount(account);
            this._syncStore.putSync(node);

            return this._updateKeysBatch(node.prefix, rootPath);
        }

        // If the node prefix matches and there are address bytes left, descend into
        // the matching child node if one exists.
        const childPrefix = node.getChild(prefix);
        if (childPrefix) {
            const childNode = this._syncStore.getSync(childPrefix);
            rootPath.push(node);
            return this._insertBatch(childNode, prefix, account, rootPath);
        }

        // If no matching child exists, add a new child account node to the current node.
        const newChild = AccountsTreeNode.terminalNode(prefix, account);
        this._syncStore.putSync(newChild);

        node = node.withChild(newChild.prefix, new Hash(null));
        this._syncStore.putSync(node);

        return this._updateKeysBatch(node.prefix, rootPath);
    }

    /**
     * @param {string} prefix
     * @param {Array.<AccountsTreeNode>} rootPath
     * @private
     */
    _pruneBatch(prefix, rootPath) {
        // Walk along the rootPath towards the root node starting with the
        // immediate predecessor of the node specified by 'prefix'.
        let i = rootPath.length - 1;
        for (; i >= 0; --i) {
            let node = rootPath[i];

            node = node.withoutChild(prefix);

            // If the node has only a single child, merge it with the next node.
            if (node.hasSingleChild() && node.prefix !== '') {
                this._syncStore.removeSync(node);

                const childPrefix = node.getFirstChild();
                const childNode = this._syncStore.getSync(childPrefix);

                this._syncStore.putSync(childNode);
                return this._updateKeysBatch(childNode.prefix, rootPath.slice(0, i));
            }
            // Otherwise, if the node has children left, update it and all keys on the
            // remaining root path. Pruning finished.
            // XXX Special case: We start with an empty root node. Don't delete it.
            else if (node.hasChildren() || node.prefix === '') {
                this._syncStore.putSync(node);
                return this._updateKeysBatch(node.prefix, rootPath.slice(0, i));
            }

            // The node has no children left, continue pruning.
            prefix = node.prefix;
        }

        // XXX This should never be reached.
        return undefined;
    }

    /**
     * @param {string} prefix
     * @param {Array.<AccountsTreeNode>} rootPath
     * @private
     */
    _updateKeysBatch(prefix, rootPath) {
        // Walk along the rootPath towards the root node starting with the
        // immediate predecessor of the node specified by 'prefix'.
        let i = rootPath.length - 1;
        for (; i >= 0; --i) {
            let node = rootPath[i];

            node = node.withChild(prefix, new Hash(null));
            this._syncStore.putSync(node);
            prefix = node.prefix;
        }
    }

    /**
     * This method updates all empty hashes (and only such).
     * @param {AccountsTreeNode} node
     * @protected
     */
    _updateHashes(node) {
        if (node.isTerminal()) {
            return node.hash();
        }

        const zeroHash = new Hash(null);
        // Compute sub hashes if necessary.
        const subHashes = node.getChildren().map(child => {
            const currentHash = node.getChildHash(child);
            if (!currentHash.equals(zeroHash)) {
                return currentHash;
            }
            const childNode = this._syncStore.getSync(child);
            return this._updateHashes(childNode);
        });

        // Then prepare new node and update.
        let newNode = node;
        node.getChildren().forEach((child, i) => {
            newNode = newNode.withChild(child, subHashes[i]);
        });
        this._syncStore.putSync(newNode);
        return newNode.hash();
    }

    /**
     * @param {Address} address
     * @param {boolean} [expectedToBePresent]
     * @returns {?Account}
     */
    getSync(address, expectedToBePresent = true) {
        const node = this._syncStore.getSync(address.toHex(), expectedToBePresent);
        return node !== undefined ? node.account : null;
    }

    /**
     * @returns {Hash}
     */
    rootSync() {
        const rootNode = this._syncStore.getRootNodeSync();
        return rootNode && rootNode.hash();
    }
}
Class.register(SynchronousAccountsTree);


class PartialAccountsTree extends SynchronousAccountsTree {
    /**
     * @private
     * @param {SynchronousAccountsTreeStore} store
     */
    constructor(store) {
        super(store);
        this._complete = false;
        /** @type {string} */
        this._lastPrefix = '';
    }

    /**
     * @param {AccountsTreeChunk} chunk
     * @returns {Promise.<PartialAccountsTree.Status>}
     */
    async pushChunk(chunk) {
        // First verify the proof.
        if (!chunk.verify()) {
            return PartialAccountsTree.Status.ERR_INCORRECT_PROOF;
        }

        const tx = this.synchronousTransaction();

        // Then apply all
        tx._putLight(chunk.terminalNodes);

        // Check if proof can be merged.
        if (!tx._mergeProof(chunk.proof, chunk.tail.prefix)) {
            await tx.abort();
            return PartialAccountsTree.Status.ERR_UNMERGEABLE;
        }
        this._complete = tx.complete;

        // Now, we can put all nodes into the store.
        await tx.commit();

        // Update last prefix.
        this._lastPrefix = chunk.tail.prefix;

        // And return OK code depending on internal state.
        return this._complete ? PartialAccountsTree.Status.OK_COMPLETE : PartialAccountsTree.Status.OK_UNFINISHED;
    }

    /**
     * @param {AccountsProof} proof
     * @param {string} upperBound
     * @returns {boolean}
     * @private
     */
    _mergeProof(proof, upperBound) {
        // Retrieve rightmost path of the in-memory tree.
        let node = this._store.getRootNodeSync();
        let nodeChildren = node.getChildren();
        let complete = true;

        // Iterate over the proof and check for consistency.
        let j = proof.length - 1;
        for (; j > 0; --j) {
            const proofNode = proof.nodes[j];
            // The node's prefix might be shorter than the proof node's prefix if it is a newly
            // introduces node in the proof.
            if (StringUtils.commonPrefix(node.prefix, proofNode.prefix) !== node.prefix) {
                return false;
            }

            const proofChildren = proofNode.getChildren();

            // The tree node may not have more children than the proof node.
            if (nodeChildren.length > proofChildren.length) {
                return false;
            }

            // The nextChild we descend to.
            const nextChild = node.getLastChild();
            let insertedNode = false;

            // There are three cases:
            // 1) the child is in our inner tree (so between lower and upper bound), then the hashes must coincide.
            // 2) the child is left of our chunk, so it must be in the store.
            // 3) the child is right of our chunk, so it is a dangling reference.
            let i = 0;
            for (const proofChild of proofChildren) {
                const upperBoundPrefix = upperBound.substr(0, proofChild.length);
                if (proofChild <= upperBoundPrefix) {
                    // An inner node.
                    const child = nodeChildren.shift();

                    // This is the next child.
                    if (StringUtils.commonPrefix(nextChild, proofChild) === proofChild) {
                        // If it is a real prefix of the next child, we have inserted a new node.
                        if (proofChild !== nextChild) {
                            insertedNode = true;
                        }
                        continue;
                    }

                    if (child !== proofChild) {
                        return false;
                    }
                    // The child is equal and not the next child, so the hash must coincide.
                    const nodeHash = node.getChildHash(child);
                    const proofHash = proofNode.getChildHash(child);
                    if (!nodeHash || !proofHash || !nodeHash.equals(proofHash)) {
                        return false;
                    }
                } else {
                    // The others may be dangling references.
                    break;
                }
                ++i;
            }

            // We must have consumed all children!
            if (nodeChildren.length !== 0) {
                return false;
            }

            // If not all of the proof children have been tested, we are definitely incomplete.
            complete = complete && (i === proofChildren.length - 1);

            // If the prefix was the same, we can move on.
            if (insertedNode) {
                nodeChildren = [nextChild];
            } else {
                // We should never end here with a terminal node.
                if (node.isTerminal()) {
                    return false;
                }
                node = this._store.getSync(node.getLastChild());
                nodeChildren = node.getChildren();
                if (node.isTerminal()) {
                    break;
                }
            }
        }

        // Check the terminal nodes.
        if (!node.equals(proof.nodes[0])) {
            return false;
        }

        this._complete = complete;
        return true;
    }

    /**
     * @param {Array.<AccountsTreeNode>} nodes
     * @private
     */
    _putLight(nodes) {
        Assert.that(nodes.every(node => node.isTerminal()), 'Can only build tree from terminal nodes');

        // Fetch the root node.
        let rootNode = this._store.getRootNodeSync();
        Assert.that(!!rootNode, 'Corrupted store: Failed to fetch AccountsTree root node');

        // TODO: Bulk insertion instead of sequential insertion!
        for (const node of nodes) {
            this._insertBatch(rootNode, node.prefix, node.account, []);
            rootNode = this._store.getRootNodeSync();
            Assert.that(!!rootNode, 'Corrupted store: Failed to fetch AccountsTree root node');
        }
        this._updateHashes(rootNode);
    }

    /** @type {boolean} */
    get complete() {
        return this._complete;
    }

    /** @type {string} */
    get missingPrefix() {
        return this._lastPrefix;
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {PartialAccountsTree}
     */
    synchronousTransaction(enableWatchdog = true) {
        const tree = new PartialAccountsTree(this._store.synchronousTransaction(enableWatchdog));
        tree._complete = this._complete;
        tree._lastPrefix = this._lastPrefix;
        return tree;
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {AccountsTree}
     */
    transaction(enableWatchdog = true) {
        if (!this.complete) {
            throw new Error('Can only construct AccountsTree from complete PartialAccountsTree');
        }
        // Use a synchronous transaction here to enable better caching.
        return new AccountsTree(this._store.synchronousTransaction(enableWatchdog));
    }

    /**
     * @returns {Promise.<boolean>}
     */
    commit() {
        return this._store.commit();
    }

    /**
     * @returns {Promise}
     */
    abort() {
        return this._store.abort();
    }
}

/**
 * @enum {number}
 */
PartialAccountsTree.Status = {
    ERR_HASH_MISMATCH: -3,
    ERR_INCORRECT_PROOF: -2,
    ERR_UNMERGEABLE: -1,
    OK_COMPLETE: 0,
    OK_UNFINISHED: 1
};
Class.register(PartialAccountsTree);


class Accounts extends Observable {
    /**
     * Generate an Accounts object that is persisted to the local storage.
     * @returns {Promise.<Accounts>} Accounts object
     */
    static async getPersistent(jdb) {
        const tree = await AccountsTree.getPersistent(jdb);
        return new Accounts(tree);
    }

    /**
     * Generate an Accounts object that loses it's data after usage.
     * @returns {Promise.<Accounts>} Accounts object
     */
    static async createVolatile() {
        const tree = await AccountsTree.createVolatile();
        return new Accounts(tree);
    }

    /**
     * @param {AccountsTree} accountsTree
     */
    constructor(accountsTree) {
        super();
        this._tree = accountsTree;

        // Forward balance change events to listeners registered on this Observable.
        this.bubble(this._tree, '*');
    }

    /**
     * @param {Block} genesisBlock
     * @param {string} encodedAccounts
     * @returns {Promise.<void>}
     */
    async initialize(genesisBlock, encodedAccounts) {
        Assert.that(await this._tree.isEmpty());

        const tree = await this._tree.synchronousTransaction();
        try {
            const buf = BufferUtils.fromBase64(encodedAccounts);
            const count = buf.readUint16();
            for (let i = 0; i < count; i++) {
                const address = Address.unserialize(buf);
                const account = Account.unserialize(buf);
                tree.putSync(address, account);
            }

            await this._commitBlockBody(tree, genesisBlock.body, genesisBlock.height, new TransactionCache());

            tree.finalizeBatch();
        } catch (e) {
            await tree.abort();
            throw e;
        }

        const hash = tree.rootSync();
        if (!genesisBlock.accountsHash.equals(hash)) {
            await tree.abort();
            throw new Error('Genesis AccountsHash mismatch');
        }

        return tree.commit();
    }

    /**
     * @param {Array.<Address>} addresses
     * @returns {Promise.<AccountsProof>}
     */
    getAccountsProof(addresses) {
        return this._tree.getAccountsProof(addresses);
    }

    /**
     * @param {string} startPrefix
     * @returns {Promise.<AccountsTreeChunk>}
     */
    getAccountsTreeChunk(startPrefix) {
        return this._tree.getChunk(startPrefix, AccountsTreeChunk.SIZE_MAX);
    }

    /**
     * @param {Block} block
     * @param {TransactionCache} transactionCache
     * @return {Promise}
     */
    async commitBlock(block, transactionCache) {
        const tree = await this._tree.synchronousTransaction();
        await tree.preloadAddresses(block.body.getAddresses());
        try {
            this._commitBlockBody(tree, block.body, block.height, transactionCache);
        } catch (e) {
            await tree.abort();
            throw e;
        }

        tree.finalizeBatch();

        const hash = tree.rootSync();
        if (!block.accountsHash.equals(hash)) {
            await tree.abort();
            throw new Error('AccountsHash mismatch');
        }
        return tree.commit();
    }

    /**
     * @param {BlockBody} body
     * @param {number} blockHeight
     * @param {TransactionCache} transactionCache
     * @return {Promise}
     */
    async commitBlockBody(body, blockHeight, transactionCache) {
        const tree = await this._tree.synchronousTransaction();
        await tree.preloadAddresses(body.getAddresses());
        try {
            this._commitBlockBody(tree, body, blockHeight, transactionCache);
        } catch (e) {
            await tree.abort();
            throw e;
        }
        tree.finalizeBatch();
        return tree.commit();
    }

    /**
     * @param {Array.<Transaction>} transactions
     * @param {number} blockHeight
     * @param {TransactionCache} transactionCache
     * @return {Promise<Array.<PrunedAccount>>}
     */
    async gatherToBePrunedAccounts(transactions, blockHeight, transactionCache) {
        const tree = await this._tree.synchronousTransaction();
        const addresses = [];
        for (const tx of transactions) {
            addresses.push(tx.sender, tx.recipient);
        }
        await tree.preloadAddresses(addresses);
        try {
            this._processSenderAccounts(tree, transactions, blockHeight, transactionCache);
            this._processRecipientAccounts(tree, transactions, blockHeight);
            this._processContracts(tree, transactions, blockHeight);

            const toBePruned = new HashSet();
            for (const tx of transactions) {
                const senderAccount = this._getSync(tx.sender, undefined, tree);
                if (senderAccount.isToBePruned()) {
                    toBePruned.add(new PrunedAccount(tx.sender, senderAccount));
                }
            }
            return toBePruned.values().sort((a, b) => a.compare(b));
        } finally {
            await tree.abort();
        }
    }

    /**
     * @param {Block} block
     * @param {TransactionCache} transactionCache
     * @return {Promise}
     */
    async revertBlock(block, transactionCache) {
        if (!block) throw new Error('block undefined');

        const hash = await this._tree.root();
        if (!block.accountsHash.equals(hash)) {
            throw new Error('AccountsHash mismatch');
        }
        return this.revertBlockBody(block.body, block.height, transactionCache);
    }

    /**
     * @param {BlockBody} body
     * @param {number} blockHeight
     * @param {TransactionCache} transactionCache
     * @return {Promise}
     */
    async revertBlockBody(body, blockHeight, transactionCache) {
        const tree = await this._tree.synchronousTransaction();
        await tree.preloadAddresses(body.getAddresses());
        try {
            this._revertBlockBody(tree, body, blockHeight, transactionCache);
        } catch (e) {
            await tree.abort();
            throw e;
        }
        tree.finalizeBatch();
        return tree.commit();
    }

    /**
     * Gets the {@link Account}-object for an address.
     *
     * @param {Address} address
     * @param {Account.Type} [accountType]
     * @param {AccountsTree} [tree]
     * @return {Promise.<Account>}
     */
    async get(address, accountType, tree = this._tree) {
        const account = await tree.get(address);
        if (!account) {
            if (typeof accountType === 'undefined') {
                return Account.INITIAL;
            }
            throw new Error('Account type was given but account not present');
        } else if (typeof accountType !== 'undefined' && account.type !== accountType) {
            throw new Error('Account type does match actual account');
        }
        return account;
    }

    /**
     * Gets the {@link Account}-object for an address.
     *
     * @param {Address} address
     * @param {Account.Type} [accountType]
     * @param {SynchronousAccountsTree} tree
     * @private
     * @return {Account}
     */
    _getSync(address, accountType, tree) {
        const account = tree.getSync(address, false);
        if (!account) {
            if (typeof accountType === 'undefined') {
                return Account.INITIAL;
            }
            throw new Error('Account type was given but account not present');
        } else if (typeof accountType !== 'undefined' && account.type !== accountType) {
            throw new Error('Account type does match actual account');
        }
        return account;
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {Promise.<Accounts>}
     */
    async transaction(enableWatchdog = true) {
        return new Accounts(await this._tree.transaction(enableWatchdog));
    }

    /**
     * @param {Accounts} [tx]
     * @returns {Promise.<Accounts>}
     */
    async snapshot(tx) {
        return new Accounts(await this._tree.snapshot(tx ? tx._tree : undefined));
    }

    /**
     * @returns {Promise.<PartialAccountsTree>}
     */
    partialAccountsTree() {
        return this._tree.partialTree();
    }

    /**
     * @returns {Promise}
     */
    commit() {
        return this._tree.commit();
    }

    /**
     * @returns {Promise}
     */
    abort() {
        return this._tree.abort();
    }

    /**
     * Step 1)
     * @param {SynchronousAccountsTree} tree
     * @param {Array.<Transaction>} transactions
     * @param {number} blockHeight
     * @param {TransactionCache} transactionCache
     * @param {boolean} [revert]
     * @private
     */
    _processSenderAccounts(tree, transactions, blockHeight, transactionCache, revert = false) {
        for (const tx of transactions) {
            const senderAccount = this._getSync(tx.sender, !revert ? tx.senderType : undefined, tree);
            tree.putBatch(tx.sender, senderAccount.withOutgoingTransaction(tx, blockHeight, transactionCache, revert));
        }
    }

    /**
     * Step 2)
     * @param {SynchronousAccountsTree} tree
     * @param {Array.<Transaction>} transactions
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @private
     */
    _processRecipientAccounts(tree, transactions, blockHeight, revert = false) {
        for (const tx of transactions) {
            const recipientAccount = this._getSync(tx.recipient, undefined, tree);
            tree.putBatch(tx.recipient, recipientAccount.withIncomingTransaction(tx, blockHeight, revert));
        }
    }

    /**
     * Step 3)
     * @param {SynchronousAccountsTree} tree
     * @param {Array.<Transaction>} transactions
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @private
     */
    _processContracts(tree, transactions, blockHeight, revert = false) {
        // TODO: Filter & sort contract command.
        if (revert) {
            transactions = transactions.slice().reverse();
        }
        for (const tx of transactions) {
            const recipientAccount = this._getSync(tx.recipient, !revert ? undefined : tx.recipientType, tree);
            tree.putBatch(tx.recipient, recipientAccount.withContractCommand(tx, blockHeight, revert));
        }
    }

    /**
     * @param {SynchronousAccountsTree} tree
     * @param {BlockBody} body
     * @param {number} blockHeight
     * @param {TransactionCache} transactionCache
     * @private
     */
    _commitBlockBody(tree, body, blockHeight, transactionCache) {
        this._processSenderAccounts(tree, body.transactions, blockHeight, transactionCache);
        this._processRecipientAccounts(tree, body.transactions, blockHeight);
        this._processContracts(tree, body.transactions, blockHeight);

        const prunedAccounts = body.prunedAccounts.slice();
        for (const tx of body.transactions) {
            const senderAccount = this._getSync(tx.sender, undefined, tree);
            if (senderAccount.isToBePruned()) {
                const accIdx = prunedAccounts.findIndex((acc) => acc.address.equals(tx.sender));
                if (accIdx === -1 || !senderAccount.equals(prunedAccounts[accIdx].account)) {
                    throw new Error('Account was not pruned correctly');
                } else {
                    // Pruned accounts are reset to their initial state
                    tree.putBatch(tx.sender, Account.INITIAL);
                    prunedAccounts.splice(accIdx, 1);
                }
            }
        }
        if (prunedAccounts.length > 0) {
            throw new Error('Account was invalidly pruned');
        }

        this._rewardMiner(tree, body, blockHeight, false);
    }

    /**
     * @param {SynchronousAccountsTree} tree
     * @param {BlockBody} body
     * @param {number} blockHeight
     * @param {TransactionCache} transactionCache
     * @private
     */
    _revertBlockBody(tree, body, blockHeight, transactionCache) {
        this._rewardMiner(tree, body, blockHeight, true);

        for (const acc of body.prunedAccounts) {
            tree.putBatch(acc.address, acc.account);
        }

        // Execute transactions in reverse order.
        this._processContracts(tree, body.transactions, blockHeight, true);
        this._processRecipientAccounts(tree, body.transactions, blockHeight, true);
        this._processSenderAccounts(tree, body.transactions, blockHeight, transactionCache, true);
    }

    /**
     * @param {SynchronousAccountsTree} tree
     * @param {BlockBody} body
     * @param {number} blockHeight
     * @param {boolean} [revert]
     * @private
     */
    _rewardMiner(tree, body, blockHeight, revert = false) {
        // Sum up transaction fees.
        const txFees = body.transactions.reduce((sum, tx) => sum + tx.fee, 0);

        // "Coinbase transaction"
        const coinbaseTransaction = new ExtendedTransaction(
            Address.NULL, Account.Type.BASIC,
            body.minerAddr, Account.Type.BASIC,
            txFees + Policy.blockRewardAt(blockHeight),
            0, // Fee
            0, // ValidityStartHeight
            Transaction.Flag.NONE,
            new Uint8Array(0));

        const recipientAccount = this._getSync(body.minerAddr, undefined, tree);
        tree.putBatch(body.minerAddr, recipientAccount.withIncomingTransaction(coinbaseTransaction, blockHeight, revert));
    }

    /**
     * @returns {Promise.<Hash>}
     */
    hash() {
        return this._tree.root();
    }

    /** @type {Transaction} */
    get tx() {
        return this._tree.tx;
    }
}
Class.register(Accounts);

class BlockHeader {
    /**
     * @param {Hash} prevHash
     * @param {Hash} interlinkHash
     * @param {Hash} bodyHash
     * @param {Hash} accountsHash
     * @param {number} nBits
     * @param {number} height
     * @param {number} timestamp
     * @param {number} nonce
     * @param {number} version
     */
    constructor(prevHash, interlinkHash, bodyHash, accountsHash, nBits, height, timestamp, nonce, version = BlockHeader.CURRENT_VERSION) {
        if (!NumberUtils.isUint16(version)) throw new Error('Malformed version');
        if (!Hash.isHash(prevHash)) throw new Error('Malformed prevHash');
        if (!Hash.isHash(interlinkHash)) throw new Error('Malformed interlinkHash');
        if (!Hash.isHash(bodyHash)) throw new Error('Malformed bodyHash');
        if (!Hash.isHash(accountsHash)) throw new Error('Malformed accountsHash');
        if (!NumberUtils.isUint32(nBits) || !BlockUtils.isValidCompact(nBits)) throw new Error('Malformed nBits');
        if (!NumberUtils.isUint32(height)) throw new Error('Invalid height');
        if (!NumberUtils.isUint32(timestamp)) throw new Error('Malformed timestamp');
        if (!NumberUtils.isUint32(nonce)) throw new Error('Malformed nonce');

        /** @type {number} */
        this._version = version;
        /** @type {Hash} */
        this._prevHash = prevHash;
        /** @type {Hash} */
        this._interlinkHash = interlinkHash;
        /** @type {Hash} */
        this._bodyHash = bodyHash;
        /** @type {Hash} */
        this._accountsHash = accountsHash;
        /** @type {number} */
        this._nBits = nBits;
        /** @type {number} */
        this._height = height;
        /** @type {number} */
        this._timestamp = timestamp;
        /** @type {number} */
        this._nonce = nonce;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {BlockHeader}
     */
    static unserialize(buf) {
        const version = buf.readUint16();
        if (!BlockHeader.SUPPORTED_VERSIONS.includes(version)) throw new Error(`Unsupported block version ${version}`);
        const prevHash = Hash.unserialize(buf);
        const interlinkHash = Hash.unserialize(buf);
        const bodyHash = Hash.unserialize(buf);
        const accountsHash = Hash.unserialize(buf);
        const nBits = buf.readUint32();
        const height = buf.readUint32();
        const timestamp = buf.readUint32();
        const nonce = buf.readUint32();
        return new BlockHeader(prevHash, interlinkHash, bodyHash, accountsHash, nBits, height, timestamp, nonce, version);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._version);
        this._prevHash.serialize(buf);
        this._interlinkHash.serialize(buf);
        this._bodyHash.serialize(buf);
        this._accountsHash.serialize(buf);
        buf.writeUint32(this._nBits);
        buf.writeUint32(this._height);
        buf.writeUint32(this._timestamp);
        buf.writeUint32(this._nonce);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*version*/ 2
            + this._prevHash.serializedSize
            + this._interlinkHash.serializedSize
            + this._bodyHash.serializedSize
            + this._accountsHash.serializedSize
            + /*nBits*/ 4
            + /*height*/ 4
            + /*timestamp*/ 4
            + /*nonce*/ 4;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {Promise.<boolean>}
     */
    async verifyProofOfWork(buf) {
        const pow = await this.pow(buf);
        return BlockUtils.isProofOfWork(pow, this.target);
    }

    /**
     * @param {BlockHeader} prevHeader
     * @returns {boolean}
     */
    isImmediateSuccessorOf(prevHeader) {
        // Check that the height is one higher than the previous height.
        if (this.height !== prevHeader.height + 1) {
            return false;
        }

        // Check that the timestamp is greater or equal to the predecessor's timestamp.
        if (this.timestamp < prevHeader.timestamp) {
            return false;
        }

        // Check that the hash of the predecessor block equals prevHash.
        const prevHash = prevHeader.hash();
        if (!this.prevHash.equals(prevHash)) {
            return false;
        }

        // Everything checks out.
        return true;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {Hash}
     */
    hash(buf) {
        this._hash = this._hash || Hash.light(this.serialize(buf));
        return this._hash;
    }
    
    /**
     * @param {SerialBuffer} [buf]
     * @return {Promise.<Hash>}
     */
    async pow(buf) {
        this._pow = this._pow || await Hash.hard(this.serialize(buf));
        return this._pow;
    }

    /**
     * @param {BlockHeader|*} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof BlockHeader
            && this._prevHash.equals(o.prevHash)
            && this._interlinkHash.equals(o.interlinkHash)
            && this._bodyHash.equals(o.bodyHash)
            && this._accountsHash.equals(o.accountsHash)
            && this._nBits === o.nBits
            && this._height === o.height
            && this._timestamp === o.timestamp
            && this._nonce === o.nonce;
    }

    /**
     * @returns {string}
     */
    toString() {
        return 'BlockHeader{'
            + `prevHash=${this._prevHash}, `
            + `interlinkHash=${this._interlinkHash}, `
            + `bodyHash=${this._bodyHash}, `
            + `accountsHash=${this._accountsHash}, `
            + `nBits=${this._nBits.toString(16)}, `
            + `height=${this._height}, `
            + `timestamp=${this._timestamp}, `
            + `nonce=${this._nonce}`
            + '}';
    }

    /** @type {number} */
    get version() {
        return this._version;
    }

    /** @type {Hash} */
    get prevHash() {
        return this._prevHash;
    }

    /** @type {Hash} */
    get interlinkHash() {
        return this._interlinkHash;
    }

    /** @type {Hash} */
    get bodyHash() {
        return this._bodyHash;
    }

    /** @type {Hash} */
    get accountsHash() {
        return this._accountsHash;
    }

    /** @type {number} */
    get nBits() {
        return this._nBits;
    }

    /** @type {BigNumber} */
    get target() {
        return BlockUtils.compactToTarget(this._nBits);
    }

    /** @type {BigNumber} */
    get difficulty() {
        return BlockUtils.compactToDifficulty(this._nBits);
    }

    /** @type {number} */
    get height() {
        return this._height;
    }

    /** @type {number} */
    get timestamp() {
        return this._timestamp;
    }

    /** @type {number} */
    get nonce() {
        return this._nonce;
    }

    // XXX The miner changes the nonce of an existing BlockHeader during the
    // mining process.
    /** @type {number} */
    set nonce(n) {
        this._nonce = n;
        this._hash = null;
        this._pow = null;
    }
}
BlockHeader.Version = {
    V1: 1
};
BlockHeader.CURRENT_VERSION = BlockHeader.Version.V1;
BlockHeader.SUPPORTED_VERSIONS = [
    BlockHeader.Version.V1
];
BlockHeader.SERIALIZED_SIZE = 146;
Class.register(BlockHeader);

class BlockInterlink {
    /**
     * @param {Array.<Hash>} hashes
     * @param {Hash} prevHash
     * @returns {{repeatBits: Uint8Array, compressed: Array.<Hash>}}
     * @protected
     */
    static _compress(hashes, prevHash) {
        const count = hashes.length;
        const repeatBitsSize = Math.ceil(count / 8);
        const repeatBits = new Uint8Array(repeatBitsSize);

        let lastHash = prevHash;
        const compressed = [];
        for (let i = 0; i < count; i++) {
            const hash = hashes[i];
            if (!hash.equals(lastHash)) {
                compressed.push(hash);
                lastHash = hash;
            } else {
                repeatBits[Math.floor(i / 8)] |= 0x80 >>> (i % 8);
            }
        }

        return {repeatBits, compressed};
    }

    /**
     * @param {Array.<Hash>} hashes
     * @param {Hash} [prevHash]
     * @param {Uint8Array} [repeatBits]
     * @param {Array.<Hash>} [compressed]
     */
    constructor(hashes, prevHash, repeatBits, compressed) {
        if (!Array.isArray(hashes) || !NumberUtils.isUint8(hashes.length)
            || hashes.some(it => !(it instanceof Hash))) throw new Error('Malformed hashes');
        if ((repeatBits || compressed) && !(repeatBits && compressed)) throw new Error('Malformed repeatBits/compressed');
        if (!prevHash && !repeatBits) throw new Error('Either prevHash or repeatBits/compressed required');

        if (!repeatBits) {
            ({repeatBits, compressed} = BlockInterlink._compress(hashes, prevHash));
        }

        /** @type {Array.<Hash>} */
        this._hashes = hashes;
        /** @type {Uint8Array} */
        this._repeatBits = repeatBits;
        /** @type {Array.<Hash>} */
        this._compressed = compressed;
    }

    /**
     * @param {SerialBuffer} buf
     * @param {Hash} prevHash
     * @returns {BlockInterlink}
     */
    static unserialize(buf, prevHash) {
        const count = buf.readUint8();
        const repeatBitsSize = Math.ceil(count / 8);
        const repeatBits = buf.read(repeatBitsSize);

        let hash = prevHash;
        const hashes = [];
        const compressed = [];
        for (let i = 0; i < count; i++) {
            const repeated = (repeatBits[Math.floor(i / 8)] & (0x80 >>> (i % 8))) !== 0;
            if (!repeated) {
                hash = Hash.unserialize(buf);
                compressed.push(hash);
            }
            hashes.push(hash);
        }

        return new BlockInterlink(hashes, prevHash, repeatBits, compressed);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._hashes.length);
        buf.write(this._repeatBits);
        for (const hash of this._compressed) {
            hash.serialize(buf);
        }
        return buf;
    }

    /**
     * @type {number}
     */
    get serializedSize() {
        return /*count*/ 1
            + this._repeatBits.length
            + this._compressed.reduce((sum, hash) => sum + hash.serializedSize, 0);
    }

    /**
     * @param {BlockInterlink|*} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof BlockInterlink
            && this._hashes.length === o._hashes.length
            && this._hashes.every((hash, i) => hash.equals(o.hashes[i]));
    }

    /**
     * @returns {Hash}
     */
    hash() {
        if (!this._hash) {
            this._hash = MerkleTree.computeRoot([this._repeatBits, GenesisConfig.GENESIS_HASH, ...this._compressed]);
        }
        return this._hash;
    }

    /**
     * @type {Array.<Hash>}
     */
    get hashes() {
        return this._hashes;
    }

    /**
     * @type {number}
     */
    get length() {
        return this._hashes.length;
    }
}
Class.register(BlockInterlink);

class BlockBody {
    /**
     * @param {Uint8Array} extraData
     * @returns {number}
     */
    static getMetadataSize(extraData) {
        return Address.SERIALIZED_SIZE
            + /*extraDataLength*/ 1
            + extraData.byteLength
            + /*transactionsLength*/ 2
            + /*prunedAccountsLength*/ 2;
    }

    /**
     * @param {Address} minerAddr
     * @param {Array.<Transaction>} transactions
     * @param {Uint8Array} [extraData]
     * @param {Array.<PrunedAccount>} prunedAccounts
     */
    constructor(minerAddr, transactions, extraData = new Uint8Array(0), prunedAccounts = []) {
        if (!(minerAddr instanceof Address)) throw new Error('Malformed minerAddr');
        if (!Array.isArray(transactions) || transactions.some(it => !(it instanceof Transaction))) throw new Error('Malformed transactions');
        if (!(extraData instanceof Uint8Array) || !NumberUtils.isUint8(extraData.byteLength)) throw new Error('Malformed extraData');

        /** @type {Address} */
        this._minerAddr = minerAddr;
        /** @type {Uint8Array} */
        this._extraData = extraData;
        /** @type {Array.<Transaction>} */
        this._transactions = transactions;
        /** @type {Array.<PrunedAccount>} */
        this._prunedAccounts = prunedAccounts;
        /** @type {Hash} */
        this._hash = null;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {BlockBody}
     */
    static unserialize(buf) {
        const minerAddr = Address.unserialize(buf);
        const extraDataLength = buf.readUint8();
        const extraData = buf.read(extraDataLength);
        const numTransactions = buf.readUint16();
        const transactions = new Array(numTransactions);
        for (let i = 0; i < numTransactions; i++) {
            transactions[i] = Transaction.unserialize(buf);
        }
        const numPrunedAccounts = buf.readUint16();
        const prunedAccounts = [];
        for (let i = 0; i < numPrunedAccounts; i++) {
            prunedAccounts.push(PrunedAccount.unserialize(buf));
        }
        return new BlockBody(minerAddr, transactions, extraData, prunedAccounts);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._minerAddr.serialize(buf);
        buf.writeUint8(this._extraData.byteLength);
        buf.write(this._extraData);
        buf.writeUint16(this._transactions.length);
        for (const tx of this._transactions) {
            tx.serialize(buf);
        }
        buf.writeUint16(this._prunedAccounts.length);
        for (const acc of this._prunedAccounts) {
            acc.serialize(buf);
        }
        return buf;
    }

    /**
     * @type {number}
     */
    get serializedSize() {
        let size = this._minerAddr.serializedSize
            + /*extraDataLength*/ 1
            + this._extraData.byteLength
            + /*transactionsLength*/ 2
            + /*prunedAccountsLength*/ 2;
        for (const tx of this._transactions) {
            size += tx.serializedSize;
        }
        size += this._prunedAccounts.reduce((sum, acc) => sum + acc.serializedSize, 0);
        return size;
    }

    /**
     * @returns {boolean}
     */
    verify() {
        /** @type {Transaction} */
        let previousTx = null;
        for (const tx of this._transactions) {
            // Ensure transactions are ordered and unique.
            if (previousTx && previousTx.compareBlockOrder(tx) >= 0) {
                Log.w(BlockBody, 'Invalid block - transactions not ordered.');
                return false;
            }
            previousTx = tx;

            // Check that all transactions are valid.
            if (!tx.verify()) {
                Log.w(BlockBody, 'Invalid block - invalid transaction');
                return false;
            }
        }

        let previousAcc = null;
        for (const acc of this._prunedAccounts) {
            // Ensure pruned accounts are ordered and unique.
            if (previousAcc && previousAcc.compare(acc) >= 0) {
                Log.w(BlockBody, 'Invalid block - pruned accounts not ordered.');
                return false;
            }
            previousAcc = acc;
            
            // Check that pruned accounts are actually supposed to be pruned
            if (!acc.account.isToBePruned()) {
                Log.w(BlockBody, 'Invalid block - invalid pruned account');
                return false;
            }
        }

        // Everything checks out.
        return true;
    }

    /**
     * @returns {Array}
     */
    getMerkleLeafs() {
        return [this._minerAddr, this._extraData, ...this._transactions, ...this.prunedAccounts];
    }

    /**
     * @return {Hash}
     */
    hash() {
        if (!this._hash) {
            this._hash = MerkleTree.computeRoot(this.getMerkleLeafs());
        }
        return this._hash;
    }

    /**
     * @param {BlockBody} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof BlockBody
            && this._minerAddr.equals(o.minerAddr)
            && BufferUtils.equals(this._extraData, o.extraData)
            && this._transactions.length === o.transactions.length
            && this._transactions.every((tx, i) => tx.equals(o.transactions[i]));
    }

    /**
     * @return {Array.<Address>}
     */
    getAddresses() {
        const addresses = [this._minerAddr];
        for (const tx of this._transactions) {
            addresses.push(tx.sender, tx.recipient);
        }
        return addresses;
    }

    /** @type {Uint8Array} */
    get extraData() {
        return this._extraData;
    }

    /** @type {Address} */
    get minerAddr() {
        return this._minerAddr;
    }

    /** @type {Array.<Transaction>} */
    get transactions() {
        return this._transactions;
    }

    /** @type {number} */
    get transactionCount() {
        return this._transactions.length;
    }

    /** @type {Array.<PrunedAccount>} */
    get prunedAccounts() {
        return this._prunedAccounts;
    }
}

Class.register(BlockBody);

class BlockUtils {
    /**
     * @param {number} compact
     * @returns {BigNumber}
     */
    static compactToTarget(compact) {
        return new BigNumber(compact & 0xffffff).times(new BigNumber(2).pow(8 * Math.max((compact >> 24) - 3, 0)));
    }

    /**
     * @param {BigNumber} target
     * @returns {number}
     */
    static targetToCompact(target) {
        if (!target.isFinite() || target.isNaN()) throw new Error('Invalid Target');

        // Divide to get first byte
        let size = Math.max(Math.ceil(Math.log2(target.toNumber()) / 8), 1);
        const firstByte = target / Math.pow(2, (size - 1) * 8);

        // If the first (most significant) byte is greater than 127 (0x7f),
        // prepend a zero byte.
        if (firstByte >= 0x80 && size >= 3) {
            size++;
        }

        // The first byte of the 'compact' format is the number of bytes,
        // including the prepended zero if it's present.
        // The following three bytes are the first three bytes of the above
        // representation. If less than three bytes are present, then one or
        // more of the last bytes of the compact representation will be zero.
        return (size << 24) + ((target / Math.pow(2, Math.max(size - 3, 0) * 8)) & 0xffffff);
    }

    /**
     * @param {BigNumber} target
     * @returns {number}
     */
    static getTargetHeight(target) {
        // Precision loss should be ok here.
        return Math.ceil(Math.log2(target.toNumber()));
    }

    /**
     * @param {BigNumber} target
     * @returns {number}
     */
    static getTargetDepth(target) {
        return BlockUtils.getTargetHeight(Policy.BLOCK_TARGET_MAX) - BlockUtils.getTargetHeight(target);
    }

    /**
     * @param {number} compact
     * @returns {BigNumber}
     */
    static compactToDifficulty(compact) {
        return Policy.BLOCK_TARGET_MAX.div(BlockUtils.compactToTarget(compact));
    }

    /**
     * @param {BigNumber} difficulty
     * @returns {number}
     */
    static difficultyToCompact(difficulty) {
        return BlockUtils.targetToCompact(BlockUtils.difficultyToTarget(difficulty));
    }

    /**
     * @param {BigNumber} difficulty
     * @returns {BigNumber}
     */
    static difficultyToTarget(difficulty) {
        return Policy.BLOCK_TARGET_MAX.div(difficulty);
    }

    /**
     * @param {BigNumber} target
     * @returns {BigNumber}
     */
    static targetToDifficulty(target) {
        return Policy.BLOCK_TARGET_MAX.div(target);
    }

    /**
     * @param {Hash} hash
     * @returns {BigNumber}
     */
    static hashToTarget(hash) {
        return new BigNumber(hash.toHex(), 16);
    }

    /**
     * @param {Hash} hash
     * @returns {BigNumber}
     */
    static realDifficulty(hash) {
        return BlockUtils.targetToDifficulty(BlockUtils.hashToTarget(hash));
    }

    /**
     * @param {Hash} hash
     * @returns {number}
     */
    static getHashDepth(hash) {
        return BlockUtils.getTargetDepth(BlockUtils.hashToTarget(hash));
    }

    /**
     * @param {Hash} hash
     * @param {BigNumber} target
     * @returns {boolean}
     */
    static isProofOfWork(hash, target) {
        return new BigNumber(hash.toHex(), 16).lte(target);
    }

    /**
     * @param {number} compact
     * @returns {boolean}
     */

    static isValidCompact(compact) {
        return BlockUtils.isValidTarget(BlockUtils.compactToTarget(compact));
    }

    /**
     * @param {?BigNumber} target
     * @returns {boolean}
     */
    static isValidTarget(target) {
        return target !== null && target.gte(1) && target.lte(Policy.BLOCK_TARGET_MAX);
    }

    /**
     * @param {BlockHeader} headBlock
     * @param {BlockHeader} tailBlock
     * @param {BigNumber} deltaTotalDifficulty
     * @returns {BigNumber}
     */
    static getNextTarget(headBlock, tailBlock, deltaTotalDifficulty) {
        Assert.that(
            (headBlock.height - tailBlock.height === Policy.DIFFICULTY_BLOCK_WINDOW)
                || (headBlock.height <= Policy.DIFFICULTY_BLOCK_WINDOW && tailBlock.height === 1),
            `Tail and head block must be ${Policy.DIFFICULTY_BLOCK_WINDOW} blocks apart`);

        let actualTime = headBlock.timestamp - tailBlock.timestamp;

        // Simulate that the Policy.BLOCK_TIME was achieved for the blocks before the genesis block, i.e. we simulate
        // a sliding window that starts before the genesis block. Assume difficulty = 1 for these blocks.
        if (headBlock.height <= Policy.DIFFICULTY_BLOCK_WINDOW) {
            actualTime += (Policy.DIFFICULTY_BLOCK_WINDOW - headBlock.height + 1) * Policy.BLOCK_TIME;
            deltaTotalDifficulty = deltaTotalDifficulty.plus(Policy.DIFFICULTY_BLOCK_WINDOW - headBlock.height + 1);
        }

        // Compute the target adjustment factor.
        const expectedTime = Policy.DIFFICULTY_BLOCK_WINDOW * Policy.BLOCK_TIME;
        let adjustment = actualTime / expectedTime;

        // Clamp the adjustment factor to [1 / MAX_ADJUSTMENT_FACTOR, MAX_ADJUSTMENT_FACTOR].
        adjustment = Math.max(adjustment, 1 / Policy.DIFFICULTY_MAX_ADJUSTMENT_FACTOR);
        adjustment = Math.min(adjustment, Policy.DIFFICULTY_MAX_ADJUSTMENT_FACTOR);

        // Compute the next target.
        const averageDifficulty = deltaTotalDifficulty.div(Policy.DIFFICULTY_BLOCK_WINDOW);
        const averageTarget = BlockUtils.difficultyToTarget(averageDifficulty);
        let nextTarget = averageTarget.times(adjustment);

        // Make sure the target is below or equal the maximum allowed target (difficulty 1).
        // Also enforce a minimum target of 1.
        nextTarget = BigNumber.min(nextTarget, Policy.BLOCK_TARGET_MAX);
        nextTarget = BigNumber.max(nextTarget, 1);

        // XXX Reduce target precision to nBits precision.
        const nBits = BlockUtils.targetToCompact(nextTarget);
        return BlockUtils.compactToTarget(nBits);
    }
}
Class.register(BlockUtils);

class Subscription {
    /**
     * @param {Array.<Address>} addresses
     */
    static fromAddresses(addresses) {
        return new Subscription(Subscription.Type.ADDRESSES, addresses);
    }

    /**
     * @param {number} minFeePerByte
     */
    static fromMinFeePerByte(minFeePerByte) {
        return new Subscription(Subscription.Type.MIN_FEE, minFeePerByte);
    }

    /**
     * @param {Subscription.Type} type
     * @param {Array.<Address>|number} [filter]
     */
    constructor(type, filter=null) {
        if (!NumberUtils.isUint8(type)) throw new Error('Invalid type');
        if (type === Subscription.Type.ADDRESSES
            && (!Array.isArray(filter) || !NumberUtils.isUint16(filter.length)
            || filter.some(it => !(it instanceof Address)))) throw new Error('Invalid addresses');
        if (type === Subscription.Type.MIN_FEE && !NumberUtils.isUint64(filter)) throw new Error('Invalid minFeePerByte');
        this._type = type;

        this._addresses = new HashSet();
        this._minFeePerByte = 0;

        switch (type) {
            case Subscription.Type.ADDRESSES:
                this._addresses.addAll(filter);
                break;
            case Subscription.Type.MIN_FEE:
                this._minFeePerByte = filter;
                break;
        }
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Subscription}
     */
    static unserialize(buf) {
        const type = /** @type {Subscription.Type} */ buf.readUint8();
        let filter = null;
        switch (type) {
            case Subscription.Type.ADDRESSES: {
                filter = [];
                const size = buf.readUint16();
                for (let i = 0; i < size; ++i) {
                    filter.push(Address.unserialize(buf));
                }
                break;
            }
            case Subscription.Type.MIN_FEE:
                filter = buf.readUint64();
                break;
        }
        return new Subscription(type, filter);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._type);
        switch (this._type) {
            case Subscription.Type.ADDRESSES:
                buf.writeUint16(this._addresses.length);
                for (const address of this._addresses) {
                    address.serialize(buf);
                }
                break;
            case Subscription.Type.MIN_FEE:
                buf.writeUint64(this._minFeePerByte);
                break;
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let additionalSize = 0;
        switch (this._type) {
            case Subscription.Type.ADDRESSES:
                additionalSize = /*length*/ 2;
                for (const address of this._addresses) {
                    additionalSize += address.serializedSize;
                }
                break;
            case Subscription.Type.MIN_FEE:
                additionalSize = /*minFeePerByte*/ 8;
                break;
        }
        return /*type*/ 1
            + additionalSize;
    }

    /**
     * @param {Block} block
     * @returns {boolean}
     */
    matchesBlock(block) {
        switch (this._type) {
            case Subscription.Type.NONE:
                return false;
            case Subscription.Type.ANY:
            case Subscription.Type.ADDRESSES:
            case Subscription.Type.MIN_FEE:
                return true;
            default:
                throw new Error('Unknown type');
        }
    }

    /**
     * @param {Transaction} transaction
     * @returns {boolean}
     */
    matchesTransaction(transaction) {
        switch (this._type) {
            case Subscription.Type.NONE:
                return false;
            case Subscription.Type.ANY:
                return true;
            case Subscription.Type.ADDRESSES:
                return this._addresses.contains(transaction.recipient) || this._addresses.contains(transaction.sender);
            case Subscription.Type.MIN_FEE:
                return transaction.fee / transaction.serializedSize >= this._minFeePerByte;
            default:
                throw new Error('Unknown type');
        }
    }

    /**
     * @param {Subscription} other
     * @returns {boolean}
     */
    isSubsetOf(other) {
        if (other.type === Subscription.Type.ANY || this.type === Subscription.Type.NONE) {
            return true;
        }
        if (other.type !== this.type) {
            return false;
        }
        switch (this.type) {
            case Subscription.Type.ADDRESSES:
                return this.addresses.reduce((isSubset, address) => isSubset && other.addresses.find(a => a.equals(address)), true);
            case Subscription.Type.MIN_FEE:
                return this.minFeePerByte > other.minFeePerByte;
        }
        return false;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `Subscription{type=${this._type}, addresses=[${this._addresses.values()}], minFeePerByte=${this._minFeePerByte}}`;
    }

    /** @type {Subscription.Type} */
    get type() {
        return this._type;
    }

    /** @type {Array.<Address>} */
    get addresses() {
        return this._addresses.values();
    }

    /** @type {number} */
    get minFeePerByte() {
        return this._minFeePerByte;
    }
}
/** @enum {number} */
Subscription.Type = {
    NONE: 0,
    ANY: 1,
    ADDRESSES: 2,
    MIN_FEE: 3
};
Subscription.NONE = new Subscription(Subscription.Type.NONE);
Subscription.BLOCKS_ONLY = new Subscription(Subscription.Type.ADDRESSES, []);
Subscription.ANY = new Subscription(Subscription.Type.ANY);
Class.register(Subscription);

/**
 * @abstract
 */
class Transaction {
    /**
     * @param {Transaction.Format} format
     * @param {Address} sender
     * @param {Account.Type} senderType
     * @param {Address} recipient
     * @param {Account.Type} recipientType
     * @param {number} value
     * @param {number} fee
     * @param {number} validityStartHeight
     * @param {Transaction.Flag | *} flags
     * @param {Uint8Array} data
     * @param {Uint8Array} [proof]
     * @param {number} [networkId]
     */
    constructor(format, sender, senderType, recipient, recipientType, value, fee, validityStartHeight, flags, data, proof, networkId = GenesisConfig.NETWORK_ID) {
        if (!(sender instanceof Address)) throw new Error('Malformed sender');
        if (!NumberUtils.isUint8(senderType)) throw new Error('Malformed sender type');
        if (!(recipient instanceof Address)) throw new Error('Malformed recipient');
        if (!NumberUtils.isUint8(recipientType)) throw new Error('Malformed recipient type');
        if (!NumberUtils.isUint64(value) || value === 0) throw new Error('Malformed value');
        if (!NumberUtils.isUint64(fee)) throw new Error('Malformed fee');
        if (!NumberUtils.isUint32(validityStartHeight)) throw new Error('Malformed validityStartHeight');
        if (!NumberUtils.isUint8(flags) && (flags & ~(Transaction.Flag.ALL)) > 0) throw new Error('Malformed flags');
        if (!(data instanceof Uint8Array) || !(NumberUtils.isUint16(data.byteLength))) throw new Error('Malformed data');
        if (proof && (!(proof instanceof Uint8Array) || !(NumberUtils.isUint16(proof.byteLength)))) throw new Error('Malformed proof');
        if (!NumberUtils.isUint8(networkId)) throw new Error('Malformed networkId');

        /** @type {Transaction.Format} */
        this._format = format;
        /** @type {Address} */
        this._sender = sender;
        /** @type {Account.Type} */
        this._senderType = senderType;
        /** @type {Address} */
        this._recipient = recipient;
        /** @type {Account.Type} */
        this._recipientType = recipientType;
        /** @type {number} */
        this._value = value;
        /** @type {number} */
        this._fee = fee;
        /** @type {number} */
        this._networkId = networkId;
        /** @type {number} */
        this._validityStartHeight = validityStartHeight;
        /** @type {Transaction.Flag | *} */
        this._flags = flags;
        /** @type {Uint8Array} */
        this._data = data;
        /** @type {Uint8Array} */
        this._proof = proof;

        if (this._recipient === Address.CONTRACT_CREATION) this._recipient = this.getContractCreationAddress();
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Transaction}
     */
    static unserialize(buf) {
        const format = /** @type {Transaction.Format} */ buf.readUint8();
        buf.readPos--;

        if (!Transaction.FORMAT_MAP.has(format)) throw new Error('Invalid transaction type');
        return Transaction.FORMAT_MAP.get(format).unserialize(buf);
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serializeContent(buf) {
        buf = buf || new SerialBuffer(this.serializedContentSize);
        buf.writeUint16(this._data.byteLength);
        buf.write(this._data);
        this._sender.serialize(buf);
        buf.writeUint8(this._senderType);
        this._recipient.serialize(buf);
        buf.writeUint8(this._recipientType);
        buf.writeUint64(this._value);
        buf.writeUint64(this._fee);
        buf.writeUint32(this._validityStartHeight);
        buf.writeUint8(this._networkId);
        buf.writeUint8(this._flags);
        return buf;
    }

    /** @type {number} */
    get serializedContentSize() {
        return /*dataSize*/ 2
            + this._data.byteLength
            + this._sender.serializedSize
            + /*senderType*/ 1
            + this._recipient.serializedSize
            + /*recipientType*/ 1
            + /*value*/ 8
            + /*fee*/ 8
            + /*validityStartHeight*/ 4
            + /*networkId*/ 1
            + /*flags*/ 1;
    }

    /**
     * @param {number} [networkId]
     * @returns {boolean}
     */
    verify(networkId) {
        if (this._valid === undefined) {
            this._valid = this._verify(networkId);
        }
        return this._valid;
    }

    /**
     * @param {number} [networkId]
     * @returns {boolean}
     * @private
     */
    _verify(networkId = GenesisConfig.NETWORK_ID) {
        if (this._networkId !== networkId) {
            Log.w(Transaction, 'Transaction is not valid in this network', this);
            return false;
        }
        // Check that sender != recipient.
        if (this._recipient.equals(this._sender)) {
            Log.w(Transaction, 'Sender and recipient must not match', this);
            return false;
        }
        if (!Account.TYPE_MAP.has(this._senderType) || !Account.TYPE_MAP.has(this._recipientType)) {
            Log.w(Transaction, 'Invalid account type', this);
            return false;
        }
        if (!Account.TYPE_MAP.get(this._senderType).verifyOutgoingTransaction(this)) {
            Log.w(Transaction, 'Invalid for sender', this);
            return false;
        }
        if (!Account.TYPE_MAP.get(this._recipientType).verifyIncomingTransaction(this)) {
            Log.w(Transaction, 'Invalid for recipient', this);
            return false;
        }
        return true;
    }

    /** @type {number} */
    get serializedSize() {
        throw new Error('Getter needs to be overwritten by subclasses');
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        throw new Error('Method needs to be overwritten by subclasses');
    }

    /**
     * @return {Hash}
     */
    hash() {
        // Exclude the signature, we don't want transactions to be malleable.
        this._hash = this._hash || Hash.light(this.serializeContent());
        return this._hash;
    }

    /**
     * @param {Transaction} o
     * @return {number}
     */
    compare(o) {
        if (this.fee / this.serializedSize > o.fee / o.serializedSize) return -1;
        if (this.fee / this.serializedSize < o.fee / o.serializedSize) return 1;
        if (this.serializedSize > o.serializedSize) return -1;
        if (this.serializedSize < o.serializedSize) return 1;
        if (this.fee > o.fee) return -1;
        if (this.fee < o.fee) return 1;
        if (this.value > o.value) return -1;
        if (this.value < o.value) return 1;
        return this.compareBlockOrder(o);
    }

    /**
     * @param {Transaction} o
     * @return {number}
     */
    compareBlockOrder(o) {
        // This function must return 0 iff this.equals(o).
        const recCompare = this._recipient.compare(o._recipient);
        if (recCompare !== 0) return recCompare;
        if (this._validityStartHeight < o._validityStartHeight) return -1;
        if (this._validityStartHeight > o._validityStartHeight) return 1;
        if (this._fee > o._fee) return -1;
        if (this._fee < o._fee) return 1;
        if (this._value > o._value) return -1;
        if (this._value < o._value) return 1;
        const senderCompare = this._sender.compare(o._sender);
        if (senderCompare !== 0) return senderCompare;
        if (this._recipientType < o._recipientType) return -1;
        if (this._recipientType > o._recipientType) return 1;
        if (this._senderType < o._senderType) return -1;
        if (this._senderType > o._senderType) return 1;
        if (this._flags < o._flags) return -1;
        if (this._flags > o._flags) return 1;
        return BufferUtils.compare(this._data, o._data);
    }

    /**
     * @param {Transaction} o
     * @return {boolean}
     */
    equals(o) {
        // This ignores format and proof to be consistent with hash():
        //   tx1.hash() == tx2.hash() iff tx1.equals(t2)
        return o instanceof Transaction
            && this._sender.equals(o._sender)
            && this._senderType === o._senderType
            && this._recipient.equals(o._recipient)
            && this._recipientType === o._recipientType
            && this._value === o._value
            && this._fee === o._fee
            && this._validityStartHeight === o._validityStartHeight
            && this._networkId === o._networkId
            && this._flags === o._flags
            && BufferUtils.equals(this._data, o._data);
    }

    /**
     * @return {string}
     */
    toString() {
        return `Transaction{`
            + `sender=${this._sender.toBase64()}, `
            + `recipient=${this._recipient.toBase64()}, `
            + `value=${this._value}, `
            + `fee=${this._fee}, `
            + `validityStartHeight=${this._validityStartHeight}, `
            + `networkId=${this._networkId}`
            + `}`;
    }

    toPlain() {
        const data = Account.TYPE_MAP.get(this.recipientType).dataToPlain(this.data);
        data.raw = BufferUtils.toHex(this.data);
        const proof = Account.TYPE_MAP.get(this.senderType).proofToPlain(this.proof);
        proof.raw = BufferUtils.toHex(this.proof);
        return {
            transactionHash: this.hash().toPlain(),
            format: Transaction.Format.toString(this._format),
            sender: this.sender.toPlain(),
            senderType: Account.Type.toString(this.senderType),
            recipient: this.recipient.toPlain(),
            recipientType: Account.Type.toString(this.recipientType),
            value: this.value,
            fee: this.fee,
            feePerByte: this.feePerByte,
            validityStartHeight: this.validityStartHeight,
            network: GenesisConfig.networkIdToNetworkName(this.networkId),
            flags: this.flags,
            data,
            proof,
            size: this.serializedSize,
            valid: this.verify()
        };
    }

    /**
     * @param {object} plain
     * @return {Transaction}
     */
    static fromPlain(plain) {
        if (!plain) throw new Error('Invalid transaction format');
        const format = Transaction.Format.fromAny(plain.format);
        if (!Transaction.FORMAT_MAP.has(format)) throw new Error('Invalid transaction type');
        return Transaction.FORMAT_MAP.get(format).fromPlain(plain);
    }

    /**
     * @param {Transaction|string|object} tx
     * @returns {Transaction}
     */
    static fromAny(tx) {
        if (tx instanceof Transaction) return tx;
        if (typeof tx === 'object') return Transaction.fromPlain(tx);
        if (typeof tx === 'string') return Transaction.unserialize(new SerialBuffer(BufferUtils.fromHex(tx)));
        throw new Error('Invalid transaction format');
    }

    /**
     * @return {Address}
     */
    getContractCreationAddress() {
        const tx = Transaction.unserialize(this.serialize());
        tx._recipient = Address.NULL;
        tx._hash = null;
        return Address.fromHash(tx.hash());
    }

    /** @type {Transaction.Format} */
    get format() {
        return this._format;
    }

    /** @type {Address} */
    get sender() {
        return this._sender;
    }

    /** @type {Account.Type} */
    get senderType() {
        return this._senderType;
    }

    /** @type {Address} */
    get recipient() {
        return this._recipient;
    }

    /** @type {Account.Type} */
    get recipientType() {
        return this._recipientType;
    }

    /** @type {number} */
    get value() {
        return this._value;
    }

    /** @type {number} */
    get fee() {
        return this._fee;
    }

    /** @type {number} */
    get feePerByte() {
        return this._fee / this.serializedSize;
    }

    /** @type {number} */
    get networkId() {
        return this._networkId;
    }

    /** @type {number} */
    get validityStartHeight() {
        return this._validityStartHeight;
    }

    /** @type {number} */
    get flags() {
        return this._flags;
    }

    /**
     * @param {Transaction.Flag} flag
     * @returns {boolean}
     */
    hasFlag(flag) {
        return (this._flags & flag) > 0;
    }

    /** @type {Uint8Array} */
    get data() {
        return this._data;
    }

    /** @type {Uint8Array} */
    get proof() {
        return this._proof;
    }

    // Sender proof is set by the Wallet after signing a transaction.
    /** @type {Uint8Array} */
    set proof(proof) {
        this._proof = proof;
    }
}

/**
 * Enum for Transaction formats.
 * @enum
 */
Transaction.Format = {
    BASIC: 0,
    EXTENDED: 1
};
/**
 * @param {Transaction.Format} format
 */
Transaction.Format.toString = function(format) {
    switch (format) {
        case Transaction.Format.BASIC: return 'basic';
        case Transaction.Format.EXTENDED: return 'extended';
    }
    throw new Error('Invalid transaction format');
};
/**
 * @param {Transaction.Format|string} format
 * @return {Transaction.Format}
 */
Transaction.Format.fromAny = function(format) {
    if (typeof format === 'number') return format;
    switch (format) {
        case 'basic': return Transaction.Format.BASIC;
        case 'extended': return Transaction.Format.EXTENDED;
    }
    throw new Error('Invalid transaction format');
};
/**
 * @enum
 */
Transaction.Flag = {
    NONE: 0,
    CONTRACT_CREATION: 0b1,
    ALL: 0b1
};
/** @type {Map.<Transaction.Format, {unserialize: function(buf: SerialBuffer):Transaction, fromPlain: function(plain:object):Transaction}>} */
Transaction.FORMAT_MAP = new Map();

Class.register(Transaction);

class SignatureProof {
    /**
     * @param {Transaction} transaction
     * @returns {boolean}
     */
    static verifyTransaction(transaction) {
        try {
            const buffer = new SerialBuffer(transaction.proof);
            const proof = SignatureProof.unserialize(buffer);

            // Reject proof if it is longer than needed.
            if (buffer.readPos !== buffer.byteLength) {
                Log.w(SignatureProof, 'Invalid SignatureProof - overlong');
                return false;
            }

            return proof.verify(transaction.sender, transaction.serializeContent());
        } catch (e) {
            Log.w(SignatureProof, `Failed to verify transaction: ${e.message || e}`);
            return false;
        }
    }

    /**
     * @param {PublicKey} publicKey
     * @param {Signature} signature
     * @returns {SignatureProof}
     */
    static singleSig(publicKey, signature) {
        return new SignatureProof(publicKey, new MerklePath([]), signature);
    }

    /**
     * @param {PublicKey} signerKey
     * @param {Array.<PublicKey>} publicKeys
     * @param {Signature} signature
     * @returns {SignatureProof}
     */
    static multiSig(signerKey, publicKeys, signature) {
        const merklePath = MerklePath.compute(publicKeys, signerKey);
        return new SignatureProof(signerKey, merklePath, signature);
    }

    /**
     * @param {PublicKey} publicKey
     * @param {MerklePath} merklePath
     * @param {Signature} signature
     */
    constructor(publicKey, merklePath, signature) {
        if (!(publicKey instanceof PublicKey)) throw new Error('Malformed publickKey');
        if (!(merklePath instanceof MerklePath)) throw new Error('Malformed merklePath');
        if (signature && !(signature instanceof Signature)) throw new Error('Malformed signature');

        /**
         * @type {PublicKey}
         * @private
         */
        this._publicKey = publicKey;
        /**
         * @type {MerklePath}
         * @private
         */
        this._merklePath = merklePath;
        /**
         * @type {Signature}
         * @private
         */
        this._signature = signature;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {SignatureProof}
     */
    static unserialize(buf) {
        const publicKey = PublicKey.unserialize(buf);
        const merklePath = MerklePath.unserialize(buf);
        const signature = Signature.unserialize(buf);
        return new SignatureProof(publicKey, merklePath, signature);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._publicKey.serialize(buf);
        this._merklePath.serialize(buf);

        // The SignatureProof is sometimes serialized before the signature is set (e.g. when creating transactions).
        // Simply don't serialize the signature if it's missing as this should never go over the wire.
        // We always expect the signature to be present when unserializing.
        if (this._signature) {
            this._signature.serialize(buf);
        }

        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return this._publicKey.serializedSize
            + this._merklePath.serializedSize
            + (this._signature ? this._signature.serializedSize : 0);
    }
    
    static get SINGLE_SIG_SIZE() {
        return PublicKey.SIZE + new MerklePath([]).serializedSize + Signature.SIZE;
    }

    /**
     * @param {SignatureProof} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof SignatureProof
            && this._publicKey.equals(o._publicKey)
            && this._merklePath.equals(o._merklePath)
            && (this._signature ? this._signature.equals(o._signature) : this._signature === o._signature);
    }

    /**
     * @param {?Address} sender
     * @param {Uint8Array} data
     * @returns {boolean}
     */
    verify(sender, data) {
        if (sender !== null && !this.isSignedBy(sender)) {
            Log.w(SignatureProof, 'Invalid SignatureProof - signer does not match sender address');
            return false;
        }

        if (!this._signature) {
            Log.w(SignatureProof, 'Invalid SignatureProof - signature is missing');
            return false;
        }

        if (!this._signature.verify(this._publicKey, data)) {
            Log.w(SignatureProof, 'Invalid SignatureProof - signature is invalid');
            return false;
        }

        return true;
    }

    /**
     * @param {Address} sender
     * @returns {boolean}
     */
    isSignedBy(sender) {
        const merkleRoot = this._merklePath.computeRoot(this._publicKey);
        const signerAddr = Address.fromHash(merkleRoot);
        return signerAddr.equals(sender);
    }

    /** @type {PublicKey} */
    get publicKey() {
        return this._publicKey;
    }

    /** @type {MerklePath} */
    get merklePath() {
        return this._merklePath;
    }

    /** @type {Signature} */
    get signature() {
        return this._signature;
    }

    /** @type {Signature} */
    set signature(signature) {
        this._signature = signature;
    }
}

Class.register(SignatureProof);

class BasicTransaction extends Transaction {
    /**
     * @param {PublicKey} senderPubKey
     * @param {Address} recipient
     * @param {number} value
     * @param {number} fee
     * @param {number} validityStartHeight
     * @param {Signature} [signature]
     * @param {number} [networkId]
     */
    constructor(senderPubKey, recipient, value, fee, validityStartHeight, signature, networkId) {
        if (!(senderPubKey instanceof PublicKey)) throw new Error('Malformed senderPubKey');
        // Signature may be initially empty and can be set later.
        if (signature !== undefined && !(signature instanceof Signature)) throw new Error('Malformed signature');

        const proof = SignatureProof.singleSig(senderPubKey, signature);
        super(Transaction.Format.BASIC, senderPubKey.toAddress(), Account.Type.BASIC, recipient, Account.Type.BASIC, value, fee, validityStartHeight, Transaction.Flag.NONE, new Uint8Array(0), proof.serialize(), networkId);

        /**
         * @type {SignatureProof}
         * @private
         */
        this._signatureProof = proof;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Transaction}
     */
    static unserialize(buf) {
        const type = buf.readUint8();
        Assert.that(type === Transaction.Format.BASIC);

        const senderPubKey = PublicKey.unserialize(buf);
        const recipient = Address.unserialize(buf);
        const value = buf.readUint64();
        const fee = buf.readUint64();
        const validityStartHeight = buf.readUint32();
        const networkId = buf.readUint8();
        const signature = Signature.unserialize(buf);
        return new BasicTransaction(senderPubKey, recipient, value, fee, validityStartHeight, signature, networkId);
    }

    /**
     * @param {object} plain
     * @return {BasicTransaction}
     */
    static fromPlain(plain) {
        if (!plain) throw new Error('Invalid transaction format');
        return new BasicTransaction(
            PublicKey.fromAny(plain.proof.publicKey || plain.senderPubKey),
            Address.fromAny(plain.recipient),
            plain.value,
            plain.fee,
            plain.validityStartHeight,
            Signature.fromAny(plain.proof.signature || plain.signature),
            GenesisConfig.networkIdFromAny(plain.network || plain.networkId)
        );
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(Transaction.Format.BASIC);
        this.senderPubKey.serialize(buf);
        this._recipient.serialize(buf);
        buf.writeUint64(this._value);
        buf.writeUint64(this._fee);
        buf.writeUint32(this._validityStartHeight);
        buf.writeUint8(this._networkId);
        this.signature.serialize(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*type*/ 1
            + this.senderPubKey.serializedSize
            + this._recipient.serializedSize
            + /*value*/ 8
            + /*fee*/ 8
            + /*validityStartHeight*/ 4
            + /*networkId*/ 1
            + this.signature.serializedSize;
    }

    /**
     * @type {PublicKey}
     */
    get senderPubKey() {
        return this._signatureProof.publicKey;
    }

    /**
     * @type {Signature}
     */
    get signature() {
        return this._signatureProof.signature;
    }

    /**
     * @type {Signature}
     */
    set signature(signature) {
        this._signatureProof.signature = signature;
        this._proof = this._signatureProof.serialize();
    }
}
Transaction.FORMAT_MAP.set(Transaction.Format.BASIC, BasicTransaction);
Class.register(BasicTransaction);

class ExtendedTransaction extends Transaction {

    /**
     * @param {Address} sender
     * @param {Account.Type} senderType
     * @param {Address} recipient
     * @param {Account.Type} recipientType
     * @param {number} value
     * @param {number} fee
     * @param {number} validityStartHeight
     * @param {Transaction.Flag | *} flags
     * @param {Uint8Array} data
     * @param {Uint8Array} [proof]
     * @param {number} [networkId]
     */
    constructor(sender, senderType, recipient, recipientType, value, fee, validityStartHeight, flags, data, proof = new Uint8Array(0), networkId) {
        super(Transaction.Format.EXTENDED, sender, senderType, recipient, recipientType, value, fee, validityStartHeight, flags, data, proof, networkId);
    }

    /**
     * @param {SerialBuffer} buf
     * @return {Transaction}
     */
    static unserialize(buf) {
        const type = /** @type {Transaction.Format} */ buf.readUint8();
        Assert.that(type === Transaction.Format.EXTENDED);

        const dataSize = buf.readUint16();
        const data = buf.read(dataSize);
        const sender = Address.unserialize(buf);
        const senderType = /** @type {Account.Type} */ buf.readUint8();
        const recipient = Address.unserialize(buf);
        const recipientType = /** @type {Account.Type} */ buf.readUint8();
        const value = buf.readUint64();
        const fee = buf.readUint64();
        const validityStartHeight = buf.readUint32();
        const networkId = buf.readUint8();
        const flags = buf.readUint8();
        const proofSize = buf.readUint16();
        const proof = buf.read(proofSize);
        return new ExtendedTransaction(sender, senderType, recipient, recipientType, value, fee, validityStartHeight, flags, data, proof, networkId);
    }

    /**
     * @param {object} plain
     * @return {ExtendedTransaction}
     */
    static fromPlain(plain) {
        if (!plain) throw new Error('Invalid transaction format');
        return new ExtendedTransaction(
            Address.fromAny(plain.sender),
            Account.Type.fromAny(plain.senderType),
            Address.fromAny(plain.recipient),
            Account.Type.fromAny(plain.recipientType),
            plain.value,
            plain.fee,
            plain.validityStartHeight,
            plain.flags,
            BufferUtils.fromAny(plain.data.raw === undefined ? plain.data : plain.data.raw),
            BufferUtils.fromAny(plain.proof.raw === undefined ? plain.proof : plain.proof.raw),
            GenesisConfig.networkIdFromAny(plain.network || plain.networkId)
        );
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(Transaction.Format.EXTENDED);
        this.serializeContent(buf);
        buf.writeUint16(this._proof.byteLength);
        buf.write(this._proof);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*type*/ 1
            + this.serializedContentSize
            + /*proofSize*/ 2
            + this._proof.byteLength;
    }
}

Transaction.FORMAT_MAP.set(Transaction.Format.EXTENDED, ExtendedTransaction);
Class.register(ExtendedTransaction);

class TransactionsProof {
    /**
     * @param {Array.<Transaction>} transactions
     * @param {MerkleProof} proof
     */
    constructor(transactions, proof) {
        if (!Array.isArray(transactions) || !NumberUtils.isUint16(transactions.length)
            || transactions.some(it => !(it instanceof Transaction))) throw new Error('Malformed transactions');
        if (!(proof instanceof MerkleProof)) throw new Error('Malformed merkle proof');

        /** @type {Array.<Transaction>} */
        this._transactions = transactions;
        /** @type {MerkleProof} */
        this._proof = proof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {TransactionsProof}
     */
    static unserialize(buf) {
        const count = buf.readUint16();
        const transactions = [];
        for (let i = 0; i < count; ++i) {
            transactions.push(Transaction.unserialize(buf));
        }
        const proof = MerkleProof.unserialize(buf);
        return new TransactionsProof(transactions, proof);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._transactions.length);
        for (const transaction of this._transactions) {
            transaction.serialize(buf);
        }
        this._proof.serialize(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*count*/ 2
            + this._transactions.reduce((sum, transaction) => sum + transaction.serializedSize, 0)
            + this._proof.serializedSize;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `TransactionsProof{length=${this.length}}`;
    }

    /**
     * @returns {Hash}
     */
    root() {
        return this._proof.computeRoot(this._transactions);
    }

    /** @type {number} */
    get length() {
        return this._transactions.length;
    }

    /** @type {Array.<Transaction>} */
    get transactions() {
        return this._transactions;
    }

    /** @type {MerkleProof} */
    get proof() {
        return this._proof;
    }
}
Class.register(TransactionsProof);

/**
 * @typedef {object} BlockDescriptor
 */

/**
 * @property {Hash} hash
 * @property {Hash} prevHash
 * @property {Array.<Hash>} transactionHashes
 */
class TransactionCache {
    /**
     * @param {InclusionHashSet.<Hash>} [transactionHashes]
     * @param {Array.<BlockDescriptor>} [blockOrder]
     */
    constructor(transactionHashes = null, blockOrder = []) {
        /** @type {InclusionHashSet.<Hash>} */
        this._transactionHashes = transactionHashes ? transactionHashes : new InclusionHashSet(txHash => txHash.toBase64());
        /** @type {Array.<BlockDescriptor>} */
        this._blockOrder = blockOrder;
    }

    /**
     * @param {Transaction} transaction
     * @returns {boolean}
     */
    containsTransaction(transaction) {
        return this._transactionHashes.contains(transaction.hash());
    }

    /**
     * @param {Block} block
     * @returns {BlockDescriptor}
     * @private
     */
    static _getBlockDescriptor(block) {
        return {
            hash: block.hash(),
            prevHash: block.prevHash,
            transactionHashes: block.transactions.map(tx => tx.hash())
        };
    }

    /**
     * @param {Block} block
     */
    pushBlock(block) {
        Assert.that(!this.head || block.prevHash.equals(this.head.hash), 'Not a successor of head');
        const blockDescriptor = TransactionCache._getBlockDescriptor(block);

        this._blockOrder.push(blockDescriptor);
        this._transactionHashes.addAll(blockDescriptor.transactionHashes);

        if (this._blockOrder.length > Policy.TRANSACTION_VALIDITY_WINDOW) {
            this.shiftBlock();
        }
    }

    shiftBlock() {
        const blockDescriptor = this._blockOrder.shift();
        if (blockDescriptor) {
            this._transactionHashes.removeAll(blockDescriptor.transactionHashes);
        }
    }

    /**
     * @param {Block} block
     * @returns {number}
     */
    revertBlock(block) {
        const blockDescriptorFromOrder = this._blockOrder.pop();
        // If there is a block to remove
        if (blockDescriptorFromOrder) {
            Assert.that(blockDescriptorFromOrder.hash.equals(block.hash()), 'Invalid block to revert');
            this._transactionHashes.removeAll(blockDescriptorFromOrder.transactionHashes);
        }

        return this.missingBlocks;
    }

    /**
     * @param {Array.<Block>} blocks
     */
    prependBlocks(blocks) {
        if (blocks.length + this._blockOrder.length > Policy.TRANSACTION_VALIDITY_WINDOW) {
            throw new Error('Exceeding transaction cache size');
        }
        Assert.that(!this.tail || blocks.length === 0 || this.tail.prevHash.equals(blocks[blocks.length - 1].hash()), 'Not a predecessor of tail');
        const blockDescriptors = blocks.map(block => TransactionCache._getBlockDescriptor(block));
        this._blockOrder.unshift(...blockDescriptors);
        blockDescriptors.forEach(b => this._transactionHashes.addAll(b.transactionHashes));
    }

    /** @type {number} */
    get missingBlocks() {
        return Policy.TRANSACTION_VALIDITY_WINDOW - this._blockOrder.length;
    }

    /** @type {InclusionHashSet.<Hash>} */
    get transactions() {
        return this._transactionHashes;
    }

    /**
     * @returns {TransactionCache}
     */
    clone() {
        return new TransactionCache(/** @type {InclusionHashSet.<Hash>} */ this._transactionHashes.clone(), this._blockOrder.slice());
    }

    /**
     * @returns {boolean}
     */
    isEmpty() {
        return this._blockOrder.length === 0;
    }

    /** @type {?BlockDescriptor} */
    get head() {
        if (this._blockOrder.length === 0) return null;
        return this._blockOrder[this._blockOrder.length - 1];
    }

    /** @type {?BlockDescriptor} */
    get tail() {
        if (this._blockOrder.length === 0) return null;
        return this._blockOrder[0];
    }
}
Class.register(TransactionCache);

class TransactionStoreEntry {
    /**
     * @param {Hash} transactionHash
     * @param {Address} sender
     * @param {Address} recipient
     * @param {number} blockHeight
     * @param {Hash} blockHash
     * @param {number} index
     */
    constructor(transactionHash, sender, recipient, blockHeight, blockHash, index) {
        this._transactionHash = transactionHash;
        this._sender = sender;
        this._recipient = recipient;
        this._blockHeight = blockHeight;
        this._blockHash = blockHash;
        this._index = index;
        this.senderBuffer = this._sender.serialize();
        this.recipientBuffer = this._recipient.serialize();
        this.transactionHashBuffer = this._transactionHash.serialize();
    }

    /**
     * @param {Block} block
     * @returns {Array.<TransactionStoreEntry>}
     */
    static fromBlock(block) {
        const blockHash = block.hash();
        /** @type {Array.<TransactionStoreEntry>} */
        const entries = [];
        for (let i = 0; i < block.transactions.length; ++i) {
            const transaction = block.transactions[i];
            entries.push(new TransactionStoreEntry(transaction.hash(), transaction.sender, transaction.recipient, block.height, blockHash, i));
        }
        return entries;
    }

    /**
     * @param {string} id
     * @param {{transactionHashBuffer: Uint8Array, senderBuffer: Uint8Array, recipientBuffer: Uint8Array, blockHeight: number, blockHash: string, index: number}} o
     * @returns {TransactionStoreEntry}
     */
    static fromJSON(id, o) {
        return new TransactionStoreEntry(
            Hash.unserialize(new SerialBuffer(o.transactionHashBuffer)),
            Address.unserialize(new SerialBuffer(o.senderBuffer)),
            Address.unserialize(new SerialBuffer(o.recipientBuffer)),
            o.blockHeight,
            Hash.fromBase64(o.blockHash),
            o.index
        );
    }

    /**
     * @returns {{transactionHashBuffer: Uint8Array, senderBuffer: Uint8Array, recipientBuffer: Uint8Array, blockHeight: number, blockHash: string, index: number}}
     */
    toJSON() {
        return {
            transactionHashBuffer: this.transactionHashBuffer,
            senderBuffer: this.senderBuffer,
            recipientBuffer: this.recipientBuffer,
            blockHeight: this.blockHeight,
            blockHash: this.blockHash.toBase64(),
            index: this.index
        };
    }

    /** @type {Hash} */
    get transactionHash() {
        return this._transactionHash;
    }

    /** @type {Address} */
    get sender() {
        return this._sender;
    }

    /** @type {Address} */
    get recipient() {
        return this._recipient;
    }

    /** @type {number} */
    get blockHeight() {
        return this._blockHeight;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {number} */
    get index() {
        return this._index;
    }
}
Class.register(TransactionStoreEntry);

class TransactionStore {
    /**
     * @param {JungleDB} jdb
     */
    static initPersistent(jdb) {
        // TODO: NUMBER_ENCODING in LMDB stores 32bit integers. This will only be safe for the next ~11 years assuming only full blocks.
        jdb.deleteObjectStore('Transactions', {upgradeCondition: oldVersion => oldVersion < 4, indexNames: ['sender', 'recipient']}); // New transaction store layout starting in ConsensusDB 4
        jdb.deleteObjectStore('Transactions', {upgradeCondition: oldVersion => oldVersion >= 4 && oldVersion < 8, indexNames: ['sender', 'recipient', 'transactionHash']});
        const store = jdb.createObjectStore('Transactions', { codec: new TransactionStoreCodec(), keyEncoding: JDB.JungleDB.NUMBER_ENCODING });
        store.createIndex('sender', ['senderBuffer'], { keyEncoding: JDB.JungleDB.BINARY_ENCODING });
        store.createIndex('recipient', ['recipientBuffer'], { keyEncoding: JDB.JungleDB.BINARY_ENCODING });
        store.createIndex('transactionHash', ['transactionHashBuffer'], { keyEncoding: JDB.JungleDB.BINARY_ENCODING });
    }

    /**
     * @param {JungleDB} jdb
     * @returns {TransactionStore}
     */
    static getPersistent(jdb) {
        return new TransactionStore(jdb.getObjectStore('Transactions'));
    }

    /**
     * @returns {TransactionStore}
     */
    static createVolatile() {
        const store = JDB.JungleDB.createVolatileObjectStore();
        store.createIndex('sender', ['senderBuffer']);
        store.createIndex('recipient', ['recipientBuffer']);
        store.createIndex('transactionHash', ['transactionHashBuffer'], { unique: true });
        return new TransactionStore(store);
    }

    /**
     * @param {IObjectStore} store
     */
    constructor(store) {
        this._store = store;
    }

    /**
     * @param {JDB.Transaction} [tx]
     * @returns {Promise.<number>}
     * @private
     */
    async _getCurrentId(tx) {
        tx = tx || this._store;
        return (await tx.get(TransactionStore.CURRENT_ID_KEY)) || 1;
    }

    /**
     * @param {number} id
     * @param {JDB.Transaction} [tx]
     * @returns {Promise}
     * @private
     */
    _setCurrentId(id, tx) {
        tx = tx || this._store;
        return tx.put(TransactionStore.CURRENT_ID_KEY, id);
    }

    /**
     * @param {Hash} transactionHash
     * @param {JDB.Transaction} [tx]
     * @returns {Promise.<number>}
     * @private
     */
    async _idForHash(transactionHash, tx) {
        tx = tx || this._store;
        const index = tx.index('transactionHash');
        const result = await index.keys(JDB.KeyRange.only(transactionHash.serialize()));
        // Should only contain one result due to unique constraint
        for (const id of result) {
            return id;
        }
        return null;
    }

    /**
     * @param {Hash} transactionHash
     * @returns {Promise.<TransactionStoreEntry>}
     */
    async get(transactionHash) {
        const index = this._store.index('transactionHash');
        const result = await index.values(JDB.KeyRange.only(transactionHash.serialize()));
        return result && result.length > 0 ? result[0] : null;
    }

    /**
     * @param {Address} sender
     * @param {number} [limit]
     * @returns {Promise.<Array.<TransactionStoreEntry>>}
     */
    async getBySender(sender, limit = null) {
        const index = this._store.index('sender');
        const entries = [];
        await index.valueStream((value, key) => {
            if (limit !== null && entries.length >= limit) return false;
            entries.push(value);
            return true;
        }, /*ascending*/ false, JDB.KeyRange.only(sender.serialize()));
        return entries;
    }

    /**
     * @param {Address} recipient
     * @param {?number} [limit]
     * @returns {Promise.<Array.<TransactionStoreEntry>>}
     */
    async getByRecipient(recipient, limit = null) {
        const index = this._store.index('recipient');
        const entries = [];
        await index.valueStream((value, key) => {
            if (limit !== null && entries.length >= limit) return false;
            entries.push(value);
            return true;
        }, /*ascending*/ false, JDB.KeyRange.only(recipient.serialize()));
        return entries;
    }

    /**
     * @override
     * @param {Block} block
     * @returns {Promise}
     */
    async put(block) {
        const indexedTransactions = TransactionStoreEntry.fromBlock(block);
        const tx = this._store.transaction();
        let currentId = await this._getCurrentId(tx);
        for (const indexedTransaction of indexedTransactions) {
            tx.putSync(currentId, indexedTransaction);
            currentId++;
        }
        await this._setCurrentId(currentId, tx);
        return tx.commit();
    }

    /**
     * @override
     * @param {Block} block
     * @returns {Promise}
     */
    async remove(block) {
        const tx = this._store.transaction();
        for (const transaction of block.transactions) {
            tx.removeSync(await this._idForHash(transaction.hash(), tx));  // eslint-disable-line no-await-in-loop
        }
        return tx.commit();
    }

    /**
     * @param {TransactionStore} [tx]
     * @returns {TransactionStore}
     */
    snapshot(tx) {
        const snapshot = this._store.snapshot();
        if (tx) {
            snapshot.inherit(tx._store);
        }
        return new TransactionStore(snapshot);
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {TransactionStore}
     */
    transaction(enableWatchdog = true) {
        const tx = this._store.transaction(enableWatchdog);
        return new TransactionStore(tx);
    }

    /**
     * @returns {Promise}
     */
    truncate() {
        return this._store.truncate();
    }

    /**
     * @returns {Promise.<boolean>}
     */
    commit() {
        return this._store.commit();
    }

    /**
     * @returns {Promise}
     */
    abort() {
        return this._store.abort();
    }

    /** @type {Transaction} */
    get tx() {
        if (this._store instanceof JDB.Transaction) {
            return this._store;
        }
        return undefined;
    }
}
TransactionStore.CURRENT_ID_KEY = 0; // This id is not used for anything but storing the current id.
Class.register(TransactionStore);

/**
 * @implements {ICodec}
 */
class TransactionStoreCodec {
    /**
     * @param {*} obj The object to encode before storing it.
     * @returns {*} Encoded object.
     */
    encode(obj) {
        return obj instanceof TransactionStoreEntry ? obj.toJSON() : obj;
    }

    /**
     * @param {*} obj The object to decode.
     * @param {string} key The object's primary key.
     * @returns {*} Decoded object.
     */
    decode(obj, key) {
        return key === 0 ? obj : TransactionStoreEntry.fromJSON(key, obj);
    }

    /**
     * @type {{encode: function(val:*):*, decode: function(val:*):*, buffer: boolean, type: string}|void}
     */
    get valueEncoding() {
        return JDB.JungleDB.JSON_ENCODING;
    }
}

class TransactionReceipt {
    /**
     * @param {Hash} transactionHash
     * @param {Hash} blockHash
     * @param {number} blockHeight
     */
    constructor(transactionHash, blockHash, blockHeight) {
        this._transactionHash = transactionHash;
        this._blockHash = blockHash;
        this._blockHeight = blockHeight;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {TransactionReceipt}
     */
    static unserialize(buf) {
        const transactionHash = Hash.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const blockHeight = buf.readUint32();
        return new TransactionReceipt(transactionHash, blockHash, blockHeight);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._transactionHash.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint32(this._blockHeight);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return this._transactionHash.serializedSize
            + this._blockHash.serializedSize
            + /*blockHeight*/ 4;
    }

    /** @type {Hash} */
    get transactionHash() {
        return this._transactionHash;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {number} */
    get blockHeight() {
        return this._blockHeight;
    }

    /**
     * @param {TransactionReceipt} o
     * @return {boolean}
     */
    equals(o) {
        if (!(o instanceof TransactionReceipt)) return false;
        return this.transactionHash.equals(o.transactionHash) &&
            this.blockHash.equals(o.blockHash) &&
            this.blockHeight === o.blockHeight;
    }

    /**
     * @return {object}
     */
    toPlain() {
        return {
            transactionHash: this.transactionHash.toPlain(),
            blockHash: this.blockHash.toPlain(),
            blockHeight: this.blockHeight
        };
    }

    /**
     * @param {object} o
     * @return {TransactionReceipt}
     */
    static fromPlain(o) {
        if (!o) throw new Error('invalid transaction receipt');
        return new TransactionReceipt(Hash.fromAny(o.transactionHash), Hash.fromAny(o.blockHash), o.blockHeight);
    }

    /**
     * @param {TransactionReceipt|object|string} o
     * @return {TransactionReceipt}
     */
    static fromAny(o) {
        if (o instanceof TransactionReceipt) return o;
        if (typeof o === 'string') return TransactionReceipt.unserialize(BufferUtils.fromHex(o));
        if (typeof o === 'object') return TransactionReceipt.fromPlain(o);
        throw new Error('invalid transaction receipt');
    }
}

Class.register(TransactionReceipt);

class Block {
    /**
     * @param {BlockHeader} header
     * @param {BlockInterlink} interlink
     * @param {BlockBody} [body]
     */
    constructor(header, interlink, body) {
        if (!(header instanceof BlockHeader)) throw new Error('Malformed header');
        if (!(interlink instanceof BlockInterlink)) throw new Error('Malformed interlink');
        if (body && !(body instanceof BlockBody)) throw new Error('Malformed body');

        /** @type {BlockHeader} */
        this._header = header;
        /** @type {BlockInterlink} */
        this._interlink = interlink;
        /** @type {BlockBody} */
        this._body = body;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {Block}
     */
    static unserialize(buf) {
        const header = BlockHeader.unserialize(buf);
        const interlink = BlockInterlink.unserialize(buf, header.prevHash);

        let body = undefined;
        const bodyPresent = buf.readUint8();
        if (bodyPresent) {
            body = BlockBody.unserialize(buf);
        }

        return new Block(header, interlink, body);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._header.serialize(buf);
        this._interlink.serialize(buf);

        if (this._body) {
            buf.writeUint8(1);
            this._body.serialize(buf);
        } else {
            buf.writeUint8(0);
        }

        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return this._header.serializedSize
            + this._interlink.serializedSize
            + /*bodyPresent*/ 1
            + (this._body ? this._body.serializedSize : 0);
    }

    /**
     * @param {Time} time
     * @returns {Promise.<boolean>}
     */
    async verify(time) {
        if (this._valid === undefined) {
            if (this.isLight() || this.body.transactions.length < 150 || !IWorker.areWorkersAsync) {
                // worker overhead doesn't pay off for small transaction numbers
                this._valid = await this._verify(time.now());
            } else {
                const transactionValid = this.body.transactions.map(t => t._valid);
                const worker = await CryptoWorker.getInstanceAsync();
                const {valid, pow, interlinkHash, bodyHash} = await worker.blockVerify(this.serialize(),
                    transactionValid, time.now(), GenesisConfig.GENESIS_HASH.serialize(), GenesisConfig.NETWORK_ID);
                this._valid = valid;
                this.header._pow = Hash.unserialize(new SerialBuffer(pow));
                this.interlink._hash = Hash.unserialize(new SerialBuffer(interlinkHash));
                this.body._hash = Hash.unserialize(new SerialBuffer(bodyHash));
            }
        }
        return this._valid;
    }

    /**
     * @param {number} timeNow
     * @returns {Promise.<boolean>}
     */
    async _verify(timeNow) {
        // Check that the timestamp is not too far into the future.
        if (this._header.timestamp * 1000 > timeNow + Block.TIMESTAMP_DRIFT_MAX * 1000) {
            Log.w(Block, 'Invalid block - timestamp too far in the future');
            return false;
        }

        // Check that the header hash matches the difficulty.
        if (!(await this._header.verifyProofOfWork())) {
            Log.w(Block, 'Invalid block - PoW verification failed');
            return false;
        }

        // Check that the maximum block size is not exceeded.
        if (this.serializedSize > Policy.BLOCK_SIZE_MAX) {
            Log.w(Block, 'Invalid block - max block size exceeded');
            return false;
        }

        // Verify that the interlink is valid.
        if (!this._verifyInterlink()) {
            return false;
        }

        // XXX Verify the body only if it is present.
        if (this.isFull() && !this._verifyBody()) {
            return false;
        }

        // Everything checks out.
        return true;
    }

    /**
     * @returns {boolean}
     * @private
     */
    _verifyInterlink() {
        // Skip check for genesis block due to the cyclic dependency (since the interlink hash contains the genesis block hash).
        if (this.height === 1 && this._header.interlinkHash.equals(new Hash(null))) {
            return true;
        }

        // Check that the interlinkHash given in the header matches the actual interlinkHash.
        const interlinkHash = this._interlink.hash();
        if (!this._header.interlinkHash.equals(interlinkHash)) {
            Log.w(Block, 'Invalid block - interlink hash mismatch');
            return false;
        }

        // Everything checks out.
        return true;
    }

    /**
     * @returns {boolean}
     * @private
     */
    _verifyBody() {
        // Check that the body is valid.
        if (!this._body.verify()) {
            return false;
        }

        // Check that bodyHash given in the header matches the actual body hash.
        const bodyHash = this._body.hash();
        if (!this._header.bodyHash.equals(bodyHash)) {
            Log.w(Block, 'Invalid block - body hash mismatch');
            return false;
        }

        // Everything checks out.
        return true;
    }

    /**
     * @param {Block} predecessor
     * @returns {Promise.<boolean>}
     */
    async isImmediateSuccessorOf(predecessor) {
        // Check the header.
        if (!this._header.isImmediateSuccessorOf(predecessor.header)) {
            return false;
        }

        // Check that the interlink is correct.
        const interlink = await predecessor.getNextInterlink(this.target, this.version);
        if (!this._interlink.equals(interlink)) {
            return false;
        }

        // Everything checks out.
        return true;
    }

    /**
     * @param {Block} predecessor
     * @returns {Promise.<boolean>}
     */
    async isInterlinkSuccessorOf(predecessor) {
        // Check that the height is higher than the predecessor's.
        if (this._header.height <= predecessor.header.height) {
            Log.v(Block, 'No interlink successor - height');
            return false;
        }

        // Check that the timestamp is greater or equal to the predecessor's timestamp.
        if (this._header.timestamp < predecessor.header.timestamp) {
            Log.v(Block, 'No interlink successor - timestamp');
            return false;
        }

        // Check that the predecessor is contained in this block's interlink and verify its position.
        const prevHash = predecessor.hash();
        if (!GenesisConfig.GENESIS_HASH.equals(prevHash)) {
            const prevPow = await predecessor.pow();
            const targetHeight = BlockUtils.getTargetHeight(this.target);
            let blockFound = false;

            let depth = 0;
            for (; depth < this._interlink.length; depth++) {
                if (prevHash.equals(this._interlink.hashes[depth])) {
                    blockFound = true;
                    const target = new BigNumber(2).pow(targetHeight - depth);
                    if (!BlockUtils.isProofOfWork(prevPow, target)) {
                        Log.v(Block, 'No interlink successor - invalid position in interlink');
                        return false;
                    }
                }
            }

            if (!blockFound) {
                Log.v(Block, 'No interlink successor - not in interlink');
                return false;
            }
        }

        // If the predecessor happens to be the immediate predecessor, check additionally:
        // - that the height of the successor is one higher
        // - that the interlink is correct.
        if (this._header.prevHash.equals(prevHash)) {
            if (this._header.height !== predecessor.header.height + 1) {
                Log.v(Block, 'No interlink successor - immediate height');
                return false;
            }

            const interlink = await predecessor.getNextInterlink(this.target, this.version);
            const interlinkHash = interlink.hash();
            if (!this._header.interlinkHash.equals(interlinkHash)) {
                Log.v(Block, 'No interlink successor - immediate interlink');
                return false;
            }
        }
        // Otherwise, if the prevHash doesn't match but the blocks should be adjacent according to their height fields,
        // this cannot be a valid successor of predecessor.
        else if (this._header.height === predecessor.header.height + 1) {
            Log.v(Block, 'No interlink successor - immediate height (2)');
            return false;
        }
        // Otherwise, check that the interlink construction is valid given the information we have.
        else {
            // TODO Take different targets into account.

            // The number of new blocks in the interlink is bounded by the height difference.
            /** @type {HashSet.<Hash>} */
            const hashes = new HashSet();
            hashes.addAll(this._interlink.hashes);
            hashes.removeAll(predecessor.interlink.hashes);
            if (hashes.length > this._header.height - predecessor.header.height) {
                Log.v(Block, 'No interlink successor - too many new blocks');
                return false;
            }

            // Check that the interlink is not too short.
            const thisDepth = BlockUtils.getTargetDepth(this.target);
            const prevDepth = BlockUtils.getTargetDepth(predecessor.target);
            const depthDiff = thisDepth - prevDepth;
            if (this._interlink.length < predecessor.interlink.length - depthDiff) {
                Log.v(Block, 'No interlink successor - interlink too short');
                return false;
            }

            // If the same block is found in both interlinks, all blocks at lower depths must be the same in both interlinks.
            let commonBlock = false;
            const thisInterlink = this._interlink.hashes;
            const prevInterlink = predecessor.interlink.hashes;
            for (let i = 1; i < prevInterlink.length && i - depthDiff < thisInterlink.length; i++) {
                if (prevInterlink[i].equals(thisInterlink[i - depthDiff])) {
                    commonBlock = true;
                } else if (commonBlock) {
                    Log.v(Block, 'No interlink successor - invalid common suffix');
                    return false;
                }
            }
        }

        // Everything checks out.
        return true;
    }

    /**
     * @param {Block} predecessor
     * @returns {Promise.<boolean>}
     */
    async isSuccessorOf(predecessor) {
        // TODO Improve this! Lots of duplicate checks.
        return (await this.isImmediateSuccessorOf(predecessor)) || (await this.isInterlinkSuccessorOf(predecessor));
    }

    /**
     * @param {BigNumber} nextTarget
     * @param {number} [nextVersion]
     * @returns {Promise.<BlockInterlink>}
     */
    async getNextInterlink(nextTarget, nextVersion = BlockHeader.CURRENT_VERSION) {
        /** @type {Array.<Hash>} */
        const hashes = [];
        const hash = this.hash();

        // Compute how many times this blockHash should be included in the next interlink.
        const thisPowDepth = BlockUtils.getHashDepth(await this.pow());
        const nextTargetDepth = BlockUtils.getTargetDepth(nextTarget);
        const numOccurrences = Math.max(thisPowDepth - nextTargetDepth + 1, 0);

        // Push this blockHash numOccurrences times onto the next interlink.
        for (let i = 0; i < numOccurrences; i++) {
            hashes.push(hash);
        }

        // Compute how many blocks to omit from the beginning of this interlink.
        const thisTargetDepth = BlockUtils.getTargetDepth(this.target);
        const targetOffset = nextTargetDepth - thisTargetDepth;
        const interlinkOffset = numOccurrences + targetOffset;

        // Push the remaining hashes from this interlink.
        for (let i = interlinkOffset; i < this.interlink.length; i++) {
            hashes.push(this.interlink.hashes[i]);
        }

        return new BlockInterlink(hashes, hash);
    }

    /**
     * @returns {Block}
     */
    shallowCopy() {
        return new Block(this._header, this._interlink, this._body);
    }

    /**
     * @param {Block|*} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof Block
            && this._header.equals(o._header)
            && this._interlink.equals(o._interlink)
            && (this._body ? this._body.equals(o._body) : !o._body);
    }

    /**
     * @returns {boolean}
     */
    isLight() {
        return !this._body;
    }

    /**
     * @returns {boolean}
     */
    isFull() {
        return !!this._body;
    }

    /**
     * @returns {Block}
     */
    toLight() {
        return this.isLight() ? this : new Block(this._header, this._interlink);
    }

    /**
     * @param {BlockBody} body
     * @returns {Block}
     */
    toFull(body) {
        return this.isFull() ? this : new Block(this._header, this._interlink, body);
    }

    /**
     * @type {BlockHeader}
     */
    get header() {
        return this._header;
    }

    /**
     * @type {BlockInterlink}
     */
    get interlink() {
        return this._interlink;
    }

    /**
     * @type {BlockBody}
     */
    get body() {
        if (this.isLight()) {
            throw new Error('Cannot access body of light block');
        }
        return this._body;
    }

    /**
     * @returns {number}
     */
    get version() {
        return this._header.version;
    }

    /**
     * @type {Hash}
     */
    get prevHash() {
        return this._header.prevHash;
    }

    /**
     * @type {Hash}
     */
    get interlinkHash() {
        return this._header.interlinkHash;
    }

    /**
     * @type {Hash}
     */
    get bodyHash() {
        return this._header.bodyHash;
    }

    /**
     * @type {Hash}
     */
    get accountsHash() {
        return this._header.accountsHash;
    }

    /**
     * @type {number}
     */
    get nBits() {
        return this._header.nBits;
    }

    /**
     * @type {BigNumber}
     */
    get target() {
        return this._header.target;
    }

    /**
     * @type {BigNumber}
     */
    get difficulty() {
        return this._header.difficulty;
    }

    /**
     * @type {number}
     */
    get height() {
        return this._header.height;
    }

    /**
     * @type {number}
     */
    get timestamp() {
        return this._header.timestamp;
    }

    /**
     * @type {number}
     */
    get nonce() {
        return this._header.nonce;
    }

    /**
     * @type {Address}
     */
    get minerAddr() {
        return this._body ? this._body.minerAddr : undefined;
    }

    /**
     * @type {?Array.<Transaction>}
     */
    get transactions() {
        return this._body ? this._body.transactions : undefined;
    }

    /**
     * @returns {?Uint8Array}
     */
    get extraData() {
        return this._body ? this._body.extraData : undefined;
    }

    /**
     * @returns {?Array.<PrunedAccount>}
     */
    get prunedAccounts() {
        return this._body ? this._body.prunedAccounts : undefined;
    }

    /**
     * @type {?number}
     */
    get transactionCount() {
        return this._body ? this._body.transactionCount : undefined;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {Hash}
     */
    hash(buf) {
        return this._header.hash(buf);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {Promise.<Hash>}
     */
    pow(buf) {
        return this._header.pow(buf);
    }

    /**
     * @param {Block|object|string} block
     */
    static fromAny(block) {
        if (block instanceof Block) return block;
        if (typeof block === 'object') return Block.fromPlain(block);
        if (typeof block === 'string') return Block.unserialize(BufferUtils.fromHex(block));
        throw new Error('Invalid block');
    }

    /**
     * @param {object} plain
     */
    static fromPlain(plain) {
        const header = new BlockHeader(
            Hash.fromAny(plain.prevHash),
            Hash.fromAny(plain.interlinkHash),
            Hash.fromAny(plain.bodyHash),
            Hash.fromAny(plain.accountsHash),
            plain.nBits,
            plain.height,
            plain.timestamp,
            plain.nonce,
            plain.version
        );
        const interlink = new BlockInterlink((plain.interlink.hashes || plain.interlink).map(h => Hash.fromAny(h)), Hash.fromAny(plain.prevHash));
        let body = null;
        if (plain.minerAddr && plain.extraData !== undefined && Array.isArray(plain.transactions) && Array.isArray(plain.prunedAccounts)) {
            body = new BlockBody(
                Address.fromAny(plain.minerAddr),
                plain.transactions.map(tx => Transaction.fromAny(tx)),
                BufferUtils.fromAny(plain.extraData),
                plain.prunedAccounts.map(pa => PrunedAccount.fromAny(pa))
            );
        }
        return new Block(header, interlink, body);
    }

    toString() {
        return `Block{height=${this.height},prev=${this.prevHash}}`;
    }

    toPlain() {
        const plain = {
            version: this.version,
            hash: this.hash().toPlain(),
            prevHash: this.prevHash.toPlain(),
            interlinkHash: this.interlinkHash.toPlain(),
            bodyHash: this.bodyHash.toPlain(),
            accountsHash: this.accountsHash.toPlain(),
            nBits: this.nBits,
            difficulty: this.difficulty.toString(),
            height: this.height,
            timestamp: this.timestamp,
            nonce: this.nonce,
            interlink: this.interlink.hashes.map(h => h.toPlain()),
        };
        if (this.isFull()) {
            plain.minerAddr = this.minerAddr.toPlain();
            plain.transactions = this.transactions.map(tx => tx.toPlain());
            plain.extraData = BufferUtils.toHex(this.extraData);
            plain.prunedAccounts = this.prunedAccounts.map(pa => pa.toPlain());
        }
        return plain;
    }
}

Block.TIMESTAMP_DRIFT_MAX = 600 /* seconds */; // 10 minutes
Class.register(Block);

/**
 * @interface
 */
class IBlockchain extends Observable {
    /**
     * @abstract
     * @type {Block}
     */
    get head() {}

    /**
     * @abstract
     * @type {Hash}
     */
    get headHash() {}

    /**
     * @abstract
     * @type {number}
     */
    get height() {}
}
Class.register(IBlockchain);

/**
 * @abstract
 */
class BaseChain extends IBlockchain {
    /**
     * @param {ChainDataStore} store
     */
    constructor(store) {
        super();
        this._store = store;
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks]
     * @param {boolean} [includeBody]
     * @returns {Promise.<?Block>}
     */
    async getBlock(hash, includeForks = false, includeBody = false) {
        const chainData = await this._store.getChainData(hash, includeBody);
        return chainData && (chainData.onMainChain || includeForks) ? chainData.head : null;
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks]
     * @returns {Promise.<?Uint8Array>}
     */
    getRawBlock(hash, includeForks = false) {
        return this._store.getRawBlock(hash, includeForks);
    }

    /**
     * @param {number} height
     * @param {boolean} [includeBody]
     * @returns {Promise.<?Block>}
     */
    getBlockAt(height, includeBody = false) {
        return this._store.getBlockAt(height, includeBody) || null;
    }

    /**
     * @param {number} height
     * @param {boolean} [lower]
     * @returns {Promise.<?Block>}
     */
    getNearestBlockAt(height, lower = true) {
        return this._store.getNearestBlockAt(height, lower) || null;
    }

    /**
     * @param {Block} block
     * @returns {Promise<Array.<Block>>}
     */
    async getSuccessorBlocks(block) {
        return this._store.getSuccessorBlocks(block);
    }

    /**
     * @returns {Promise.<Array.<Hash>>}
     */
    async getBlockLocators() {
        // Push top 10 hashes first, then back off exponentially.
        /** @type {Array.<Hash>} */
        const locators = [this.headHash];

        let block = this.head;
        for (let i = Math.min(10, this.height) - 1; i > 0; i--) {
            if (!block) {
                break;
            }
            locators.push(block.prevHash);
            block = await this.getBlock(block.prevHash); // eslint-disable-line no-await-in-loop
        }

        let step = 2;
        for (let i = this.height - 10 - step; i > 0; i -= step) {
            block = await this.getBlockAt(i); // eslint-disable-line no-await-in-loop
            if (block) {
                locators.push(await block.hash()); // eslint-disable-line no-await-in-loop
            }
            step *= 2;
            // Respect max size for GetBlocksMessages
            if (locators.length >= GetBlocksMessage.LOCATORS_MAX_COUNT) break;
        }

        // Push the genesis block hash.
        if (locators.length === 0 || !locators[locators.length - 1].equals(GenesisConfig.GENESIS_HASH)) {
            // Respect max size for GetBlocksMessages, make space for genesis hash if necessary
            if (locators.length >= GetBlocksMessage.LOCATORS_MAX_COUNT) {
                locators.pop();
            }
            locators.push(GenesisConfig.GENESIS_HASH);
        }

        return locators;
    }

    /**
     * Computes the target value for the block after the given block or the head of this chain if no block is given.
     * @param {Block} [block]
     * @param {Block} [next]
     * @returns {Promise.<BigNumber>}
     */
    async getNextTarget(block, next) {
        /** @type {ChainData} */
        let headData;
        if (block) {
            const hash = block.hash();
            headData = await this._store.getChainData(hash);
            Assert.that(!!headData);
        } else {
            block = this.head;
            headData = this._mainChain;
        }

        if (next) {
            headData = await headData.nextChainData(next);
            block = next;
        }

        // Retrieve the timestamp of the block that appears DIFFICULTY_BLOCK_WINDOW blocks before the given block in the chain.
        // The block might not be on the main chain.
        const tailHeight = Math.max(block.height - Policy.DIFFICULTY_BLOCK_WINDOW, 1);
        /** @type {ChainData} */
        let tailData;
        if (headData.onMainChain) {
            tailData = await this._store.getChainDataAt(tailHeight);
        } else {
            let prevData = headData;
            for (let i = 0; i < Policy.DIFFICULTY_BLOCK_WINDOW && !prevData.onMainChain; i++) {
                prevData = await this._store.getChainData(prevData.head.prevHash);
                if (!prevData) {
                    // Not enough blocks are available to compute the next target, fail.
                    return null;
                }
            }

            if (prevData.onMainChain && prevData.head.height > tailHeight) {
                tailData = await this._store.getChainDataAt(tailHeight);
            } else {
                tailData = prevData;
            }
        }

        if (!tailData || tailData.totalDifficulty.lt(1)) {
            // Not enough blocks are available to compute the next target, fail.
            return null;
        }

        const deltaTotalDifficulty = headData.totalDifficulty.minus(tailData.totalDifficulty);
        return BlockUtils.getNextTarget(headData.head.header, tailData.head.header, deltaTotalDifficulty);
    }



    /* NIPoPoW Prover functions */

    /**
     * MUST be synchronized with .pushBlock() and variants!
     * @returns {Promise.<ChainProof>}
     * @protected
     */
    _getChainProof() {
        return this._prove(Policy.M, Policy.K, Policy.DELTA);
    }

    /**
     * The "Prove" algorithm from the NIPoPow paper.
     * @param {number} m
     * @param {number} k
     * @param {number} delta
     * @returns {Promise.<ChainProof>}
     * @private
     */
    async _prove(m, k, delta) {
        Assert.that(m >= 1, 'm must be >= 1');
        Assert.that(delta > 0, 'delta must be > 0');
        let prefix = new BlockChain([]);

        // B <- C[0]
        let startHeight = 1;

        /** @type {ChainData} */
        const headData = await this._store.getChainDataAt(Math.max(this.height - k, 1)); // C[-k]
        const maxDepth = headData.superBlockCounts.getCandidateDepth(m);

        // for mu = |C[-k].interlink| down to 0 do
        for (let depth = maxDepth; depth >= 0; depth--) {
            // alpha = C[:-k]{B:}|^mu
            /** @type {Array.<ChainData>} */
            const alpha = await this._getSuperChain(depth, headData, startHeight); // eslint-disable-line no-await-in-loop

            // pi = pi (union) alpha
            prefix = BlockChain.merge(prefix, new BlockChain(alpha.map(data => data.head.toLight())));

            // if good_(delta,m)(C, alpha, mu) then
            if (BaseChain._isGoodSuperChain(alpha, depth, m, delta)) {
                Assert.that(alpha.length >= m, `Good superchain expected to be at least ${m} long`);
                Log.v(BaseChain, () => `Found good superchain at depth ${depth} with length ${alpha.length} (#${startHeight} - #${headData.head.height})`);
                // B <- alpha[-m]
                startHeight = alpha[alpha.length - m].head.height;
            }
        }

        // X <- C[-k:]
        const suffix = await this._getHeaderChain(this.height - headData.head.height);

        // return piX
        return new ChainProof(prefix, suffix);
    }

    /**
     * @param {number} depth
     * @param {ChainData} headData
     * @param {number} [tailHeight]
     * @returns {Promise.<Array.<ChainData>>}
     * @private
     */
    async _getSuperChain(depth, headData, tailHeight = 1) {
        Assert.that(tailHeight >= 1, 'tailHeight must be >= 1');
        /** @type {Array.<ChainData>} */
        const chain = [];

        // Include head if it is at the requested depth or below.
        const headDepth = BlockUtils.getHashDepth(await headData.head.pow());
        if (headDepth >= depth) {
            chain.push(headData);
        }

        // Follow the interlink pointers back at the requested depth.
        /** @type {ChainData} */
        let chainData = headData;
        let j = Math.max(depth - BlockUtils.getTargetDepth(chainData.head.target), -1);
        while (j < chainData.head.interlink.hashes.length && chainData.head.height > tailHeight) {
            const reference = j < 0 ? chainData.head.prevHash : chainData.head.interlink.hashes[j];
            chainData = await this._store.getChainData(reference); // eslint-disable-line no-await-in-loop
            if (!chainData) {
                // This can happen in the light/nano client if chain superquality is harmed.
                // Return a best-effort chain in this case.
                Log.w(BaseChain, `Failed to find block ${reference} while constructing SuperChain at depth ${depth} - returning truncated chain`);
                break;
            }
            chain.push(chainData);

            j = Math.max(depth - BlockUtils.getTargetDepth(chainData.head.target), -1);
        }

        if ((chain.length === 0 || chain[chain.length - 1].head.height > 1) && tailHeight === 1) {
            chain.push(await ChainData.initial(GenesisConfig.GENESIS_BLOCK));
        }

        return chain.reverse();
    }

    /**
     * @param {Array.<ChainData>} superchain
     * @param {number} depth
     * @param {number} m
     * @param {number} delta
     * @returns {boolean}
     */
    static _isGoodSuperChain(superchain, depth, m, delta) {
        return BaseChain._hasSuperQuality(superchain, depth, m, delta)
            && BaseChain._hasMultiLevelQuality(superchain, depth, m, delta);
    }

    /**
     * @param {Array.<ChainData>} superchain
     * @param {number} depth
     * @param {number} m
     * @param {number} delta
     * @returns {boolean}
     * @private
     */
    static _hasSuperQuality(superchain, depth, m, delta) {
        Assert.that(m >= 1, 'm must be >= 1');
        if (superchain.length < m) {
            return false;
        }

        for (let i = m; i <= superchain.length; i++) {
            const underlyingLength = superchain[superchain.length - 1].head.height - superchain[superchain.length - i].head.height + 1;
            if (!BaseChain._isLocallyGood(i, underlyingLength, depth, delta)) {
                return false;
            }
        }

        return true;
    }

    /**
     *
     * @param {Array.<ChainData>} superchain
     * @param {number} depth
     * @param {number} k1
     * @param {number} delta
     * @returns {boolean}
     * @private
     */
    static _hasMultiLevelQuality(superchain, depth, k1, delta) {
        if (depth <= 0) {
            return true;
        }

        for (let i = 0; i < superchain.length - k1; i++) {
            const tailData = superchain[i];
            const headData = superchain[i + k1];

            for (let mu = depth; mu >= 1; mu--) {
                const upperChainLength = headData.superBlockCounts.get(mu) - tailData.superBlockCounts.get(mu);

                switch (BaseChain.MULTILEVEL_STRATEGY) {
                    case BaseChain.MultilevelStrategy.STRICT: {
                        const lowerChainLength = headData.superBlockCounts.get(mu - 1) - tailData.superBlockCounts.get(mu - 1);

                        /*
                        // Original paper badness check:
                        if (lowerChainLength > Math.pow(1 + delta, 1 / depth) * 2 * upperChainLength) {
                            Log.d(BaseChain, `Chain badness detected at depth ${depth}, failing at ${mu}/${mu - 1}`
                                + ` with ${upperChainLength}/${Math.pow(1 + delta, 1 / depth) * 2 * upperChainLength}/${lowerChainLength} blocks`);
                            return false;
                        }
                        */

                        // Alternative badness check:
                        if (2 * upperChainLength < Math.pow(1 - delta, 1 / depth) * lowerChainLength) {
                            Log.d(BaseChain, `Chain badness detected at depth ${depth}, failing at ${mu}/${mu - 1}`
                                + ` with ${upperChainLength}/${Math.pow(1 - delta, 1 / depth) * lowerChainLength}/${lowerChainLength} blocks`);
                            return false;
                        }
                        break;
                    }

                    default:
                    case BaseChain.MultilevelStrategy.MODERATE: {
                        // Relaxed badness check:
                        for (let j = mu - 1; j >= 0; j--) {
                            const lowerChainLength = headData.superBlockCounts.get(j) - tailData.superBlockCounts.get(j);
                            if (!BaseChain._isLocallyGood(upperChainLength, lowerChainLength, mu - j, delta)) {
                                Log.d(BaseChain, `Chain badness detected at depth ${depth}[${i}:${i + k1}], failing at ${mu}/${j}`);
                                return false;
                            }
                        }
                        break;
                    }

                    case BaseChain.MultilevelStrategy.RELAXED: {
                        // Local goodness only:
                        const lowerChainLength = headData.superBlockCounts.get(mu - 1) - tailData.superBlockCounts.get(mu - 1);
                        const underlyingLength = headData.head.height - tailData.head.height + 1;
                        if (!BaseChain._isLocallyGood(lowerChainLength, underlyingLength, depth, delta)) {
                            Log.d(BaseChain, `Chain badness detected at depth ${depth}[${i}:${i + k1}], failing at ${mu}`);
                            return false;
                        }
                        break;
                    }
                }
            }
        }

        return true;
    }

    /**
     * @param {number} superLength
     * @param {number} underlyingLength
     * @param {number} depth
     * @param {number} delta
     * @returns {boolean}
     * @private
     */
    static _isLocallyGood(superLength, underlyingLength, depth, delta) {
        // |C'| > (1 - delta) * 2^(-mu) * |C|
        return superLength > (1 - delta) * Math.pow(2, -depth) * underlyingLength;
    }

    /**
     * @param {number} length
     * @param {Block} [head]
     * @returns {Promise.<HeaderChain>}
     * @private
     */
    async _getHeaderChain(length, head = this.head) {
        const headers = [];
        while (head && headers.length < length) {
            headers.push(head.header);
            head = await this.getBlock(head.prevHash); // eslint-disable-line no-await-in-loop
        }
        return new HeaderChain(headers.reverse());
    }

    /**
     * @param {ChainProof} proof
     * @param {BlockHeader} header
     * @param {boolean} [failOnBadness]
     * @returns {Promise.<ChainProof>}
     * @protected
     */
    async _extendChainProof(proof, header, failOnBadness = true) {
        // Append new header to proof suffix.
        const suffix = proof.suffix.headers.slice();
        suffix.push(header);

        // If the suffix is not long enough (short chain), we're done.
        const prefix = proof.prefix.blocks.slice();
        if (suffix.length <= Policy.K) {
            return new ChainProof(new BlockChain(prefix), new HeaderChain(suffix));
        }

        // Cut the tail off the suffix.
        const suffixTail = suffix.shift();

        // Construct light block out of the old suffix tail.
        const interlink = await proof.prefix.head.getNextInterlink(suffixTail.target, suffixTail.version);
        const prefixHead = new Block(suffixTail, interlink);

        // Append old suffix tail block to prefix.
        prefix.push(prefixHead);

        // Extract layered superchains from prefix. Make a copy because we are going to change the chains array.
        const chains = (await proof.prefix.getSuperChains()).slice();

        // Append new prefix head to chains.
        const depth = BlockUtils.getHashDepth(await prefixHead.pow());
        for (let i = depth; i >= 0; i--) {
            // Append block. Don't modify the chain, create a copy.
            if (!chains[i]) {
                chains[i] = new BlockChain([prefixHead]);
            } else {
                chains[i] = new BlockChain([...chains[i].blocks, prefixHead]);
            }
        }

        // If the new header isn't a superblock, we're done.
        if (depth - BlockUtils.getTargetDepth(prefixHead.target) <= 0) {
            return new ChainProof(new BlockChain(prefix, chains), new HeaderChain(suffix));
        }

        // Prune unnecessary blocks if the chain is good.
        // Try to extend proof if the chain is bad.
        const deletedBlockHeights = new Set();
        for (let i = depth; i >= 0; i--) {
            const superchain = chains[i];
            if (superchain.length < Policy.M) {
                continue;
            }

            // XXX Hack: Convert BlockChain to array of pseudo-ChainData for the super quality check.
            const _superchain = superchain.blocks.map(block => ({ head: block }));
            if (!BaseChain._hasSuperQuality(_superchain, i, Policy.M, Policy.DELTA)) {
                Log.w(BaseChain, `Chain quality badness detected at depth ${i}`);
                // TODO extend superchains at lower levels
                if (failOnBadness) {
                    return null;
                }
                continue;
            }

            // Remove all blocks in lower chains up to (including) superchain[-m].
            const referenceBlock = superchain.blocks[superchain.length - Policy.M];
            for (let j = i - 1; j >= 0; j--) {
                let numBlocksToDelete = 0;
                let candidateBlock = chains[j].blocks[numBlocksToDelete];
                while (candidateBlock.height <= referenceBlock.height) {
                    // eslint-disable-next-line no-await-in-loop
                    const candidateDepth = BlockUtils.getHashDepth(await candidateBlock.pow());
                    if (candidateDepth === j && candidateBlock.height > 1) {
                        deletedBlockHeights.add(candidateBlock.height);
                    }

                    numBlocksToDelete++;
                    candidateBlock = chains[j].blocks[numBlocksToDelete];
                }

                if (numBlocksToDelete > 0) {
                    // Don't modify the chain, create a copy.
                    chains[j] = new BlockChain(chains[j].blocks.slice(numBlocksToDelete));
                }
            }
        }

        // Remove all deleted blocks from prefix.
        const newPrefix = new BlockChain(prefix.filter(block => !deletedBlockHeights.has(block.height)), chains);

        // Return the extended proof.
        return new ChainProof(newPrefix, new HeaderChain(suffix));
    }

    /**
     * MUST be synchronized with .pushBlock() and variants!
     * @param {Block} blockToProve
     * @param {Block} knownBlock
     * @returns {Promise.<?BlockChain>}
     * @protected
     */
    async _getBlockProof(blockToProve, knownBlock) {
        /**
         * @param {Block} block
         * @param {number} depth
         * @returns {Hash}
         */
        const getInterlinkReference = (block, depth) => {
            const index = Math.min(depth - BlockUtils.getTargetDepth(block.target), block.interlink.length - 1);
            return index < 0 ? block.prevHash : block.interlink.hashes[index];
        };

        const blocks = [];
        const hashToProve = blockToProve.hash();

        const proveTarget = BlockUtils.hashToTarget(await blockToProve.pow());
        const proveDepth = BlockUtils.getTargetDepth(proveTarget);

        let depth = BlockUtils.getTargetDepth(knownBlock.target) + knownBlock.interlink.length - 1;
        let block = knownBlock;

        let reference = getInterlinkReference(block, depth);
        while (!hashToProve.equals(reference)) {
            const nextBlock = await this.getBlock(reference); // eslint-disable-line no-await-in-loop
            if (!nextBlock) {
                // This can happen in the light/nano client if the blockToProve is known but blocks between tailBlock
                // and blockToProve are missing.
                Log.w(BaseChain, `Failed to find block ${reference} while constructing inclusion proof`);
                return null;
            }

            if (nextBlock.height < blockToProve.height) {
                // We have gone past the blockToProve, but are already at proveDepth, fail.
                if (depth <= proveDepth) {
                    return null;
                }

                // Decrease depth and thereby step size.
                depth--;
                reference = getInterlinkReference(block, depth);
            } else if (nextBlock.height > blockToProve.height) {
                // We are still in front of blockToProve, add block to result and advance.
                blocks.push(nextBlock.toLight());

                block = nextBlock;
                reference = getInterlinkReference(block, depth);
            } else {
                // We found a reference to a different block than blockToProve at its height.
                Log.w(BaseChain, `Failed to prove block ${hashToProve} - different block ${reference} at its height ${block.height}`);
                return null;
            }
        }

        // Include the blockToProve in the result.
        blocks.push(blockToProve.toLight());

        return new BlockChain(blocks.reverse());
    }

    /**
     * @param {Array.<BlockHeader>} headers
     * @return {Promise.<void>}
     */
    static async manyPow(headers) {
        const worker = await CryptoWorker.getInstanceAsync();
        const size = worker.poolSize || 1;
        const partitions = [];
        let j = 0;
        for (let i = 0; i < size; ++i) {
            partitions.push([]);
            for (; j < ((i + 1) / size) * headers.length; ++j) {
                partitions[i].push(headers[j].serialize());
            }
        }
        const promises = [];
        for (const part of partitions) {
            promises.push(worker.computeArgon2dBatch(part));
        }
        const pows = (await Promise.all(promises)).reduce((a, b) => [...a, ...b], []);
        for (let i = 0; i < headers.length; ++i) {
            headers[i]._pow = new Hash(pows[i]);
        }
    }


    /* NiPoPoW Verifier functions */

    /**
     * @param {ChainProof} proof1
     * @param {ChainProof} proof2
     * @param {number} m
     * @returns {Promise.<boolean>}
     */
    static async isBetterProof(proof1, proof2, m) {
        const lca = BlockChain.lowestCommonAncestor(proof1.prefix, proof2.prefix);
        const score1 = await NanoChain._getProofScore(proof1.prefix, lca, m);
        const score2 = await NanoChain._getProofScore(proof2.prefix, lca, m);
        return score1 === score2
            ? proof1.suffix.totalDifficulty().gt(proof2.suffix.totalDifficulty())
            : score1 > score2;
    }

    /**
     *
     * @param {BlockChain} chain
     * @param {Block} lca
     * @param {number} m
     * @returns {Promise.<number>}
     * @protected
     */
    static async _getProofScore(chain, lca, m) {
        const counts = [];
        for (const block of chain.blocks) {
            if (block.height < lca.height) {
                continue;
            }

            const depth = BlockUtils.getHashDepth(await block.pow()); // eslint-disable-line no-await-in-loop
            counts[depth] = counts[depth] ? counts[depth] + 1 : 1;
        }

        let sum = 0;
        let depth;
        for (depth = counts.length - 1; sum < m && depth >= 0; depth--) {
            sum += counts[depth] ? counts[depth] : 0;
        }

        let maxScore = Math.pow(2, depth + 1) * sum;
        let length = sum;
        for (let i = depth; i >= 0; i--) {
            length += counts[i] ? counts[i] : 0;
            const score = Math.pow(2, i) * length;
            maxScore = Math.max(maxScore, score);
        }

        return maxScore;
    }

}
BaseChain.MultilevelStrategy = {
    STRICT: 1,
    MODERATE: 2,
    RELAXED: 3
};
BaseChain.MULTILEVEL_STRATEGY = BaseChain.MultilevelStrategy.MODERATE;
Class.register(BaseChain);

class BlockChain {
    /**
     * @param {BlockChain} chain1
     * @param {BlockChain} chain2
     * @returns {BlockChain}
     */
    static merge(chain1, chain2) {
        const merged = [];
        let i1 = 0, i2 = 0;
        while (i1 < chain1.length && i2 < chain2.length) {
            const block1 = chain1.blocks[i1];
            const block2 = chain2.blocks[i2];

            if (block1.height === block2.height) {
                Assert.that(block1.equals(block2), 'Encountered different blocks at same height during chain merge');
                merged.push(block1);
                i1++;
                i2++;
            } else if (block1.height < block2.height) {
                merged.push(block1);
                i1++;
            } else {
                merged.push(block2);
                i2++;
            }
        }

        for (; i1 < chain1.length; i1++) {
            merged.push(chain1.blocks[i1]);
        }
        for (; i2 < chain2.length; i2++) {
            merged.push(chain2.blocks[i2]);
        }

        return new BlockChain(merged);
    }

    /**
     * @param {BlockChain} chain1
     * @param {BlockChain} chain2
     * @returns {?Block}
     */
    static lowestCommonAncestor(chain1, chain2) {
        let i1 = chain1.length - 1;
        let i2 = chain2.length - 1;
        while (i1 >= 0 && i2 >= 0) {
            const block1 = chain1.blocks[i1];
            const block2 = chain2.blocks[i2];

            if (block1.equals(block2)) {
                return block1;
            } else if (block1.height > block2.height) {
                i1--;
            } else {
                i2--;
            }
        }
        return undefined;
    }

    /**
     * @param {Array.<Block>} blocks
     * @param {Array.<BlockChain>} [superChains]
     */
    constructor(blocks, superChains) {
        if (!Array.isArray(blocks) || !NumberUtils.isUint16(blocks.length)
            || blocks.some(it => !(it instanceof Block) || !it.isLight())) throw new Error('Malformed blocks');

        /** @type {Array.<Block>} */
        this._blocks = blocks;
        /** @type {Array.<BlockChain>} */
        this._chains = superChains;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {BlockChain}
     */
    static unserialize(buf) {
        const count = buf.readUint16();
        const blocks = [];
        for (let i = 0; i < count; i++) {
            blocks.push(Block.unserialize(buf));
        }
        return new BlockChain(blocks);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._blocks.length);
        for (const block of this._blocks) {
            block.serialize(buf);
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*count*/ 2
            + this._blocks.reduce((sum, block) => sum + block.serializedSize, 0);
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async verify() {
        // For performance reasons, we DO NOT VERIFY the validity of the blocks in the chain here.
        // Block validity is checked by the Nano/LightChain upon receipt of a ChainProof.

        // Check that all blocks in the chain are valid successors of one another.
        for (let i = this._blocks.length - 1; i >= 1; i--) {
            if ((i % 100) === 99) await EventLoopHelper.webYield();
            if (!(await this._blocks[i].isSuccessorOf(this._blocks[i - 1]))) { // eslint-disable-line no-await-in-loop
                return false;
            }
        }

        // Everything checks out.
        return true;
    }

    /**
     * @returns {Array.<Block>}
     */
    denseSuffix() {
        // Compute the dense suffix.
        const denseSuffix = [this.head];
        let denseSuffixHead = this.head;
        for (let i = this.length - 2; i >= 0; i--) {
            const block = this.blocks[i];
            const hash = block.hash();
            if (!hash.equals(denseSuffixHead.prevHash)) {
                break;
            }

            denseSuffix.push(block);
            denseSuffixHead = block;
        }
        denseSuffix.reverse();
        return denseSuffix;
    }

    /**
     * @returns {Promise.<Array.<BlockChain>>}
     */
    async getSuperChains() {
        if (!this._chains) {
            this._chains = [];
            for (let i = 0; i < this.length; i++) {
                const block = this.blocks[i];
                const depth = BlockUtils.getHashDepth(await block.pow());

                if (this._chains[depth]) {
                    this._chains[depth].blocks.push(block);
                } else if (!this._chains[depth]) {
                    this._chains[depth] = new BlockChain([block]);
                }

                for (let j = depth - 1; j >= 0; j--) {
                    if (this._chains[j]) {
                        this._chains[j].blocks.push(block);
                    }
                }
            }

            for (let i = 0; i < this._chains.length; i++) {
                if (!this._chains[i]) {
                    this._chains[i] = new BlockChain([]);
                }
            }
        }
        return this._chains;
    }

    /**
     * @returns {boolean}
     */
    isAnchored() {
        return GenesisConfig.GENESIS_HASH.equals(this.tail.hash());
    }

    /**
     * @returns {string}
     */
    toString() {
        return `BlockChain{length=${this.length}}`;
    }

    /** @type {number} */
    get length() {
        return this._blocks.length;
    }

    /** @type {Array.<Block>} */
    get blocks() {
        return this._blocks;
    }

    /** @type {Block} */
    get head() {
        return this._blocks[this.length - 1];
    }

    /** @type {Block} */
    get tail() {
        return this._blocks[0];
    }

    /**
     * @returns {number}
     */
    totalDifficulty() {
        return this._blocks.reduce((sum, block) => sum + BlockUtils.targetToDifficulty(block.target), 0);
    }
}
Class.register(BlockChain);

class BlockProducer {

    constructor(blockchain, accounts, mempool, time) {
        /** @type {BaseChain} */
        this._blockchain = blockchain;
        /** @type {Accounts} */
        this._accounts = accounts;
        /** @type {Mempool} */
        this._mempool = mempool;
        /** @type {Time} */
        this._time = time;
    }


    /**
     * @param {Address} address
     * @param {Uint8Array} [extraData]
     * @return {Promise.<Block>}
     */
    async getNextBlock(address, extraData = new Uint8Array(0)) {
        const nextTarget = await this._blockchain.getNextTarget();
        const interlink = await this._getNextInterlink(nextTarget);
        const body = await this._getNextBody(interlink.serializedSize, address, extraData);
        const header = await this._getNextHeader(nextTarget, interlink, body);
        if (!(await this._blockchain.getNextTarget()).equals(nextTarget)) return this.getNextBlock(address, extraData);
        return new Block(header, interlink, body);
    }

    /**
     * @param {BigNumber} nextTarget
     * @param {BlockInterlink} interlink
     * @param {BlockBody} body
     * @return {Promise.<BlockHeader>}
     * @package
     */
    async _getNextHeader(nextTarget, interlink, body) {
        const prevHash = this._blockchain.headHash;
        const interlinkHash = interlink.hash();
        const height = this._blockchain.height + 1;

        // Compute next accountsHash.
        const accounts = await this._accounts.transaction();
        let accountsHash;
        try {
            await accounts.commitBlockBody(body, height, this._blockchain.transactionCache);
            accountsHash = await accounts.hash();
        } catch (e) {
            throw new Error(`Invalid block body: ${e.message}`);
        } finally {
            await accounts.abort();
        }

        const bodyHash = body.hash();
        const timestamp = this._getNextTimestamp();
        const nBits = BlockUtils.targetToCompact(nextTarget);
        const nonce = 0;
        return new BlockHeader(prevHash, interlinkHash, bodyHash, accountsHash, nBits, height, timestamp, nonce);
    }

    /**
     * @param {BigNumber} nextTarget
     * @returns {Promise.<BlockInterlink>}
     * @package
     */
    _getNextInterlink(nextTarget) {
        return this._blockchain.head.getNextInterlink(nextTarget);
    }

    /**
     * @param {number} interlinkSize
     * @param {Address} address
     * @param {Uint8Array} extraData
     * @return {BlockBody}
     * @package
     */
    async _getNextBody(interlinkSize, address, extraData) {
        const maxSize = Policy.BLOCK_SIZE_MAX
            - BlockHeader.SERIALIZED_SIZE
            - interlinkSize
            - BlockBody.getMetadataSize(extraData);
        const transactions = await this._mempool.getTransactionsForBlock(maxSize);
        const prunedAccounts = await this._accounts.gatherToBePrunedAccounts(transactions, this._blockchain.height + 1, this._blockchain.transactionCache);
        return new BlockBody(address, transactions, extraData, prunedAccounts);
    }

    /**
     * @return {number}
     * @package
     */
    _getNextTimestamp() {
        const now = Math.floor(this._time.now() / 1000);
        return Math.max(now, this._blockchain.head.timestamp + 1);
    }

}

Class.register(BlockProducer);

class HeaderChain {
    /**
     * @param {Array.<BlockHeader>} headers
     */
    constructor(headers) {
        if (!headers || !Array.isArray(headers) || !NumberUtils.isUint16(headers.length)
            || headers.some(it => !(it instanceof BlockHeader))) throw new Error('Malformed headers');

        /** @type {Array.<BlockHeader>} */
        this._headers = headers;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {HeaderChain}
     */
    static unserialize(buf) {
        const count = buf.readUint16();
        const headers = [];
        for (let i = 0; i < count; i++) {
            headers.push(BlockHeader.unserialize(buf));
        }
        return new HeaderChain(headers);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint16(this._headers.length);
        for (const header of this._headers) {
            header.serialize(buf);
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*count*/ 2
            + this._headers.reduce((sum, header) => sum + header.serializedSize, 0);
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async verify() {
        // For performance reasons, we DO NOT VERIFY the validity of the blocks in the chain here.
        // Block validity is checked by the Nano/LightChain upon receipt of a ChainProof.

        // Check that all headers in the chain are valid successors of one another.
        for (let i = this._headers.length - 1; i >= 1; i--) {
            if (!this._headers[i].isImmediateSuccessorOf(this._headers[i - 1])) {
                return false;
            }
        }

        // Everything checks out.
        return true;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `HeaderChain{length=${this.length}}`;
    }

    /** @type {number} */
    get length() {
        return this._headers.length;
    }

    /** @type {Array.<BlockHeader>} */
    get headers() {
        return this._headers;
    }

    /** @type {BlockHeader} */
    get head() {
        return this._headers[this.length - 1];
    }

    /** @type {BlockHeader} */
    get tail() {
        return this._headers[0];
    }

    /**
     * @returns {BigNumber}
     */
    totalDifficulty() {
        let totalDifficulty = new BigNumber(0);
        for (const header of this._headers) {
            totalDifficulty = totalDifficulty.plus(header.difficulty);
        }
        return totalDifficulty;
    }
}
Class.register(HeaderChain);

class ChainProof {
    /**
     * @param {BlockChain} prefix
     * @param {HeaderChain} suffix
     */
    constructor(prefix, suffix) {
        if (!(prefix instanceof BlockChain) || !prefix.length) throw new Error('Malformed prefix');
        if (!(suffix instanceof HeaderChain)) throw new Error('Malformed suffix');

        /** @type {BlockChain} */
        this._prefix = prefix;
        /** @type {HeaderChain} */
        this._suffix = suffix;
    }

    static unserialize(buf) {
        const prefix = BlockChain.unserialize(buf);
        const suffix = HeaderChain.unserialize(buf);
        return new ChainProof(prefix, suffix);
    }

    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        this._prefix.serialize(buf);
        this._suffix.serialize(buf);
        return buf;
    }

    get serializedSize() {
        return this._prefix.serializedSize
            + this._suffix.serializedSize;
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async verify() {
        // Check that the prefix chain is anchored.
        if (!this._prefix.isAnchored()) {
            return false;
        }

        // Check that both prefix and suffix are valid chains.
        if (!(await this._prefix.verify()) || !(await this._suffix.verify())) {
            return false;
        }

        // Check that the suffix connects to the prefix.
        if (this._suffix.length > 0 && !this._suffix.tail.isImmediateSuccessorOf(this._prefix.head.header)) {
            return false;
        }

        // Verify the block targets where possible.
        if (!this._verifyDifficulty()) {
            return false;
        }

        // Everything checks out.
        return true;
    }

    /**
     * @returns {boolean}
     * @private
     */
    _verifyDifficulty() {
        // Extract the dense suffix of the prefix.
        /** Array.<BlockHeader> */
        const denseSuffix = this.prefix.denseSuffix().map(block => block.header);
        /** Array.<BlockHeader> */
        const denseChain = denseSuffix.concat(this.suffix.headers);

        // Compute totalDifficulty for each block of the dense chain.
        let totalDifficulty = new BigNumber(0);
        const totalDifficulties = [];
        for (let i = 0; i < denseChain.length; i++) {
            totalDifficulty = totalDifficulty.plus(denseChain[i].difficulty);
            totalDifficulties[i] = new BigNumber(totalDifficulty);
        }

        let headIndex = denseChain.length - 2;
        let tailIndex = headIndex - Policy.DIFFICULTY_BLOCK_WINDOW;
        while (tailIndex >= 0 && headIndex >= 0) {
            const headBlock = denseChain[headIndex];
            const tailBlock = denseChain[tailIndex];
            const deltaTotalDifficulty = totalDifficulties[headIndex].minus(totalDifficulties[tailIndex]);
            const target = BlockUtils.getNextTarget(headBlock, tailBlock, deltaTotalDifficulty);
            const nBits = BlockUtils.targetToCompact(target);

            /** @type {BlockHeader} */
            const checkBlock = denseChain[headIndex + 1];
            if (checkBlock.nBits !== nBits) {
                Log.w(ChainProof, `Block target mismatch: expected=${nBits}, got=${checkBlock.nBits}`);
                return false;
            }

            --headIndex;
            if (tailIndex !== 0 || tailBlock.height !== 1) {
                --tailIndex;
            }
        }

        return true;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `ChainProof{prefix=${this._prefix.length}, suffix=${this._suffix.length}, height=${this.head.height}}`;
    }

    /** @type {BlockChain} */
    get prefix() {
        return this._prefix;
    }

    /** @type {HeaderChain} */
    get suffix() {
        return this._suffix;
    }

    /** @type {BlockHeader} */
    get head() {
        return this._suffix.length > 0 ? this._suffix.head : this._prefix.head.header;
    }
}
Class.register(ChainProof);

class ChainData {
    /**
     * @param {Block} block
     * @param {SuperBlockCounts} [superBlockCounts]
     * @returns {Promise.<ChainData>}
     */
    static async initial(block, superBlockCounts) {
        const pow = await block.pow();
        const totalWork = BlockUtils.realDifficulty(pow);

        const depth = BlockUtils.getHashDepth(pow);
        if (superBlockCounts) {
            superBlockCounts = superBlockCounts.copyAndAdd(depth);
        } else {
            superBlockCounts = new SuperBlockCounts();
            superBlockCounts.add(depth);
        }

        return new ChainData(block, block.difficulty, totalWork, superBlockCounts, true);
    }

    /**
     * @param {Block} head
     * @param {BigNumber} totalDifficulty
     * @param {BigNumber} totalWork
     * @param {SuperBlockCounts} superBlockCounts
     * @param {boolean} [onMainChain]
     * @param {Hash} [mainChainSuccessor]
     */
    constructor(head, totalDifficulty, totalWork, superBlockCounts, onMainChain = false, mainChainSuccessor = null) {
        this._head = head;
        this._totalDifficulty = totalDifficulty;
        this._totalWork = totalWork;
        this._superBlockCounts = superBlockCounts;
        this._onMainChain = onMainChain;
        this._mainChainSuccessor = mainChainSuccessor;
        this._height = head.height;
    }

    /**
     * @returns {{_head: SerialBuffer, _totalDifficulty: string, _totalWork: string, _superBlockCounts: Array.<number>, _onMainChain: boolean, _mainChainSuccessor: ?SerialBuffer, _height: number, _pow: SerialBuffer}}
     */
    toObj() {
        Assert.that(this._head.header._pow instanceof Hash, 'Expected cached PoW hash');
        return {
            _head: this._head.toLight().serialize(),
            _totalDifficulty: this._totalDifficulty.toString(),
            _totalWork: this._totalWork.toString(),
            _superBlockCounts: this._superBlockCounts.array,
            _onMainChain: this._onMainChain,
            _mainChainSuccessor: this._mainChainSuccessor ? this._mainChainSuccessor.serialize() : null,
            _height: this._head.height,
            _pow: this._head.header._pow.serialize()
        };
    }

    /**
     * @param {{_head: Uint8Array, _totalDifficulty: string, _totalWork: string, _superBlockCounts: Array.<number>, _onMainChain: boolean, _mainChainSuccessor: ?Uint8Array, _height: number, _pow: Uint8Array}} obj
     * @param {string} [hashBase64]
     * @returns {ChainData}
     */
    static fromObj(obj, hashBase64) {
        if (!obj) return null;
        const head = Block.unserialize(new SerialBuffer(obj._head));
        head.header._pow = Hash.unserialize(new SerialBuffer(obj._pow));
        head.header._hash = hashBase64 ? Hash.fromBase64(hashBase64) : null;
        const superBlockCounts = new SuperBlockCounts(obj._superBlockCounts);
        const successor = obj._mainChainSuccessor ? Hash.unserialize(new SerialBuffer(obj._mainChainSuccessor)) : null;
        return new ChainData(
            head,
            new BigNumber(obj._totalDifficulty),
            new BigNumber(obj._totalWork),
            superBlockCounts,
            obj._onMainChain,
            successor
        );
    }

    /**
     * @returns {ChainData}
     */
    shallowCopy() {
        return new ChainData(this.head.shallowCopy(), this.totalDifficulty, this.totalWork, this.superBlockCounts, this.onMainChain, this.mainChainSuccessor);
    }

    /**
     * @param {Block} block
     * @returns {Promise.<ChainData>}
     */
    async nextChainData(block) {
        Assert.that(this._totalDifficulty > 0);

        const pow = await block.pow();
        const totalDifficulty = this.totalDifficulty.plus(block.difficulty);
        const totalWork = this.totalWork.plus(BlockUtils.realDifficulty(pow));
        const superBlockCounts = this.superBlockCounts.copyAndAdd(BlockUtils.getHashDepth(pow));
        return new ChainData(block, totalDifficulty, totalWork, superBlockCounts);
    }

    /**
     * @param {Block} block
     * @returns {Promise.<ChainData>}
     */
    async previousChainData(block) {
        Assert.that(this._totalDifficulty > 0);

        const pow = await this.head.pow();
        const totalDifficulty = this.totalDifficulty.minus(this.head.difficulty);
        const totalWork = this.totalWork.minus(BlockUtils.realDifficulty(pow));
        const superBlockCounts = this.superBlockCounts.copyAndSubtract(BlockUtils.getHashDepth(pow));
        return new ChainData(block, totalDifficulty, totalWork, superBlockCounts);
    }

    /** @type {Block} */
    get head() {
        return this._head;
    }

    /** @type {BigNumber} */
    get totalDifficulty() {
        return this._totalDifficulty;
    }

    /** @type {BigNumber} */
    get totalWork() {
        return this._totalWork;
    }

    /** @type {SuperBlockCounts} */
    get superBlockCounts() {
        return this._superBlockCounts;
    }

    /** @type {boolean} */
    get onMainChain() {
        return this._onMainChain;
    }

    /** @type {boolean} */
    set onMainChain(onMainChain) {
        this._onMainChain = onMainChain;
    }

    /** @type {Hash} */
    get mainChainSuccessor() {
        return this._mainChainSuccessor;
    }

    /** @type {Hash} */
    set mainChainSuccessor(mainChainSuccessor) {
        this._mainChainSuccessor = mainChainSuccessor;
    }
}
Class.register(ChainData);

class SuperBlockCounts {
    /**
     * @constructor
     * @param {Array.<number>} array
     */
    constructor(array = []) {
        this._arr = array;
    }

    /**
     * @param {number} depth
     */
    add(depth) {
        Assert.that(NumberUtils.isUint8(depth));
        for (let i = 0; i <= depth; i++) {
            this._arr[i] = this.get(i) + 1;
        }
    }

    /**
     * @param {number} depth
     */
    subtract(depth) {
        Assert.that(NumberUtils.isUint8(depth));
        for (let i = 0; i <= depth; i++) {
            this._arr[i]--;
            Assert.that(this._arr[i] >= 0);
        }
    }

    /**
     * @param {number} depth
     * @returns {SuperBlockCounts}
     */
    copyAndAdd(depth) {
        const copy = new SuperBlockCounts(this._arr.slice());
        copy.add(depth);
        return copy;
    }

    /**
     * @param {number} depth
     * @returns {SuperBlockCounts}
     */
    copyAndSubtract(depth) {
        const copy = new SuperBlockCounts(this._arr.slice());
        copy.subtract(depth);
        return copy;
    }

    /**
     * @param {number} depth
     * @returns {number}
     */
    get(depth) {
        Assert.that(NumberUtils.isUint8(depth));
        return this._arr[depth] || 0;
    }

    /**
     * @param {number} m
     * @returns {number}
     */
    getCandidateDepth(m) {
        for (let i = this._arr.length - 1; i >= 0; i--) {
            if (this._arr[i] >= m) {
                return i;
            }
        }
        return 0;
    }

    /** @type {number} */
    get length() {
        return this._arr.length;
    }

    /** @type {Array.<number>} */
    get array() {
        return this._arr;
    }
}
Class.register(SuperBlockCounts);

class ChainDataStore {
    /**
     * @param {JungleDB} jdb
     */
    static initPersistent(jdb) {
        const chainStore = jdb.createObjectStore('ChainData', {
            codec: new ChainDataStoreCodec(),
            enableLruCache: ChainDataStore.CHAINDATA_CACHING_ENABLED,
            lruCacheSize: ChainDataStore.CHAINDATA_CACHE_SIZE
        });
        ChainDataStore._createIndexes(chainStore);

        jdb.createObjectStore('Block', {
            codec: new BlockStoreCodec(),
            enableLruCache: ChainDataStore.BLOCKS_CACHING_ENABLED,
            lruCacheSize: ChainDataStore.BLOCKS_CACHE_SIZE,
            rawLruCacheSize: ChainDataStore.BLOCKS_RAW_CACHE_SIZE
        });
    }

    /**
     * @param {JungleDB} jdb
     * @returns {ChainDataStore}
     */
    static getPersistent(jdb) {
        const chainStore = jdb.getObjectStore('ChainData');
        const blockStore = jdb.getObjectStore('Block');
        return new ChainDataStore(chainStore, blockStore);
    }

    /**
     * @returns {ChainDataStore}
     */
    static createVolatile() {
        const chainStore = JDB.JungleDB.createVolatileObjectStore({ codec: new ChainDataStoreCodec() });
        const blockStore = JDB.JungleDB.createVolatileObjectStore({ codec: new BlockStoreCodec() });
        ChainDataStore._createIndexes(chainStore);
        return new ChainDataStore(chainStore, blockStore);
    }

    /**
     * @param {IObjectStore} chainStore
     * @private
     */
    static _createIndexes(chainStore) {
        chainStore.createIndex('height', ['_height'], { lmdbKeyEncoding: JDB.JungleDB.NUMBER_ENCODING, leveldbKeyEncoding: JDB.JungleDB.NUMBER_ENCODING });
    }

    /**
     * @param {IObjectStore} chainStore
     * @param {IObjectStore} blockStore
     */
    constructor(chainStore, blockStore) {
        /** @type {IObjectStore} */
        this._chainStore = chainStore;
        /** @type {IObjectStore} */
        this._blockStore = blockStore;
    }

    /**
     * @param {Hash} key
     * @param {boolean} [includeBody]
     * @returns {Promise.<?ChainData>}
     */
    async getChainData(key, includeBody = false) {
        /** @type {ChainData} */
        let chainData = await this._chainStore.get(key.toBase64());

        // Do not modify object from store, since it might be cached
        if (chainData) {
            chainData = chainData.shallowCopy();
        }

        if (!chainData || !includeBody) {
            return chainData;
        }

        const block = await this._blockStore.get(key.toBase64());
        if (block && block.isFull()) {
            chainData.head._body = block.body;
        }

        return chainData;
    }

    /**
     * @param {Hash} key
     * @param {ChainData} chainData
     * @param {boolean} [includeBody]
     * @returns {Promise.<void>}
     */
    putChainData(key, chainData, includeBody = true) {
        // Do not modify object from store, since it might be cached
        const cleanChainData = chainData.shallowCopy();
        cleanChainData.head._body = null;

        if (this._chainStore instanceof JDB.Transaction) {
            this._chainStore.putSync(key.toBase64(), cleanChainData);
            if (includeBody && chainData.head.isFull()) {
                this._blockStore.putSync(key.toBase64(), chainData.head);
            }
            return Promise.resolve(true);
        }

        if (includeBody && chainData.head.isFull()) {
            const chainTx = this._chainStore.synchronousTransaction();
            chainTx.putSync(key.toBase64(), cleanChainData);
            const blockTx = this._blockStore.synchronousTransaction();
            blockTx.putSync(key.toBase64(), chainData.head);
            return JDB.JungleDB.commitCombined(chainTx, blockTx);
        }

        return this._chainStore.put(key.toBase64(), cleanChainData);
    }

    /**
     * @param {Hash} key
     * @param {ChainData} chainData
     * @param {boolean} [includeBody]
     * @returns {void}
     */
    putChainDataSync(key, chainData, includeBody = true) {
        // Do not modify object from store, since it might be cached
        const cleanChainData = chainData.shallowCopy();
        cleanChainData.head._body = null;

        Assert.that(this._chainStore instanceof JDB.Transaction);
        this._chainStore.putSync(key.toBase64(), cleanChainData);
        if (includeBody && chainData.head.isFull()) {
            this._blockStore.putSync(key.toBase64(), chainData.head);
        }
    }

    /**
     * @param {Hash} key
     * @returns {void}
     */
    removeChainDataSync(key) {
        Assert.that(this._chainStore instanceof JDB.Transaction);
        this._chainStore.removeSync(key.toBase64());
        this._blockStore.removeSync(key.toBase64());
    }

    /**
     * @param {Hash} key
     * @param {boolean} [includeBody]
     * @returns {?Block}
     */
    async getBlock(key, includeBody = false) {
        if (includeBody) {
            const block = await this._blockStore.get(key.toBase64());
            if (block) {
                return block;
            }
        }

        const chainData = await this._chainStore.get(key.toBase64());
        return chainData ? chainData.head : null;
    }

    /**
     * @param {Hash} key
     * @param {boolean} [includeForks]
     * @returns {Promise.<?Uint8Array>}
     */
    async getRawBlock(key, includeForks = false) {
        /** @type {ChainData} */
        const chainData = await this._chainStore.get(key.toBase64());
        if (!chainData || (!chainData.onMainChain && !includeForks)) {
            return null;
        }

        const block = await this._blockStore.get(key.toBase64(), { raw: true });
        if (block) {
            return new Uint8Array(block);
        }

        return null;
    }

    /**
     * @param {number} height
     * @returns {Promise.<?Array.<ChainData>>}
     */
    async getChainDataCandidatesAt(height) {
        /** @type {Array.<ChainData>} */
        const candidates = await this._chainStore.values(JDB.Query.eq('height', height));
        if (!candidates || !candidates.length) {
            return undefined;
        }
        return candidates;
    }

    /**
     * @param {number} height
     * @param {boolean} [includeBody]
     * @returns {Promise.<?ChainData>}
     */
    async getChainDataAt(height, includeBody = false) {
        /** @type {Array.<ChainData>} */
        const candidates = await this.getChainDataCandidatesAt(height);
        if (!candidates) {
            return undefined;
        }

        for (const chainData of candidates) {
            if (chainData.onMainChain) {
                // Do not modify object from store, since it might be cached
                const finalChainData = chainData.shallowCopy();
                if (includeBody) {
                    // eslint-disable-next-line no-await-in-loop
                    const block = await this._blockStore.get(chainData.head.hash().toBase64());
                    if (block) {
                        finalChainData.head._body = block.body;
                    }
                }
                return finalChainData;
            }
        }

        return null;
    }

    /**
     * @param {number} height
     * @param {boolean} [includeBody]
     * @returns {Promise.<?Block>}
     */
    async getBlockAt(height, includeBody = false) {
        const chainData = await this.getChainDataAt(height, includeBody);
        return chainData ? chainData.head : null;
    }

    /**
     * @param {Block} block
     * @returns {Promise<Array.<Block>>}
     */
    async getSuccessorBlocks(block) {
        const candidates = await this.getChainDataCandidatesAt(block.height + 1);
        if (!candidates) {
            return [];
        }
        const res = [];
        for (const chainData of candidates) {
            if (chainData.head.prevHash.equals(block.hash())) {
                res.push(chainData.head);
            }
        }
        return res;
    }

    /**
     * @param {number} height
     * @param {boolean} [lower]
     * @returns {Promise.<?Block>}
     */
    async getNearestBlockAt(height, lower = true) {
        const index = this._chainStore.index('height');
        /** @type {Array.<ChainData>} */
        const candidates = lower ?
            await index.maxValues(JDB.KeyRange.upperBound(height)) :
            await index.minValues(JDB.KeyRange.lowerBound(height));
        if (!candidates || !candidates.length) {
            return undefined;
        }

        for (const chainData of candidates) {
            if (chainData.onMainChain) {
                return chainData.head;
            }
        }

        return null;
    }

    /**
     * @param {Hash} startBlockHash
     * @param {number} [count]
     * @param {boolean} [forward]
     * @returns {Promise.<Array.<Block>>}
     */
    getBlocks(startBlockHash, count = 500, forward = true) {
        if (count <= 0) {
            return Promise.resolve([]);
        }

        if (forward) {
            return this.getBlocksForward(startBlockHash, count);
        } else {
            return this.getBlocksBackward(startBlockHash, count);
        }
    }

    /**
     * @param {Hash} startBlockHash
     * @param {number} count
     * @returns {Promise.<Array.<Block>>}
     */
    async getBlocksForward(startBlockHash, count = 500) {
        /** @type {ChainData} */
        let chainData = await this._chainStore.get(startBlockHash.toBase64());
        if (!chainData) {
            return [];
        }

        const blocks = [];
        while (blocks.length < count && chainData.mainChainSuccessor) {
            chainData = await this._chainStore.get(chainData.mainChainSuccessor.toBase64());
            if (!chainData) {
                return blocks;
            }
            blocks.push(chainData.head);
        }
        return blocks;
    }

    /**
     * @param {Hash} startBlockHash
     * @param {number} count
     * @param {boolean} includeBody
     * @returns {Promise.<Array.<Block>>}
     */
    async getBlocksBackward(startBlockHash, count = 500, includeBody = false) {
        const getBlock = includeBody
            ? key => this._blockStore.get(key)
            : key => this._chainStore.get(key).then(data => data.head);

        /** @type {ChainData} */
        const chainData = await this._chainStore.get(startBlockHash.toBase64());
        if (!chainData) {
            return [];
        }

        /** @type {Block} */
        let block = chainData.head;
        const blocks = [];
        while (blocks.length < count && block.height > 1) {
            block = await getBlock(block.prevHash.toBase64());
            if (!block) {
                return blocks;
            }
            blocks.push(block);
        }
        return blocks;
    }

    /**
     * @returns {Promise.<Hash|undefined>}
     */
    async getHead() {
        const key = await this._chainStore.get('main');
        return key ? Hash.fromBase64(key) : undefined;
    }

    /**
     * @param {Hash} key
     * @returns {Promise.<void>}
     */
    setHead(key) {
        return this._chainStore.put('main', key.toBase64());
    }

    /**
     * @param {Hash} key
     * @returns {void}
     */
    setHeadSync(key) {
        Assert.that(this._chainStore instanceof JDB.SynchronousTransaction);
        this._chainStore.putSync('main', key.toBase64());
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {ChainDataStore}
     */
    transaction(enableWatchdog = true) {
        const chainTx = this._chainStore.transaction(enableWatchdog);
        const blockTx = this._blockStore.transaction(enableWatchdog);
        return new ChainDataStore(chainTx, blockTx);
    }

    /**
     * @param {boolean} [enableWatchdog]
     * @returns {ChainDataStore}
     */
    synchronousTransaction(enableWatchdog = true) {
        const chainTx = this._chainStore.synchronousTransaction(enableWatchdog);
        const blockTx = this._blockStore.synchronousTransaction(enableWatchdog);
        return new ChainDataStore(chainTx, blockTx);
    }

    /**
     * @returns {Promise}
     */
    commit() {
        if (this._chainStore instanceof JDB.Transaction) {
            return JDB.JungleDB.commitCombined(this._chainStore, this._blockStore);
        }
        return Promise.resolve();
    }

    /**
     * @returns {Promise}
     */
    abort() {
        return Promise.all([this._chainStore.abort(), this._blockStore.abort()]);
    }

    /**
     * @returns {ChainDataStore}
     */
    snapshot() {
        const chainSnapshot = this._chainStore.snapshot();
        const blockSnapshot = this._blockStore.snapshot();
        return new ChainDataStore(chainSnapshot, blockSnapshot);
    }

    /**
     * @returns {Promise}
     */
    truncate() {
        if (this._chainStore instanceof JDB.Transaction) {
            this._chainStore.truncateSync();
            this._blockStore.truncateSync();
            return Promise.resolve(true);
        }

        const chainTx = this._chainStore.transaction();
        chainTx.truncateSync();
        const blockTx = this._blockStore.transaction();
        blockTx.truncateSync();
        return JDB.JungleDB.commitCombined(chainTx, blockTx);
    }

    /** @type {Array.<JDB.Transaction>} */
    get txs() {
        if (this._chainStore instanceof JDB.Transaction) {
            return [this._chainStore, this._blockStore];
        }
        return [];
    }
}
ChainDataStore.CHAINDATA_CACHING_ENABLED = true;
ChainDataStore.CHAINDATA_CACHE_SIZE = 5000;
ChainDataStore.BLOCKS_CACHING_ENABLED = true;
ChainDataStore.BLOCKS_CACHE_SIZE = 0;
ChainDataStore.BLOCKS_RAW_CACHE_SIZE = 500;
Class.register(ChainDataStore);

/**
 * @implements {ICodec}
 */
class ChainDataStoreCodec {
    /**
     * @param {*} obj The object to encode before storing it.
     * @returns {*} Encoded object.
     */
    encode(obj) {
        return typeof obj === 'string' ? obj : obj.toObj();
    }

    /**
     * @param {*} obj The object to decode.
     * @param {string} key The object's primary key.
     * @returns {*} Decoded object.
     */
    decode(obj, key) {
        return typeof obj === 'string' ? obj : ChainData.fromObj(obj, key);
    }

    /**
     * @type {{encode: function(val:*):*, decode: function(val:*):*, buffer: boolean, type: string}|void}
     */
    get valueEncoding() {
        return JDB.JungleDB.JSON_ENCODING;
    }
}

/**
 * @implements {ICodec}
 */
class BlockStoreCodec {
    /**
     * @param {*} obj The object to encode before storing it.
     * @returns {*} Encoded object.
     */
    encode(obj) {
        return obj.serialize();
    }

    /**
     * @param {*} obj The object to decode.
     * @param {string} key The object's primary key.
     * @returns {*} Decoded object.
     */
    decode(obj, key) {
        const block = Block.unserialize(new SerialBuffer(obj));
        block.header._hash = Hash.fromBase64(key);
        return block;
    }

    /**
     * @type {{encode: function(val:*):*, decode: function(val:*):*, buffer: boolean, type: string}|void}
     */
    get valueEncoding() {
        return JDB.JungleDB.BINARY_ENCODING;
    }
}

class MempoolTransactionSet {
    /**
     * @param {Array.<Transaction>} [sortedTransactions]
     */
    constructor(sortedTransactions) {
        // Sorted descending by fee per byte
        /** @type {SortedList.<Transaction>} */
        this._transactions = new SortedList(sortedTransactions);
    }

    /**
     * @param {Transaction} transaction
     * @return {MempoolTransactionSet}
     */
    add(transaction) {
        this._transactions.add(transaction);
        return this;
    }

    /**
     * @param {Transaction} transaction
     * @return {MempoolTransactionSet}
     */
    remove(transaction) {
        this._transactions.remove(transaction);
        return this;
    }

    /**
     * @param {Transaction} transaction
     * @return {MempoolTransactionSet}
     */
    copyAndAdd(transaction) {
        const transactions = this._transactions.copy();
        transactions.add(transaction);
        return new MempoolTransactionSet(transactions.values());
    }

    /** @type {Array.<Transaction>} */
    get transactions() {
        return this._transactions.values();
    }

    /** @type {Address} */
    get sender() {
        return this._transactions.length > 0 ? this._transactions.values()[0].sender : null;
    }

    /** @type {?Account.Type} */
    get senderType() {
        return this._transactions.length > 0 ? this._transactions.values()[0].senderType : undefined;
    }

    /** @type {number} */
    get length() {
        return this._transactions.length;
    }

    /**
     * @param {number} feePerByte
     * @return {number}
     */
    numBelowFeePerByte(feePerByte) {
        let count = 0;
        // TODO optimise, since we know it is sorted
        for (const t of this._transactions) {
            if (t.feePerByte < feePerByte) {
                count++;
            }
        }
        return count;
    }

    toString() {
        return `MempoolTransactionSet{length=${this.length}}`;
    }
}

Class.register(MempoolTransactionSet);

class MempoolFilter {
    constructor() {
        this._blacklist = new LimitInclusionHashSet(MempoolFilter.BLACKLIST_SIZE);
    }

    /**
     * @param {Transaction} tx
     * @returns {boolean}
     */
    acceptsTransaction(tx) {
        return tx.fee >= MempoolFilter.FEE
            && tx.value >= MempoolFilter.VALUE
            && tx.value + tx.fee >= MempoolFilter.TOTAL_VALUE
            && (
                !tx.hasFlag(Transaction.Flag.CONTRACT_CREATION)
                || (
                    tx.fee >= MempoolFilter.CONTRACT_FEE
                    && tx.feePerByte >= MempoolFilter.CONTRACT_FEE_PER_BYTE
                    && tx.value >= MempoolFilter.CONTRACT_VALUE
                )
            );
    }

    /**
     * @param {Transaction} tx
     * @param {Account} oldAccount
     * @param {Account} newAccount
     * @returns {boolean}
     */
    acceptsRecipientAccount(tx, oldAccount, newAccount) {
        return newAccount.balance >= MempoolFilter.RECIPIENT_BALANCE
            && (
                !oldAccount.isInitial()
                || (
                    tx.fee >= MempoolFilter.CREATION_FEE
                    && tx.feePerByte >= MempoolFilter.CREATION_FEE_PER_BYTE
                    && tx.value >= MempoolFilter.CREATION_VALUE
                )
            );
    }

    /**
     * @param {Transaction} tx
     * @param {Account} oldAccount
     * @param {Account} newAccount
     * @returns {boolean}
     */
    acceptsSenderAccount(tx, oldAccount, newAccount) {
        return newAccount.balance >= MempoolFilter.SENDER_BALANCE
            || newAccount.isInitial()
            || newAccount.isToBePruned();
    }

    /**
     * @param {Hash} hash
     */
    blacklist(hash) {
        this._blacklist.add(hash);
    }

    /**
     * @param {Hash} hash
     * @returns {boolean}
     */
    isBlacklisted(hash) {
        return this._blacklist.contains(hash);
    }
}
MempoolFilter.BLACKLIST_SIZE = 25000;

MempoolFilter.FEE = 0;
MempoolFilter.VALUE = 0;
MempoolFilter.TOTAL_VALUE = 0;
MempoolFilter.RECIPIENT_BALANCE = 0;
MempoolFilter.SENDER_BALANCE = 0;
MempoolFilter.CREATION_FEE = 0;
MempoolFilter.CREATION_FEE_PER_BYTE = 0;
MempoolFilter.CREATION_VALUE = 0;
MempoolFilter.CONTRACT_FEE = 0;
MempoolFilter.CONTRACT_FEE_PER_BYTE = 0;
MempoolFilter.CONTRACT_VALUE = 0;

Class.register(MempoolFilter);

class Mempool extends Observable {
    /**
     * @param {IBlockchain} blockchain
     * @param {Accounts} accounts
     */
    constructor(blockchain, accounts) {
        super();
        /** @type {IBlockchain} */
        this._blockchain = blockchain;
        /** @type {Accounts} */
        this._accounts = accounts;

        // Our pool of transactions.
        /** @type {SortedList.<Transaction>} */
        this._transactionsByFeePerByte = new SortedList(); // uses Transaction.compare, by fee descending
        /** @type {HashMap.<Hash, Transaction>} */
        this._transactionsByHash = new HashMap();
        /** @type {HashMap.<Address, MempoolTransactionSet>} */
        this._transactionSetBySender = new HashMap();
        /** @type {HashMap.<Address, HashSet.<Hash>>} */
        this._transactionSetByRecipient = new HashMap();
        /** @type {MempoolFilter} */
        this._filter = new MempoolFilter();
        /** @type {Synchronizer} */
        this._synchronizer = new Synchronizer();

        // Listen for changes in the blockchain head to evict transactions that have become invalid.
        blockchain.on('head-changed', (block, rebranching) => {
            if (!rebranching) {
                this._evictTransactions().catch(Log.e.tag(Mempool));
            }
        });
        blockchain.on('rebranched', async (revertBlocks) => {
            await this._evictTransactions();
            await this._restoreTransactions(revertBlocks);
        });
    }

    /**
     * @param {Transaction} transaction
     * @fires Mempool#transaction-added
     * @returns {Promise.<Mempool.ReturnCode>}
     */
    pushTransaction(transaction) {
        return this._synchronizer.push(() => this._pushTransaction(transaction));
    }

    /**
     * @param {Transaction} transaction
     * @returns {Promise.<Mempool.ReturnCode>}
     * @private
     */
    async _pushTransaction(transaction) {
        // Check if we already know this transaction.
        const hash = transaction.hash();
        if (this._transactionsByHash.contains(hash)) {
            return Mempool.ReturnCode.KNOWN;
        }

        // Check transaction against filter rules.
        if (!this._filter.acceptsTransaction(transaction)) {
            this._filter.blacklist(hash);
            return Mempool.ReturnCode.FILTERED;
        }

        // Check limit for free transactions.
        const set = this._transactionSetBySender.get(transaction.sender) || new MempoolTransactionSet();
        if (transaction.fee / transaction.serializedSize < Mempool.TRANSACTION_RELAY_FEE_MIN
            && set.numBelowFeePerByte(Mempool.TRANSACTION_RELAY_FEE_MIN) >= Mempool.FREE_TRANSACTIONS_PER_SENDER_MAX) {
            return Mempool.ReturnCode.FEE_TOO_LOW;
        }

        // Intrinsic transaction verification
        if (!transaction.verify()) {
            return Mempool.ReturnCode.INVALID;
        }

        // Retrieve recipient account and test incoming transaction.
        /** @type {Account} */
        try {
            const recipientAccount = await this._accounts.get(transaction.recipient);
            const newRecipientAccount = recipientAccount.withIncomingTransaction(transaction, this._blockchain.height + 1);

            // Check recipient account against filter rules.
            if (!this._filter.acceptsRecipientAccount(transaction, recipientAccount, newRecipientAccount)) {
                this._filter.blacklist(hash);
                return Mempool.ReturnCode.FILTERED;
            }
        } catch (e) {
            Log.d(Mempool, () => `Rejected transaction ${hash.toHex()} from ${transaction.sender.toUserFriendlyAddress()} - ${e.message}`);
            return Mempool.ReturnCode.INVALID;
        }

        // Retrieve sender account.
        /** @type {Account} */
        let senderAccount;
        try {
            senderAccount = await this._accounts.get(transaction.sender, transaction.senderType);
        } catch (e) {
            Log.d(Mempool, () => `Rejected transaction ${hash.toHex()} from ${transaction.sender.toUserFriendlyAddress()} - ${e.message}`);
            return Mempool.ReturnCode.INVALID;
        }

        // Add new transaction to the sender's pending transaction set. Then re-check all transactions in the set
        // in fee/byte order against the sender account state. Adding high fee transactions may thus invalidate
        // low fee transactions in the set.
        const transactions = [];
        const txsToRemove = [];
        let tmpAccount = senderAccount;
        for (const tx of set.copyAndAdd(transaction).transactions) {
            let error = 'transactions per sender exceeded';
            let exception;
            try {
                if (transactions.length < Mempool.TRANSACTIONS_PER_SENDER_MAX) {
                    tmpAccount = tmpAccount.withOutgoingTransaction(tx, this._blockchain.height + 1, this._blockchain.transactionCache);
                    transactions.push(tx);

                    // Transaction ok, move to next one.
                    continue;
                }
            } catch (e) {
                exception = e;
                error = e.message;
            }

            // An error occurred processing this transaction.
            // If the rejected transaction is the one we're pushing, fail.
            // Otherwise, evict the rejected transaction from the mempool.
            if (tx.equals(transaction)) {
                Log.d(Mempool, () => `Rejected transaction from ${transaction.sender.toUserFriendlyAddress()} - ${error}`);
                if (exception instanceof Account.DoubleTransactionError) {
                    return Mempool.ReturnCode.MINED;
                } else if (exception instanceof Account.ValidityError) {
                    return Mempool.ReturnCode.EXPIRED;
                } else {
                    return Mempool.ReturnCode.INVALID;
                }
            } else {
                txsToRemove.push(tx);
            }
        }

        // Check sender account against filter rules.
        if (!this._filter.acceptsSenderAccount(transaction, senderAccount, tmpAccount)) {
            this._filter.blacklist(hash);
            return Mempool.ReturnCode.FILTERED;
        }

        // Remove invalidated transactions.
        for (const tx of txsToRemove) {
            this._removeTransaction(tx);
        }

        // Transaction is valid, add it to the mempool.
        this._transactionsByFeePerByte.add(transaction);
        this._transactionsByHash.put(hash, transaction);
        this._transactionSetBySender.put(transaction.sender, new MempoolTransactionSet(transactions));
        /** @type {HashSet.<Hash>} */
        const byRecipient = this._transactionSetByRecipient.get(transaction.recipient) || new HashSet();
        byRecipient.add(transaction.hash());
        this._transactionSetByRecipient.put(transaction.recipient, byRecipient);

        // Tell listeners about the new valid transaction we received.
        this.fire('transaction-added', transaction);

        if (this._transactionsByFeePerByte.length > Mempool.SIZE_MAX) {
            this._popLowFeeTransaction();
        }

        return Mempool.ReturnCode.ACCEPTED;
    }

    /**
     * @private
     */
    _popLowFeeTransaction() {
        // Remove transaction
        const transaction = this._transactionsByFeePerByte.pop();

        /** @type {MempoolTransactionSet} */
        const set = this._transactionSetBySender.get(transaction.sender);
        set.remove(transaction);
        if (set.length === 0) this._transactionSetBySender.remove(transaction.sender);

        /** @type {HashSet.<Hash>} */
        const byRecipient = this._transactionSetByRecipient.get(transaction.recipient);
        if (byRecipient) {
            if (byRecipient.length === 1) {
                this._transactionSetByRecipient.remove(transaction.recipient);
            } else {
                byRecipient.remove(transaction.hash());
            }
        } else {
            Log.e(Mempool, `Invalid state: no transactionsByRecipient for ${transaction}`);
        }

        this._transactionsByHash.remove(transaction.hash());
        this.fire('transaction-removed', transaction);
    }

    /**
     * Does *not* remove transaction from transactionsBySender!
     * @param {Transaction} transaction
     * @private
     */
    _removeTransaction(transaction) {
        this._transactionsByHash.remove(transaction.hash());

        // TODO: Optimise remove from this._transactionsByMinFee.
        this._transactionsByFeePerByte.remove(transaction);

        /** @type {HashSet.<Hash>} */
        const byRecipient = this._transactionSetByRecipient.get(transaction.recipient);
        if (byRecipient) {
            if (byRecipient.length === 1) {
                this._transactionSetByRecipient.remove(transaction.recipient);
            } else {
                byRecipient.remove(transaction.hash());
            }
            this.fire('transaction-removed', transaction);
        } else {
            Log.e(Mempool, `Invalid state: no transactionsByRecipient for ${transaction}`);
        }
    }

    /**
     * @param {Hash} hash
     * @returns {Transaction}
     */
    getTransaction(hash) {
        return this._transactionsByHash.get(hash);
    }

    /**
     * @param {number} [maxSize]
     * @param {number} [minFeePerByte]
     * @yields {IterableIterator.<Transaction>}
     */
    *transactionGenerator(maxSize = Infinity, minFeePerByte = 0) {
        let size = 0;
        for (const /** @type {Transaction} */ tx of this._transactionsByFeePerByte) {
            const txSize = tx.serializedSize;
            if (size + txSize >= maxSize) continue;
            if (tx.feePerByte < minFeePerByte) break;

            yield tx;
            size += txSize;
        }
    }

    /**
     * @param {number} [maxSize]
     * @param {number} [minFeePerByte]
     * @returns {Array.<Transaction>}
     */
    getTransactions(maxSize = Infinity, minFeePerByte = 0) {
        return Array.from(this.transactionGenerator(maxSize, minFeePerByte));
    }

    /**
     * @param {number} maxSize
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getTransactionsForBlock(maxSize) {
        const transactions = this.getTransactions(maxSize);
        const prunedAccounts = await this._accounts.gatherToBePrunedAccounts(transactions, this._blockchain.height + 1, this._blockchain.transactionCache);
        const prunedAccountsSize = prunedAccounts.reduce((sum, acc) => sum + acc.serializedSize, 0);

        let size = prunedAccountsSize + transactions.reduce((sum, tx) => sum + tx.serializedSize, 0);
        while (size > maxSize) {
            size -= transactions.pop().serializedSize;
        }

        transactions.sort((a, b) => a.compareBlockOrder(b));
        return transactions;
    }

    /**
     * @param {Address} address
     * @return {Array.<Transaction>}
     */
    getPendingTransactions(address) {
        return this.getTransactionsBySender(address);
    }

    /**
     * @param {Address} address
     * @return {Array.<Transaction>}
     */
    getTransactionsBySender(address) {
        /** @type {MempoolTransactionSet} */
        const set = this._transactionSetBySender.get(address);
        return set ? set.transactions : [];
    }

    /**
     * @param {Address} address
     * @return {Array.<Transaction>}
     */
    getTransactionsByRecipient(address) {
        /** @type {HashSet.<Hash>} */
        const set = this._transactionSetByRecipient.get(address);
        if (!set) {
            return [];
        }

        /** @type {Array.<Transaction>} */
        const transactions = [];
        for (const hash of set.valueIterator()) {
            const tx = this._transactionsByHash.get(hash);
            Assert.that(!!tx);
            transactions.push(tx);
        }
        return transactions;
    }

    /**
     * @param {Array.<Address>} addresses
     * @param {number} [maxTransactions]
     * @return {Array.<Transaction>}
     */
    getTransactionsByAddresses(addresses, maxTransactions = Infinity) {
        const transactions = [];
        for (const address of addresses) {
            // Fetch transactions by sender first
            /** @type {Array.<Transaction>} */
            const bySender = this.getTransactionsBySender(address);
            for (const tx of bySender) {
                if (transactions.length >= maxTransactions) return transactions;
                transactions.push(tx);
            }

            // Fetch transactions by recipient second
            /** @type {Array.<Transaction>} */
            const byRecipient = this.getTransactionsByRecipient(address);
            for (const tx of byRecipient) {
                if (transactions.length >= maxTransactions) return transactions;
                transactions.push(tx);
            }
        }
        return transactions;
    }

    /**
     * @param {number} minFeePerByte
     */
    evictBelowMinFeePerByte(minFeePerByte) {
        /** @type {Transaction} */
        let transaction = this._transactionsByFeePerByte.peekLast();
        while (transaction && transaction.feePerByte < minFeePerByte) {
            this._transactionsByFeePerByte.pop();

            this._transactionsByHash.remove(transaction.hash());

            /** @type {MempoolTransactionSet} */
            const bySender = this._transactionSetBySender.get(transaction.sender);
            if (bySender.length === 1) {
                this._transactionSetBySender.remove(transaction.sender);
            } else {
                bySender.remove(transaction);
            }
            /** @type {HashSet.<Hash>} */
            const byRecipient = this._transactionSetByRecipient.get(transaction.recipient);
            if (byRecipient.length === 1) {
                this._transactionSetByRecipient.remove(transaction.recipient);
            } else {
                byRecipient.remove(transaction.hash());
            }

            transaction = this._transactionsByFeePerByte.peekLast();
        }
    }

    /**
     * @param {Hash} txHash
     * @returns {boolean}
     */
    isFiltered(txHash) {
        return this._filter.isBlacklisted(txHash);
    }

    /**
     * @param {Array.<Block>} blocks
     * @returns {Promise}
     * @private
     */
    _restoreTransactions(blocks) {
        return this._synchronizer.push(async () => {
            for (let i = blocks.length - 1; i >= 0; i--) {
                for (const tx of blocks[i].transactions) {
                    await this._pushTransaction(tx); // eslint-disable-line no-await-in-loop
                }
            }
        });
    }

    /**
     * @fires Mempool#transactions-ready
     * @returns {Promise}
     * @private
     */
    _evictTransactions() {
        return this._synchronizer.push(() => this.__evictTransactions());
    }

    /**
     * @fires Mempool#transactions-ready
     * @returns {Promise}
     * @private
     */
    async __evictTransactions() {
        // Evict all transactions from the pool that have become invalid due
        // to changes in the account state (i.e. typically because the were included
        // in a newly mined block). No need to re-check signatures.
        for (const sender of this._transactionSetBySender.keys()) {
            /** @type {MempoolTransactionSet} */
            const set = this._transactionSetBySender.get(sender);

            try {
                const senderAccount = await this._accounts.get(set.sender, set.senderType);

                // If a transaction in the set is not valid anymore,
                // we try to construct a new set based on the heuristic of including
                // high fee/byte transactions first.
                const transactions = [];
                let account = senderAccount;
                for (const tx of set.transactions) {
                    try {
                        const tmpAccount = account.withOutgoingTransaction(tx, this._blockchain.height + 1, this._blockchain.transactionCache);

                        const recipientAccount = await this._accounts.get(tx.recipient);
                        recipientAccount.withIncomingTransaction(tx, this._blockchain.height + 1);

                        transactions.push(tx);
                        account = tmpAccount;
                    } catch (e) {
                        // Remove transaction
                        this._removeTransaction(tx);
                    }
                }
                if (transactions.length === 0) {
                    this._transactionSetBySender.remove(sender);
                } else {
                    this._transactionSetBySender.put(sender, new MempoolTransactionSet(transactions));
                }
            } catch (e) {
                // In case of an error, remove all transactions of this set.
                for (const tx of set.transactions) {
                    this._removeTransaction(tx);
                }
                this._transactionSetBySender.remove(sender);
            }
        }

        // Tell listeners that the pool has updated after a blockchain head change.
        /**
         * @event Mempool#transactions-ready
         */
        this.fire('transactions-ready');
    }

    /** @type {number} */
    get length() {
        return this._transactionsByHash.length;
    }

    /** @type {Synchronizer} */
    get queue() {
        return this._synchronizer;
    }
}

/**
 * Fee threshold in sat/byte below which transactions are considered "free".
 * @type {number}
 */
Mempool.TRANSACTION_RELAY_FEE_MIN = 1;
/**
 * Maximum number of transactions per sender.
 * @type {number}
 */
Mempool.TRANSACTIONS_PER_SENDER_MAX = 500;
/**
 * Maximum number of "free" transactions per sender.
 * @type {number}
 */
Mempool.FREE_TRANSACTIONS_PER_SENDER_MAX = 10;
/**
 * Maximum number of transactions in the mempool.
 * @type {number}
 */
Mempool.SIZE_MAX = 50000;

/** @enum {number} */
Mempool.ReturnCode = {
    EXPIRED: -5,
    MINED: -4,
    FILTERED: -3,
    FEE_TOO_LOW: -2,
    INVALID: -1,

    ACCEPTED: 1,
    KNOWN: 2
};

Class.register(Mempool);

class InvRequestManager {
    constructor() {
        /** @type {HashMap.<InvVector, {current: BaseConsensusAgent, waiting: Set.<BaseConsensusAgent>}>} */
        this._vectorsToRequest = new HashMap();
        /** @type {Timers} */
        this._timers = new Timers();
    }

    /**
     * @param {BaseConsensusAgent} agent
     * @param {InvVector} vector
     */
    askToRequestVector(agent, vector) {
        if (agent.syncing || this._vectorsToRequest.length > InvRequestManager.MAX_INV_MANAGED) {
            agent.requestVector(vector);
            return;
        }
        if (this._vectorsToRequest.contains(vector)) {
            const o = this._vectorsToRequest.get(vector);
            if (o.current.peer.channel.closed) {
                o.current = null;
            }
            if (o.current === null) {
                o.current = agent;
                this._request(vector);
            } else {
                o.waiting.add(agent);
            }
        } else {
            this._vectorsToRequest.put(vector, {current: agent, waiting: new Set()});
            this._request(vector);
        }
    }

    /**
     * @param {InvVector} vector
     * @private
     */
    _request(vector) {
        Assert.that(this._vectorsToRequest.contains(vector));
        const agent = this._vectorsToRequest.get(vector).current;
        Assert.that(agent);
        agent.requestVector(vector);
        this._timers.resetTimeout(vector.hash, () => this.noteVectorNotReceived(agent, vector), InvRequestManager.MAX_TIME_PER_VECTOR);
    }

    /**
     * @param {BaseConsensusAgent} agent
     * @param {InvVector} vector
     */
    noteVectorNotReceived(agent, vector) {
        if (this._vectorsToRequest.contains(vector)) {
            const o = this._vectorsToRequest.get(vector);
            if (o.current !== agent) {
                o.waiting.delete(agent);
            } else {
                this._timers.clearTimeout(vector.hash);
                o.current = null;
                if (o.waiting.size !== 0) {
                    o.current = o.waiting.values().next().value;
                    o.waiting.delete(o.current);
                    this._request(vector);
                }
                if (o.current === null) {
                    this._vectorsToRequest.remove(vector);
                }
            }
        }
    }

    noteVectorReceived(vector) {
        this._timers.clearTimeout(vector.hash);
        this._vectorsToRequest.remove(vector);
    }
}

InvRequestManager.MAX_TIME_PER_VECTOR = 10000;
InvRequestManager.MAX_INV_MANAGED = 10000;

Class.register(InvRequestManager);

/**
 * @abstract
 */
class BaseConsensusAgent extends Observable {
    /**
     * @param {Time} time
     * @param {Peer} peer
     * @param {InvRequestManager} invRequestManager
     * @param {Subscription} [targetSubscription]
     */
    constructor(time, peer, invRequestManager, targetSubscription) {
        super();
        /** @type {Time} */
        this._time = time;
        /** @type {Peer} */
        this._peer = peer;

        // Flag indicating that have synced our blockchain with the peer's.
        /** @type {boolean} */
        this._synced = false;

        // Set of all objects (InvVectors) that we think the remote peer knows.
        /** @type {LimitInclusionHashSet.<InvVector>} */
        this._knownObjects = new LimitInclusionHashSet(BaseConsensusAgent.KNOWN_OBJECTS_COUNT_MAX);
        this._knownObjects.add(new InvVector(InvVector.Type.BLOCK, peer.headHash));

        // InvVectors we want to request via getData are collected here and
        // periodically requested.
        /** @type {UniqueQueue.<InvVector>} */
        this._blocksToRequest = new UniqueQueue();
        /** @type {ThrottledQueue.<InvVector>} */
        this._txsToRequest = new ThrottledQueue(
            BaseConsensusAgent.TRANSACTIONS_AT_ONCE + BaseConsensusAgent.FREE_TRANSACTIONS_AT_ONCE,
            BaseConsensusAgent.TRANSACTIONS_PER_SECOND + BaseConsensusAgent.FREE_TRANSACTIONS_PER_SECOND,
            1000, BaseConsensusAgent.REQUEST_TRANSACTIONS_WAITING_MAX);

        // Objects that are currently being requested from the peer.
        /** @type {HashSet.<InvVector>} */
        this._objectsInFlight = new HashSet();

        // All objects that were requested from the peer but not received yet.
        /** @type {HashSet.<InvVector>} */
        this._objectsThatFlew = new HashSet();

        // Objects that are currently being processed by the blockchain/mempool.
        /** @type {HashSet.<InvVector>} */
        this._objectsProcessing = new HashSet();

        // A Subscription object specifying which objects should be announced to the peer.
        // Initially, we don't announce anything to the peer until it tells us otherwise.
        /** @type {Subscription} */
        this._remoteSubscription = Subscription.NONE;
        // Subscribe to all announcements from the peer.
        /** @type {Subscription} */
        this._localSubscription = Subscription.NONE;
        this._lastSubscriptionChange = null;
        /** @type {Subscription} */
        this._targetSubscription = targetSubscription || Subscription.ANY;

        // Helper object to keep track of timeouts & intervals.
        /** @type {Timers} */
        this._timers = new Timers();

        // Queue of transaction inv vectors waiting to be sent out
        /** @type {ThrottledQueue.<InvVector>} */
        this._waitingInvVectors = new ThrottledQueue(
            BaseConsensusAgent.TRANSACTIONS_AT_ONCE,
            BaseConsensusAgent.TRANSACTIONS_PER_SECOND,
            1000, BaseConsensusAgent.REQUEST_TRANSACTIONS_WAITING_MAX);
        this._timers.setInterval('invVectors', () => this._sendWaitingInvVectors(), BaseConsensusAgent.TRANSACTION_RELAY_INTERVAL);

        // Queue of "free" transaction inv vectors waiting to be sent out
        /** @type {ThrottledQueue.<FreeTransactionVector>} */
        this._waitingFreeInvVectors = new ThrottledQueue(
            BaseConsensusAgent.FREE_TRANSACTIONS_AT_ONCE,
            BaseConsensusAgent.FREE_TRANSACTIONS_PER_SECOND,
            1000, BaseConsensusAgent.REQUEST_TRANSACTIONS_WAITING_MAX);
        this._timers.setInterval('freeInvVectors', () => this._sendFreeWaitingInvVectors(), BaseConsensusAgent.FREE_TRANSACTION_RELAY_INTERVAL);

        // Helper object to keep track of block proofs we're requesting.
        this._blockProofRequest = null;

        // Helper object to keep track of transaction proofs we're requesting.
        this._transactionsProofRequest = null;

        // Helper object to keep track of transaction receipts we're requesting.
        this._transactionReceiptsRequest = null;

        /** @type {HashMap.<InvVector, Array.<{resolve: function, reject: function}>>} */
        this._pendingRequests = new HashMap();

        /** @type {MultiSynchronizer} */
        this._synchronizer = new MultiSynchronizer();

        /** @type {InvRequestManager} */
        this._invRequestManager = invRequestManager;

        /** @type {Set.<{obj: Observable, type: string, id: number}>} */
        this._listenersToDisconnect = new Set();

        // Listen to consensus messages from the peer.
        this._onToDisconnect(peer.channel, 'inv', msg => this._onInv(msg));
        this._onToDisconnect(peer.channel, 'block', msg => this._onBlock(msg));
        this._onToDisconnect(peer.channel, 'header', msg => this._onHeader(msg));
        this._onToDisconnect(peer.channel, 'tx', msg => this._onTx(msg));
        this._onToDisconnect(peer.channel, 'not-found', msg => this._onNotFound(msg));

        this._onToDisconnect(peer.channel, 'subscribe', msg => this._onSubscribe(msg));
        this._onToDisconnect(peer.channel, 'get-data', msg => this._onGetData(msg));
        this._onToDisconnect(peer.channel, 'get-header', msg => this._onGetHeader(msg));

        this._onToDisconnect(peer.channel, 'block-proof', msg => this._onBlockProof(msg));
        this._onToDisconnect(peer.channel, 'transactions-proof', msg => this._onTransactionsProof(msg));
        this._onToDisconnect(peer.channel, 'transaction-receipts', msg => this._onTransactionReceipts(msg));

        this._onToDisconnect(peer.channel, 'mempool', msg => this._onMempool(msg));

        this._onToDisconnect(peer.channel, 'get-head', msg => this._onGetHead(msg));
        this._onToDisconnect(peer.channel, 'head', msg => this._onHead(msg));

        // Clean up when the peer disconnects.
        this._onToDisconnect(peer.channel, 'close', () => this._onClose());

        this._requestHead();
    }

    /**
     * @param {Observable} obj
     * @param {string} type
     * @param {function} callback
     * @protected
     */
    _onToDisconnect(obj, type, callback) {
        const id = obj.on(type, callback);
        this._listenersToDisconnect.add({obj, type, id});
    }

    /**
     * @protected
     */
    _disconnectListeners() {
        for (const listener of this._listenersToDisconnect) {
            listener.obj.off(listener.type, listener.id);
        }
        this._offAll();
    }

    /**
     * @param {...number} services
     * @returns {boolean}
     */
    providesServices(...services) {
        return Services.providesServices(this._peer.peerAddress.services, ...services);
    }

    _requestHead() {
        this._peer.channel.getHead();
    }

    onHeadUpdated() {
        this._timers.resetTimeout('get-next-head', () => this._requestHead(), BaseConsensusAgent.HEAD_REQUEST_INTERVAL);
    }

    /**
     * @param {GetHeadMessage} msg
     * @private
     */
    _onGetHead(msg) {
        this._peer.channel.head(this._blockchain.head.header);
    }

    /**
     * @param {HeadMessage} msg
     */
    _onHead(msg) {
        this._peer.head = msg.header;
        this.onHeadUpdated();
    }

    /**
     * @param {Subscription} subscription
     */
    subscribe(subscription) {
        this._targetSubscription = subscription;
        this._subscribe(subscription);
    }

    _subscribeTarget() {
        this._subscribe(this._targetSubscription);
    }

    /**
     * @param {Subscription} subscription
     */
    _subscribe(subscription) {
        this._localSubscription = subscription;
        this._lastSubscriptionChange = Date.now();
        this._peer.channel.subscribe(this._localSubscription);
    }

    /**
     * @param {Block} block
     * @returns {boolean}
     */
    relayBlock(block) {
        // Don't relay block if have not synced with the peer yet.
        if (!this._synced) {
            return false;
        }

        // Only relay block if it matches the peer's subscription.
        if (!this._remoteSubscription.matchesBlock(block)) {
            return false;
        }

        // Create InvVector.
        const vector = InvVector.fromBlock(block);

        // Don't relay block to this peer if it already knows it.
        if (this._knownObjects.contains(vector)) {
            return false;
        }

        // Relay block to peer.
        this._peer.channel.inv([vector, ...this._waitingInvVectors.dequeueMulti(BaseInventoryMessage.VECTORS_MAX_COUNT - 1)]);

        // Assume that the peer knows this block after short time.
        this._timers.setTimeout(`knows-block-${vector.hash.toBase64()}`, () => {
            this._knownObjects.add(vector);
        }, BaseConsensusAgent.KNOWS_OBJECT_AFTER_INV_DELAY);

        return true;
    }

    /**
     * @param {Hash} hash
     * @return {Promise.<?Block>}
     */
    requestBlock(hash) {
        return new Promise((resolve, reject) => {
            const vector = new InvVector(InvVector.Type.BLOCK, hash);
            if (this._pendingRequests.contains(vector)) {
                this._pendingRequests.get(vector).push({resolve, reject});
            } else {
                this._pendingRequests.put(vector, [{resolve, reject}]);

                this._peer.channel.getData([vector]);

                this._timers.setTimeout(`block-request-${vector.hash.toBase64()}`, () => {
                    const requests = this._pendingRequests.get(vector);
                    if (!requests) return;

                    this._pendingRequests.remove(vector);

                    for (const {reject} of requests) {
                        reject(new Error('Timeout'));
                    }
                }, BaseConsensusAgent.REQUEST_TIMEOUT);
            }
        });
    }

    /**
     * @param {Hash} hash
     * @return {Promise.<?Transaction>}
     */
    requestTransaction(hash) {
        return new Promise((resolve, reject) => {
            const vector = new InvVector(InvVector.Type.TRANSACTION, hash);
            if (this._pendingRequests.contains(vector)) {
                this._pendingRequests.get(vector).push({resolve, reject});
            } else {
                this._pendingRequests.put(vector, [{resolve, reject}]);

                if (!this._objectsInFlight.contains(vector)) {
                    this._peer.channel.getData([vector]);
                    this._objectsInFlight.add(vector);
                }

                this._timers.setTimeout(`tx-request-${vector.hash.toBase64()}`, () => {
                    const requests = this._pendingRequests.get(vector);
                    if (!requests) return;

                    this._pendingRequests.remove(vector);

                    for (const {reject} of requests) {
                        reject(new Error('Timeout'));
                    }
                }, BaseConsensusAgent.REQUEST_TIMEOUT);
            }
        });
    }

    _sendWaitingInvVectors() {
        const invVectors = this._waitingInvVectors.dequeueMulti(BaseInventoryMessage.VECTORS_MAX_COUNT);
        if (invVectors.length > 0) {
            this._peer.channel.inv(invVectors);
            Log.v(BaseConsensusAgent, () => `[INV] Sent ${invVectors.length} vectors to ${this._peer.peerAddress}`);
        }
    }

    _sendFreeWaitingInvVectors() {
        const invVectors = [];
        let size = 0;
        while (invVectors.length < BaseInventoryMessage.VECTORS_MAX_COUNT && this._waitingFreeInvVectors.isAvailable()
            && size < BaseConsensusAgent.FREE_TRANSACTION_SIZE_PER_INTERVAL) {
            const freeTransaction = this._waitingFreeInvVectors.dequeue();
            invVectors.push(freeTransaction.inv);
            size += freeTransaction.serializedSize;
        }
        if (invVectors.length > 0) {
            this._peer.channel.inv(invVectors);
            Log.v(BaseConsensusAgent, () => `[INV] Sent ${invVectors.length} vectors to ${this._peer.peerAddress}`);
        }
    }

    /**
     * @param {Transaction} transaction
     * @return {boolean}
     */
    relayTransaction(transaction) {
        // Only relay transaction if it matches the peer's subscription.
        if (!this._remoteSubscription.matchesTransaction(transaction)) {
            Log.v(BaseConsensusAgent, `Not sending ${transaction.hash()} to ${this.peer.peerAddress}: not subscribed`);
            return false;
        }

        // Create InvVector.
        const vector = InvVector.fromTransaction(transaction);

        // Don't relay transaction to this peer if it already knows it.
        if (this._knownObjects.contains(vector)) {
            Log.v(BaseConsensusAgent, `Not sending ${transaction.hash()} to ${this.peer.peerAddress}: already knows`);
            return false;
        }

        // Relay transaction to peer later.
        const serializedSize = transaction.serializedSize;
        if (transaction.fee / serializedSize < BaseConsensusAgent.TRANSACTION_RELAY_FEE_MIN) {
            this._waitingFreeInvVectors.enqueue(new FreeTransactionVector(vector, serializedSize));
        } else {
            this._waitingInvVectors.enqueue(vector);
        }

        // Assume that the peer knows this transaction after short time.
        this._timers.setTimeout(`knows-tx-${vector.hash.toBase64()}`, () => {
            this._knownObjects.add(vector);
        }, BaseConsensusAgent.KNOWS_OBJECT_AFTER_INV_DELAY);

        Log.v(BaseConsensusAgent, `Sending ${transaction.hash()} to ${this.peer.peerAddress}`);

        return true;
    }

    /**
     * @param {Transaction} transaction
     */
    removeTransaction(transaction) {
        // Create InvVector.
        const vector = InvVector.fromTransaction(transaction);

        // Remove transaction from relay queues.
        this._waitingFreeInvVectors.remove(vector); // InvVector and FreeTransactionVector have the same hashCode.
        this._waitingInvVectors.remove(vector);
    }

    /**
     * @param {Hash} blockHash
     * @returns {boolean}
     */
    knowsBlock(blockHash) {
        const vector = new InvVector(InvVector.Type.BLOCK, blockHash);
        return this._knownObjects.contains(vector);
    }

    /**
     * @param {Hash} txHash
     * @returns {boolean}
     */
    knowsTransaction(txHash) {
        const vector = new InvVector(InvVector.Type.TRANSACTION, txHash);
        return this._knownObjects.contains(vector);
    }

    /**
     * @param {SubscribeMessage} msg
     * @protected
     */
    _onSubscribe(msg) {
        this._remoteSubscription = msg.subscription;
    }

    /**
     * @param {MempoolMessage} msg
     * @return {Promise}
     * @private
     */
    async _onMempool(msg) {
        // Query mempool for transactions
        const transactions = this._getSubscribedMempoolTransactions();

        // Send an InvVector for each transaction in the mempool.
        // Split into multiple Inv messages if the mempool is large.
        let vectors = [];
        for (const tx of transactions) {
            vectors.push(InvVector.fromTransaction(tx));

            if (vectors.length >= BaseInventoryMessage.VECTORS_MAX_COUNT) {
                this._peer.channel.inv(vectors);
                vectors = [];
                await new Promise((resolve) => setTimeout(resolve, FullConsensusAgent.MEMPOOL_THROTTLE));
            }
        }

        if (vectors.length > 0) {
            this._peer.channel.inv(vectors);
        }
    }

    /**
     * @returns {Iterable.<Transaction>}
     * @protected
     * @override
     */
    _getSubscribedMempoolTransactions() {
        return [];
    }

    /**
     * @param {InvMessage} msg
     * @returns {Promise.<void>}
     * @protected
     */
    _onInv(msg) {
        return this._synchronizer.push('onInv',
            this.__onInv.bind(this, msg));
    }

    /**
     * @param {InvMessage} msg
     * @returns {Promise.<void>}
     * @protected
     */
    async __onInv(msg) {
        // Keep track of the objects the peer knows.
        for (const vector of msg.vectors) {
            this._knownObjects.add(vector);
            this._waitingInvVectors.remove(vector);
            this._waitingFreeInvVectors.remove(vector); // The inv vector has the same hashCode as a FreeTransactionVector
        }

        // Check which of the advertised objects we know
        // Request unknown objects, ignore known ones.
        const unknownBlocks = [];
        const unknownTxs = [];
        for (const vector of msg.vectors) {
            // Ignore objects that we are currently requesting / processing.
            if (this._objectsInFlight.contains(vector) || this._objectsProcessing.contains(vector)) {
                continue;
            }

            // Filter out objects that we are not interested in.
            if (!this._shouldRequestData(vector)) {
                continue;
            }

            switch (vector.type) {
                case InvVector.Type.BLOCK: {
                    const block = await this._getBlock(vector.hash, /*includeForks*/ true); // eslint-disable-line no-await-in-loop
                    if (!block) {
                        unknownBlocks.push(vector);
                        this._onNewBlockAnnounced(vector.hash);
                    } else {
                        this._onKnownBlockAnnounced(vector.hash, block);
                    }
                    break;
                }
                case InvVector.Type.TRANSACTION: {
                    const transaction = this._getTransaction(vector.hash);
                    if (!transaction) {
                        unknownTxs.push(vector);
                        this._onNewTransactionAnnounced(vector.hash);
                    } else {
                        this._onKnownTransactionAnnounced(vector.hash, transaction);
                    }
                    break;
                }
                default:
                    // ignore
            }
        }

        Log.v(BaseConsensusAgent, () => `[INV] ${msg.vectors.length} vectors (${unknownBlocks.length} new blocks, ${unknownTxs.length} new txs) received from ${this._peer.peerAddress}`);

        if (unknownBlocks.length > 0 || unknownTxs.length > 0) {
            for (const vector of unknownBlocks) {
                this._invRequestManager.askToRequestVector(this, vector);
            }
            for (const vector of unknownTxs) {
                this._invRequestManager.askToRequestVector(this, vector);
            }
        } else {
            this._onNoUnknownObjects();
        }
    }

    /**
     * @param {...InvVector} vector
     */
    requestVector(...vector) {
        // Store unknown vectors in objectsToRequest.
        this._blocksToRequest.enqueueAll(vector.filter(v => v.type === InvVector.Type.BLOCK));
        this._txsToRequest.enqueueAll(vector.filter(v => v.type === InvVector.Type.TRANSACTION));

        // Clear the request throttle timeout.
        this._timers.clearTimeout('inv');

        // If there are enough objects queued up, send out a getData request.
        if (this._blocksToRequest.length + this._txsToRequest.available >= BaseConsensusAgent.REQUEST_THRESHOLD) {
            this._requestData();
        }
        // Otherwise, wait a short time for more inv messages to arrive, then request.
        else {
            this._timers.setTimeout('inv', () => this._requestData(), BaseConsensusAgent.REQUEST_THROTTLE);
        }
    }

    /**
     * @param {InvVector} vector
     * @returns {boolean}
     * @protected
     */
    _shouldRequestData(vector) {
        return true;
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks]
     * @param {boolean} [includeBody]
     * @returns {Promise.<?Block>}
     * @protected
     * @abstract
     */
    _getBlock(hash, includeForks = false, includeBody = false) {
        // MUST be implemented by subclasses.
        throw new Error('not implemented');
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks]
     * @returns {Promise.<?Uint8Array>}
     * @protected
     * @abstract
     */
    _getRawBlock(hash, includeForks = false) {
        // MUST be implemented by subclasses.
        throw new Error('not implemented');
    }

    /**
     * @param {Hash} hash
     * @returns {?Transaction}
     * @protected
     * @abstract
     */
    _getTransaction(hash) {
        // MUST be implemented by subclasses.
        throw new Error('not implemented');
    }

    /**
     * @param {Hash} hash
     * @returns {void}
     * @protected
     */
    _onNewBlockAnnounced(hash) {
    }
    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {void}
     * @protected
     */
    _onKnownBlockAnnounced(hash, block) {
    }
    /**
     * @param {Hash} hash
     * @returns {void}
     * @protected
     */
    _onNewTransactionAnnounced(hash) {
    }
    /**
     * @param {Hash} hash
     * @param {Transaction} transaction
     * @returns {void}
     * @protected
     */
    _onKnownTransactionAnnounced(hash, transaction) {
    }

    /**
     * @returns {void}
     * @protected
     */
    _requestData() {
        // Only one request at a time.
        if (!this._objectsInFlight.isEmpty()) return;

        // Don't do anything if there are no objects queued to request.
        if (this._blocksToRequest.isEmpty() && !this._txsToRequest.isAvailable()) return;

        // Request queued objects from the peer. Only request up to VECTORS_MAX_COUNT objects at a time.
        const vectorsMaxCount = BaseInventoryMessage.VECTORS_MAX_COUNT;
        /** @type {Array.<InvVector>} */
        let vectors = this._blocksToRequest.dequeueMulti(vectorsMaxCount);
        if (vectors.length < vectorsMaxCount) {
            vectors = vectors.concat(this._txsToRequest.dequeueMulti(vectorsMaxCount - vectors.length));
        }

        // Mark the requested objects as in-flight.
        this._objectsInFlight.addAll(vectors);

        // Request data from peer.
        this._doRequestData(vectors);

        // Set timer to detect end of request / missing objects
        this._timers.setTimeout('getData', () => this._noMoreData(), BaseConsensusAgent.REQUEST_TIMEOUT);
    }

    /**
     * @param {Array.<InvVector>} vectors
     * @returns {void}
     * @protected
     */
    _doRequestData(vectors) {
        if (this._willRequestHeaders()) {
            /** @type {Array.<InvVector>} */
            const blocks = [];
            /** @type {Array.<InvVector>} */
            const transactions = [];
            for (const vector of vectors) {
                if (vector.type === InvVector.Type.BLOCK) {
                    blocks.push(vector);
                } else {
                    transactions.push(vector);
                }
            }

            // Request headers and transactions from peer.
            this._peer.channel.getHeader(blocks);
            this._peer.channel.getData(transactions);
        } else {
            this._peer.channel.getData(vectors);
        }
    }

    _willRequestHeaders() {
        return false;
    }

    /**
     * @param {BlockMessage} msg
     * @return {Promise.<void>}
     * @protected
     */
    async _onBlock(msg) {
        const hash = msg.block.hash();
        const vector = new InvVector(InvVector.Type.BLOCK, hash);
        const blockRequest = this._pendingRequests.get(vector);

        // Check if we have requested this block.
        if (!blockRequest && !this._objectsInFlight.contains(vector) && !this._objectsThatFlew.contains(vector)) {
            Log.w(BaseConsensusAgent, `Unsolicited block ${hash} received from ${this._peer.peerAddress}, discarding`);
            return;
        }

        // Reuse already known (verified) transactions
        const transactions = msg.block.isFull() ? msg.block.body.transactions : [];
        const transactionsFromMempool = transactions.map(t => this._getTransaction(t.hash()));
        for (let i = 0; i < transactions.length; i++) {
            const transaction = transactionsFromMempool[i];
            if (transaction) {
                transactions[i] = transaction;
            }
        }

        if (blockRequest) {
            this._pendingRequests.remove(vector);
            this._timers.clearTimeout(`block-request-${vector.hash.toBase64()}`);
            for (const {resolve} of blockRequest) {
                try {
                    resolve(msg.block);
                } catch (e) {
                    // Ignore
                }
            }
            return;
        }

        // Track the peer's head.
        if ((!this._peer.head && this._peer.headHash.equals(hash)) || (this._peer.head && this._peer.head.height < msg.block.height)) {
            this._peer.head = msg.block.header;
            this.onHeadUpdated();
        }

        // Mark object as received.
        this._onObjectReceived(vector);

        // Process block.
        this._objectsProcessing.add(vector);
        await this._processBlock(hash, msg.block);

        // Mark object as processed.
        this._onObjectProcessed(vector);

        this._invRequestManager.noteVectorReceived(InvVector.fromBlock(msg.block));
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {Promise.<void>}
     * @protected
     */
    async _processBlock(hash, block) {
    }

    /**
     * @param {HeaderMessage} msg
     * @return {Promise.<void>}
     * @protected
     */
    async _onHeader(msg) {
        const hash = msg.header.hash();

        // Check if we have requested this header.
        const vector = new InvVector(InvVector.Type.BLOCK, hash);
        if (!this._objectsInFlight.contains(vector) && !this._objectsThatFlew.contains(vector)) {
            Log.w(BaseConsensusAgent, `Unsolicited header ${hash} received from ${this._peer.peerAddress}, discarding`);
            return;
        }

        // Track the peer's head.
        if ((!this._peer.head && this._peer.headHash.equals(hash)) || (this._peer.head && this._peer.head.height < msg.header.height)) {
            this._peer.head = msg.header;
            this.onHeadUpdated();
        }

        // Mark object as received.
        this._onObjectReceived(vector);

        // Process header.
        this._objectsProcessing.add(vector);
        await this._processHeader(hash, msg.header);

        // Mark object as processed.
        this._onObjectProcessed(vector);
    }

    /**
     * @param {Hash} hash
     * @param {BlockHeader} header
     * @returns {Promise.<void>}
     * @protected
     */
    async _processHeader(hash, header) {
    }

    /**
     * @param {TxMessage} msg
     * @return {Promise}
     * @protected
     */
    async _onTx(msg) {
        const hash = msg.transaction.hash();
        //Log.d(BaseConsensusAgent, () => `[TX] Received transaction ${hash} from ${this._peer.peerAddress}`);

        // Check if we have requested this transaction.
        const vector = new InvVector(InvVector.Type.TRANSACTION, hash);
        if (!this._objectsInFlight.contains(vector) && !this._objectsThatFlew.contains(vector)) {
            Log.w(BaseConsensusAgent, `Unsolicited transaction ${hash} received from ${this._peer.peerAddress}, discarding`);
            return;
        }

        this._invRequestManager.noteVectorReceived(InvVector.fromTransaction(msg.transaction));

        // Mark object as received.
        this._onObjectReceived(vector);

        // Mark transaction as processing.
        this._objectsProcessing.add(vector);

        // Process transaction if we subscribed for this transaction.
        if (this._localSubscription.matchesTransaction(msg.transaction)) {
            await this._processTransaction(hash, msg.transaction);
        }

        const txRequest = this._pendingRequests.get(vector);
        if (txRequest) {
            this._pendingRequests.remove(vector);
            this._timers.clearTimeout(`tx-request-${vector.hash.toBase64()}`);
            for (const {resolve} of txRequest) {
                try {
                    resolve(msg.transaction);
                } catch (e) {
                    // Ignore
                }
            }
        } else if (!this._localSubscription.matchesTransaction(msg.transaction) && this._lastSubscriptionChange + BaseConsensusAgent.SUBSCRIPTION_CHANGE_GRACE_PERIOD > Date.now()) {
            this._peer.channel.close(CloseType.TRANSACTION_NOT_MATCHING_SUBSCRIPTION, 'received transaction not matching our subscription');
        }

        // Mark object as processed.
        this._onObjectProcessed(vector);
    }

    /**
     * @param {Hash} hash
     * @param {Transaction} transaction
     * @returns {Promise.<void>}
     * @protected
     */
    async _processTransaction(hash, transaction) {
    }

    /**
     * @param {NotFoundMessage} msg
     * @returns {void}
     * @protected
     */
    _onNotFound(msg) {
        Log.d(BaseConsensusAgent, `[NOTFOUND] ${msg.vectors.length} unknown objects received from ${this._peer.peerAddress}`);

        for (const vector of msg.vectors) {
            const requests = this._pendingRequests.get(vector);
            if (requests) {
                this._pendingRequests.remove(vector);
                this._timers.clearTimeout((vector.type === InvVector.Type.BLOCK ? 'block' : 'tx') + '-request-' + vector.hash.toBase64());
                for (const {reject} of requests) {
                    try {
                        reject(new Error('Not found'));
                    } catch (e) {
                        // Ignore
                    }
                }
            }

            // Remove unknown objects from in-flight list.
            if (!this._objectsInFlight.contains(vector)) {
                continue;
            }

            this._invRequestManager.noteVectorNotReceived(this, vector);

            // Mark object as received.
            this._onObjectReceived(vector);
        }
    }

    /**
     * @param {InvVector} vector
     * @returns {void}
     * @protected
     */
    _onObjectReceived(vector) {
        if (this._objectsInFlight.isEmpty()) return;

        // Remove the vector from objectsInFlight.
        this._objectsInFlight.remove(vector);

        // Reset the request timeout if we expect more objects to come.
        if (!this._objectsInFlight.isEmpty()) {
            this._timers.resetTimeout('getData', () => this._noMoreData(), BaseConsensusAgent.REQUEST_TIMEOUT);
        } else {
            this._noMoreData();
        }
    }

    /**
     * @returns {void}
     * @protected
     */
    _noMoreData() {
        // Cancel the request timeout timer.
        this._timers.clearTimeout('getData');

        for(const vector of this._objectsInFlight.values()) {
            this._invRequestManager.noteVectorNotReceived(this, vector);
        }

        // Reset objects in flight.
        this._objectsThatFlew.addAll(this._objectsInFlight.values());
        this._objectsInFlight.clear();

        // If there are more objects to request, request them.
        if (!this._blocksToRequest.isEmpty() || this._txsToRequest.isAvailable()) {
            this._requestData();
        } else {
            this._onAllObjectsReceived();
        }
    }

    /**
     * @returns {void}
     * @protected
     */
    _onNoUnknownObjects() {
    }

    /**
     * @returns {void}
     * @protected
     */
    _onAllObjectsReceived() {
    }

    /**
     * @param {InvVector} vector
     * @returns {void}
     * @protected
     */
    _onObjectProcessed(vector) {
        // Remove the vector from objectsProcessing.
        this._objectsProcessing.remove(vector);

        if (this._objectsProcessing.isEmpty()) {
            this._onAllObjectsProcessed();
        }
    }

    /**
     * @returns {void}
     * @protected
     */
    _onAllObjectsProcessed() {
    }

    /**
     * @param {GetDataMessage} msg
     * @returns {Promise.<void>}
     * @protected
     */
    async _onGetData(msg) {
        // Keep track of the objects the peer knows.
        for (const vector of msg.vectors) {
            this._knownObjects.add(vector);
        }

        // Check which of the requested objects we know.
        // Send back all known objects.
        // Send notFound for unknown objects.
        const unknownObjects = [];
        for (const vector of msg.vectors) {
            switch (vector.type) {
                case InvVector.Type.BLOCK: {
                    const block = await this._getRawBlock(vector.hash, /*includeForks*/ false); // eslint-disable-line no-await-in-loop
                    if (block) {
                        // We have found a requested block, send it back to the sender.
                        this._peer.channel.rawBlock(block);
                    } else {
                        // Requested block is unknown.
                        unknownObjects.push(vector);
                    }
                    break;
                }
                case InvVector.Type.TRANSACTION: {
                    const tx = this._getTransaction(vector.hash);
                    if (tx) {
                        // We have found a requested transaction, send it back to the sender.
                        this._peer.channel.tx(tx);
                        this.fire('transaction-relayed', tx);
                    } else {
                        // Requested transaction is unknown.
                        unknownObjects.push(vector);
                    }
                    break;
                }
                default:
                    // ignore
            }
        }

        // Report any unknown objects back to the sender.
        if (unknownObjects.length) {
            this._peer.channel.notFound(unknownObjects);
        }
    }

    /**
     * @param {GetHeaderMessage} msg
     * @returns {Promise}
     * @protected
     */
    async _onGetHeader(msg) {
        // Keep track of the objects the peer knows.
        for (const vector of msg.vectors) {
            this._knownObjects.add(vector);
        }

        // Check which of the requested objects we know.
        // Send back all known objects.
        // Send notFound for unknown objects.
        const unknownObjects = [];
        for (const vector of msg.vectors) {
            switch (vector.type) {
                case InvVector.Type.BLOCK: {
                    const block = await this._getBlock(vector.hash); // eslint-disable-line no-await-in-loop
                    if (block) {
                        // We have found a requested block, send it back to the sender.
                        this._peer.channel.header(block.header);
                    } else {
                        // Requested block is unknown.
                        unknownObjects.push(vector);
                    }
                    break;
                }
                case InvVector.Type.TRANSACTION:
                default:
                    // ignore
            }
        }

        // Report any unknown objects back to the sender.
        if (unknownObjects.length) {
            this._peer.channel.notFound(unknownObjects);
        }
    }

    /**
     * @param {Hash} blockHashToProve
     * @param {Block} knownBlock
     * @returns {Promise.<Block>}
     */
    getBlockProof(blockHashToProve, knownBlock) {
        return this._synchronizer.push('getBlockProof',
            this._getBlockProof.bind(this, blockHashToProve, knownBlock));
    }

    /**
     * @param {Hash} blockHashToProve
     * @param {Block} knownBlock
     * @returns {Promise.<Block>}
     * @private
     */
    _getBlockProof(blockHashToProve, knownBlock) {
        Assert.that(this._blockProofRequest === null);

        Log.v(BaseConsensusAgent, () => `Requesting BlockProof for ${blockHashToProve} from ${this._peer.peerAddress}`);

        return new Promise((resolve, reject) => {
            this._blockProofRequest = {
                blockHashToProve,
                knownBlock,
                resolve,
                reject
            };

            // Request BlockProof from peer.
            this._peer.channel.getBlockProof(blockHashToProve, knownBlock.hash());

            this._peer.channel.expectMessage(Message.Type.BLOCK_PROOF, () => {
                this._blockProofRequest = null;
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.BLOCK_PROOF_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {number} blockHeightToProve
     * @param {Block} knownBlock
     * @returns {Promise.<Block>}
     */
    getBlockProofAt(blockHeightToProve, knownBlock) {
        if (this._peer.version < 2) throw new Error('Request not supported by peer version');
        return this._synchronizer.push('getBlockProof',
            this._getBlockProofAt.bind(this, blockHeightToProve, knownBlock));
    }

    /**
     * @param {number} blockHeightToProve
     * @param {Block} knownBlock
     * @returns {Promise.<Block>}
     * @private
     */
    _getBlockProofAt(blockHeightToProve, knownBlock) {
        Assert.that(this._blockProofRequest === null);

        Log.v(BaseConsensusAgent, () => `Requesting BlockProof at ${blockHeightToProve} from ${this._peer.peerAddress}`);

        return new Promise((resolve, reject) => {
            this._blockProofRequest = {
                blockHeightToProve,
                knownBlock,
                resolve,
                reject
            };

            // Request BlockProof from peer.
            this._peer.channel.getBlockProofAt(blockHeightToProve, knownBlock.hash());

            this._peer.channel.expectMessage(Message.Type.BLOCK_PROOF, () => {
                this._blockProofRequest = null;
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.BLOCK_PROOF_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {BlockProofMessage} msg
     * @returns {Promise.<void>}
     * @private
     */
    async _onBlockProof(msg) {
        Log.v(BaseConsensusAgent, () => `[BLOCK-PROOF] Received from ${this._peer.peerAddress}: proof=${msg.proof} (${msg.serializedSize} bytes)`);

        // Check if we have requested a BlockProof, discard unsolicited ones.
        if (!this._blockProofRequest) {
            Log.w(BaseConsensusAgent, `Unsolicited header proof received from ${this._peer.peerAddress}`);
            return;
        }

        const { /** @type {Hash} */ blockHashToProve, blockHeightToProve, /** @type {Block} */ knownBlock, resolve, reject } = this._blockProofRequest;
        this._blockProofRequest = null;

        if (!msg.hasProof() || msg.proof.length === 0) {
            reject(new Error('Block proof request was rejected'));
            return;
        }

        // Check that the tail of the proof corresponds to the requested block.
        const proof = msg.proof;
        if (!proof.tail.hash().equals(blockHashToProve) && proof.tail.height !== blockHeightToProve) {
            Log.w(BaseConsensusAgent, `Received BlockProof with invalid tail block from ${this._peer.peerAddress}`);
            reject(new Error('Invalid tail block'));
            return;
        }

        // Check that the proof links up to our reference block.
        if (!(await knownBlock.isInterlinkSuccessorOf(proof.head))) {
            Log.w(BaseConsensusAgent, `Received BlockProof with invalid head block from ${this._peer.peerAddress}`);
            reject(new Error('Invalid head block'));
            return;
        }

        // Verify the proof.
        if (!(await proof.verify())) {
            Log.w(BaseConsensusAgent, `Invalid BlockProof received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_BLOCK_PROOF, 'Invalid BlockProof');
            reject(new Error('Invalid BlockProof'));
            return;
        }

        // Verify individual blocks.
        const verificationResults = await Promise.all(proof.blocks.map(block => block.verify(this._time)));
        if (!verificationResults.every(result => result)) {
            Log.w(BaseConsensusAgent, `Invalid BlockProof received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_BLOCK_PROOF, 'Invalid BlockProof');
            reject(new Error('Invalid BlockProof'));
            return;
        }

        // Return the proven block.
        resolve(proof.tail);
    }

    /**
     * @param {Block} block
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Transaction>>}
     * @deprecated
     */
    getTransactionsProof(block, addresses) {
        return this.getTransactionsProofByAddresses(block, addresses);
    }

    /**
     * @param {Block} block
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Transaction>>}
     */
    getTransactionsProofByAddresses(block, addresses) {
        return this._synchronizer.push('getTransactionsProof',
            this._getTransactionsProofByAddresses.bind(this, block, addresses));
    }

    /**
     * @param {Block} block
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     */
    getTransactionsProofByHashes(block, hashes) {
        if (this._peer.version < 2) throw new Error('Request not supported by peer version');
        return this._synchronizer.push('getTransactionsProof',
            this._getTransactionsProofByHashes.bind(this, block, hashes));
    }

    /**
     * @param {Block} block
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Transaction>>}
     * @private
     */
    _getTransactionsProofByAddresses(block, addresses) {
        Assert.that(this._transactionsProofRequest === null);

        Log.v(BaseConsensusAgent, () => `Requesting TransactionsProof for ${addresses}@${block.height} from ${this._peer.peerAddress}`);

        return new Promise((resolve, reject) => {
            this._transactionsProofRequest = {
                addresses,
                block,
                resolve,
                reject,
            };

            // Request TransactionProof from peer.
            this._peer.channel.getTransactionsProofByAddresses(block.hash(), addresses);

            // Drop the peer if it doesn't send the TransactionProof within the timeout.
            this._peer.channel.expectMessage(Message.Type.TRANSACTIONS_PROOF, () => {
                this._transactionsProofRequest = null;
                this._peer.channel.close(CloseType.GET_TRANSACTIONS_PROOF_TIMEOUT, 'getTransactionsProof timeout');
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.TRANSACTIONS_PROOF_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {Block} block
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     * @private
     */
    _getTransactionsProofByHashes(block, hashes) {
        Assert.that(this._transactionsProofRequest === null);

        Log.v(BaseConsensusAgent, () => `Requesting TransactionsProof for ${hashes}@${block.height} from ${this._peer.peerAddress}`);

        return new Promise((resolve, reject) => {
            this._transactionsProofRequest = {
                hashes,
                block,
                resolve,
                reject,
            };

            // Request TransactionProof from peer.
            this._peer.channel.getTransactionsProofByHashes(block.hash(), hashes);

            // Drop the peer if it doesn't send the TransactionProof within the timeout.
            this._peer.channel.expectMessage(Message.Type.TRANSACTIONS_PROOF, () => {
                this._transactionsProofRequest = null;
                this._peer.channel.close(CloseType.GET_TRANSACTIONS_PROOF_TIMEOUT, 'getTransactionsProof timeout');
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.TRANSACTIONS_PROOF_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {TransactionsProofMessage} msg
     * @returns {void}
     * @private
     */
    _onTransactionsProof(msg) {
        Log.v(BaseConsensusAgent, () => `[TRANSACTIONS-PROOF] Received from ${this._peer.peerAddress}:`
            + ` blockHash=${msg.blockHash}, proof=${msg.proof} (${msg.serializedSize} bytes)`);

        // Check if we have requested a TransactionsProof, discard unsolicited ones.
        if (!this._transactionsProofRequest) {
            Log.w(BaseConsensusAgent, `Unsolicited transactions proof received from ${this._peer.peerAddress}`);
            return;
        }

        const {/** @type {Array.<Address>} */ addresses = [], /** @type {Array.<Hash>} */ hashes = [], /** @type {Block} */ block, resolve, reject} = this._transactionsProofRequest;
        this._transactionsProofRequest = null;

        if (!msg.hasProof()) {
            Log.w(BaseConsensusAgent, `TransactionsProof request was rejected by ${this._peer.peerAddress}`);
            reject(new Error('TransactionsProof request was rejected'));
            return;
        }

        // Check that the reference block corresponds to the one we requested.
        if (!block.hash().equals(msg.blockHash)) {
            Log.w(BaseConsensusAgent, `Received TransactionsProof for invalid reference block from ${this._peer.peerAddress}`);
            reject(new Error('Invalid reference block'));
            return;
        }

        // Verify the proof.
        const proof = msg.proof;
        let root = null;
        try {
            root = proof.root();
        } catch (e) {
            // ignore
        }
        if (!block.bodyHash.equals(root)) {
            Log.w(BaseConsensusAgent, `Invalid TransactionsProof received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_TRANSACTION_PROOF, 'Invalid TransactionsProof');
            reject(new Error('Invalid TransactionsProof'));
            return;
        }

        // Verify that the proof only contains transactions that match the requested addresses/hashes.
        for (const tx of proof.transactions) {
            if (!addresses.some(address => tx.sender.equals(address) || tx.recipient.equals(address))
                && !hashes.some(hash => tx.hash().equals(hash))) {
                Log.w(BaseConsensusAgent, `TransactionsProof with unwanted transactions received from ${this._peer.peer}`);
                this._peer.channel.close(CloseType.INVALID_TRANSACTION_PROOF, 'TransactionsProof contains unwanted transactions');
                reject(new Error('TransactionsProof contains unwanted transactions'));
                return;
            }
        }

        // Return the retrieved transactions.
        resolve(proof.transactions);
    }

    /**
     * @param {Address} address
     * @returns {Promise.<Array.<TransactionReceipt>>}
     * @deprecated
     */
    getTransactionReceipts(address) {
        return this.getTransactionReceiptsByAddress(address);
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    getTransactionReceiptsByAddress(address, limit) {
        return this._synchronizer.push('getTransactionReceipts',
            this._getTransactionReceiptsByAddress.bind(this, address, limit));
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    getTransactionReceiptsByHashes(hashes) {
        if (this._peer.version < 2) throw new Error('Request not supported by peer version');
        return this._synchronizer.push('getTransactionReceipts',
            this._getTransactionReceiptsByHashes.bind(this, hashes));
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<TransactionReceipt>>}
     * @private
     */
    _getTransactionReceiptsByAddress(address, limit) {
        Assert.that(this._transactionReceiptsRequest === null);

        return new Promise((resolve, reject) => {
            this._transactionReceiptsRequest = {
                address,
                limit,
                resolve,
                reject
            };

            this._peer.channel.getTransactionReceiptsByAddress(address);

            this._peer.channel.expectMessage(Message.Type.TRANSACTION_RECEIPTS, () => {
                this._transactionReceiptsRequest = null;
                this._peer.channel.close(CloseType.GET_TRANSACTION_RECEIPTS_TIMEOUT, 'getTransactionReceipts timeout');
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.TRANSACTION_RECEIPTS_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<TransactionReceipt>>}
     * @private
     */
    _getTransactionReceiptsByHashes(hashes) {
        Assert.that(this._transactionReceiptsRequest === null);

        return new Promise((resolve, reject) => {
            this._transactionReceiptsRequest = {
                hashes,
                resolve,
                reject
            };

            this._peer.channel.getTransactionReceiptsByHashes(hashes);

            this._peer.channel.expectMessage(Message.Type.TRANSACTION_RECEIPTS, () => {
                this._transactionReceiptsRequest = null;
                this._peer.channel.close(CloseType.GET_TRANSACTION_RECEIPTS_TIMEOUT, 'getTransactionReceipts timeout');
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.TRANSACTION_RECEIPTS_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {TransactionReceiptsMessage} msg
     * @returns {void}
     * @private
     */
    _onTransactionReceipts(msg) {
        Log.v(BaseConsensusAgent, () => `[TRANSACTION-RECEIPTS] Received from ${this._peer.peerAddress}:`
            + ` ${msg.hasReceipts() ? msg.receipts.length : '<rejected>'}`);

        // Check if we have requested transaction receipts, discard unsolicited ones.
        // TODO: How about more than one transactionReceipts message?
        if (!this._transactionReceiptsRequest) {
            Log.w(BaseConsensusAgent, `Unsolicited transaction receipts received from ${this._peer.peerAddress}`);
            return;
        }

        const {address, hashes, limit, resolve, reject} = this._transactionReceiptsRequest;
        this._transactionReceiptsRequest = null;

        if (!msg.hasReceipts()) {
            Log.w(BaseConsensusAgent, `TransactionReceipts request was rejected by ${this._peer.peerAddress}`);
            reject(new Error('TransactionReceipts request was rejected'));
            return;
        }

        let receipts = msg.receipts;
        if (limit !== undefined && limit < receipts.length) receipts = receipts.slice(0, limit);

        if (hashes !== undefined) {
            for (const receipt of receipts) {
                if (!hashes.some(hash => hash.equals(receipt.transactionHash))) {
                    Log.w(BaseConsensusAgent, `TransactionsReceipts with unwanted transactions received from ${this._peer.peer}`);
                    this._peer.channel.close(CloseType.INVALID_TRANSACTION_RECEIPTS, 'TransactionsReceipts contains unwanted transactions');
                    reject(new Error('TransactionsReceipts contains unwanted transactions'));
                    return;
                }
            }
        }

        resolve(receipts);
    }

    /**
     * @returns {void}
     * @protected
     */
    _onClose() {
        this._shutdown();

        // Notify listeners that the peer has disconnected.
        this.fire('close', this);

        this._disconnectListeners();
    }

    /** @package */
    shutdown() {
        this._disconnectListeners();
        this._shutdown();
    }

    /** @private */
    _shutdown() {
        this._synchronizer.clear();

        // Clear all timers and intervals when the peer disconnects.
        this._timers.clearAll();
        this._txsToRequest.stop();
        this._waitingInvVectors.stop();
        this._waitingFreeInvVectors.stop();
    }

    /** @type {Peer} */
    get peer() {
        return this._peer;
    }

    /** @type {boolean} */
    get synced() {
        return this._synced;
    }

    /** @type {boolean} */
    get syncing() {
        return false;
    }
}
/**
 * Number of InvVectors in invToRequest pool to automatically trigger a get-data request.
 * @type {number}
 */
BaseConsensusAgent.REQUEST_THRESHOLD = 50;
/**
 * Time (ms) to wait after the last received inv message before sending get-data.
 * @type {number}
 */
BaseConsensusAgent.REQUEST_THROTTLE = 500;
/**
 * Maximum time (ms) to wait after sending out get-data or receiving the last object for this request.
 * @type {number}
 */
BaseConsensusAgent.REQUEST_TIMEOUT = 1000 * 10;
BaseConsensusAgent.REQUEST_TRANSACTIONS_WAITING_MAX = 5000;
BaseConsensusAgent.REQUEST_BLOCKS_WAITING_MAX = 5000;
/**
 * Maximum time (ms) to wait for block-proof.
 * @type {number}
 */
BaseConsensusAgent.BLOCK_PROOF_REQUEST_TIMEOUT = 1000 * 10;
/**
 * Maximum time (ms) to wait for transactions-proof.
 * @type {number}
 */
BaseConsensusAgent.TRANSACTIONS_PROOF_REQUEST_TIMEOUT = 1000 * 10;
/**
 * Maximum time (ms) to wait for transactions-receipts.
 * @type {number}
 */
BaseConsensusAgent.TRANSACTION_RECEIPTS_REQUEST_TIMEOUT = 1000 * 15;
/**
 * Time interval (ms) to wait between sending out transactions.
 * @type {number}
 */
BaseConsensusAgent.TRANSACTION_RELAY_INTERVAL = 5000;
BaseConsensusAgent.TRANSACTIONS_AT_ONCE = 100;
BaseConsensusAgent.TRANSACTIONS_PER_SECOND = 10;
/**
 * Time interval (ms) to wait between sending out "free" transactions.
 * @type {number}
 */
BaseConsensusAgent.FREE_TRANSACTION_RELAY_INTERVAL = 6000;
BaseConsensusAgent.FREE_TRANSACTIONS_AT_ONCE = 10;
BaseConsensusAgent.FREE_TRANSACTIONS_PER_SECOND = 1;
/**
 * Soft limit for the total size (bytes) of free transactions per relay interval.
 * @type {number}
 */
BaseConsensusAgent.FREE_TRANSACTION_SIZE_PER_INTERVAL = 15000; // ~100 legacy transactions
/**
 * Minimum fee per byte (sat/byte) such that a transaction is not considered free.
 * @type {number}
 */
BaseConsensusAgent.TRANSACTION_RELAY_FEE_MIN = 1;
/**
 * Number of ms the peer may send non-matching transactions/blocks after a subscription change.
 * @type {number}
 */
BaseConsensusAgent.SUBSCRIPTION_CHANGE_GRACE_PERIOD = 1000 * 3;
BaseConsensusAgent.HEAD_REQUEST_INTERVAL = 1000 * 100; // 100 seconds, give client time to announce new head without request
BaseConsensusAgent.KNOWS_OBJECT_AFTER_INV_DELAY = 1000 * 3;

BaseConsensusAgent.KNOWN_OBJECTS_COUNT_MAX = 40000;
Class.register(BaseConsensusAgent);

class FreeTransactionVector {
    /**
     * @param {InvVector} inv
     * @param {number} serializedSize
     */
    constructor(inv, serializedSize) {
        this._inv = inv;
        this._serializedSize = serializedSize;
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this._inv.hashCode();
    }

    /**
     * @returns {string}
     */
    toString() {
        return this._inv.toString();
    }

    /** @type {InvVector} */
    get inv() {
        return this._inv;
    }

    /** @type {number} */
    get serializedSize() {
        return this._serializedSize;
    }
}

/**
 * @abstract
 */
class BaseConsensus extends Observable {
    /**
     * @param {BaseChain} blockchain
     * @param {Observable} mempool
     * @param {Network} network
     */
    constructor(blockchain, mempool, network) {
        super();
        /** @type {BaseChain} */
        this._blockchain = blockchain;
        /** @type {Network} */
        this._network = network;

        /** @type {HashMap.<Peer,BaseConsensusAgent>} */
        this._agents = new HashMap();

        /** @type {Timers} */
        this._timers = new Timers();

        /**
         * @type {boolean}
         * @protected
         */
        this._established = false;

        /** @type {Peer} */
        this._syncPeer = null;

        /** @type {Subscription} */
        this._subscription = Subscription.ANY;

        /** @type {InvRequestManager} */
        this._invRequestManager = new InvRequestManager();

        /** @type {Set.<{obj: Observable, type: string, id: number}>} */
        this._listenersToDisconnect = new Set();

        this._onToDisconnect(network, 'peer-joined', peer => this._onPeerJoined(peer));
        this._onToDisconnect(network, 'peer-left', peer => this._onPeerLeft(peer));

        // Notify peers when our blockchain head changes.
        this._onToDisconnect(blockchain, 'head-changed', head => this._onHeadChanged(head));
        this._onToDisconnect(blockchain, 'rebranched', (revertBlocks, forkBlocks, blockHash) => this._onRebranched(blockHash, revertBlocks, forkBlocks));
        this._onToDisconnect(blockchain, 'extended', (blockHash) => this._onExtended(blockHash));
        this._onToDisconnect(blockchain, 'block', (blockHash) => this.fire('block', blockHash));

        // Relay new (verified) transactions to peers.
        this._onToDisconnect(mempool,'transaction-added', tx => this._onTransactionAdded(tx));
        this._onToDisconnect(mempool,'transaction-removed', tx => this._onTransactionRemoved(tx));
    }

    //
    // Public consensus interface
    //

    /**
     * @returns {Promise.<Hash>}
     */
    async getHeadHash() { // eslint-disable-line require-await
        return this._blockchain.headHash;
    }

    /**
     * @returns {Promise.<number>}
     */
    async getHeadHeight() { // eslint-disable-line require-await
        return this._blockchain.height;
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeBody = true]
     * @param {boolean} [includeBodyFromLocal]
     * @param {number} [blockHeight]
     * @returns {Promise.<Block>}
     */
    async getBlock(hash, includeBody = true, includeBodyFromLocal = includeBody, blockHeight) {
        let block = await this._blockchain.getBlock(hash, true, includeBody || includeBodyFromLocal);
        // XXX: Fetches full blocks if no peer supports protocol version 2 and it would be full from local.
        includeBody = includeBody || (includeBodyFromLocal && !this._hasPeersWithVersion(2));
        if (!block || (includeBody && !block.isFull())) {
            block = await this._requestBlock(hash, includeBody, block ? block.height : blockHeight, !!block) || block;
        }
        return block;
    }

    /**
     * @param {number} height
     * @param {boolean} [includeBody = true]
     * @returns {Promise.<Block>}
     */
    async getBlockAt(height, includeBody = true) {
        if (height > this._blockchain.height || height < 1) {
            throw new Error('Invalid height');
        }
        let block = await this._blockchain.getBlockAt(height, includeBody);
        if (!block) {
            block = await this._requestBlockAt(height, includeBody);
        } else if (block && includeBody && !block.isFull()) {
            block = await this._requestBlock(block.hash(), includeBody, height, true) || block;
        }
        return block;
    }

    /**
     * @param {Address} minerAddress
     * @param {Uint8Array} [extraData]
     * @returns {Promise.<Block>}
     */
    async getBlockTemplate(minerAddress, extraData) { // eslint-disable-line require-await, no-unused-vars
        throw new Error('not implemented: getBlockTemplate');
    }

    /**
     * @param {Block} block
     * @returns {Promise.<boolean>}
     */
    async submitBlock(block) { // eslint-disable-line require-await, no-unused-vars
        throw new Error('not implemented: submitBlock');
    }

    /**
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Account>>}
     * @abstract
     */
    async getAccounts(addresses) { // eslint-disable-line require-await, no-unused-vars
        throw new Error('not implemented: getAccounts');
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     */
    getPendingTransactions(hashes) {
        return this._requestPendingTransactions(hashes);
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactionsByAddress(address, limit) { // eslint-disable-line require-await, no-unused-vars
        throw new Error('not implemented: getPendingTransactionsByAddress');
    }

    /**
     * @param {Array.<Hash>} hashes
     * @param {Hash} blockHash
     * @param {number} [blockHeight]
     * @param {Block} [block]
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getTransactionsFromBlock(hashes, blockHash, blockHeight, block) {
        if (!block) {
            block = await this.getBlock(blockHash, false, true, blockHeight);
        }
        if (block && block.isFull()) {
            // Just search the block
            return block.transactions.filter(tx => hashes.find(hash => hash.equals(tx.hash())));
        } else {
            return this._requestTransactionsByHashes(hashes, block);
        }
    }

    /**
     * @param {Array.<Address>} addresses
     * @param {Hash} blockHash
     * @param {number} [blockHeight]
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getTransactionsFromBlockByAddresses(addresses, blockHash, blockHeight) {
        let block = await this._blockchain.getBlock(blockHash, false, true);
        if (!block) {
            block = this._requestBlock(blockHash, false, blockHeight);
        }
        if (block && block.isFull()) {
            // Just search the block
            return block.transactions.filter(tx => !!addresses.find(a => a.equals(tx.sender) || a.equals(tx.recipient)));
        } else {
            return this._requestTransactionsByAddresses(addresses, block);
        }
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    getTransactionReceiptsByAddress(address, limit) {
        return this._requestTransactionReceiptsByAddress(address, limit);
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    getTransactionReceiptsByHashes(hashes) {
        return this._requestTransactionReceiptsByHashes(hashes);
    }

    /**
     * @param {Transaction} tx
     * @returns {Promise.<BaseConsensus.SendTransactionResult>}
     * @abstract
     */
    async sendTransaction(tx) { // eslint-disable-line no-unused-vars, require-await
        throw new Error('not implemented: sendTransaction');
    }

    /**
     * @returns {Array.<Transaction>}
     */
    getMempoolContents() {
        return [];
    }

    //
    //

    /**
     * @param {Observable} obj
     * @param {string} type
     * @param {function} callback
     * @protected
     */
    _onToDisconnect(obj, type, callback) {
        const id = obj.on(type, callback);
        this._listenersToDisconnect.add({obj, type, id});
    }

    /**
     * @protected
     */
    _disconnectListeners() {
        for (const listener of this._listenersToDisconnect) {
            listener.obj.off(listener.type, listener.id);
        }
        this._offAll();
    }

    /**
     * @param {BaseConsensus} consensus
     * @returns {BaseConsensus}
     */
    handoverTo(consensus) {
        this._disconnectListeners();
        for (const agent of this._agents.valueIterator()) {
            const peer = agent.peer;
            agent.shutdown();
            this._onPeerLeft(peer);
            consensus._onPeerJoined(peer);
        }
        return consensus;
    }

    /**
     * @param {number} version
     * @returns {boolean}
     * @private
     */
    _hasPeersWithVersion(version) {
        for (const agent of this._agents.valueIterator()) {
            if (agent.peer.version >= version) {
                return true;
            }
        }
        return false;
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeBody = false]
     * @param {?number} [blockHeight]
     * @param {boolean} [proven = false]
     * @returns {Promise.<?Block>}
     */
    async _requestBlock(hash, includeBody = false, blockHeight, proven) {
        /** @type {Block} */
        let block = null;
        if (includeBody || !blockHeight) {
            /** @type {Array.<BaseConsensusAgent>} */
            const agents = [];
            const requiresHistory = !blockHeight || blockHeight < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION;
            for (const agent of this._agents.valueIterator()) {
                if (agent.synced && agent.providesServices(Services.FULL_BLOCKS) && (!requiresHistory || agent.providesServices(Services.BLOCK_HISTORY))) {
                    agents.push(agent);
                }
            }

            // Try agents first that (we think) know the block hash.
            agents.sort((a, b) =>
                a.knowsBlock(hash) !== b.knowsBlock(hash)
                    ? -a.knowsBlock(hash) + 0.5
                    : Math.random() - 0.5);

            for (const agent of agents) {
                try {
                    block = await agent.requestBlock(hash); // eslint-disable-line no-await-in-loop
                    if (block) break;
                } catch (e) {
                    Log.w(BaseConsensus, `Failed to retrieve block for ${hash} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                    // Try the next peer.
                }
            }
            if (!block) {
                throw new Error(`Failed to retrieve block for ${hash}`);
            }
            if (!proven) await this._requestBlockProof(hash, block.height);
            return block;
        } else {
            // TODO: Should block be proven?
            return this._requestBlockProof(hash, blockHeight);
        }
    }

    /**
     * @param {number} blockHeight
     * @param {boolean} [includeBody=false]
     * @returns {Promise.<?Block>}
     */
    async _requestBlockAt(blockHeight, includeBody) {
        /** @type {Block} */
        const block = await this._requestBlockProofAt(blockHeight);
        if (includeBody && !block.isFull()) {
            const hash = block.hash();
            /** @type {Array.<BaseConsensusAgent>} */
            const agents = [];
            const requiresHistory = blockHeight < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION;
            for (const agent of this._agents.valueIterator()) {
                if (agent.synced && agent.providesServices(Services.FULL_BLOCKS) && (!requiresHistory || agent.providesServices(Services.BLOCK_HISTORY))) {
                    agents.push(agent);
                }
            }

            // Try agents first that (we think) know the block hash.
            agents.sort((a, b) =>
                a.knowsBlock(hash) !== b.knowsBlock(hash)
                    ? -a.knowsBlock(hash) + 0.5
                    : Math.random() - 0.5);

            for (const agent of agents) {
                try {
                    return await agent.requestBlock(hash); // eslint-disable-line no-await-in-loop
                } catch (e) {
                    Log.w(BaseConsensus, `Failed to retrieve block for ${hash}@${blockHeight} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                    // Try the next peer.
                }
            }
            throw new Error(`Failed to retrieve block for ${hash}@${blockHeight}`);
        }
        return block;
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     */
    _requestPendingTransactions(hashes) {
        return Promise.all(hashes.map(hash => this._requestPendingTransaction(hash)));
    }

    /**
     * @param {Hash} hash
     * @return {Promise.<?Transaction>}
     * @private
     */
    async _requestPendingTransaction(hash) {
        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.MEMPOOL)) {
                agents.push(agent);
            }
        }

        // Try agents first that (we think) know the transaction hash.
        agents.sort((a, b) =>
            a.knowsTransaction(hash) !== b.knowsTransaction(hash)
                ? -a.knowsTransaction(hash) + 0.5
                : Math.random() - 0.5);

        for (const agent of agents) {
            try {
                const tx = await agent.requestTransaction(hash); // eslint-disable-line no-await-in-loop
                if (tx) return tx;
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve pending transaction for ${hash} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested transaction, fail.
        throw new Error(`Failed to retrieve pending transaction for ${hash}`);
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    async _requestTransactionReceiptsByHashes(hashes) {
        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.TRANSACTION_INDEX) && agent.peer.version >= 2) {
                agents.push(agent);
            }
        }

        for (const agent of agents) {
            try {
                return await agent.getTransactionReceiptsByHashes(hashes); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve transaction receipts for ${hashes} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested transaction receipts, fail.
        throw new Error(`Failed to retrieve transaction receipts for ${hashes}`);
    }

    /**
     * @param {Array.<Hash>} hashes
     * @param {Block} block
     * @returns {Promise.<Array.<Transaction>>}
     */
    async _requestTransactionsByHashes(hashes, block) {
        // TODO: Use the agent that provided the receipt
        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        const requiresHistory = block.height < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION;
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.BODY_PROOF) && (!requiresHistory || agent.providesServices(Services.BLOCK_HISTORY)) && agent.peer.version >= 2) {
                agents.push(agent);
            }
        }

        // Try agents first that (we think) know the reference block hash.
        const knownBlockHash = block.hash();
        agents.sort((a, b) =>
            a.knowsBlock(knownBlockHash) !== b.knowsBlock(knownBlockHash)
                ? -a.knowsBlock(knownBlockHash) + 0.5
                : Math.random() - 0.5);

        for (const agent of agents) {
            try {
                return await agent.getTransactionsProofByHashes(block, hashes); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve transactions for ${hashes} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested transactions, fail.
        throw new Error(`Failed to retrieve transactions for ${hashes}`);
    }

    /**
     * @param {Subscription} subscription
     */
    subscribe(subscription) {
        this._subscription = subscription;
        for (const /** @type {BaseConsensusAgent} */ agent of this._agents.valueIterator()) {
            agent.subscribe(subscription);
        }
    }

    /**
     * @returns {Subscription}
     */
    getSubscription() {
        return this._subscription;
    }

    /**
     * @param {Peer} peer
     * @returns {BaseConsensusAgent}
     * @protected
     */
    _newConsensusAgent(peer) { // eslint-disable-line no-unused-vars
        throw new Error('not implemented');
    }

    /**
     * @param {Peer} peer
     * @returns {BaseConsensusAgent}
     * @protected
     */
    _onPeerJoined(peer) {
        // Create a ConsensusAgent for each peer that connects.
        const agent = this._newConsensusAgent(peer);
        this._agents.put(peer.id, agent);

        // Register agent event listeners.
        agent.on('close', () => this._onPeerLeft(agent.peer));
        agent.on('sync', () => this._onPeerSynced(agent.peer));
        agent.on('out-of-sync', () => this._onPeerOutOfSync(agent.peer));
        this.bubble(agent, 'transaction-relayed');

        // If no more peers connect within the specified timeout, start syncing.
        this._timers.resetTimeout('sync', this._syncBlockchain.bind(this), BaseConsensus.SYNC_THROTTLE);

        return agent;
    }

    /**
     * @param {Peer} peer
     * @protected
     */
    _onPeerLeft(peer) {
        // Reset syncPeer if it left during the sync.
        if (peer.equals(this._syncPeer)) {
            Log.d(BaseConsensus, `Peer ${peer.peerAddress} left during sync`);
            this._syncPeer = null;
            this.fire('sync-failed', peer.peerAddress);
        }

        this._agents.remove(peer.id);
        this._syncBlockchain();
    }

    /**
     * @protected
     */
    _syncBlockchain() {
        const candidates = [];
        let numSyncedFullNodes = 0;
        for (const /** @type {BaseConsensusAgent} */ agent of this._agents.valueIterator()) {
            if (!agent.synced) {
                candidates.push(agent);
            } else if (Services.isFullNode(agent.peer.peerAddress.services)) {
                numSyncedFullNodes++;
            }
        }

        // Report consensus-lost if we are synced with less than the minimum number of full nodes or have no connections at all.
        if (this._established && (numSyncedFullNodes < BaseConsensus.MIN_FULL_NODES || this._agents.length === 0)) {
            this._established = false;
            this.fire('lost');
        }

        // Wait for ongoing sync to finish.
        if (this._syncPeer) {
            return;
        }

        // Choose a random peer which we aren't sync'd with yet.
        const agent = ArrayUtils.randomElement(candidates);
        if (!agent) {
            // We are synced with all connected peers.

            // Report consensus-established if we are connected to the minimum number of full nodes.
            if (this._hasEnoughPeers(numSyncedFullNodes, this._agents.length)) {
                if (!this._established) {
                    Log.i(BaseConsensus, `Synced with all connected peers (${this._agents.length}), consensus established.`);
                    Log.d(BaseConsensus, `Blockchain: height=${this._blockchain.height}, headHash=${this._blockchain.headHash}`);

                    // Report consensus-established.
                    this._established = true;
                    this.fire('established');

                    // Allow inbound network connections after establishing consensus.
                    this._network.allowInboundConnections = true;
                }
            }
            // Otherwise, wait until more peer connections are established.
            else {
                this.fire('waiting');
            }

            return;
        }

        this._syncPeer = agent.peer;

        // Notify listeners when we start syncing and have not established consensus yet.
        if (!this._established) {
            this.fire('syncing');
        }

        Log.v(BaseConsensus, `Syncing blockchain with peer ${agent.peer.peerAddress}`);
        agent.syncBlockchain().catch(Log.e.tag(BaseConsensusAgent));
    }

    /**
     * @param {number} numSyncedFullNodes
     * @param {number} numSyncedNodes
     * @return {boolean}
     * @protected
     */
    _hasEnoughPeers(numSyncedFullNodes, numSyncedNodes) { // eslint-disable-line no-unused-vars
        return numSyncedFullNodes >= BaseConsensus.MIN_FULL_NODES;
    }

    /**
     * @param {Peer} peer
     * @protected
     */
    _onPeerSynced(peer) {
        // Reset syncPeer if we finished syncing with it.
        if (peer.equals(this._syncPeer)) {
            Log.v(BaseConsensus, `Finished sync with peer ${peer.peerAddress}`);
            this._syncPeer = null;
        }
        this._syncBlockchain();
    }

    /**
     * @param {Peer} peer
     * @protected
     */
    _onPeerOutOfSync(peer) {
        Log.w(BaseConsensus, `Peer ${peer.peerAddress} out of sync, resyncing`);
        this._syncBlockchain();
    }

    /**
     * @param {Block} head
     * @protected
     */
    _onHeadChanged(head) {
        // Don't announce head changes if we are not synced yet.
        if (!this._established) return;

        for (const agent of this._agents.valueIterator()) {
            agent.relayBlock(head);
        }
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Block>} revertBlocks
     * @param {Array.<Block>} forkBlocks
     * @private
     */
    async _onRebranched(blockHash, revertBlocks, forkBlocks) {
        await this.fire('head-changed', blockHash, 'rebranched', revertBlocks, forkBlocks);
    }

    /**
     * @param {Block} block
     * @private
     */
    async _onExtended(block) {
        await this.fire('head-changed', block.hash(), 'extended', [], [block]);
    }

    /**
     * @param {Transaction} tx
     * @protected
     */
    _onTransactionAdded(tx) {
        this.fire('transaction-added', tx);

        // Don't relay transactions if we are not synced yet.
        if (!this._established) return;

        for (const agent of this._agents.valueIterator()) {
            agent.relayTransaction(tx);
        }
    }

    /**
     * @param {Transaction} tx
     * @protected
     */
    _onTransactionRemoved(tx) {
        this.fire('transaction-removed', tx);

        for (const agent of this._agents.valueIterator()) {
            agent.removeTransaction(tx);
        }
    }

    /**
     * @param {Hash} blockHashToProve
     * @param {number} blockHeightToProve
     * @returns {Promise.<Block>}
     * @protected
     */
    async _requestBlockProof(blockHashToProve, blockHeightToProve) {
        /** @type {Block} */
        const knownBlock = await this._blockchain.getNearestBlockAt(blockHeightToProve, /*lower*/ false);
        if (!knownBlock) {
            throw new Error('No suitable reference block found for block proof');
        }

        if (blockHashToProve.equals(knownBlock.hash())) {
            return knownBlock;
        }

        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        const requiresHistory = blockHeightToProve < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION ||
            knownBlock.height < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION;
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.BLOCK_PROOF) && (!requiresHistory || agent.providesServices(Services.BLOCK_HISTORY))) {
                agents.push(agent);
            }
        }

        // Try agents first that (we think) know the reference block hash.
        const knownBlockHash = knownBlock.hash();
        agents.sort((a, b) =>
            a.knowsBlock(knownBlockHash) !== b.knowsBlock(knownBlockHash)
                ? -a.knowsBlock(knownBlockHash) + 0.5
                : Math.random() - 0.5);

        for (const agent of agents) {
            try {
                return await agent.getBlockProof(blockHashToProve, knownBlock); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve block proof for ${blockHashToProve}@${blockHeightToProve} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested block proof, fail.
        throw new Error(`Failed to retrieve block proof for ${blockHashToProve}`);
    }

    /**
     * @param {number} blockHeightToProve
     * @returns {Promise.<Block>}
     * @protected
     */
    async _requestBlockProofAt(blockHeightToProve) {
        /** @type {Block} */
        const knownBlock = await this._blockchain.getNearestBlockAt(blockHeightToProve, /*lower*/ false);
        if (!knownBlock) {
            throw new Error('No suitable reference block found for block proof');
        }

        if (blockHeightToProve === knownBlock.height) {
            return knownBlock;
        }

        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        const requiresHistory = blockHeightToProve < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION ||
            knownBlock.height < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION;
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.BLOCK_PROOF) && (!requiresHistory || agent.providesServices(Services.BLOCK_HISTORY)) && agent.peer.version >= 2) {
                agents.push(agent);
            }
        }

        // Try agents first that (we think) know the reference block hash.
        const knownBlockHash = knownBlock.hash();
        agents.sort((a, b) =>
            a.knowsBlock(knownBlockHash) !== b.knowsBlock(knownBlockHash)
                ? -a.knowsBlock(knownBlockHash) + 0.5
                : Math.random() - 0.5);

        for (const agent of agents) {
            try {
                return await agent.getBlockProofAt(blockHeightToProve, knownBlock); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve block proof at ${blockHeightToProve} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested block proof, fail.
        throw new Error(`Failed to retrieve block proof at ${blockHeightToProve}`);
    }

    /**
     * @param {Array.<Address>} addresses
     * @param {Block} [block]
     * @returns {Promise.<Array<Transaction>>}
     * @protected
     */
    async _requestTransactionsByAddresses(addresses, block = this._blockchain.head) {
        if (addresses.length === 0) {
            return [];
        }

        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        const requiresHistory = block.height < this._blockchain.height - Policy.NUM_BLOCKS_VERIFICATION;
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.BODY_PROOF) && (!requiresHistory || agent.providesServices(Services.BLOCK_HISTORY))) {
                agents.push(agent);
            }
        }

        // Try agents first that (we think) know the reference block hash.
        const blockHash = block.hash();
        agents.sort((a, b) =>
            a.knowsBlock(blockHash) !== b.knowsBlock(blockHash)
                ? -a.knowsBlock(blockHash) + 0.5
                : Math.random() - 0.5);

        for (const agent of agents) {
            try {
                return await agent.getTransactionsProofByAddresses(block, addresses); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve transactions proof for ${addresses} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested transactions proof, fail.
        throw new Error(`Failed to retrieve transactions proof for ${addresses}`);
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<TransactionReceipt>>}
     * @protected
     */
    async _requestTransactionReceiptsByAddress(address, limit) {
        /** @type {Array.<BaseConsensusAgent>} */
        const agents = [];
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && agent.providesServices(Services.TRANSACTION_INDEX)) {
                agents.push(agent);
            }
        }
        agents.sort(() => Math.random() - 0.5);

        for (const agent of agents) {
            try {
                return await agent.getTransactionReceiptsByAddress(address, limit); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseConsensus, `Failed to retrieve transaction receipts for ${address} from ${agent.peer.peerAddress}: ${e && e.message || e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested receipts, fail.
        throw new Error(`Failed to retrieve transaction receipts for ${address}`);
    }

    /**
     * @param {Address} address
     * @returns {Promise.<Array.<{transaction: Transaction, header: BlockHeader}>>}
     * @protected
     * @deprecated
     */
    async _requestTransactionHistory(address) {
        // 1. Get transaction receipts.
        const receipts = await this._requestTransactionReceiptsByAddress(address);

        // 2. Request proofs for missing blocks.
        /** @type {Array.<Promise.<Block>>} */
        const blockRequests = [];
        let lastBlockHash = null;
        for (const receipt of receipts) {
            if (!receipt.blockHash.equals(lastBlockHash)) {
                // eslint-disable-next-line no-await-in-loop
                const block = await this._blockchain.getBlock(receipt.blockHash);
                if (block) {
                    blockRequests.push(Promise.resolve(block));
                } else {
                    const request = this._requestBlockProof(receipt.blockHash, receipt.blockHeight)
                        .catch(e => Log.e(BaseConsensus, `Failed to retrieve proof for block ${receipt.blockHash}`
                            + ` (${e}) - transaction history may be incomplete`));
                    blockRequests.push(request);
                }

                lastBlockHash = receipt.blockHash;
            }
        }
        const blocks = await Promise.all(blockRequests);

        // 3. Request transaction proofs.
        const transactionRequests = [];
        for (const block of blocks) {
            if (!block) continue;

            const request = this._requestTransactionsByAddresses([address], block)
                .then(txs => txs.map(tx => ({ transaction: tx, header: block.header })))
                .catch(e => Log.e(BaseConsensus, `Failed to retrieve transactions for block ${block.hash()}`
                    + ` (${e}) - transaction history may be incomplete`));
            transactionRequests.push(request);
        }

        const transactions = await Promise.all(transactionRequests);
        return transactions
            .reduce((flat, it) => it ? flat.concat(it) : flat, [])
            .sort((a, b) => a.header.height - b.header.height);
    }

    /** @type {boolean} */
    get established() {
        return this._established;
    }

    /** @type {Network} */
    get network() {
        return this._network;
    }

    /** @type {InvRequestManager} */
    get invRequestManager() {
        return this._invRequestManager;
    }
}
BaseConsensus.MAX_ATTEMPTS_TO_FETCH = 5;
BaseConsensus.SYNC_THROTTLE = 1500; // ms
BaseConsensus.MIN_FULL_NODES = 1;
BaseConsensus.TRANSACTION_RELAY_TIMEOUT = 10000;
BaseConsensus.SendTransactionResult = {
    REJECTED_LOCAL: -4,
    EXPIRED: -3,
    ALREADY_MINED: -2,
    INVALID: -1,
    NONE: 0,
    RELAYED: 1,
    KNOWN: 2,
    PENDING_LOCAL: 3,
};
Class.register(BaseConsensus);

/**
 * @abstract
 */
class BaseMiniConsensusAgent extends BaseConsensusAgent {
    /**
     * @param {BaseChain} blockchain
     * @param {NanoMempool} mempool
     * @param {Time} time
     * @param {Peer} peer
     * @param {InvRequestManager} invRequestManager
     * @param {Subscription} [targetSubscription]
     */
    constructor(blockchain, mempool, time, peer, invRequestManager, targetSubscription) {
        super(time, peer, invRequestManager, targetSubscription);

        /** @type {BaseChain} */
        this._blockchain = blockchain;
        /** @type {NanoMempool} */
        this._mempool = mempool;

        this._subscribeTarget();

        // Helper object to keep track of the accounts we're requesting from the peer.
        this._accountsRequest = null;
        this._onToDisconnect(peer.channel, 'accounts-proof', msg => this._onAccountsProof(msg));
    }

    requestMempool() {
        // Request the peer's mempool.
        // XXX Use a random delay here to prevent requests to multiple peers at once.
        const delay = BaseMiniConsensusAgent.MEMPOOL_DELAY_MIN
            + Math.random() * (BaseMiniConsensusAgent.MEMPOOL_DELAY_MAX - BaseMiniConsensusAgent.MEMPOOL_DELAY_MIN);
        setTimeout(() => this._peer.channel.mempool(), delay);
    }


    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Account>>}
     */
    getAccounts(blockHash, addresses) {
        return this._synchronizer.push('getAccounts',
            this._getAccounts.bind(this, blockHash, addresses));
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array<Account>>}
     * @private
     */
    async _getAccounts(blockHash, addresses) {
        Assert.that(this._accountsRequest === null);

        const block = await this._blockchain.getBlock(blockHash);
        if (!block) {
            throw new Error('Unknown block hash');
        }

        Log.d(BaseMiniConsensusAgent, `Requesting AccountsProof for ${addresses} from ${this._peer.peerAddress}`);

        return new Promise((resolve, reject) => {
            this._accountsRequest = {
                addresses,
                block,
                resolve,
                reject
            };

            // Request AccountsProof from peer.
            this._peer.channel.getAccountsProof(blockHash, addresses);

            // Drop the peer if it doesn't send the accounts proof within the timeout.
            this._peer.channel.expectMessage(Message.Type.ACCOUNTS_PROOF, () => {
                this._peer.channel.close(CloseType.GET_ACCOUNTS_PROOF_TIMEOUT, 'getAccountsProof timeout');
                reject(new Error('Timeout'));
            }, BaseMiniConsensusAgent.ACCOUNTSPROOF_REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {AccountsProofMessage} msg
     * @returns {Promise.<void>}
     * @private
     */
    async _onAccountsProof(msg) {
        Log.d(BaseMiniConsensusAgent, `[ACCOUNTS-PROOF] Received from ${this._peer.peerAddress}: blockHash=${msg.blockHash}, proof=${msg.proof} (${msg.serializedSize} bytes)`);

        // Check if we have requested an accounts proof, discard unsolicited ones.
        if (!this._accountsRequest) {
            Log.w(BaseMiniConsensusAgent, `Unsolicited accounts proof received from ${this._peer.peerAddress}`);
            return;
        }

        // Reset accountsRequest.
        const {addresses, /** @type {Block} */ block, resolve, reject} = this._accountsRequest;
        this._accountsRequest = null;

        if (!msg.hasProof()) {
            reject(new Error('Accounts request was rejected'));
            return;
        }

        // Check that the reference block corresponds to the one we requested.
        const blockHash = block.hash();
        if (!blockHash.equals(msg.blockHash)) {
            Log.w(BaseMiniConsensusAgent, `Received AccountsProof for invalid reference block from ${this._peer.peerAddress}`);
            reject(new Error('Invalid reference block'));
            return;
        }

        // Verify the proof.
        const proof = msg.proof;
        if (!proof.verify()) {
            Log.w(BaseMiniConsensusAgent, `Invalid AccountsProof received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_ACCOUNTS_PROOF, 'Invalid AccountsProof');
            reject(new Error('Invalid AccountsProof'));
            return;
        }

        // Check that the proof root hash matches the accountsHash in the reference block.
        const rootHash = proof.root();
        if (!block.accountsHash.equals(rootHash)) {
            Log.w(BaseMiniConsensusAgent, `Invalid AccountsProof (root hash) received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_ACCOUNTS_PROOF, 'AccountsProof root hash mismatch');
            reject(new Error('AccountsProof root hash mismatch'));
            return;
        }

        // Check that all requested accounts are part of this proof.
        // XXX return a map address -> account instead?
        const accounts = [];
        for (const address of addresses) {
            try {
                const account = proof.getAccount(address);
                accounts.push(account);
            } catch (e) {
                Log.w(BaseMiniConsensusAgent, `Incomplete AccountsProof received from ${this._peer.peerAddress}`);
                this._peer.channel.close(CloseType.INVALID_ACCOUNTS_PROOF, 'Incomplete AccountsProof');
                reject(new Error('Incomplete AccountsProof'));
                return;
            }
        }

        // Return the retrieved accounts.
        resolve(accounts);
    }

    /**
     * @returns {Iterable.<Transaction>}
     * @protected
     * @override
     */
    _getSubscribedMempoolTransactions() {
        switch (this._remoteSubscription.type) {
            case Subscription.Type.ADDRESSES:
                return this._mempool.getTransactionsByAddresses(this._remoteSubscription.addresses, BaseMiniConsensusAgent.MEMPOOL_ENTRIES_MAX);
            case Subscription.Type.MIN_FEE:
                return this._mempool.getTransactions().filter((tx) => tx.feePerByte >= this._remoteSubscription.minFeePerByte);
            case Subscription.Type.ANY:
                return this._mempool.getTransactions(BaseMiniConsensusAgent.MEMPOOL_ENTRIES_MAX);
        }
        return [];
    }
}
/**
 * Maximum time (ms) to wait for accounts-proof after sending out get-accounts-proof before dropping the peer.
 * @type {number}
 */
BaseMiniConsensusAgent.ACCOUNTSPROOF_REQUEST_TIMEOUT = 1000 * 5;
/**
 * Minimum time {ms} to wait before triggering the initial mempool request.
 * @type {number}
 */
BaseMiniConsensusAgent.MEMPOOL_DELAY_MIN = 500; // 0.5 seconds
/**
 * Maximum time {ms} to wait before triggering the initial mempool request.
 * @type {number}
 */
BaseMiniConsensusAgent.MEMPOOL_DELAY_MAX = 1000 * 5; // 5 seconds
/**
 * Number of transaction vectors to send
 * @type {number}
 */
BaseMiniConsensusAgent.MEMPOOL_ENTRIES_MAX = 1000;
Class.register(BaseMiniConsensusAgent);

/**
 * @abstract
 */
class BaseMiniConsensus extends BaseConsensus {
    /**
     * @param {BaseChain} blockchain
     * @param {Observable} mempool
     * @param {Network} network
     */
    constructor(blockchain, mempool, network) {
        super(blockchain, mempool, network);

        /** @type {BaseChain} */
        this._blockchain = blockchain;
        /** @type {Observable} */
        this._mempool = mempool;

        /** @type {Subscription} */
        this._subscription = Subscription.BLOCKS_ONLY;
        this._onToDisconnect(this, 'head-changed', (hash, reason, reverted, adopted) => this._onNewAdoptedBlocks(adopted));
        this._onToDisconnect(mempool, 'transaction-mined', (tx, block) => this.fire('transaction-mined', tx, block, this._blockchain.head));
    }

    /**
     * @param {Array.<Address>} addresses
     * @deprecated
     */
    subscribeAccounts(addresses) {
        this.subscribe(Subscription.fromAddresses(addresses));
    }

    subscribe(subscription) {
        const oldSubscription = this._subscription;
        super.subscribe(subscription);
        if (subscription.type === Subscription.Type.ADDRESSES) {
            this._mempool.evictExceptAddresses(subscription.addresses);
        }
        if (!subscription.isSubsetOf(oldSubscription)) {
            for (const /** @type {BaseMiniConsensusAgent} */ agent of this._agents.valueIterator()) {
                agent.requestMempool();
            }
        }
    }

    /**
     * @param {Array.<Address>|Address} newAddresses
     * @deprecated
     */
    addSubscriptions(newAddresses) {
        newAddresses = Array.isArray(newAddresses) ? newAddresses : [newAddresses];
        const addresses = new HashSet();
        addresses.addAll(this._subscription.addresses);
        addresses.addAll(newAddresses);
        this.subscribeAccounts(addresses.values());
    }

    /**
     * @param {Array.<Address>|Address} addressesToRemove
     * @deprecated
     */
    removeSubscriptions(addressesToRemove) {
        addressesToRemove = Array.isArray(addressesToRemove) ? addressesToRemove : [addressesToRemove];
        const addresses = new HashSet();
        addresses.addAll(this._subscription.addresses);
        addresses.removeAll(addressesToRemove);
        this.subscribeAccounts(addresses.values());
    }

    /**
     * @param {Transaction} tx
     * @protected
     */
    _onTransactionAdded(tx) {
        this.fire('transaction-added', tx);
        // Don't relay transactions added to the mempool.
    }

    /**
     * @param {Array.<Block>} adoptedBlocks
     * @private
     */
    async _onNewAdoptedBlocks(adoptedBlocks) {
        if (!this._established) return;
        for (const block of adoptedBlocks) {
            try {
                const includedTransactions = await this._requestTransactionsByAddresses(this._subscription.addresses, block);
                await this._mempool.changeHead(block, includedTransactions);
            } catch (e) {
                Log.e(BaseMiniConsensus, `Failed to retrieve transaction proof to update mempool: ${e.message || e}`);
            }
        }
    }

    /**
     * @param {Address} address
     * @param {Hash} [blockHash]
     * @returns {Promise.<?Account>}
     */
    async getAccount(address, blockHash = null) {
        return (await this.getAccounts([address], blockHash))[0];
    }

    /**
     * @param {Array.<Address>} addresses
     * @param {Hash} [blockHash]
     * @returns {Promise.<Array.<Account>>}
     */
    async getAccounts(addresses, blockHash) {
        blockHash = blockHash ? blockHash : this._blockchain.headHash;

        /** @type {Array.<BaseMiniConsensusAgent>} */
        const agents = [];
        for (const agent of this._agents.valueIterator()) {
            if (agent.synced && Services.providesServices(agent.peer.peerAddress.services, Services.ACCOUNTS_PROOF)) {
                agents.push(agent);
            }
        }

        // Try agents first that (we think) know the block hash.
        agents.sort((a, b) =>
            a.knowsBlock(blockHash) !== b.knowsBlock(blockHash)
                ? -a.knowsBlock(blockHash) + 0.5
                : Math.random() - 0.5);

        for (const agent of agents) {
            try {
                return await agent.getAccounts(blockHash, addresses); // eslint-disable-line no-await-in-loop
            } catch (e) {
                Log.w(BaseMiniConsensus, `Failed to retrieve accounts ${addresses} from ${agent.peer.peerAddress}: ${e}`);
                // Try the next peer.
            }
        }

        // No peer supplied the requested account, fail.
        throw new Error(`Failed to retrieve accounts ${addresses}`);
    }

    /**
     * @param {Transaction} tx
     * @returns {Promise.<BaseConsensus.SendTransactionResult>}
     */
    async sendTransaction(tx) {
        try {
            await this.relayTransaction(tx);
            // Wait for transaction relay
            const relayed = await new Promise((resolve) => {
                let id;
                // eslint-disable-next-line prefer-const
                id = this.on('transaction-relayed', relayedTx => {
                    if (relayedTx.equals(tx)) {
                        this.off('transaction-relayed', id);
                        resolve(true);
                    }
                });
                setTimeout(() => {
                    this.off('transaction-relayed', id);
                    resolve(false);
                }, BaseConsensus.TRANSACTION_RELAY_TIMEOUT);
            });
            if (relayed) {
                return BaseConsensus.SendTransactionResult.RELAYED;
            } else {
                return BaseConsensus.SendTransactionResult.PENDING_LOCAL;
            }
        } catch (e) {
            Log.d(BaseMiniConsensus, () => `Error sending transaction ${tx}: ${e.message || e}`);
            if (e instanceof BaseMiniConsensus.MempoolRejectedError) {
                switch (e.mempoolReturnCode) {
                    case Mempool.ReturnCode.KNOWN:
                        return BaseConsensus.SendTransactionResult.KNOWN;
                    case Mempool.ReturnCode.INVALID:
                        return BaseConsensus.SendTransactionResult.INVALID;
                    case Mempool.ReturnCode.EXPIRED:
                        return BaseConsensus.SendTransactionResult.EXPIRED;
                }
            }
            try {
                this._mempool.removeTransaction(tx);
            } catch (e) {
                // Ignore
            }
            return BaseConsensus.SendTransactionResult.REJECTED_LOCAL;
        }
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactions(hashes) {
        const txs = new HashSet();
        for (const hash of hashes) {
            const tx = this._mempool.getTransaction(hash);
            txs.add(tx);
        }
        if (txs.length !== hashes.length) {
            txs.addAll(await this._requestPendingTransactions(hashes.filter(h => !txs.get(h))));
        }
        return /** @type {Array.<Transaction>} */ hashes.map(h => txs.get(h)).filter(tx => !!tx);
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactionsByAddress(address, limit) { // eslint-disable-line require-await
        if (this._subscription.addresses && this._subscription.addresses.some(a => a.equals(address))) {
            return this._mempool.getTransactionsByAddresses([address], limit);
        } else {
            throw new Error('Can not provide pending transactions without prior subscription');
        }
    }

    /**
     * @param {Transaction} transaction
     * @returns {Promise.<void>}
     */
    async relayTransaction(transaction) {
        // Store transaction in mempool.
        const mempoolCode = await this._mempool.pushTransaction(transaction);
        if (mempoolCode !== Mempool.ReturnCode.ACCEPTED) {
            throw new BaseMiniConsensus.MempoolRejectedError(mempoolCode);
        }

        // Relay transaction to all connected peers.
        let relayed = false;
        for (const agent of this._agents.valueIterator()) {
            relayed = (agent.relayTransaction(transaction) && agent.providesServices(Services.MEMPOOL)) || relayed;
        }

        // Fail if the transaction was not relayed.
        if (!relayed) {
            throw new Error('Failed to relay transaction - no agent relayed transaction');
        }
    }
}

BaseMiniConsensus.MempoolRejectedError = class extends Error {
    /**
     * @param {Mempool.ReturnCode} mempoolCode
     */
    constructor(mempoolCode) {
        super('Failed to relay transaction - mempool rejected transaction');
        this._mempoolReturnCode = mempoolCode;
    }

    /** @type {Mempool.ReturnCode} */
    get mempoolReturnCode() {
        return this._mempoolReturnCode;
    }
};

Class.register(BaseMiniConsensus);

/**
 * An anchored, contiguous chain of full blocks.
 */
class FullChain extends BaseChain {
    /**
     * @param {JungleDB} jdb
     * @param {Accounts} accounts
     * @param {Time} time
     * @param {TransactionStore} [transactionStore]
     * @returns {Promise.<FullChain>}
     */
    static getPersistent(jdb, accounts, time, transactionStore) {
        const store = ChainDataStore.getPersistent(jdb);
        const chain = new FullChain(store, accounts, time, transactionStore);
        return chain._init();
    }

    /**
     * @param {Accounts} accounts
     * @param {Time} time
     * @param {TransactionStore} [transactionStore]
     * @returns {Promise.<FullChain>}
     */
    static createVolatile(accounts, time, transactionStore) {
        const store = ChainDataStore.createVolatile();
        const chain = new FullChain(store, accounts, time, transactionStore);
        return chain._init();
    }

    /**
     * @param {ChainDataStore} store
     * @param {Accounts} accounts
     * @param {Time} time
     * @param {TransactionStore} [transactionStore]
     * @returns {FullChain}
     */
    constructor(store, accounts, time, transactionStore) {
        super(store);
        this._accounts = accounts;
        this._time = time;

        /** @type {HashMap.<Hash,Accounts>} */
        this._snapshots = new HashMap();
        /** @type {Array.<Hash>} */
        this._snapshotOrder = [];

        /** @type {ChainData} */
        this._mainChain = null;

        /** @type {ChainProof} */
        this._proof = null;

        /** @type {TransactionCache} */
        this._transactionCache = new TransactionCache();

        /** @type {TransactionStore} */
        this._transactionStore = transactionStore;

        /** @type {PrioritySynchronizer} */
        this._synchronizer = new PrioritySynchronizer(2, FullChain.SYNCHRONIZER_THROTTLE_AFTER, FullChain.SYNCHRONIZER_THROTTLE_WAIT);

        /** @type {number} */
        this._blockKnownCount = this._blockInvalidCount = this._blockOrphanCount = this._blockExtendedCount = this._blockRebranchedCount = this._blockForkedCount = 0;
    }

    /**
     * @returns {Promise.<FullChain>}
     * @protected
     */
    async _init() {
        this._headHash = await this._store.getHead();
        if (this._headHash) {
            // Check that the correct genesis block is stored.
            const genesis = await this._store.getChainData(GenesisConfig.GENESIS_HASH);
            if (!genesis || !genesis.onMainChain) {
                throw new Error('Invalid genesis block stored. Reset your consensus database.');
            }

            // Load main chain from store.
            this._mainChain = await this._store.getChainData(this._headHash, /*includeBody*/ true);
            Assert.that(!!this._mainChain, 'Failed to load main chain from storage');

            // Check that chain/accounts state is consistent.
            if (!this._mainChain.head.accountsHash.equals(await this._accounts.hash())) {
                throw new Error('Corrupted store: Inconsistent chain/accounts state');
            }

            // Initialize TransactionCache.
            const blocks = await this._store.getBlocksBackward(this.headHash, this._transactionCache.missingBlocks - 1, /*includeBody*/ true);
            this._transactionCache.prependBlocks([...blocks.reverse(), this._mainChain.head]);
        } else {
            // Initialize chain & accounts with Genesis block.
            this._mainChain = await ChainData.initial(GenesisConfig.GENESIS_BLOCK);
            this._headHash = GenesisConfig.GENESIS_HASH;

            const tx = this._store.synchronousTransaction();
            tx.putChainDataSync(GenesisConfig.GENESIS_HASH, this._mainChain);
            tx.setHeadSync(GenesisConfig.GENESIS_HASH);
            await tx.commit();

            await this._accounts.initialize(GenesisConfig.GENESIS_BLOCK, GenesisConfig.GENESIS_ACCOUNTS);
        }

        return this;
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     */
    pushBlock(block) {
        return this._synchronizer.push(/*priority*/ 0,
            this._pushBlock.bind(this, block));
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     * @protected
     */
    async _pushBlock(block) {
        // Check if we already know this block.
        const hash = block.hash();
        const knownBlock = await this._store.getBlock(hash);
        if (knownBlock) {
            this._blockKnownCount++;
            return FullChain.OK_KNOWN;
        }

        // Check that the given block is a full block (includes block body).
        if (!block.isFull()) {
            Log.w(FullChain, 'Rejecting block - body missing');
            this._blockInvalidCount++;
            return FullChain.ERR_INVALID;
        }

        // Check all intrinsic block invariants.
        if (!(await block.verify(this._time))) {
            this._blockInvalidCount++;
            return FullChain.ERR_INVALID;
        }

        // Check if the block's immediate predecessor is part of the chain.
        /** @type {ChainData} */
        const prevData = await this._store.getChainData(block.prevHash);
        if (!prevData) {
            Log.w(FullChain, 'Rejecting block - unknown predecessor');
            this._blockOrphanCount++;
            return FullChain.ERR_ORPHAN;
        }

        // Check that the block is a valid successor of its immediate predecessor.
        const predecessor = prevData.head;
        if (!(await block.isImmediateSuccessorOf(predecessor))) {
            Log.w(FullChain, 'Rejecting block - not a valid immediate successor');
            this._blockInvalidCount++;
            return FullChain.ERR_INVALID;
        }

        // Check that the difficulty is correct.
        const nextTarget = await this.getNextTarget(predecessor);
        Assert.that(BlockUtils.isValidTarget(nextTarget), 'Failed to compute next target in FullChain');
        if (block.nBits !== BlockUtils.targetToCompact(nextTarget)) {
            Log.w(FullChain, 'Rejecting block - difficulty mismatch');
            this._blockInvalidCount++;
            return FullChain.ERR_INVALID;
        }

        // Block looks good, create ChainData.
        const chainData = await prevData.nextChainData(block);

        // Check if the block extends our current main chain.
        if (block.prevHash.equals(this.headHash)) {
            // Append new block to the main chain.
            if (!(await this._extend(hash, chainData, prevData))) {
                this._blockInvalidCount++;
                return FullChain.ERR_INVALID;
            }
            this._blockExtendedCount++;
            return FullChain.OK_EXTENDED;
        }

        // Otherwise, check if the new chain is harder than our current main chain.
        if (chainData.totalDifficulty.gt(this.totalDifficulty)) {
            // A fork has become the hardest chain, rebranch to it.
            if (!(await this._rebranch(hash, chainData))) {
                this._blockInvalidCount++;
                return FullChain.ERR_INVALID;
            }
            this._blockRebranchedCount++;
            return FullChain.OK_REBRANCHED;
        }

        // Otherwise, we are creating/extending a fork. Store chain data.
        Log.v(FullChain, `Creating/extending fork with block ${hash}, height=${block.height}, totalDifficulty=${chainData.totalDifficulty}, totalWork=${chainData.totalWork}`);
        await this._store.putChainData(hash, chainData);

        this._blockForkedCount++;
        await this.fire('block', hash);
        return FullChain.OK_FORKED;
    }

    /**
     * @param {Block} block
     * @returns {Promise.<boolean>}
     * @protected
     */
    async _verifyInterlink(block) {
        // Check that all blocks referenced in the interlink of the given block are valid predecessors of that block.
        for (let i = 0; i < block.interlink.length; i++) {
            const predecessor = await this._store.getBlock(block.interlink.hashes[i]); // eslint-disable-line no-await-in-loop
            if (!predecessor || !(await block.isInterlinkSuccessorOf(predecessor))) { // eslint-disable-line no-await-in-loop
                return false;
            }
        }
        return true;
    }

    /**
     * @param {Hash} blockHash
     * @param {ChainData} chainData
     * @param {ChainData} prevData
     * @returns {Promise.<boolean>}
     * @fires FullChain#head-changed
     * @private
     */
    async _extend(blockHash, chainData, prevData) {
        const accountsTx = await this._accounts.transaction();
        try {
            await accountsTx.commitBlock(chainData.head, this._transactionCache);
        } catch (e) {
            // AccountsHash mismatch. This can happen if someone gives us an invalid block.
            Log.w(FullChain, `Rejecting block - failed to commit to AccountsTree: ${e.message || e}`);
            accountsTx.abort().catch(Log.w.tag(FullChain));
            return false;
        }

        chainData.onMainChain = true;
        prevData.mainChainSuccessor = blockHash;

        const storeTx = await this._store.synchronousTransaction();
        storeTx.putChainDataSync(blockHash, chainData);
        storeTx.putChainDataSync(chainData.head.prevHash, prevData, /*includeBody*/ false);
        storeTx.setHeadSync(blockHash);

        if (this._transactionStore) {
            const transactionStoreTx = this._transactionStore.transaction();
            await transactionStoreTx.put(chainData.head);
            await JDB.JungleDB.commitCombined(...storeTx.txs, accountsTx.tx, transactionStoreTx.tx);
        } else {
            await JDB.JungleDB.commitCombined(...storeTx.txs, accountsTx.tx);
        }

        // New block on main chain, so store a new snapshot.
        await this._saveSnapshot(blockHash);

        // Update transactions cache.
        this._transactionCache.pushBlock(chainData.head);

        if (this._shouldExtendChainProof() && this._proof) {
            // If we want to maintain our proof by extending it and have a cached proof, extend it.
            this._proof = await this._extendChainProof(this._proof, chainData.head.header);
        } else {
            // Otherwise, clear the proof and recompute it the next time it is needed.
            this._proof = null;
        }

        // Update head.
        this._mainChain = chainData;
        this._headHash = blockHash;

        // Tell listeners that the head of the chain has changed.
        await this.fire('head-changed', this.head, /*rebranching*/ false);
        await this.fire('block', blockHash);
        await this.fire('extended', this.head);

        return true;
    }

    /**
     * @returns {boolean}
     * @private
     */
    _shouldExtendChainProof() {
        return false;
    }

    /**
     * @param {Hash} blockHash
     * @param {ChainData} chainData
     * @returns {Promise.<boolean>}
     * @protected
     */
    async _rebranch(blockHash, chainData) {
        Log.v(FullChain, `Rebranching to fork ${blockHash}, height=${chainData.head.height}, totalDifficulty=${chainData.totalDifficulty}, totalWork=${chainData.totalWork}`);

        // Drop all snapshots.
        for (const hash of this._snapshotOrder) {
            const snapshot = this._snapshots.get(hash);
            snapshot.abort(); // We do not need to wait for the abortion as long as it has been triggered.
        }
        this._snapshots.clear();
        this._snapshotOrder = [];

        // Find the common ancestor between our current main chain and the fork chain.
        // Walk up the fork chain until we find a block that is part of the main chain.
        // Store the chain along the way.
        /** @type {Array.<ChainData>} */
        const forkChain = [];
        /** @type {Array.<Hash>} */
        const forkHashes = [];

        /** @type {ChainData} */
        let curData = chainData;
        /** @type {Hash} */
        let curHash = blockHash;
        while (!curData.onMainChain) {
            forkChain.push(curData);
            forkHashes.push(curHash);

            curHash = curData.head.prevHash;
            // TODO FIXME This can fail in the light client. It might not have the requested block at all or only the light block.
            curData = await this._store.getChainData(curHash, /*includeBody*/ true); // eslint-disable-line no-await-in-loop
            Assert.that(!!curData, 'Corrupted store: Failed to find fork predecessor while rebranching');
        }

        Log.v(FullChain, () => `Found common ancestor ${curHash.toBase64()} ${forkChain.length} blocks up`);

        /** @type {ChainData} */
        const ancestorData = curData;
        /** @type {Hash} */
        const ancestorHash = curHash;

        // Validate all accountsHashes on the fork. Revert the AccountsTree to the common ancestor state first.
        const accountsTx = await this._accounts.transaction(false);
        const transactionCacheTx = this._transactionCache.clone();
        // Also update transactions in index.
        const transactionStoreTx = this._transactionStore ? this._transactionStore.transaction() : null;

        /** @type {Array.<ChainData>} */
        const revertChain = [];
        /** @type {Hash} */
        let headHash = this._headHash;
        /** @type {ChainData} */
        let headData = this._mainChain;
        while (!headHash.equals(ancestorHash)) {
            try {
                // This only works in the light client if we revert less than Policy.TRANSACTION_VALIDITY_WINDOW blocks.
                await accountsTx.revertBlock(headData.head, transactionCacheTx);
                transactionCacheTx.revertBlock(headData.head);

                // Also update transactions in index.
                if (this._transactionStore) {
                    await transactionStoreTx.remove(headData.head);
                }
                revertChain.push(headData);
            } catch (e) {
                Log.e(FullChain, 'Failed to revert main chain while rebranching', e);
                accountsTx.abort().catch(Log.w.tag(FullChain));
                if (this._transactionStore) {
                    transactionStoreTx.abort().catch(Log.w.tag(FullChain));
                }
                return false;
            }

            headHash = headData.head.prevHash;
            headData = await this._store.getChainData(headHash, /*includeBody*/ true);
            Assert.that(!!headData, 'Corrupted store: Failed to find main chain predecessor while rebranching');
            Assert.that(headData.head.accountsHash.equals(await accountsTx.hash()), 'Failed to revert main chain - inconsistent state');
        }

        Assert.that(!transactionCacheTx.head || headHash.equals(transactionCacheTx.head.hash), 'Invalid TransactionCache head');

        // Try to fetch missing transactions for the cache.
        // TODO FIXME The light client might not have all necessary blocks.
        const numMissingBlocks = transactionCacheTx.missingBlocks;
        /** @type {Hash} */
        const startHash = transactionCacheTx.isEmpty()
            ? ancestorData.mainChainSuccessor
            : transactionCacheTx.tail.hash;
        const blocks = await this._store.getBlocksBackward(startHash, numMissingBlocks, /*includeBody*/ true);
        transactionCacheTx.prependBlocks(blocks.reverse());

        // Try to apply all fork blocks.
        for (let i = forkChain.length - 1; i >= 0; i--) {
            try {
                await accountsTx.commitBlock(forkChain[i].head, transactionCacheTx);
                transactionCacheTx.pushBlock(forkChain[i].head);

                // Also update transactions in index.
                if (this._transactionStore) {
                    await transactionStoreTx.put(forkChain[i].head);
                }
            } catch (e) {
                // A fork block is invalid.
                Log.e(FullChain, 'Failed to apply fork block while rebranching', e);
                accountsTx.abort().catch(Log.w.tag(FullChain));
                if (this._transactionStore) {
                    transactionStoreTx.abort().catch(Log.w.tag(FullChain));
                }

                // Delete invalid block and its successors from store.
                const chainTx = this._store.synchronousTransaction(false);
                for (; i >= 0; i--) {
                    chainTx.removeChainDataSync(forkHashes[i]);
                }
                await chainTx.commit();

                return false;
            }
        }

        // Fork looks good.
        // Unset onMainChain flag / mainChainSuccessor on the current main chain up to (excluding) the common ancestor.
        /** @type {ChainDataStore} */
        const chainTx = this._store.synchronousTransaction(false);
        for (const revertedData of revertChain) {
            revertedData.onMainChain = false;
            revertedData.mainChainSuccessor = null;
            chainTx.putChainDataSync(revertedData.head.hash(), revertedData, /*includeBody*/ false);
        }

        // Update the mainChainSuccessor of the common ancestor block.
        ancestorData.mainChainSuccessor = forkHashes[forkHashes.length - 1];
        chainTx.putChainDataSync(ancestorHash, ancestorData, /*includeBody*/ false);

        // Set onMainChain flag / mainChainSuccessor on the fork.
        for (let i = forkChain.length - 1; i >= 0; i--) {
            const forkData = forkChain[i];
            forkData.onMainChain = true;
            forkData.mainChainSuccessor = i > 0 ? forkHashes[i - 1] : null;
            // Include the body of the new block (at position 0).
            chainTx.putChainDataSync(forkHashes[i], forkData, /*includeBody*/ i === 0);
        }

        // Update head & commit transactions.
        chainTx.setHeadSync(blockHash);
        if (this._transactionStore) {
            await JDB.JungleDB.commitCombined(...chainTx.txs, accountsTx.tx, transactionStoreTx.tx);
        } else {
            await JDB.JungleDB.commitCombined(...chainTx.txs, accountsTx.tx);
        }
        this._transactionCache = transactionCacheTx;

        // Reset chain proof. We don't recompute the chain proof here, but do it lazily the next time it is needed.
        // TODO modify chain proof directly, don't recompute.
        this._proof = null;

        // Fire block-reverted event for each block reverted during rebranch.
        const revertBlocks = [];
        for (const revertedData of revertChain) {
            await this.fire('block-reverted', revertedData.head);
            revertBlocks.push(revertedData.head);
        }

        // Fire head-changed event for each fork block.
        const forkBlocks = [];
        for (let i = forkChain.length - 1; i >= 0; i--) {
            this._mainChain = forkChain[i];
            this._headHash = forkHashes[i];
            await this.fire('head-changed', this.head, /*rebranching*/ i > 0);
            forkBlocks.push(this.head);
        }

        // Tell listeners that we have rebranched.
        await this.fire('block', blockHash);
        await this.fire('rebranched', revertBlocks, forkBlocks, blockHash);

        return true;
    }

    /**
     *
     * @param {Hash} startBlockHash
     * @param {number} count
     * @param {boolean} forward
     * @returns {Promise.<Array.<Block>>}
     */
    getBlocks(startBlockHash, count = 500, forward = true) {
        return this._store.getBlocks(startBlockHash, count, forward);
    }

    /**
     * @returns {Promise.<ChainProof>}
     * @override
     */
    getChainProof() {
        return this._synchronizer.push(/*priority*/ 1, async () => {
            if (!this._proof) {
                this._proof = await this._getChainProof();
            }
            return this._proof;
        });
    }

    /**
     * @param {Block} blockToProve
     * @param {Block} knownBlock
     * @returns {Promise.<?BlockChain>}
     **/
    getBlockProof(blockToProve, knownBlock) {
        return this._synchronizer.push(/*priority*/ 1,
            this._getBlockProof.bind(this, blockToProve, knownBlock));
    }

    /**
     * @param {Hash} blockHash
     * @param {string} startPrefix
     * @returns {Promise.<?AccountsTreeChunk>}
     */
    async getAccountsTreeChunk(blockHash, startPrefix) {
        const snapshot = await this._getSnapshot(blockHash);
        return snapshot && await snapshot.getAccountsTreeChunk(startPrefix);
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @returns {Promise.<?AccountsProof>}
     */
    async getAccountsProof(blockHash, addresses) {
        const snapshot = await this._getSnapshot(blockHash);
        return snapshot && await snapshot.getAccountsProof(addresses);
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @returns {Promise.<?TransactionsProof>}
     * @deprecated
     */
    async getTransactionsProof(blockHash, addresses) {
        return this.getTransactionsProofByAddresses(blockHash, addresses);
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @returns {Promise.<?TransactionsProof>}
     */
    async getTransactionsProofByAddresses(blockHash, addresses) {
        const block = await this.getBlock(blockHash, /*includeForks*/ false, /*includeBody*/ true);
        if (!block || !block.isFull()) {
            return null;
        }

        const matches = [];
        const addressSet = new HashSet();
        addressSet.addAll(addresses);
        for (const transaction of block.transactions) {
            if (addressSet.contains(transaction.sender) || addressSet.contains(transaction.recipient)) {
                matches.push(transaction);
            }
        }

        const proof = MerkleProof.compute(block.body.getMerkleLeafs(), matches);
        return new TransactionsProof(matches, proof);
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<?TransactionsProof>}
     */
    async getTransactionsProofByHashes(blockHash, hashes) {
        const block = await this.getBlock(blockHash, /*includeForks*/ false, /*includeBody*/ true);
        if (!block || !block.isFull()) {
            return null;
        }

        const matches = [];
        const hashSet = new HashSet();
        hashSet.addAll(hashes);
        for (const transaction of block.transactions) {
            if (hashSet.contains(transaction.hash())) {
                matches.push(transaction);
            }
        }

        const proof = MerkleProof.compute(block.body.getMerkleLeafs(), matches);
        return new TransactionsProof(matches, proof);
    }

    /**
     * @param {Address} address
     * @param {?number} [limit]
     * @returns {Promise.<?Array.<TransactionReceipt>>}
     */
    async getTransactionReceiptsByAddress(address, limit = null) {
        if (!this._transactionStore) {
            return null;
        }

        const transactionReceipts = [];
        const entriesBySender = await this._transactionStore.getBySender(address, (!limit || limit < 0 || !Number.isFinite(limit)) ? null : (limit / 2));
        const entriesByRecipient = await this._transactionStore.getByRecipient(address, (!limit || limit < 0 || !Number.isFinite(limit)) ? null : (limit / 2));

        entriesBySender.forEach(entry => {
            transactionReceipts.push(new TransactionReceipt(entry.transactionHash, entry.blockHash, entry.blockHeight));
        });

        entriesByRecipient.forEach(entry => {
            transactionReceipts.push(new TransactionReceipt(entry.transactionHash, entry.blockHash, entry.blockHeight));
        });

        return transactionReceipts;
    }

    /**
     * @param {Array.<Hash>} hashes
     * @param {?number} [limit]
     * @returns {Promise.<?Array.<TransactionReceipt>>}
     */
    async getTransactionReceiptsByHashes(hashes, limit = null) {
        if (!this._transactionStore) {
            return null;
        }

        const transactionReceipts = [];
        /** @type {Array.<?TransactionStoreEntry>} */
        const entries = await Promise.all(hashes.map(hash => this._transactionStore.get(hash)));
        for (const entry of entries) {
            if (entry && (!limit || limit < 0 || transactionReceipts.length < limit)) {
                transactionReceipts.push(new TransactionReceipt(entry.transactionHash, entry.blockHash, entry.blockHeight));
            }
        }

        return transactionReceipts;
    }

    /**
     * @param {Hash} transactionHash
     * @returns {Promise.<?TransactionStoreEntry>}
     */
    async getTransactionInfoByHash(transactionHash) {
        if (!this._transactionStore) {
            throw new Error('Invalid request');
        }

        const txStoreEntry = await this._transactionStore.get(transactionHash);
        if (!txStoreEntry) {
            return null;
        }

        return txStoreEntry;
    }

    /**
     * @param {Hash} blockHash
     * @returns {Promise.<?Accounts>}
     */
    _getSnapshot(blockHash) {
        // TODO Does this have to be synchronized with pushBlock() ?
        return this._synchronizer.push(/*priority*/ 1, async () => {
            const block = await this.getBlock(blockHash);
            // Check if blockHash is a block on the main chain within the allowed window.
            if (!block || this._mainChain.head.height - block.height > Policy.NUM_SNAPSHOTS_MAX) {
                return null;
            }

            // Check if there already is a snapshot, otherwise create it.
            let snapshot = null;
            if (!this._snapshots.contains(blockHash)) {
                const tx = await this._accounts.transaction();
                const transactionsTx = this._transactionCache.clone();
                let currentHash = this._headHash;
                // Save all snapshots up to blockHash (and stop when its predecessor would be next).
                while (!block.prevHash.equals(currentHash)) {
                    const currentBlock = await this.getBlock(currentHash, /*includeForks*/ false, /*includeBody*/ true);

                    if (!this._snapshots.contains(currentHash)) {
                        snapshot = await this._accounts.snapshot(tx);
                        this._snapshots.put(currentHash, snapshot);
                        this._snapshotOrder.unshift(currentHash);
                    }

                    await tx.revertBlock(currentBlock, transactionsTx);
                    transactionsTx.revertBlock(currentBlock);
                    currentHash = currentBlock.prevHash;
                }
                await tx.abort();
            } else {
                snapshot = this._snapshots.get(blockHash);
            }

            Assert.that(block.accountsHash.equals(await snapshot.hash()), 'AccountsHash mismatch for snapshot of block ${blockHash}');

            return snapshot;
        });
    }

    /**
     * @param {Hash} blockHash
     * @returns {Promise.<void>}
     * @private
     */
    async _saveSnapshot(blockHash) {
        // Replace oldest snapshot if possible.
        // This ensures snapshots are only created lazily.
        if (this._snapshotOrder.length > 0) {
            const oldestHash = this._snapshotOrder.shift();
            // If the hash is not reused, remove it.
            const oldestSnapshot = this._snapshots.get(oldestHash);
            if (oldestSnapshot) {
                await oldestSnapshot.abort();
            } else {
                Log.e(FullChain, () => `Snapshot with hash ${oldestHash.toBase64()} not found.`);
            }
            this._snapshots.remove(oldestHash);

            // Add new snapshot.
            const snapshot = await this._accounts.snapshot();
            this._snapshots.put(blockHash, snapshot);
            this._snapshotOrder.push(blockHash);
        }
    }

    /** @type {Block} */
    get head() {
        return this._mainChain.head;
    }

    /** @type {Hash} */
    get headHash() {
        return this._headHash;
    }

    get height() {
        return this._mainChain.head.height;
    }

    /** @type {BigNumber} */
    get totalDifficulty() {
        return this._mainChain.totalDifficulty;
    }

    /** @type {BigNumber} */
    get totalWork() {
        return this._mainChain.totalWork;
    }

    /** @type {Accounts} */
    // XXX Do we really want to expose this?
    get accounts() {
        return this._accounts;
    }

    /** @type {TransactionCache} */
    get transactionCache() {
        return this._transactionCache;
    }

    /** @type {number} */
    get blockForkedCount() {
        return this._blockForkedCount;
    }

    /** @type {number} */
    get blockRebranchedCount() {
        return this._blockRebranchedCount;
    }

    /** @type {number} */
    get blockExtendedCount() {
        return this._blockExtendedCount;
    }

    /** @type {number} */
    get blockOrphanCount() {
        return this._blockOrphanCount;
    }

    /** @type {number} */
    get blockInvalidCount() {
        return this._blockInvalidCount;
    }

    /** @type {number} */
    get blockKnownCount() {
        return this._blockKnownCount;
    }

    /**
     * @returns {Promise.<Hash>}
     */
    // XXX Do we really want to expose this?
    accountsHash() {
        return this._accounts.hash();
    }

    /** @type {PrioritySynchronizer} */
    get queue() {
        return this._synchronizer;
    }
}

FullChain.ERR_ORPHAN = -2;
FullChain.ERR_INVALID = -1;
FullChain.OK_KNOWN = 0;
FullChain.OK_EXTENDED = 1;
FullChain.OK_REBRANCHED = 2;
FullChain.OK_FORKED = 3;

FullChain.SYNCHRONIZER_THROTTLE_AFTER = 500; // ms
FullChain.SYNCHRONIZER_THROTTLE_WAIT = 30; // ms

Class.register(FullChain);

class FullConsensusAgent extends BaseConsensusAgent {
    /**
     * @param {FullChain} blockchain
     * @param {Mempool} mempool
     * @param {Time} time
     * @param {Peer} peer
     * @param {InvRequestManager} invRequestManager
     * @param {Subscription} targetSubscription
     */
    constructor(blockchain, mempool, time, peer, invRequestManager, targetSubscription) {
        super(time, peer, invRequestManager, targetSubscription);
        /** @type {FullChain} */
        this._blockchain = blockchain;
        /** @type {Mempool} */
        this._mempool = mempool;

        // Flag indicating that we are currently syncing our blockchain with the peer's.
        /** @type {boolean} */
        this._syncing = false;

        // The number of blocks that extended our blockchain since the last requestBlocks().
        /** @type {number} */
        this._numBlocksExtending = -1;
        // The number of blocks that forked our blockchain since the last requestBlocks().
        /** @type {number} */
        this._numBlocksForking = -1;
        // The last fork block the peer has sent us.
        /** @type {Block} */
        this._forkHead = null;

        // The number of failed blockchain sync attempts.
        /** @type {number} */
        this._failedSyncs = 0;

        // The block hash that we want to learn to consider the sync complete.
        /** @type {Hash} */
        this._syncTarget = peer.headHash;

        /** @type {RateLimit} */
        this._chainProofLimit = new RateLimit(FullConsensusAgent.CHAIN_PROOF_RATE_LIMIT);
        /** @type {RateLimit} */
        this._accountsProofLimit = new RateLimit(FullConsensusAgent.ACCOUNTS_PROOF_RATE_LIMIT);
        /** @type {RateLimit} */
        this._accountsTreeChunkLimit = new RateLimit(FullConsensusAgent.ACCOUNTS_TREE_CHUNK_RATE_LIMIT);
        /** @type {RateLimit} */
        this._transactionsProofLimit = new RateLimit(FullConsensusAgent.TRANSACTION_PROOF_RATE_LIMIT);
        /** @type {RateLimit} */
        this._transactionReceiptsLimit = new RateLimit(FullConsensusAgent.TRANSACTION_RECEIPTS_RATE_LIMIT);
        /** @type {RateLimit} */
        this._blockProofLimit = new RateLimit(FullConsensusAgent.BLOCK_PROOF_RATE_LIMIT);
        /** @type {RateLimit} */
        this._getBlocksLimit = new RateLimit(FullConsensusAgent.GET_BLOCKS_RATE_LIMIT);

        // Listen to consensus messages from the peer.
        this._onToDisconnect(peer.channel, 'get-blocks', msg => this._onGetBlocks(msg));
        this._onToDisconnect(peer.channel, 'get-chain-proof', msg => this._onGetChainProof(msg));
        this._onToDisconnect(peer.channel, 'get-accounts-proof', msg => this._onGetAccountsProof(msg));
        this._onToDisconnect(peer.channel, 'get-accounts-tree-chunk', msg => this._onGetAccountsTreeChunk(msg));
        this._onToDisconnect(peer.channel, 'get-transactions-proof', msg => this._onGetTransactionsProofByAddresses(msg));
        this._onToDisconnect(peer.channel, 'get-transaction-receipts', msg => this._onGetTransactionReceiptsByAddress(msg));
        this._onToDisconnect(peer.channel, 'get-block-proof', msg => this._onGetBlockProof(msg));
        this._onToDisconnect(peer.channel, 'get-block-proof-at', msg => this._onGetBlockProofAt(msg));
        this._onToDisconnect(peer.channel, 'get-transactions-proof-by-hashes', msg => this._onGetTransactionsProofByHashes(msg));
        this._onToDisconnect(peer.channel, 'get-transaction-receipts-by-hashes', msg => this._onGetTransactionReceiptsByHashes(msg));
    }

    async syncBlockchain() {
        this._syncing = true;

        // We only sync with other full nodes.
        if (!this.providesServices(Services.BLOCK_HISTORY, Services.FULL_BLOCKS)) {
            this._syncFinished();
            return;
        }

        // Wait for all objects to arrive.
        if (!this._objectsInFlight.isEmpty()) {
            Log.v(FullConsensusAgent, `Waiting for ${this._objectsInFlight.length} objects to arrive ...`);
            return;
        }

        // Wait for all objects to be processed.
        if (!this._objectsProcessing.isEmpty()) {
            Log.v(FullConsensusAgent, `Waiting for ${this._objectsProcessing.length} objects to be processed ...`);
            return;
        }

        // If we know our sync target block, the sync process is finished.
        const head = await this._blockchain.getBlock(this._syncTarget, /*includeForks*/ true);
        if (head) {
            this._syncFinished();
            return;
        }

        // If the peer didn't send us any blocks that extended our chain, count it as a failed sync attempt.
        // This sets a maximum length for forks that the full client will accept:
        //   FullConsensusAgent.SYNC_ATTEMPTS_MAX * BaseInvectoryMessage.VECTORS_MAX_COUNT
        if (this._numBlocksExtending === 0 && ++this._failedSyncs >= FullConsensusAgent.SYNC_ATTEMPTS_MAX) {
            this._peer.channel.close(CloseType.BLOCKCHAIN_SYNC_FAILED, 'blockchain sync failed');
            return;
        }

        // We don't know the peer's head block, request blocks from it.
        this._requestBlocks().catch(Log.w.tag(FullConsensusAgent));
    }

    _syncFinished() {
        // Subscribe to all announcements from the peer.
        this._subscribeTarget();

        // Request the peer's mempool.
        // XXX Use a random delay here to prevent requests to multiple peers at once.
        const delay = FullConsensusAgent.MEMPOOL_DELAY_MIN
            + Math.random() * (FullConsensusAgent.MEMPOOL_DELAY_MAX - FullConsensusAgent.MEMPOOL_DELAY_MIN);
        setTimeout(() => this._peer.channel.mempool(), delay);

        this._syncing = false;
        this._synced = true;

        this._numBlocksExtending = 0;
        this._numBlocksForking = 0;
        this._forkHead = null;
        this._failedSyncs = 0;

        this.fire('sync');
    }

    async _requestBlocks(maxInvSize) {
        // Only one getBlocks request at a time.
        if (this._peer.channel.isExpectingMessage(Message.Type.INV)) {
            return;
        }

        // Drop the peer if it doesn't start sending InvVectors for its chain within the timeout.
        // Set timeout early to prevent re-entering the method.
        this._peer.channel.expectMessage(Message.Type.INV, () => {
            this._peer.channel.close(CloseType.GET_BLOCKS_TIMEOUT, 'getBlocks timeout');
        }, BaseConsensusAgent.REQUEST_TIMEOUT);

        // Check if the peer is sending us a fork.
        const onFork = this._forkHead && this._numBlocksExtending === 0 && this._numBlocksForking > 0;

        /** @type {Array.<Hash>} */
        let locators;
        if (onFork) {
            // Only send the fork head as locator if the peer is sending us a fork.
            locators = [this._forkHead.hash()];
        } else {
            locators = await this._blockchain.getBlockLocators();
        }

        // Reset block counters.
        this._numBlocksExtending = 0;
        this._numBlocksForking = 0;

        // Request blocks from peer.
        this._peer.channel.getBlocks(locators, maxInvSize);
    }

    /**
     * @param {InvVector} vector
     * @returns {boolean}
     * @protected
     * @override
     */
    _shouldRequestData(vector) {
        // Ignore block announcements from nano clients as they will ignore our getData requests anyways (they only know headers).
        // Also don't request transactions that the mempool has filtered.
        return !(vector.type === InvVector.Type.BLOCK && !this.providesServices(Services.FULL_BLOCKS))
            && !(vector.type === InvVector.Type.TRANSACTION && this._mempool.isFiltered(vector.hash));
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks]
     * @param {boolean} [includeBody]
     * @returns {Promise.<?Block>}
     * @protected
     * @override
     */
    _getBlock(hash, includeForks = false, includeBody = false) {
        return this._blockchain.getBlock(hash, includeForks, includeBody);
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks]
     * @returns {Promise.<?Uint8Array>}
     * @protected
     * @override
     */
    _getRawBlock(hash, includeForks = false) {
        return this._blockchain.getRawBlock(hash, includeForks);
    }

    /**
     * @param {Hash} hash
     * @returns {?Transaction}
     * @protected
     * @override
     */
    _getTransaction(hash) {
        return this._mempool.getTransaction(hash);
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {void}
     * @protected
     * @override
     */
    async _onKnownBlockAnnounced(hash, block) {
        if (!this._syncing) return;

        this._numBlocksForking++;
        this._forkHead = block;
    }

    /**
     * @returns {void}
     * @protected
     * @override
     */
    _onNoUnknownObjects() {
        // The peer does not have any new inv vectors for us.
        if (this._syncing) {
            this.syncBlockchain().catch(Log.e.tag(FullConsensusAgent));
        }
    }

    /**
     * @protected
     * @override
     */
    _onAllObjectsReceived() {
        // If all objects have been received, request more if we're syncing the blockchain.
        if (this._syncing) {
            this.syncBlockchain().catch(Log.e.tag(FullConsensusAgent));
        }
    }

    /**
     * @param {HeaderMessage} msg
     * @return {Promise.<void>}
     * @protected
     * @override
     */
    _onHeader(msg) {
        // Ignore header messages.
        Log.w(FullConsensusAgent, `Unsolicited header message received from ${this._peer.peerAddress}, discarding`);
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processBlock(hash, block) {
        // TODO send reject message if we don't like the block
        const status = await this._blockchain.pushBlock(block);
        switch (status) {
            case FullChain.ERR_INVALID:
                this._peer.channel.close(CloseType.INVALID_BLOCK, 'received invalid block');
                break;

            case FullChain.OK_EXTENDED:
            case FullChain.OK_REBRANCHED:
                if (this._syncing) this._numBlocksExtending++;
                break;

            case FullChain.OK_FORKED:
                if (this._syncing) {
                    this._numBlocksForking++;
                    this._forkHead = block;
                }
                break;

            case FullChain.ERR_ORPHAN:
                this._onOrphanBlock(hash, block);
                break;

            case FullChain.OK_KNOWN:
                Log.v(FullConsensusAgent, `Received known block ${hash} (height=${block.height}, prevHash=${block.prevHash}) from ${this._peer.peerAddress}`);
                break;
        }
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @protected
     */
    _onOrphanBlock(hash, block) {
        // Ignore orphan blocks if we're not synced yet. This shouldn't happen.
        if (!this._synced) {
            Log.w(FullConsensusAgent, `Received orphan block ${hash} (height=${block.height}, prevHash=${block.prevHash}) while syncing`);
            return;
        }

        // The peer has announced an orphaned block after the initial sync. We're probably out of sync.
        Log.d(FullConsensusAgent, `Received orphan block ${hash} (height=${block.height}, prevHash=${block.prevHash}) from ${this._peer.peerAddress}`);

        // Disable announcements from the peer once.
        if (!this._timers.timeoutExists('outOfSync')) {
            this._subscribe(Subscription.NONE);
        }

        // Set the orphaned block as the new sync target.
        this._syncTarget = hash;

        // Wait a short time for:
        // - our (un-)subscribe message to be sent
        // - potentially more orphaned blocks to arrive
        this._timers.resetTimeout('outOfSync', () => this._outOfSync(), FullConsensusAgent.RESYNC_THROTTLE);
    }

    /**
     * @private
     */
    _outOfSync() {
        this._timers.clearTimeout('outOfSync');

        this._synced = false;

        this.fire('out-of-sync');
    }

    /**
     * @param {Hash} hash
     * @param {Transaction} transaction
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processTransaction(hash, transaction) {
        const result = await this._mempool.pushTransaction(transaction);
        switch (result) {
            case Mempool.ReturnCode.FEE_TOO_LOW:
                this._peer.channel.reject(Message.Type.TX, RejectMessage.Code.REJECT_INSUFFICIENT_FEE,
                    'Sender has too many free transactions', transaction.hash().serialize());
                break;
            case Mempool.ReturnCode.INVALID:
                this._peer.channel.reject(Message.Type.TX, RejectMessage.Code.REJECT_INVALID, 'Invalid transaction',
                    transaction.hash().serialize());
                break;
            case Mempool.ReturnCode.MINED:
            case Mempool.ReturnCode.EXPIRED:
                Log.v(FullConsensusAgent, () => `Ignored transaction ${hash.toHex()} relayed by ${this._peer.peerAddress} (${this._peer.netAddress})`);
                break;
            case Mempool.ReturnCode.FILTERED:
                Log.v(FullConsensusAgent, () => `Filtered transaction ${hash.toHex()} relayed by ${this._peer.peerAddress} (${this._peer.netAddress})`);
                break;
        }
    }

    /**
     * @protected
     * @override
     */
    _onAllObjectsProcessed() {
        // If all objects have been processed, request more if we're syncing the blockchain.
        if (this._syncing) {
            this.syncBlockchain().catch(Log.e.tag(FullConsensusAgent));
        }
    }


    /* Request endpoints */

    /**
     * @param {GetBlocksMessage} msg
     * @return {Promise}
     * @private
     */
    async _onGetBlocks(msg) {
        if (!this._getBlocksLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetBlocks message - rate-limit exceeded');
            return;
        }
        Log.v(FullConsensusAgent, `[GETBLOCKS] ${msg.locators.length} block locators maxInvSize ${msg.maxInvSize} received from ${this._peer.peerAddress}`);

        // A peer has requested blocks. Check all requested block locator hashes
        // in the given order and pick the first hash that is found on our main
        // chain, ignore the rest. If none of the requested hashes is found,
        // pick the genesis block hash. Send the main chain starting from the
        // picked hash back to the peer.
        let startBlock = GenesisConfig.GENESIS_BLOCK;
        for (const locator of msg.locators) {
            const block = await this._blockchain.getBlock(locator);
            if (block) {
                // We found a block, ignore remaining block locator hashes.
                startBlock = block;
                break;
            }
        }

        // Collect up to GETBLOCKS_VECTORS_MAX inventory vectors for the blocks starting right
        // after the identified block on the main chain.
        const blocks = await this._blockchain.getBlocks(startBlock.hash(),
            Math.min(msg.maxInvSize, FullConsensusAgent.GETBLOCKS_VECTORS_MAX),
            msg.direction === GetBlocksMessage.Direction.FORWARD);
        const vectors = [];
        for (const block of blocks) {
            vectors.push(InvVector.fromBlock(block));
        }

        // Send the vectors back to the requesting peer.
        this._peer.channel.inv(vectors);
    }

    /**
     * @param {GetChainProofMessage} msg
     * @private
     */
    async _onGetChainProof(msg) {
        if (!this._chainProofLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetChainProof message - rate-limit exceeded');
            this._peer.channel.close(CloseType.RATE_LIMIT_EXCEEDED, 'rate-limit exceeded');
            return;
        }
        const proof = await this._blockchain.getChainProof();
        this._peer.channel.chainProof(proof);
    }

    /**
     * @param {GetBlockProofMessage} msg
     * @private
     */
    async _onGetBlockProof(msg) {
        if (!this._blockProofLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetBlockProof message - rate-limit exceeded');
            this._peer.channel.blockProof(null);
            return;
        }
        const blockToProve = await this._blockchain.getBlock(msg.blockHashToProve);
        const knownBlock = await this._blockchain.getBlock(msg.knownBlockHash);
        if (!blockToProve || !knownBlock) {
            this._peer.channel.blockProof();
            return;
        }

        const proof = await this._blockchain.getBlockProof(blockToProve, knownBlock);
        this._peer.channel.blockProof(proof);
    }

    /**
     * @param {GetBlockProofAtMessage} msg
     * @private
     */
    async _onGetBlockProofAt(msg) {
        if (!this._blockProofLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetBlockProof message - rate-limit exceeded');
            this._peer.channel.blockProof(null);
            return;
        }
        const blockToProve = await this._blockchain.getBlockAt(msg.blockHeightToProve);
        const knownBlock = await this._blockchain.getBlock(msg.knownBlockHash);
        if (!blockToProve || !knownBlock) {
            this._peer.channel.blockProof();
            return;
        }

        const proof = await this._blockchain.getBlockProof(blockToProve, knownBlock);
        this._peer.channel.blockProof(proof);
    }

    /**
     * @param {GetAccountsProofMessage} msg
     * @private
     */
    async _onGetAccountsProof(msg) {
        if (!this._accountsProofLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetAccountsProof message - rate-limit exceeded');
            this._peer.channel.accountsProof(msg.blockHash, null);
            return;
        }
        const proof = await this._blockchain.getAccountsProof(msg.blockHash, msg.addresses);
        this._peer.channel.accountsProof(msg.blockHash, proof);
    }

    /**
     * @param {GetTransactionsProofByAddressesMessage} msg
     * @private
     */
    async _onGetTransactionsProofByAddresses(msg) {
        if (!this._transactionsProofLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetTransactionsProof message - rate-limit exceeded');
            this._peer.channel.transactionsProof(msg.blockHash, null);
            return;
        }
        const proof = await this._blockchain.getTransactionsProofByAddresses(msg.blockHash, msg.addresses);
        this._peer.channel.transactionsProof(msg.blockHash, proof);
    }

    /**
     * @param {GetTransactionsProofByHashesMessage} msg
     * @private
     */
    async _onGetTransactionsProofByHashes(msg) {
        if (!this._transactionsProofLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetTransactionsProof message - rate-limit exceeded');
            this._peer.channel.transactionsProof(msg.blockHash, null);
            return;
        }
        const proof = await this._blockchain.getTransactionsProofByHashes(msg.blockHash, msg.hashes);
        this._peer.channel.transactionsProof(msg.blockHash, proof);
    }

    /**
     * @param {GetAccountsTreeChunkMessage} msg
     * @private
     */
    async _onGetAccountsTreeChunk(msg) {
        if (!this._accountsTreeChunkLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetAccountsTreeChunk message - rate-limit exceeded');
            this._peer.channel.accountsTreeChunk(msg.blockHash, null);
            return;
        }
        const chunk = await this._blockchain.getAccountsTreeChunk(msg.blockHash, msg.startPrefix);
        this._peer.channel.accountsTreeChunk(msg.blockHash, chunk);
    }

    /**
     * @param {GetTransactionReceiptsByAddressMessage} msg
     * @private
     */
    async _onGetTransactionReceiptsByAddress(msg) {
        if (!this._transactionReceiptsLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetTransactionReceipts message - rate-limit exceeded');
            this._peer.channel.transactionReceipts(null);
            return;
        }

        const receipts = await this._blockchain.getTransactionReceiptsByAddress(msg.address, TransactionReceiptsMessage.RECEIPTS_MAX_COUNT);
        this._peer.channel.transactionReceipts(receipts);
    }

    /**
     * @param {GetTransactionReceiptsByHashesMessage} msg
     * @private
     */
    async _onGetTransactionReceiptsByHashes(msg) {
        if (!this._transactionReceiptsLimit.note()) {
            Log.w(FullConsensusAgent, 'Rejecting GetTransactionReceipts message - rate-limit exceeded');
            this._peer.channel.transactionReceipts(null);
            return;
        }

        const receipts = await this._blockchain.getTransactionReceiptsByHashes(msg.hashes, TransactionReceiptsMessage.RECEIPTS_MAX_COUNT);
        this._peer.channel.transactionReceipts(receipts);
    }

    /** @type {boolean} */
    get syncing() {
        return this._syncing;
    }

    /**
     * @returns {Iterable.<Transaction>}
     * @protected
     * @override
     */
    _getSubscribedMempoolTransactions() {
        switch (this._remoteSubscription.type) {
            case Subscription.Type.ADDRESSES:
                return this._mempool.getTransactionsByAddresses(this._remoteSubscription.addresses, FullConsensusAgent.MEMPOOL_ENTRIES_MAX);
            case Subscription.Type.MIN_FEE:
                return new LimitIterable(this._mempool.transactionGenerator(/*maxSize*/ undefined, this._remoteSubscription.minFeePerByte), FullConsensusAgent.MEMPOOL_ENTRIES_MAX);
            case Subscription.Type.ANY:
                return new LimitIterable(this._mempool.transactionGenerator(), FullConsensusAgent.MEMPOOL_ENTRIES_MAX);
        }
        return [];
    }
}
/**
 * Maximum number of blockchain sync retries before closing the connection.
 * XXX If the peer is on a long fork, it will count as a failed sync attempt
 * if our blockchain doesn't switch to the fork within 500 (max InvVectors returned by getBlocks)
 * blocks.
 * @type {number}
 */
FullConsensusAgent.SYNC_ATTEMPTS_MAX = 25;
/**
 * Maximum number of inventory vectors to sent in the response for onGetBlocks.
 * @type {number}
 */
FullConsensusAgent.GETBLOCKS_VECTORS_MAX = 500;
/**
 * Time {ms} to wait before triggering a blockchain re-sync with the peer.
 * @type {number}
 */
FullConsensusAgent.RESYNC_THROTTLE = 1000 * 3; // 3 seconds
/**
 * Minimum time {ms} to wait before triggering the initial mempool request.
 * @type {number}
 */
FullConsensusAgent.MEMPOOL_DELAY_MIN = 1000 * 2; // 2 seconds
/**
 * Maximum time {ms} to wait before triggering the initial mempool request.
 * @type {number}
 */
FullConsensusAgent.MEMPOOL_DELAY_MAX = 1000 * 20; // 20 seconds
/**
 * Time {ms} to wait between sending full inv vectors of transactions during Mempool request
 * @type {number}
 */
FullConsensusAgent.MEMPOOL_THROTTLE = 1000;
/**
 * Number of transaction vectors to send
 * @type {number}
 */
FullConsensusAgent.MEMPOOL_ENTRIES_MAX = 10000;
FullConsensusAgent.CHAIN_PROOF_RATE_LIMIT = 3; // per minute
FullConsensusAgent.ACCOUNTS_PROOF_RATE_LIMIT = 60; // per minute
FullConsensusAgent.ACCOUNTS_TREE_CHUNK_RATE_LIMIT = 300; // per minute
FullConsensusAgent.TRANSACTION_PROOF_RATE_LIMIT = 60; // per minute
FullConsensusAgent.TRANSACTION_RECEIPTS_RATE_LIMIT = 30; // per minute
FullConsensusAgent.BLOCK_PROOF_RATE_LIMIT = 60; // per minute
FullConsensusAgent.GET_BLOCKS_RATE_LIMIT = 30; // per minute
Class.register(FullConsensusAgent);

class FullConsensus extends BaseConsensus {
    /**
     * @param {FullChain} blockchain
     * @param {Mempool} mempool
     * @param {Network} network
     */
    constructor(blockchain, mempool, network) {
        super(blockchain, mempool, network);
        /** @type {FullChain} */
        this._blockchain = blockchain;
        /** @type {Mempool} */
        this._mempool = mempool;
        /** @type {BlockProducer} */
        this._producer = new BlockProducer(blockchain, blockchain.accounts, mempool, network.time);
    }

    //
    // Public consensus interface
    //

    /**
     * @param {Hash} hash
     * @param {boolean} [includeBody = true]
     * @param {boolean} [includeBodyFromLocal]
     * @param {number} [blockHeight]
     * @returns {Promise.<Block>}
     * @override
     */
    getBlock(hash, includeBody = true, includeBodyFromLocal = includeBody, blockHeight) { // eslint-disable-line no-unused-vars
        // Override to not fallback to network.
        const block = this._blockchain.getBlock(hash, true, includeBody);
        if (!block) {
            throw new Error(`No block found for hash ${hash}`);
        }
        return block;
    }

    /**
     * @param {number} height
     * @param {boolean} [includeBody = true]
     * @returns {Promise.<Block>}
     * @override
     */
    getBlockAt(height, includeBody = true) {
        // Override to not fallback to network.
        if (height > this._blockchain.height || height < 1) {
            throw new Error('Invalid height');
        }

        const block = this._blockchain.getBlockAt(height, includeBody);
        if (!block) {
            throw new Error(`No block found at height ${height}`);
        }
        return block;
    }

    /**
     * @param {Address} minerAddress
     * @param {Uint8Array} [extraData]
     * @returns {Promise.<Block>}
     */
    getBlockTemplate(minerAddress, extraData) {
        return this._producer.getNextBlock(minerAddress, extraData);
    }

    /**
     * @param {Block} block
     * @returns {Promise.<boolean>}
     */
    async submitBlock(block) {
        return (await this.blockchain.pushBlock(block)) >= 0;
    }

    /**
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Account>>}
     */
    getAccounts(addresses) {
        return Promise.all(addresses.map(addr => this._blockchain.accounts.get(addr)));
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactions(hashes) { // eslint-disable-line require-await
        return /** @type {Array.<Transaction>} */ hashes.map(hash => this._mempool.getTransaction(hash)).filter(tx => tx != null);
    }

    /**
     * @param {Address} address
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactionsByAddress(address, limit) { // eslint-disable-line require-await
        return this._mempool.getTransactionsByAddresses([address], limit);
    }

    /**
     * @param {Array.<Hash>} hashes
     * @param {Hash} blockHash
     * @param {number} [blockHeight]
     * @param {Block} [block]
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getTransactionsFromBlock(hashes, blockHash, blockHeight, block) {
        // Override to not fallback to network
        block = block && block.isFull() ? block : await this._blockchain.getBlock(blockHash, false, true);
        if (!block) {
            throw new Error(`No block found for hash ${blockHash}`);
        }
        return block.transactions.filter(tx => hashes.find(hash => hash.equals(tx.hash())));
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    getTransactionReceiptsByAddress(address, limit) {
        // XXX Assumes that blockchain supports transaction index.
        return this._blockchain.getTransactionReceiptsByAddress(address, limit);
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    getTransactionReceiptsByHashes(hashes) {
        // XXX Assumes that blockchain supports transaction index.
        return this._blockchain.getTransactionReceiptsByHashes(hashes);
    }

    /**
     * @param {Transaction} tx
     * @returns {Promise.<BaseConsensus.SendTransactionResult>}
     */
    async sendTransaction(tx) {
        const mempoolCode = await this._mempool.pushTransaction(tx);
        switch (mempoolCode) {
            case Mempool.ReturnCode.ACCEPTED: {
                // Wait for transaction relay
                const relayed = await new Promise((resolve) => {
                    let id;
                    // eslint-disable-next-line prefer-const
                    id = this.on('transaction-relayed', relayedTx => {
                        if (relayedTx.equals(tx)) {
                            this.off('transaction-relayed', id);
                            resolve(true);
                        }
                    });
                    setTimeout(() => {
                        this.off('transaction-relayed', id);
                        resolve(false);
                    }, BaseConsensus.TRANSACTION_RELAY_TIMEOUT);
                });
                if (relayed) {
                    return BaseConsensus.SendTransactionResult.RELAYED;
                } else {
                    return BaseConsensus.SendTransactionResult.PENDING_LOCAL;
                }
            }
            case Mempool.ReturnCode.KNOWN:
                return BaseConsensus.SendTransactionResult.KNOWN;
            case Mempool.ReturnCode.FEE_TOO_LOW:
            case Mempool.ReturnCode.FILTERED:
                return BaseConsensus.SendTransactionResult.REJECTED_LOCAL;
            case Mempool.ReturnCode.MINED:
                return BaseConsensus.SendTransactionResult.ALREADY_MINED;
            case Mempool.ReturnCode.EXPIRED:
                return BaseConsensus.SendTransactionResult.EXPIRED;
            case Mempool.ReturnCode.INVALID:
                return BaseConsensus.SendTransactionResult.INVALID;
        }
        return BaseConsensus.SendTransactionResult.NONE;
    }

    /**
     * @returns {Array.<Transaction>}
     */
    getMempoolContents() {
        return this._mempool.getTransactions();
    }

    //
    //

    /**
     * @param {number} minFeePerByte
     */
    subscribeMinFeePerByte(minFeePerByte) {
        this.subscribe(Subscription.fromMinFeePerByte(minFeePerByte));
        this.mempool.evictBelowMinFeePerByte(minFeePerByte);
    }

    /**
     * @type {number} minFeePerByte
     */
    get minFeePerByte() {
        return this._subscription.type === Subscription.Type.MIN_FEE ? this._subscription.minFeePerByte : 0;
    }

    /**
     * @param {Peer} peer
     * @returns {BaseConsensusAgent}
     * @override
     */
    _newConsensusAgent(peer) {
        return new FullConsensusAgent(this._blockchain, this._mempool, this._network.time, peer, this._invRequestManager, this._subscription);
    }

    /** @type {FullChain} */
    get blockchain() {
        return this._blockchain;
    }

    /** @type {Mempool} */
    get mempool() {
        return this._mempool;
    }
}

Class.register(FullConsensus);

/**
 * A LightChain is initialized by using NiPoPoWs instead of the full
 * blockchain history, but after initialization, it behaves as a regular
 * full blockchain.
 */
class LightChain extends FullChain {
    /**
    * @param {JungleDB} jdb
    * @param {Accounts} accounts
    * @param {Time} time
    * @returns {Promise.<LightChain>}
    */
    static getPersistent(jdb, accounts, time) {
        const store = ChainDataStore.getPersistent(jdb);
        const chain = new LightChain(store, accounts, time);
        return chain._init();
    }

    /**
     * @param {Accounts} accounts
     * @param {Time} time
     * @returns {Promise.<LightChain>}
     */
    static createVolatile(accounts, time) {
        const store = ChainDataStore.createVolatile();
        const chain = new LightChain(store, accounts, time);
        return chain._init();
    }

    /**
     * @param {ChainDataStore} store
     * @param {Accounts} accounts
     * @param {Time} time
     * @returns {PartialLightChain}
     */
    constructor(store, accounts, time) {
        super(store, accounts, time);
    }

    /**
     * @override
     * @protected
     */
    async _init() {
        // FIXME: this is a workaround as Babel doesn't understand await super().
        await FullChain.prototype._init.call(this);
        if (!this._proof) {
            this._proof = await this._getChainProof();
        }
        return this;
    }

    /**
     * @return {PartialLightChain}
     */
    async partialChain() {
        const proof = await this.getChainProof();
        const partialChain = new PartialLightChain(this._store, this._accounts, this._time, proof, this._synchronizer);
        partialChain.on('committed', (proof, headHash, mainChain, transactionCache) => {
            this._proof = proof;
            this._headHash = headHash;
            this._mainChain = mainChain;
            this._transactionCache = transactionCache;
            this.fire('block', headHash);
            this.fire('head-changed', this.head);
        });
        await partialChain._init();
        return partialChain;
    }

    /**
     * @returns {boolean}
     * @private
     * @override
     */
    _shouldExtendChainProof() {
        return true;
    }
}
Class.register(LightChain);

class LightConsensusAgent extends FullConsensusAgent {
    /**
     * @param {LightChain} blockchain
     * @param {Mempool} mempool
     * @param {Time} time
     * @param {Peer} peer
     * @param {InvRequestManager} invRequestManager
     * @param {Subscription} targetSubscription
     */
    constructor(blockchain, mempool, time, peer, invRequestManager, targetSubscription) {
        super(blockchain, mempool, time, peer, invRequestManager, targetSubscription);
        /** @type {LightChain} */
        this._blockchain = blockchain;
        /** @type {PartialLightChain} */
        this._partialChain = null;

        /** @type {boolean} */
        this._syncing = false;

        // Flag indicating whether we do a full catchup or request a proof.
        /** @type {boolean} */
        this._catchup = false;

        // Flag indicating whether we believe to be on the main chain of the client.
        /** @type {boolean} */
        this._onMainChain = false;

        /** @type {Array.<Block>} */
        this._orphanedBlocks = [];

        /** @type {boolean} */
        this._busy = false;

        // Helper object to keep track of the accounts we're requesting from the peer.
        this._accountsRequest = null;

        // Flag to track chain proof requests.
        this._requestedChainProof = false;

        // Number of weak proofs we have received from the peer.
        this._numWeakProofs = 0;

        // Listen to consensus messages from the peer.
        this._onToDisconnect(peer.channel, 'chain-proof', msg => this._onChainProof(msg));
        this._onToDisconnect(peer.channel, 'accounts-tree-chunk', msg => this._onAccountsTreeChunk(msg));
    }

    /**
     * @returns {Promise.<void>}
     * @override
     */
    async syncBlockchain() {
        // We don't sync with nano nodes.
        if (!this.providesServices(Services.FULL_BLOCKS, Services.CHAIN_PROOF, Services.ACCOUNTS_CHUNKS, Services.MEMPOOL)) {
            this._syncFinished();
            return;
        }

        // Wait for all objects to arrive.
        if (!this._objectsInFlight.isEmpty()) {
            Log.v(LightConsensusAgent, `Waiting for ${this._objectsInFlight.length} objects to arrive ...`);
            return;
        }

        // Wait for all objects to be processed.
        if (!this._objectsProcessing.isEmpty()) {
            Log.v(LightConsensusAgent, `Waiting for ${this._objectsProcessing.length} objects to be processed ...`);
            return;
        }

        // Ban peer if the sync failed more often than allowed.
        if (this._failedSyncs >= LightConsensusAgent.SYNC_ATTEMPTS_MAX) {
            this._peer.channel.close(CloseType.BLOCKCHAIN_SYNC_FAILED, 'blockchain sync failed');
            if (this._partialChain) {
                await this._partialChain.abort();
                this._partialChain = null;
            }
            return;
        }

        // Check if we know head block.
        const block = await this._blockchain.getBlock(this._syncTarget, /*includeForks*/ true);

        /*
         * Three cases:
         * 1) We know block and are not yet syncing: All is done.
         * 2) We don't know the block and are not yet syncing: Start syncing.
         *    and determine sync mode (full catchup or not).
         * 3) We are syncing. Behave differently based on sync mode.
         *    Note that we can switch from catchup to proof if we notice that
         *    we're on a fork and get an INV vector starting from the genesis block.
         */

        // Case 1: We're up to date.
        if (block && !this._syncing) {
            this._syncFinished();
            return;
        }

        // Case 2: Check header.
        if (!block && !this._syncing) {
            this._syncing = true;
            this._onMainChain = false;

            let header;
            try {
                header = await this.getHeader(this._syncTarget);
            } catch (e) {
                this._peer.channel.close(CloseType.ABORTED_SYNC, 'Failed to retrieve sync target header');
                return;
            }

            // Check how to sync based on heuristic:
            // Allow catchup sync in a window of NUM_BLOCKS_VERIFICATION in both directions
            this._catchup = Math.abs(header.height - this._blockchain.height) <= Policy.NUM_BLOCKS_VERIFICATION;
            Log.d(LightConsensusAgent, `Start syncing, catchup mode: ${this._catchup}`);
        }

        // Case 3: We are syncing.
        if (this._syncing && !this._busy) {
            if (this._catchup) {
                await FullConsensusAgent.prototype.syncBlockchain.call(this);
            } else {
                // Initialize partial chain on first call.
                if (!this._partialChain) {
                    await this._initChainProofSync();
                }

                switch (this._partialChain.state) {
                    case PartialLightChain.State.PROVE_CHAIN:
                        this._requestChainProof();
                        this.fire('sync-chain-proof', this._peer.peerAddress);
                        break;
                    case PartialLightChain.State.PROVE_ACCOUNTS_TREE:
                        this._requestAccountsTree();
                        this.fire('sync-accounts-tree', this._peer.peerAddress);
                        break;
                    case PartialLightChain.State.PROVE_BLOCKS:
                        this._requestProofBlocks();
                        this.fire('verify-accounts-tree', this._peer.peerAddress);
                        break;
                    case PartialLightChain.State.COMPLETE:
                        // Commit state on success.
                        this.fire('sync-finalize', this._peer.peerAddress);
                        this._busy = true;
                        await this._partialChain.commit();
                        await this._applyOrphanedBlocks();
                        this._syncFinished();
                        break;
                    case PartialLightChain.State.ABORTED:
                        this._peer.channel.close(CloseType.ABORTED_SYNC, 'aborted sync');
                        break;
                    case PartialLightChain.State.WEAK_PROOF:
                        Log.d(LightConsensusAgent, `Not syncing with ${this._peer.peerAddress} - weaker proof`);
                        this._numWeakProofs++;
                        if (this._numWeakProofs >= LightConsensusAgent.WEAK_PROOFS_MAX) {
                            this._peer.channel.close(CloseType.BLOCKCHAIN_SYNC_FAILED, 'too many weak proofs');
                        } else {
                            this._syncFinished();
                        }
                        break;
                }
            }
        }
    }

    /**
     * @returns {Promise.<void>}
     * @private
     */
    async _initChainProofSync() {
        // Subscribe to all announcements from the peer.
        this._subscribeTarget();

        this._syncing = true;
        this._synced = false;
        this._catchup = false;
        this._onMainChain = true;

        if (this._partialChain) {
            await this._partialChain.abort();
        }

        this._partialChain = await this._blockchain.partialChain();
    }

    /**
     * @returns {void}
     * @private
     */
    _syncFinished() {
        if (this._partialChain) {
            this._partialChain = null;
        }

        this._busy = false;
        super._syncFinished();
    }

    /**
     * @returns {Promise.<void>}
     * @private
     */
    async _applyOrphanedBlocks() {
        for (const block of this._orphanedBlocks) {
            const status = await this._blockchain.pushBlock(block);
            if (status === LightChain.ERR_INVALID) {
                this._peer.channel.close(CloseType.INVALID_BLOCK, 'received invalid block');
                break;
            }
        }
        this._orphanedBlocks = [];
    }

    // Syncing stages.
    // Stage 1: Chain proof.
    /**
     * @returns {void}
     * @private
     */
    _requestChainProof() {
        Assert.that(this._partialChain && this._partialChain.state === PartialLightChain.State.PROVE_CHAIN);
        Assert.that(!this._requestedChainProof);
        this._busy = true;

        // Request ChainProof from peer.
        this._peer.channel.getChainProof();
        this._requestedChainProof = true;

        // Drop the peer if it doesn't send the chain proof within the timeout.
        this._peer.channel.expectMessage(Message.Type.CHAIN_PROOF, () => {
            this._peer.channel.close(CloseType.GET_CHAIN_PROOF_TIMEOUT, 'getChainProof timeout');
        }, LightConsensusAgent.CHAINPROOF_REQUEST_TIMEOUT, LightConsensusAgent.CHAINPROOF_CHUNK_TIMEOUT);
    }

    /**
     * @param {ChainProofMessage} msg
     * @returns {Promise.<void>}
     * @private
     */
    async _onChainProof(msg) {
        Assert.that(this._partialChain && this._partialChain.state === PartialLightChain.State.PROVE_CHAIN);
        Log.d(LightConsensusAgent, `[CHAIN-PROOF] Received from ${this._peer.peerAddress}: ${msg.proof}`);

        // Check if we have requested an interlink chain, discard unsolicited ones.
        if (!this._requestedChainProof) {
            Log.w(LightConsensusAgent, `Unsolicited chain proof received from ${this._peer.peerAddress}`);
            return;
        }
        this._requestedChainProof = false;

        if (this._syncing) {
            this.fire('verify-chain-proof', this._peer.peerAddress);
        }

        // Push the proof into the LightChain.
        if (!(await this._partialChain.pushProof(msg.proof))) {
            Log.w(LightConsensusAgent, `Invalid chain proof received from ${this._peer.peerAddress} - verification failed`);
            this._peer.channel.close(CloseType.INVALID_CHAIN_PROOF, 'Invalid chain proof');
            return;
        }

        // TODO add all blocks from the chain proof to knownObjects.

        this._busy = false;
        this.syncBlockchain().catch(Log.e.tag(LightConsensusAgent));
    }

    // Stage 2: Request AccountsTree.
    /**
     * @private
     */
    _requestAccountsTree() {
        Assert.that(this._partialChain && this._partialChain.state === PartialLightChain.State.PROVE_ACCOUNTS_TREE);
        Assert.that(!this._accountsRequest);
        this._busy = true;

        const startPrefix = this._partialChain.getMissingAccountsPrefix();
        const headHash = this._partialChain.headHash;
        Log.d(LightConsensusAgent, `Requesting AccountsTreeChunk starting at ${startPrefix} from ${this._peer.peerAddress}`);

        this._accountsRequest = {
            startPrefix,
            blockHash: headHash
        };

        // Request AccountsProof from peer.
        this._peer.channel.getAccountsTreeChunk(headHash, startPrefix);

        // Drop the peer if it doesn't send the accounts proof within the timeout.
        this._peer.channel.expectMessage(Message.Type.ACCOUNTS_TREE_CHUNK, () => {
            this._accountsRequest = null;
            this._peer.channel.close(CloseType.GET_ACCOUNTS_TREE_CHUNK_TIMEOUT, 'getAccountsTreeChunk timeout');
        }, LightConsensusAgent.ACCOUNTS_TREE_CHUNK_REQUEST_TIMEOUT);
    }

    /**
     * @param {AccountsTreeChunkMessage} msg
     * @returns {Promise.<void>}
     * @private
     */
    async _onAccountsTreeChunk(msg) {
        Log.d(LightConsensusAgent, `[ACCOUNTS-TREE-CHUNK] Received from ${this._peer.peerAddress}: blockHash=${msg.blockHash}, proof=${msg.chunk}`);

        // Check if we have requested an accounts proof, discard unsolicited ones.
        if (!this._accountsRequest) {
            Log.w(LightConsensusAgent, `Unsolicited accounts tree chunk received from ${this._peer.peerAddress}`);
            return;
        }

        Assert.that(this._partialChain && this._partialChain.state === PartialLightChain.State.PROVE_ACCOUNTS_TREE);

        const {startPrefix, blockHash} = this._accountsRequest;
        this._accountsRequest = null;

        if (!msg.hasChunk()) {
            // Restart syncing.
            await this._partialChain.abort();
            this._partialChain = null;
            this._busy = false;
            this._failedSyncs++;
            return;
        }

        // Check that we know the reference block.
        if (!blockHash.equals(msg.blockHash) || msg.chunk.head.prefix <= startPrefix) {
            Log.w(LightConsensusAgent, `Received AccountsTreeChunk for block != head or wrong start prefix from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.UNEXPECTED_ACCOUNTS_TREE_CHUNK, 'Unexpected AccountsTreeChunk');
            return;
        }

        // Verify the proof.
        const chunk = msg.chunk;
        if (!chunk.verify()) {
            Log.w(LightConsensusAgent, `Invalid AccountsTreeChunk received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_ACCOUNTS_TREE_CHUNCK, 'Invalid AccountsTreeChunk');
            return;
        }

        // Check that the proof root hash matches the accountsHash in the reference block.
        const rootHash = chunk.root();
        const block = await this._partialChain.getBlock(blockHash);
        if (!block.accountsHash.equals(rootHash)) {
            Log.w(LightConsensusAgent, `Invalid AccountsTreeChunk (root hash) received from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_ACCOUNTS_TREE_CHUNCK, 'AccountsTreeChunk root hash mismatch');
            return;
        }

        // Return the retrieved accounts.
        const result = await this._partialChain.pushAccountsTreeChunk(chunk);

        // Something went wrong!
        if (result < 0) {
            Log.e(`AccountsTree sync failed with error code ${result} from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.INVALID_ACCOUNTS_TREE_CHUNCK, 'AccountsTreeChunk root hash mismatch');
        }

        this._busy = false;
        this.syncBlockchain().catch(Log.e.tag(LightConsensusAgent));
    }

    // Stage 3: Request proof blocks.
    /**
     * @private
     */
    _requestProofBlocks() {
        Assert.that(this._partialChain && this._partialChain.state === PartialLightChain.State.PROVE_BLOCKS);

        // If nothing happend since the last request, increase failed syncs.
        if (this._lastChainHeight === this._partialChain.proofHeadHeight) {
            this._failedSyncs++;
        }
        this._lastChainHeight = this._partialChain.proofHeadHeight;

        // XXX Only one getBlocks request at a time.
        if (this._peer.channel.isExpectingMessage(Message.Type.INV)) {
            Log.e(LightConsensusAgent, 'Duplicate _requestProofBlocks()');
            return;
        }

        // Drop the peer if it doesn't start sending InvVectors for its chain within the timeout.
        this._peer.channel.expectMessage(Message.Type.INV, () => {
            this._peer.channel.close(CloseType.GET_BLOCKS_TIMEOUT, 'getBlocks timeout');
        }, BaseConsensusAgent.REQUEST_TIMEOUT);

        // Request the full block for our proof head.
        const locators = this._partialChain.getBlockLocators();
        this.requestVector(new InvVector(InvVector.Type.BLOCK, locators[0]));

        // Request blocks from peer.
        this._peer.channel.getBlocks(locators, this._partialChain.numBlocksNeeded(), false);
    }

    // Block processing.
    /**
     * @returns {Promise.<void>}
     * @private
     */
    _requestBlocks() {
        // If we are syncing and not yet sure whether our blocks are on the main chain, just sync one block for now.
        if (this._syncing && !this._onMainChain) {
            return super._requestBlocks(1);
        }
        return super._requestBlocks();
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processBlock(hash, block) {
        // If we find that we are on a fork far away from our chain, resync.
        if (block.height < this._chain.height - Policy.NUM_BLOCKS_VERIFICATION
            && (!this._partialChain || this._partialChain.state !== PartialLightChain.State.PROVE_BLOCKS)) {
            this._onMainChain = false;
            await this._initChainProofSync();
            this.syncBlockchain().catch(Log.e.tag(LightConsensusAgent));
            return;
        } else {
            this._onMainChain = true;
        }

        // Put block into blockchain.
        const status = await this._chain.pushBlock(block);

        switch (status) {
            case FullChain.ERR_INVALID:
                this._peer.channel.close(CloseType.INVALID_BLOCK, 'received invalid block');
                break;

            case FullChain.OK_EXTENDED:
            case FullChain.OK_REBRANCHED:
                if (this._syncing) this._numBlocksExtending++;
                break;

            case FullChain.OK_FORKED:
                if (this._syncing) {
                    this._numBlocksForking++;
                    this._forkHead = block;
                }
                break;

            case LightChain.ERR_ORPHAN:
                this._onOrphanBlock(hash, block);
                break;
        }
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {void}
     * @protected
     * @override
     */
    async _onKnownBlockAnnounced(hash, block) {
        if (this._syncing && this._catchup) {
            // If we find that we are on a fork far away from our chain, resync.
            if (block.height < this._chain.height - Policy.NUM_BLOCKS_VERIFICATION
                && (!this._partialChain || this._partialChain.state !== PartialLightChain.State.PROVE_BLOCKS)) {
                this._onMainChain = false;
                await this._initChainProofSync();
                this.syncBlockchain().catch(Log.e.tag(LightConsensusAgent));
                return;
            } else {
                this._onMainChain = true;
            }

            FullConsensusAgent.prototype._onKnownBlockAnnounced.call(this, hash, block);
        }
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @private
     * @override
     */
    _onOrphanBlock(hash, block) {
        if (this._syncing && !this._catchup) {
            this._orphanedBlocks.push(block);
        } else {
            super._onOrphanBlock(hash, block);
        }
    }

    // Header processing.
    /**
     * @param {Hash} hash
     * @return {Promise.<BlockHeader>}
     */
    getHeader(hash) {
        Assert.that(!this._headerRequest);

        return new Promise((resolve, reject) => {
            const vector = new InvVector(InvVector.Type.BLOCK, hash);
            this._headerRequest = {
                hash,
                resolve,
                reject
            };

            this._peer.channel.getHeader([vector]);

            // Drop the peer if it doesn't send the accounts proof within the timeout.
            this._peer.channel.expectMessage(Message.Type.HEADER, () => {
                this._headerRequest = null;
                this._peer.channel.close(CloseType.GET_HEADER_TIMEOUT, 'getHeader timeout');
                reject(new Error('Timeout'));
            }, BaseConsensusAgent.REQUEST_TIMEOUT);
        });
    }

    /**
     * @param {HeaderMessage} msg
     * @return {void}
     * @protected
     * @override
     */
    _onHeader(msg) {
        const header = msg.header;
        const hash = header.hash();

        // Check if we have requested this block.
        if (!this._headerRequest) {
            Log.w(NanoConsensusAgent, `Unsolicited header ${hash} received from ${this._peer.peerAddress}, discarding`);
            return;
        }

        const {hash: requestedHash, resolve, reject} = this._headerRequest;
        this._headerRequest = null;

        // Check that it is the correct hash.
        if (!requestedHash.equals(hash)) {
            Log.w(LightConsensusAgent, `Received wrong header from ${this._peer.peerAddress}`);
            this._peer.channel.close(CloseType.UNEXPECTED_HEADER, 'Received wrong header');
            reject(new Error('Received wrong header'));
            return;
        }

        resolve(header);
    }

    /**
     * @returns {void}
     * @protected
     * @override
     */
    _onClose() {
        if (this._partialChain) {
            this._partialChain.abort().catch(Log.w.tag(LightConsensusAgent));
        }

        super._onClose();
    }

    /** @type {LightChain} */
    get _chain() {
        if (this._syncing && !this._catchup && this._partialChain) {
            return this._partialChain;
        }
        return this._blockchain;
    }

    /** @type {boolean} */
    get syncing() {
        return this._syncing;
    }
}
/**
 * Maximum time (ms) to wait for chain-proof after sending out get-chain-proof before dropping the peer.
 * @type {number}
 */
LightConsensusAgent.CHAINPROOF_REQUEST_TIMEOUT = 1000 * 45;
/**
 * Maximum time (ms) to wait for between chain-proof chunks before dropping the peer.
 * @type {number}
 */
LightConsensusAgent.CHAINPROOF_CHUNK_TIMEOUT = 1000 * 10;
/**
 * Maximum time (ms) to wait for accounts-tree-chunk after sending out get-accounts-tree-chunk before dropping the peer.
 * @type {number}
 */
LightConsensusAgent.ACCOUNTS_TREE_CHUNK_REQUEST_TIMEOUT = 1000 * 8;
/**
 * Maximum number of blockchain sync retries before closing the connection.
 * @type {number}
 */
LightConsensusAgent.SYNC_ATTEMPTS_MAX = 5;
/**
 * Maximum number of inventory vectors to sent in the response for onGetBlocks.
 * @type {number}
 */
LightConsensusAgent.GETBLOCKS_VECTORS_MAX = 500;
/**
 * Maximum number of weak proofs we allow before closing the connection.
 * @type {number}
 */
LightConsensusAgent.WEAK_PROOFS_MAX = 3;

Class.register(LightConsensusAgent);

class LightConsensus extends BaseConsensus {
    /**
     * @param {LightChain} blockchain
     * @param {Mempool} mempool
     * @param {Network} network
     */
    constructor(blockchain, mempool, network) {
        super(blockchain, mempool, network);
        /** @type {LightChain} */
        this._blockchain = blockchain;
        /** @type {Mempool} */
        this._mempool = mempool;
        /** @type {BlockProducer} */
        this._producer = new BlockProducer(blockchain, blockchain.accounts, mempool, network.time);
    }

    //
    // Public consensus interface
    //

    /**
     * @param {Address} minerAddress
     * @param {Uint8Array} [extraData]
     * @returns {Promise.<Block>}
     */
    getBlockTemplate(minerAddress, extraData) {
        return this._producer.getNextBlock(minerAddress, extraData);
    }

    /**
     * @param {Block} block
     * @returns {Promise.<boolean>}
     */
    async submitBlock(block) {
        return (await this.blockchain.pushBlock(block)) >= 0;
    }

    /**
     * @param {Array.<Address>} addresses
     * @returns {Promise.<Array.<Account>>}
     */
    getAccounts(addresses) {
        return Promise.all(addresses.map(addr => this._blockchain.accounts.get(addr)));
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactions(hashes) { // eslint-disable-line require-await
        return /** @type {Array.<Transaction>} */ hashes.map(hash => this._mempool.getTransaction(hash)).filter(tx => tx != null);
    }

    /**
     * @param {Address} address
     * @param {number} limit
     * @returns {Promise.<Array.<Transaction>>}
     */
    async getPendingTransactionsByAddress(address, limit) { // eslint-disable-line require-await
        return this._mempool.getTransactionsByAddresses([address], limit);
    }

    /**
     * @param {Transaction} tx
     * @returns {Promise.<BaseConsensus.SendTransactionResult>}
     */
    async sendTransaction(tx) {
        const mempoolCode = await this._mempool.pushTransaction(tx);
        switch (mempoolCode) {
            case Mempool.ReturnCode.ACCEPTED: {
                // Wait for transaction relay
                const relayed = await new Promise((resolve) => {
                    let id;
                    // eslint-disable-next-line prefer-const
                    id = this.on('transaction-relayed', relayedTx => {
                        if (relayedTx.equals(tx)) {
                            this.off('transaction-relayed', id);
                            resolve(true);
                        }
                    });
                    setTimeout(() => {
                        this.off('transaction-relayed', id);
                        resolve(false);
                    }, BaseConsensus.TRANSACTION_RELAY_TIMEOUT);
                });
                if (relayed) {
                    return BaseConsensus.SendTransactionResult.RELAYED;
                } else {
                    return BaseConsensus.SendTransactionResult.PENDING_LOCAL;
                }
            }
            case Mempool.ReturnCode.KNOWN:
                return BaseConsensus.SendTransactionResult.KNOWN;
            case Mempool.ReturnCode.FEE_TOO_LOW:
            case Mempool.ReturnCode.FILTERED:
                return BaseConsensus.SendTransactionResult.REJECTED_LOCAL;
            case Mempool.ReturnCode.MINED:
                return BaseConsensus.SendTransactionResult.ALREADY_MINED;
            case Mempool.ReturnCode.EXPIRED:
                return BaseConsensus.SendTransactionResult.EXPIRED;
            case Mempool.ReturnCode.INVALID:
                return BaseConsensus.SendTransactionResult.INVALID;
        }
        return BaseConsensus.SendTransactionResult.NONE;
    }

    /**
     * @returns {Array.<Transaction>}
     */
    getMempoolContents() {
        return this._mempool.getTransactions();
    }

    //
    //

    /**
     * @param {number} minFeePerByte
     */
    subscribeMinFeePerByte(minFeePerByte) {
        this.subscribe(Subscription.fromMinFeePerByte(minFeePerByte));
        this.mempool.evictBelowMinFeePerByte(minFeePerByte);
    }

    /**
     * @type {number} minFeePerByte
     */
    get minFeePerByte() {
        return this._subscription.type === Subscription.Type.MIN_FEE ? this._subscription.minFeePerByte : 0;
    }

    /**
     * @param {Peer} peer
     * @returns {BaseConsensusAgent}
     * @override
     */
    _newConsensusAgent(peer) {
        return new LightConsensusAgent(this._blockchain, this._mempool, this._network.time, peer, this._invRequestManager, this._subscription);
    }

    /**
     * @param {Peer} peer
     * @override
     */
    _onPeerJoined(peer) {
        const agent = super._onPeerJoined(peer);

        // Forward sync events.
        this.bubble(agent, 'sync-chain-proof', 'verify-chain-proof', 'sync-accounts-tree', 'verify-accounts-tree', 'sync-finalize');

        return agent;
    }

    /** @type {LightChain} */
    get blockchain() {
        return this._blockchain;
    }

    /** @type {Mempool} */
    get mempool() {
        return this._mempool;
    }
}

Class.register(LightConsensus);

class PartialLightChain extends LightChain {
    /**
     * @param {ChainDataStore} store
     * @param {Accounts} accounts
     * @param {Time} time
     * @param {ChainProof} proof
     * @param {PrioritySynchronizer} commitSynchronizer
     * @returns {PartialLightChain}
     */
    constructor(store, accounts, time, proof, commitSynchronizer) {
        const tx = store.transaction(false);
        super(tx, accounts, time);

        /** @type {ChainProof} */
        this._proof = proof;

        /** @type {PartialLightChain.State} */
        this._state = PartialLightChain.State.PROVE_CHAIN;
        /** @type {PartialAccountsTree} */
        this._partialTree = null;
        /** @type {Accounts} */
        this._accountsTx = null;
        /** @type {ChainData} */
        this._proofHead = null;
        /** @type {PrioritySynchronizer} */
        this._commitSynchronizer = commitSynchronizer;
    }

    /**
     * @param {ChainProof} proof
     * @returns {Promise.<boolean>}
     */
    pushProof(proof) {
        // Synchronize with .pushBlock()
        return this._synchronizer.push(/*priority*/ 0,
            this._pushProof.bind(this, proof));
    }

    /**
     * @param {ChainProof} proof
     * @returns {Promise.<boolean>}
     * @private
     */
    async _pushProof(proof) {
        const toDo = [];
        for (let i = 0; i < proof.prefix.length; ++i) {
            const block = proof.prefix.blocks[i];
            const hash = block.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (!knownBlock && !block.header._pow) {
                toDo.push(block.header);
            }
        }
        for (let i = 0; i < proof.suffix.length; ++i) {
            const header = proof.suffix.headers[i];
            const hash = header.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (!knownBlock && !header._pow) {
                toDo.push(header);
            }
        }
        await BaseChain.manyPow(toDo);

        // Verify all prefix blocks that we don't know yet.
        for (let i = 0; i < proof.prefix.length; i++) {
            const block = proof.prefix.blocks[i];
            const hash = block.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (knownBlock) {
                proof.prefix.blocks[i] = knownBlock.toLight();
            } else if (!(await block.verify(this._time))) {
                Log.w(PartialLightChain, 'Rejecting proof - prefix contains invalid block');
                return false;
            }
        }

        // Verify all suffix headers that we don't know yet.
        for (let i = 0; i < proof.suffix.length; i++) {
            const header = proof.suffix.headers[i];
            const hash = header.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (knownBlock) {
                proof.suffix.headers[i] = knownBlock.header;
            } else if (!(await header.verifyProofOfWork())) {
                Log.w(PartialLightChain, 'Rejecting proof - suffix contains invalid header');
                return false;
            }
        }

        // Check that the proof is valid.
        if (!(await proof.verify())) {
            Log.w(PartialLightChain, 'Rejecting proof - verification failed');
            return false;
        }

        // Check that the suffix is long enough.
        if (proof.suffix.length !== Policy.K && proof.suffix.length !== proof.head.height - 1) {
            Log.w(PartialLightChain, 'Rejecting proof - invalid suffix length');
            return false;
        }

        // Check that the dense suffix of the prefix is long enough.
        // The paper doesn't require this, we however need a sufficiently long dense suffix
        // to be able to verify block difficulties.
        const denseSuffix = proof.prefix.denseSuffix();
        if (denseSuffix.length < Policy.M && proof.prefix.length > 0 && proof.prefix.head.height >= Policy.M) {
            Log.w(NanoChain, 'Rejecting proof - dense suffix too short');
            return false;
        }

        // Compute and verify interlinks for the suffix.
        const suffixBlocks = [];
        let head = proof.prefix.head;
        for (const header of proof.suffix.headers) {
            const interlink = await head.getNextInterlink(header.target, header.version);
            const interlinkHash = interlink.hash();
            if (!header.interlinkHash.equals(interlinkHash)) {
                Log.w(PartialLightChain, 'Rejecting proof - invalid interlink hash in proof suffix');
                return false;
            }

            head = new Block(header, interlink);
            suffixBlocks.push(head);
        }

        // If the given proof is better than our current proof, adopt the given proof as the new best proof.
        const currentProof = this._proof || await this._getChainProof();
        if (await BaseChain.isBetterProof(proof, currentProof, Policy.M)) {
            await this._acceptProof(proof, suffixBlocks);
        } else {
            await this.abort();
            this._state = PartialLightChain.State.WEAK_PROOF;
        }

        return true;
    }

    /**
     * @param {ChainProof} proof
     * @param {Array.<Block>} suffix
     * @returns {Promise.<void>}
     * @protected
     */
    async _acceptProof(proof, suffix) {
        // Delete our current chain.
        await this._store.truncate();

        /** @type {Array.<Block>} */
        const denseSuffix = proof.prefix.denseSuffix();

        // Put all other prefix blocks in the store as well (so they can be retrieved via getBlock()/getBlockAt()),
        // but don't allow blocks to be appended to them by setting totalDifficulty = -1;
        let superBlockCounts = new SuperBlockCounts();
        for (let i = 0; i < proof.prefix.length - denseSuffix.length; i++) {
            const block = proof.prefix.blocks[i];
            const hash = block.hash();
            const depth = BlockUtils.getHashDepth(await block.pow());
            superBlockCounts = superBlockCounts.copyAndAdd(depth);

            const data = new ChainData(block, /*totalDifficulty*/ new BigNumber(-1), /*totalWork*/ new BigNumber(-1), superBlockCounts, true);
            await this._store.putChainData(hash, data);
        }

        // Set the tail end of the dense suffix of the prefix as the new chain head.
        const tailEnd = denseSuffix[0];
        this._headHash = tailEnd.hash();
        this._mainChain = await ChainData.initial(tailEnd, superBlockCounts);
        await this._store.putChainData(this._headHash, this._mainChain);

        // Only in the dense suffix of the prefix we can calculate the difficulties.
        for (let i = 1; i < denseSuffix.length; i++) {
            const block = denseSuffix[i];
            const result = await this._pushLightBlock(block); // eslint-disable-line no-await-in-loop
            Assert.that(result >= 0);
        }

        // Push all suffix blocks.
        for (const block of suffix) {
            const result = await this._pushLightBlock(block); // eslint-disable-line no-await-in-loop
            Assert.that(result >= 0);
        }

        this._state = PartialLightChain.State.PROVE_ACCOUNTS_TREE;
        this._partialTree = await this._accounts.partialAccountsTree();
        this._proofHead = this._mainChain;
        await this._store.setHead(this.headHash);

        this._proof = proof;
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     * @private
     */
    async _pushLightBlock(block) {
        // Check if we already know this header/block.
        const hash = block.hash();
        const knownBlock = await this._store.getBlock(hash);
        if (knownBlock) {
            return NanoChain.OK_KNOWN;
        }

        // Retrieve the immediate predecessor.
        /** @type {ChainData} */
        const prevData = await this._store.getChainData(block.prevHash);
        if (!prevData || prevData.totalDifficulty.lte(0)) {
            return NanoChain.ERR_ORPHAN;
        }

        return this._pushBlockInternal(block, hash, prevData);
    }

    /**
     * @param {Block} block
     * @param {Hash} blockHash
     * @param {ChainData} prevData
     * @returns {Promise.<number>}
     * @private
     */
    async _pushBlockInternal(block, blockHash, prevData) {
        // Block looks good, create ChainData.
        const chainData = await prevData.nextChainData(block);

        // Check if the block extends our current main chain.
        if (block.prevHash.equals(this.headHash)) {
            // Append new block to the main chain.
            chainData.onMainChain = true;
            prevData.mainChainSuccessor = blockHash;

            await this._store.putChainData(blockHash, chainData);
            await this._store.putChainData(block.prevHash, prevData, /*includeBody*/ false);

            // Update head.
            this._mainChain = chainData;
            this._headHash = blockHash;

            // Append new block to chain proof.
            if (this._proof) {
                const proofHeadHash = this._proof.head.hash();
                if (block.prevHash.equals(proofHeadHash)) {
                    this._proof = await this._extendChainProof(this._proof, block.header);
                }
            }

            // Tell listeners that the head of the chain has changed.
            this.fire('head-changed', this.head, /*rebranching*/ false);

            return NanoChain.OK_EXTENDED;
        }

        throw new Error('Invalid call to _pushBlockInternal');
    }

    /**
     * @override
     * @param {Block} block
     * @returns {Promise.<number>}
     */
    _pushBlock(block) {
        // Queue new blocks while syncing.
        if (this._state === PartialLightChain.State.PROVE_BLOCKS) {
            const blockHash = block.hash();
            if (this._proofHead.head.prevHash.equals(blockHash)) {
                return this._pushBlockBackwards(block);
            } else if (this._proofHead.head.hash().equals(blockHash)) {
                return this._pushHeadBlock(block);
            }
        }

        return FullChain.ERR_ORPHAN;
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     * @private
     */
    async _pushHeadBlock(block) {
        // Check if we already know this block.
        const hash = block.hash();

        // Check that the given block is a full block (includes block body).
        if (!block.isFull()) {
            Log.w(PartialLightChain, 'Rejecting block - body missing');
            return FullChain.ERR_INVALID;
        }

        // Check all intrinsic block invariants.
        if (!(await block.verify(this._time))) {
            return FullChain.ERR_INVALID;
        }

        // Check that all known interlink blocks are valid predecessors of the given block.
        if (!(await this._verifyInterlink(block))) {
            Log.w(PartialLightChain, 'Rejecting block - interlink verification failed');
            return FullChain.ERR_INVALID;
        }

        // We know that the current proof head is the successor.
        // Check that the block is a valid predecessor of its immediate successor.
        const prevData = await this._store.getChainData(block.prevHash);
        if (!prevData) {
            Log.w(PartialLightChain, 'Rejecting block - unknown predecessor');
            return FullChain.ERR_ORPHAN;
        }

        // Check that the block is a valid successor of its immediate predecessor.
        const predecessor = prevData.head;
        if (!(await block.isImmediateSuccessorOf(predecessor))) {
            Log.w(PartialLightChain, 'Rejecting block - not a valid immediate successor');
            return FullChain.ERR_INVALID;
        }

        // Check that the difficulty is correct.
        const nextTarget = await this.getNextTarget(predecessor);
        if (BlockUtils.isValidTarget(nextTarget)) {
            if (block.nBits !== BlockUtils.targetToCompact(nextTarget)) {
                Log.w(PartialLightChain, 'Rejecting block - difficulty mismatch');
                return FullChain.ERR_INVALID;
            }
        } else {
            Log.w(PartialLightChain, 'Skipping difficulty verification - not enough blocks available');
        }

        // Block looks good, create ChainData.
        const chainData = await prevData.nextChainData(block);

        // Prepend new block to the main chain.
        if (!(await this._prepend(hash, chainData))) {
            return FullChain.ERR_INVALID;
        }

        this._mainChain = chainData;
        this._proofHead = chainData; // So now it is a full block.
        this._headHash = hash;

        // Check whether we're complete.
        if (!this.needsMoreBlocks()) {
            const result = await this._complete();
            if (!result) {
                return FullChain.ERR_INVALID;
            }
        }

        return FullChain.OK_EXTENDED;
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     * @private
     */
    async _pushBlockBackwards(block) {
        // Check if we already know this block.
        const hash = block.hash();

        // Check that the given block is a full block (includes block body).
        if (!block.isFull()) {
            Log.w(PartialLightChain, 'Rejecting block - body missing');
            return FullChain.ERR_INVALID;
        }

        // Check all intrinsic block invariants.
        if (!(await block.verify(this._time))) {
            return FullChain.ERR_INVALID;
        }

        // Check that all known interlink blocks are valid predecessors of the given block.
        if (!(await this._verifyInterlink(block))) {
            Log.w(PartialLightChain, 'Rejecting block - interlink verification failed');
            return FullChain.ERR_INVALID;
        }

        // We know that the current proof head is the successor.
        // Check that the block is a valid predecessor of its immediate successor.
        if (!(await this._proofHead.head.isImmediateSuccessorOf(block))) {
            Log.w(PartialLightChain, 'Rejecting block - not a valid immediate predecessor');
            return FullChain.ERR_INVALID;
        }

        // Check that the difficulty is correct.
        const nextTarget = await this.getNextTarget(block);
        if (BlockUtils.isValidTarget(nextTarget)) {
            if (this._proofHead.head.nBits !== BlockUtils.targetToCompact(nextTarget)) {
                Log.w(PartialLightChain, 'Rejecting block - difficulty mismatch');
                return FullChain.ERR_INVALID;
            }
        } else {
            Log.w(PartialLightChain, 'Skipping difficulty verification - not enough blocks available');
        }

        // Block looks good, create ChainData.
        const chainData = await this._proofHead.previousChainData(block);

        // Prepend new block to the main chain.
        if (!(await this._prepend(hash, chainData))) {
            return FullChain.ERR_INVALID;
        }

        return FullChain.OK_EXTENDED;
    }

    /**
     * @param {Hash} blockHash
     * @param {ChainData} chainData
     * @returns {Promise.<boolean>}
     * @private
     */
    async _prepend(blockHash, chainData) {
        try {
            const transactionCache = new TransactionCache();
            await this._accountsTx.revertBlock(chainData.head, transactionCache);
        } catch (e) {
            // AccountsHash mismatch. This can happen if someone gives us an invalid block.
            Log.w(PartialLightChain, `Rejecting block - failed to commit to AccountsTree: ${e.message || e}`);
            return false;
        }

        chainData.onMainChain = true;
        chainData.mainChainSuccessor = chainData.head.hash().equals(this._proofHead.head.hash()) ? null : this._proofHead.head.hash();
        await this._store.putChainData(blockHash, chainData);

        this._proofHead = chainData;

        // Check whether we're complete.
        if (!this.needsMoreBlocks()) {
            return this._complete();
        }

        return true;
    }

    /**
     * @param {AccountsTreeChunk} chunk
     * @returns {Promise.<PartialAccountsTree.Status>}
     */
    async pushAccountsTreeChunk(chunk) {
        if (this._state !== PartialLightChain.State.PROVE_ACCOUNTS_TREE) {
            return PartialAccountsTree.Status.ERR_INCORRECT_PROOF;
        }

        const result = await this._partialTree.pushChunk(chunk);

        // If we're done, prepare next phase.
        if (result === PartialAccountsTree.Status.OK_COMPLETE) {
            this._state = PartialLightChain.State.PROVE_BLOCKS;
            this._accountsTx = new Accounts(this._partialTree.transaction(false));
        }

        return result;
    }

    /**
     * @returns {Promise.<boolean>}
     * @private
     */
    async _complete() {
        // Build up transaction cache and validate against double spends
        this._transactionCache = new TransactionCache();
        let chainData = this._proofHead;
        while (chainData) {
            // Check against transaction cache
            for (const tx of chainData.head.transactions) {
                if (this._transactionCache.containsTransaction(tx)) {
                    Log.w(PartialLightChain, `Rejecting block - Double Transaction Error!`);
                    return false;
                }
            }
            this._transactionCache.pushBlock(chainData.head);
            chainData = chainData.mainChainSuccessor ? await this._store.getChainData(chainData.mainChainSuccessor, true) : null;
        }

        this._state = PartialLightChain.State.COMPLETE;
        if (this._accountsTx) {
            await this._accountsTx.abort();
            this._accountsTx = null;
        }

        const currentProof = this._proof || await this._getChainProof();
        this.fire('complete', currentProof, this._headHash, this._mainChain, this._transactionCache);
        return true;
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async commit() {
        return this._commitSynchronizer.push(/*priority*/ 0,
            this._commit.bind(this));
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async _commit() {
        if (this._accountsTx) {
            await this._accountsTx.abort();
            this._accountsTx = null;
        }

        const result = await JDB.JungleDB.commitCombined(...this._store.txs, this._partialTree.tx);
        this._partialTree = null;

        const currentProof = this._proof || await this._getChainProof();
        // Only set values in FullChain if commit was successful
        if (result) {
            this.fire('committed', currentProof, this._headHash, this._mainChain, this._transactionCache);
        }

        return result;
    }

    /**
     * @returns {Promise.<void>}
     */
    async abort() {
        if (this._state === PartialLightChain.State.ABORTED) return;
        this._state = PartialLightChain.State.ABORTED;
        if (this._accountsTx) {
            await this._accountsTx.abort();
            this._accountsTx = null;
        }
        if (this._partialTree) {
            await this._partialTree.abort();
            this._partialTree = null;
        }
        await this._store.abort();
        this.fire('aborted');
    }

    /**
     * @returns {string}
     */
    getMissingAccountsPrefix() {
        if (this._partialTree) {
            return this._partialTree.missingPrefix;
        }
        return '';
    }

    /**
     * @returns {Array.<Hash>}
     */
    getBlockLocators() {
        return this._proofHead ? [this._proofHead.head.hash()] : [this.headHash];
    }

    /**
     * @returns {number}
     */
    numBlocksNeeded() {
        if (!this._proofHead) {
            return Policy.NUM_BLOCKS_VERIFICATION;
        }
        let numBlocks = Policy.NUM_BLOCKS_VERIFICATION - (this.height - this._proofHead.head.height + 1);
        // If we begin syncing, we need one block additionally.
        if (!this._proofHead.head.isFull()) {
            numBlocks++;
        }
        return numBlocks;
    }

    /**
     * @returns {boolean}
     */
    needsMoreBlocks() {
        return this.numBlocksNeeded() > 0;
    }

    /** @type {PartialLightChain.State} */
    get state() {
        return this._state;
    }

    /** @type {number} */
    get proofHeadHeight() {
        return this._proofHead.head.height;
    }
}
/**
 * @enum {number}
 */
PartialLightChain.State = {
    WEAK_PROOF: -2,
    ABORTED: -1,
    PROVE_CHAIN: 0,
    PROVE_ACCOUNTS_TREE: 1,
    PROVE_BLOCKS: 2,
    COMPLETE: 3
};
Class.register(PartialLightChain);

class NanoChain extends BaseChain {
    /**
     * @param {Time} time
     * @returns {Promise.<NanoChain>}
     */
    constructor(time) {
        super(ChainDataStore.createVolatile());

        /** @type {Time} */
        this._time = time;

        /** @type {ChainProof} */
        this._proof = new ChainProof(new BlockChain([GenesisConfig.GENESIS_BLOCK.toLight()]), new HeaderChain([]));

        /** @type {Hash} */
        this._headHash = GenesisConfig.GENESIS_HASH;

        /** @type {PrioritySynchronizer} */
        this._synchronizer = new PrioritySynchronizer(2, NanoChain.SYNCHRONIZER_THROTTLE_AFTER, NanoChain.SYNCHRONIZER_THROTTLE_WAIT);

        return this._init();
    }

    async _init() {
        this._mainChain = await ChainData.initial(GenesisConfig.GENESIS_BLOCK);
        await this._store.putChainData(GenesisConfig.GENESIS_HASH, this._mainChain);

        return this;
    }

    /**
     * @param {ChainProof} proof
     * @returns {Promise.<boolean>}
     */
    pushProof(proof) {
        return this._synchronizer.push(/*priority*/ 0,
            this._pushProof.bind(this, proof));
    }

    /**
     * @param {ChainProof} proof
     * @returns {Promise.<boolean>}
     * @private
     */
    async _pushProof(proof) {
        const toDo = [];
        for (let i = 0; i < proof.prefix.length; ++i) {
            const block = proof.prefix.blocks[i];
            const hash = block.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (!knownBlock && !block.header._pow) {
                toDo.push(block.header);
            }
        }
        for (let i = 0; i < proof.suffix.length; ++i) {
            const header = proof.suffix.headers[i];
            const hash = header.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (!knownBlock && !header._pow) {
                toDo.push(header);
            }
        }
        await BaseChain.manyPow(toDo);

        // Verify all prefix blocks that we don't know yet.
        for (let i = 0; i < proof.prefix.length; i++) {
            if ((i % 1000) === 999) await EventLoopHelper.webYield();
            const block = proof.prefix.blocks[i];
            const hash = block.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (knownBlock) {
                proof.prefix.blocks[i] = knownBlock.toLight();
            } else if (!(await block.verify(this._time))) {
                Log.w(NanoChain, 'Rejecting proof - prefix contains invalid block');
                return false;
            }
        }

        // Verify all suffix headers that we don't know yet.
        for (let i = 0; i < proof.suffix.length; i++) {
            const header = proof.suffix.headers[i];
            const hash = header.hash();
            const knownBlock = await this._store.getBlock(hash);
            if (knownBlock) {
                proof.suffix.headers[i] = knownBlock.header;
            } else if (!(await header.verifyProofOfWork())) {
                Log.w(NanoChain, 'Rejecting proof - suffix contains invalid header');
                return false;
            }
        }

        // Check that the proof is valid.
        if (!(await proof.verify())) {
            Log.w(NanoChain, 'Rejecting proof - verification failed');
            return false;
        }

        // Check that the suffix is long enough.
        if (proof.suffix.length !== Policy.K && proof.suffix.length !== proof.head.height - 1) {
            Log.w(NanoChain, 'Rejecting proof - invalid suffix length');
            return false;
        }

        // Check that the dense suffix of the prefix is long enough.
        // The paper doesn't require this, we however need a sufficiently long dense suffix
        // to be able to verify block difficulties.
        const denseSuffix = proof.prefix.denseSuffix();
        if (denseSuffix.length < Policy.M && proof.prefix.length > 0 && proof.prefix.head.height >= Policy.M) {
            Log.w(NanoChain, 'Rejecting proof - dense suffix too short');
            return false;
        }

        // Compute and verify interlinks for the suffix.
        const suffixBlocks = [];
        let head = proof.prefix.head;
        for (const header of proof.suffix.headers) {
            const interlink = await head.getNextInterlink(header.target, header.version);
            const interlinkHash = interlink.hash();
            if (!header.interlinkHash.equals(interlinkHash)) {
                Log.w(NanoChain, 'Rejecting proof - invalid interlink hash in proof suffix');
                return false;
            }

            head = new Block(header, interlink);
            suffixBlocks.push(head);
        }

        await EventLoopHelper.webYield();

        // If the given proof is better than our current proof, adopt the given proof as the new best proof.
        const currentProof = this._proof || await this._getChainProof();
        if (await BaseChain.isBetterProof(proof, currentProof, Policy.M)) {
            await this._acceptProof(proof, suffixBlocks);
        }

        return true;
    }

    /**
     * @param {ChainProof} proof
     * @param {Array.<Block>} suffix
     * @returns {Promise.<void>}
     * @private
     */
    async _acceptProof(proof, suffix) {
        this._proof = proof;

        // If the proof prefix head is not part of our current dense chain suffix, reset store and start over.
        // TODO use a store transaction here?
        const head = proof.prefix.head;
        const headHash = head.hash();
        const headData = await this._store.getChainData(headHash);
        if (!headData || headData.totalDifficulty.lte(0)) {
            // Delete our current chain.
            await this._store.truncate();

            /** @type {Array.<Block>} */
            const denseSuffix = proof.prefix.denseSuffix();

            // Store all prefix blocks so they can be retrieved via getBlock()/getBlockAt()),
            // but don't allow blocks to be appended to them by setting totalDifficulty = -1;
            let superBlockCounts = new SuperBlockCounts();
            for (let i = 0; i < proof.prefix.length - denseSuffix.length; i++) {
                if ((i % 100) === 99) await EventLoopHelper.webYield();

                const block = proof.prefix.blocks[i];
                const hash = block.hash();
                const depth = BlockUtils.getHashDepth(await block.pow());
                superBlockCounts = superBlockCounts.copyAndAdd(depth);

                const data = new ChainData(block, /*totalDifficulty*/ new BigNumber(-1), /*totalWork*/ new BigNumber(-1), superBlockCounts, true);
                await this._store.putChainData(hash, data);
            }

            // Set the tail end of the dense suffix of the prefix as the new chain head.
            const tailEnd = denseSuffix[0];
            this._headHash = tailEnd.hash();
            this._mainChain = await ChainData.initial(tailEnd, superBlockCounts);
            await this._store.putChainData(this._headHash, this._mainChain);

            // Only in the dense suffix of the prefix we can calculate the difficulties.
            for (let i = 1; i < denseSuffix.length; i++) {
                if ((i % 50) === 49) await EventLoopHelper.webYield();

                const block = denseSuffix[i];
                const result = await this._pushBlock(block); // eslint-disable-line no-await-in-loop
                Assert.that(result >= 0);
            }
        }

        // Push all suffix blocks.
        for (const block of suffix) {
            if ((block.height % 50) === 49) await EventLoopHelper.webYield();

            const result = await this._pushBlock(block); // eslint-disable-line no-await-in-loop
            Assert.that(result >= 0);
        }
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     * @private
     */
    async _pushBlock(block) {
        // Check if we already know this header/block.
        const hash = await block.hash();
        const knownBlock = await this._store.getBlock(hash);
        if (knownBlock) {
            return NanoChain.OK_KNOWN;
        }

        // Retrieve the immediate predecessor.
        /** @type {ChainData} */
        const prevData = await this._store.getChainData(block.prevHash);
        if (!prevData || prevData.totalDifficulty.lte(0)) {
            return NanoChain.ERR_ORPHAN;
        }

        return this._pushBlockInternal(block, hash, prevData);
    }

    /**
     * @param {BlockHeader} header
     * @returns {Promise.<number>}
     */
    pushHeader(header) {
        // Synchronize with .pushProof()
        return this._synchronizer.push(/*priority*/ 0,
            this._pushHeader.bind(this, header));
    }

    /**
     * @param {BlockHeader} header
     * @returns {Promise.<number>}
     * @private
     */
    async _pushHeader(header) {
        // Check if we already know this header/block.
        const hash = header.hash();
        const knownBlock = await this._store.getBlock(hash);
        if (knownBlock) {
            return NanoChain.OK_KNOWN;
        }

        // Verify proof of work.
        if (!(await header.verifyProofOfWork())) {
            Log.w(NanoChain, 'Rejecting header - PoW verification failed');
            return NanoChain.ERR_INVALID;
        }

        // Retrieve the immediate predecessor.
        /** @type {ChainData} */
        const prevData = await this._store.getChainData(header.prevHash);
        if (!prevData || prevData.totalDifficulty.lte(0)) {
            Log.w(NanoChain, 'Rejecting header - unknown predecessor');
            return NanoChain.ERR_ORPHAN;
        }

        // Check that the block is valid successor to its predecessor.
        /** @type {Block} */
        const predecessor = prevData.head;
        if (!header.isImmediateSuccessorOf(predecessor.header)) {
            Log.w(NanoChain, 'Rejecting header - not a valid successor');
            return NanoChain.ERR_INVALID;
        }

        // Check that the difficulty is correct (if we can compute the next target)
        const nextTarget = await this.getNextTarget(predecessor);
        if (BlockUtils.isValidTarget(nextTarget)) {
            if (header.nBits !== BlockUtils.targetToCompact(nextTarget)) {
                Log.w(NanoChain, 'Rejecting header - difficulty mismatch');
                return NanoChain.ERR_INVALID;
            }
        } else {
            Log.w(NanoChain, 'Skipping difficulty verification - not enough blocks available');
        }

        // Compute and verify interlink.
        const interlink = await predecessor.getNextInterlink(header.target, header.version);
        const interlinkHash = interlink.hash();
        if (!interlinkHash.equals(header.interlinkHash)) {
            Log.w(NanoChain, 'Rejecting header - interlink verification failed');
            return NanoChain.ERR_INVALID;
        }

        const block = new Block(header, interlink);
        return this._pushBlockInternal(block, hash, prevData);
    }

    /**
     * @param {Block} block
     * @param {Hash} blockHash
     * @param {ChainData} prevData
     * @returns {Promise.<number>}
     * @private
     */
    async _pushBlockInternal(block, blockHash, prevData) {
        // Block looks good, create ChainData.
        const chainData = await prevData.nextChainData(block);

        // Check if the block extends our current main chain.
        if (block.prevHash.equals(this.headHash)) {
            // Append new block to the main chain.
            chainData.onMainChain = true;
            prevData.mainChainSuccessor = blockHash;

            const storeTx = this._store.synchronousTransaction();
            storeTx.putChainDataSync(blockHash, chainData);
            storeTx.putChainDataSync(block.prevHash, prevData);
            await storeTx.commit();

            // Update head.
            this._mainChain = chainData;
            this._headHash = blockHash;

            // Append new block to chain proof.
            if (this._proof) {
                const proofHeadHash = this._proof.head.hash();
                if (block.prevHash.equals(proofHeadHash)) {
                    this._proof = await this._extendChainProof(this._proof, block.header);
                }
            }

            // Tell listeners that the head of the chain has changed.
            await this.fire('head-changed', this.head, /*rebranching*/ false);

            await this.fire('block', blockHash);
            await this.fire('extended', this.head);
            return NanoChain.OK_EXTENDED;
        }

        // Otherwise, check if the new chain is harder than our current main chain.
        if (chainData.totalDifficulty.gt(this._mainChain.totalDifficulty)) {
            // A fork has become the hardest chain, rebranch to it.
            await this._rebranch(blockHash, chainData);

            return NanoChain.OK_REBRANCHED;
        }

        // Otherwise, we are creating/extending a fork. Store chain data.
        Log.v(NanoChain, `Creating/extending fork with block ${blockHash}, height=${block.height}, totalDifficulty=${chainData.totalDifficulty}, totalWork=${chainData.totalWork}`);
        await this._store.putChainData(blockHash, chainData);

        await this.fire('block', blockHash);
        return NanoChain.OK_FORKED;
    }

    /**
     * @param {Hash} blockHash
     * @param {ChainData} chainData
     * @returns {Promise}
     * @private
     */
    async _rebranch(blockHash, chainData) {
        Log.v(NanoChain, `Rebranching to fork ${blockHash}, height=${chainData.head.height}, totalDifficulty=${chainData.totalDifficulty}, totalWork=${chainData.totalWork}`);

        // Find the common ancestor between our current main chain and the fork chain.
        // Walk up the fork chain until we find a block that is part of the main chain.
        // Store the chain along the way.
        const forkChain = [];
        const forkHashes = [];

        let curData = chainData;
        let curHash = blockHash;
        while (!curData.onMainChain) {
            forkChain.push(curData);
            forkHashes.push(curHash);

            curHash = curData.head.prevHash;
            curData = await this._store.getChainData(curHash); // eslint-disable-line no-await-in-loop
            Assert.that(!!curData, 'Failed to find fork predecessor while rebranching');
        }

        Log.v(NanoChain, () => `Found common ancestor ${curHash.toBase64()} ${forkChain.length} blocks up`);

        /** @type {ChainData} */
        const ancestorData = curData;
        /** @type {Hash} */
        const ancestorHash = curHash;

        /** @type {ChainDataStore} */
        const chainTx = this._store.synchronousTransaction(false);
        /** @type {Array.<ChainData>} */
        const revertChain = [];
        /** @type {Hash} */
        let headHash = this._headHash;
        /** @type {ChainData} */
        let headData = this._mainChain;

        // Unset onMainChain flag / mainChainSuccessor on the current main chain up to (excluding) the common ancestor.
        while (!headHash.equals(ancestorHash)) {
            headData.onMainChain = false;
            headData.mainChainSuccessor = null;
            chainTx.putChainDataSync(headHash, headData);
            revertChain.push(headData);

            headHash = headData.head.prevHash;
            headData = await this._store.getChainData(headHash);
            Assert.that(!!headData, 'Failed to find main chain predecessor while rebranching');
        }

        // Update the mainChainSuccessor of the common ancestor block.
        ancestorData.mainChainSuccessor = forkHashes[forkHashes.length - 1];
        chainTx.putChainDataSync(ancestorHash, ancestorData);

        // Set onMainChain flag / mainChainSuccessor on the fork.
        for (let i = forkChain.length - 1; i >= 0; i--) {
            const forkData = forkChain[i];
            forkData.onMainChain = true;
            forkData.mainChainSuccessor = i > 0 ? forkHashes[i - 1] : null;
            chainTx.putChainDataSync(forkHashes[i], forkData);
        }

        await chainTx.commit();

        // Reset chain proof. We don't recompute the chain proof here, but do it lazily the next time it is needed.
        // TODO modify chain proof directly, don't recompute.
        this._proof = null;

        // Fire block-reverted event for each block reverted during rebranch
        const revertBlocks = [];
        for (const revertedData of revertChain) {
            await this.fire('block-reverted', revertedData.head);
            revertBlocks.push(revertedData.head);
        }

        // Fire head-changed event for each fork block.
        const forkBlocks = [];
        for (let i = forkChain.length - 1; i >= 0; i--) {
            this._mainChain = forkChain[i];
            this._headHash = forkHashes[i];
            await this.fire('head-changed', this.head, /*rebranching*/ i > 0);
            forkBlocks.push(this.head);
        }

        await this.fire('block', blockHash);
        await this.fire('rebranched', revertBlocks, forkBlocks, blockHash);
    }

    /**
     * @returns {Promise.<ChainProof>}
     * @override
     */
    getChainProof() {
        return this._synchronizer.push(/*priority*/ 1, async () => {
            if (!this._proof) {
                this._proof = await this._getChainProof();
            }
            return this._proof;
        });
    }

    /** @type {Block} */
    get head() {
        return this._mainChain.head;
    }

    /** @type {Hash} */
    get headHash() {
        return this._headHash;
    }

    /** @type {number} */
    get height() {
        return this._mainChain.head.height;
    }
}
NanoChain.ERR_ORPHAN = -2;
NanoChain.ERR_INVALID = -1;
NanoChain.OK_KNOWN = 0;
NanoChain.OK_EXTENDED = 1;
NanoChain.OK_REBRANCHED = 2;
NanoChain.OK_FORKED = 3;

NanoChain.SYNCHRONIZER_THROTTLE_AFTER = 500; // ms
NanoChain.SYNCHRONIZER_THROTTLE_WAIT = 30; // ms

Class.register(NanoChain);

class NanoConsensusAgent extends BaseMiniConsensusAgent {
    /**
     * @param {NanoChain} blockchain
     * @param {NanoMempool} mempool
     * @param {Time} time
     * @param {Peer} peer
     * @param {InvRequestManager} invRequestManager
     * @param {Subscription} targetSubscription
     */
    constructor(blockchain, mempool, time, peer, invRequestManager, targetSubscription) {
        super(blockchain, mempool, time, peer, invRequestManager, targetSubscription);
        /** @type {NanoChain} */
        this._blockchain = blockchain;
        /** @type {NanoMempool} */
        this._mempool = mempool;

        // Flag indicating that we are currently syncing our blockchain with the peer's.
        /** @type {boolean} */
        this._syncing = false;

        /** @type {Array.<BlockHeader>} */
        this._orphanedBlocks = [];

        // Flag to track chain proof requests.
        this._requestedChainProof = false;

        // Listen to consensus messages from the peer.
        this._onToDisconnect(peer.channel, 'chain-proof', msg => this._onChainProof(msg));
        this._onToDisconnect(peer.channel, 'get-chain-proof', msg => this._onGetChainProof(msg));

        // Subscribe to all announcements from the peer.
        this._subscribeTarget();
    }

    /**
     * @returns {Promise.<void>}
     */
    async syncBlockchain() {
        if (!this.providesServices(Services.CHAIN_PROOF)) {
            this._syncFinished();
            return;
        }

        this._syncing = true;

        const headBlock = await this._blockchain.getBlock(this._peer.headHash);
        if (!headBlock) {
            this._requestChainProof();
            this.fire('sync-chain-proof', this._peer.peerAddress);
        } else {
            this._syncFinished();
        }
    }

    /**
     * @returns {void}
     * @private
     */
    _syncFinished() {
        this._syncing = false;
        this._synced = true;

        this.requestMempool();

        this.fire('sync');
    }

    /**
     * @returns {void}
     * @private
     */
    _requestChainProof() {
        // Only one chain proof request at a time.
        if (this._requestedChainProof) {
            return;
        }

        // Request ChainProof from peer.
        this._peer.channel.getChainProof();
        this._requestedChainProof = true;

        // Drop the peer if it doesn't send the chain proof within the timeout.
        this._peer.channel.expectMessage(Message.Type.CHAIN_PROOF, () => {
            this._peer.channel.close(CloseType.GET_CHAIN_PROOF_TIMEOUT, 'getChainProof timeout');
        }, NanoConsensusAgent.CHAINPROOF_REQUEST_TIMEOUT, NanoConsensusAgent.CHAINPROOF_CHUNK_TIMEOUT);
    }

    /**
     * @param {ChainProofMessage} msg
     * @returns {Promise.<void>}
     * @private
     */
    async _onChainProof(msg) {
        Log.d(NanoConsensusAgent, `[CHAIN-PROOF] Received from ${this._peer.peerAddress}: ${msg.proof}`);

        // Check if we have requested a chain proof, discard unsolicited ones.
        if (!this._requestedChainProof) {
            Log.w(NanoConsensusAgent, `Unsolicited chain proof received from ${this._peer.peerAddress}`);
            return;
        }
        this._requestedChainProof = false;

        if (this._syncing) {
            this.fire('verify-chain-proof', this._peer.peerAddress);
        }

        // Push the proof into the NanoChain.
        if (!(await this._blockchain.pushProof(msg.proof))) {
            Log.w(NanoConsensusAgent, `Invalid chain proof received from ${this._peer.peerAddress} - verification failed`);
            this._peer.channel.close(CloseType.INVALID_CHAIN_PROOF, 'Invalid chain proof');
            return;
        }

        // TODO add all blocks from the chain proof to knownObjects.

        // Apply any orphaned blocks we received while waiting for the chain proof.
        await this._applyOrphanedBlocks();

        if (this._syncing) {
            this._syncFinished();
        }
    }

    /**
     * @returns {Promise.<void>}
     * @private
     */
    async _applyOrphanedBlocks() {
        for (const header of this._orphanedBlocks) {
            const status = await this._blockchain.pushHeader(header);
            if (status === NanoChain.ERR_INVALID) {
                this._peer.channel.close(CloseType.INVALID_BLOCK, 'received invalid block');
                break;
            }
        }
        this._orphanedBlocks = [];
    }

    _willRequestHeaders() {
        return true;
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks = false]
     * @param {boolean} [includeBody = false]
     * @returns {Promise.<?Block>}
     * @protected
     * @override
     */
    _getBlock(hash, includeForks = false, includeBody = false) {
        return this._blockchain.getBlock(hash, includeForks, includeBody);
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks = false]
     * @returns {Promise.<?Uint8Array>}
     * @protected
     * @override
     */
    _getRawBlock(hash, includeForks = false) {
        return this._blockchain.getRawBlock(hash, includeForks);
    }

    /**
     * @param {Hash} hash
     * @returns {?Transaction}
     * @protected
     * @override
     */
    _getTransaction(hash) {
        return this._mempool.getTransaction(hash);
    }

    /**
     * @param {Hash} hash
     * @param {BlockHeader} header
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processHeader(hash, header) {
        // TODO send reject message if we don't like the block
        const status = await this._blockchain.pushHeader(header);
        if (status === NanoChain.ERR_INVALID) {
            this._peer.channel.close(CloseType.INVALID_HEADER, 'received invalid header');
        }
        // Re-sync with this peer if it starts sending orphan blocks after the initial sync.
        else if (status === NanoChain.ERR_ORPHAN) {
            this._orphanedBlocks.push(header);
            if (this._synced) {
                this._requestChainProof();
            }
        }
    }

    /**
     * @param {Hash} hash
     * @param {Transaction} transaction
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processTransaction(hash, transaction) {
        await this._mempool.pushTransaction(transaction);
    }

    /**
     * @param {GetChainProofMessage} msg
     * @private
     */
    async _onGetChainProof(msg) {
        const proof = await this._blockchain.getChainProof();
        if (proof) {
            this._peer.channel.chainProof(proof);
        }
    }

    /**
     * @returns {void}
     * @protected
     * @override
     */
    _onClose() {
        // Clear the synchronizer queue.
        this._synchronizer.clear();
        super._onClose();
    }

    /** @type {boolean} */
    get syncing() {
        return this._syncing;
    }
}
/**
 * Maximum time (ms) to wait for chain-proof after sending out get-chain-proof before dropping the peer.
 * @type {number}
 */
NanoConsensusAgent.CHAINPROOF_REQUEST_TIMEOUT = 1000 * 45;
/**
 * Maximum time (ms) to wait for between chain-proof chunks before dropping the peer.
 * @type {number}
 */
NanoConsensusAgent.CHAINPROOF_CHUNK_TIMEOUT = 1000 * 10;
Class.register(NanoConsensusAgent);

class NanoConsensus extends BaseMiniConsensus {
    /**
     * @param {NanoChain} blockchain
     * @param {NanoMempool} mempool
     * @param {Network} network
     */
    constructor(blockchain, mempool, network) {
        super(blockchain, mempool, network);
        /** @type {NanoChain} */
        this._blockchain = blockchain;
        /** @type {NanoMempool} */
        this._mempool = mempool;
    }

    /**
     * @param {Peer} peer
     * @returns {BaseConsensusAgent}
     * @override
     */
    _newConsensusAgent(peer) {
        return new NanoConsensusAgent(this._blockchain, this._mempool, this._network.time, peer, this._invRequestManager, this._subscription);
    }

    /**
     * @param {Peer} peer
     * @override
     */
    _onPeerJoined(peer) {
        const agent = super._onPeerJoined(peer);

        // Forward sync events.
        this.bubble(agent, 'sync-chain-proof', 'verify-chain-proof');

        return agent;
    }

    /** @type {NanoChain} */
    get blockchain() {
        return this._blockchain;
    }

    /** @type {NanoMempool} */
    get mempool() {
        return this._mempool;
    }
}
Class.register(NanoConsensus);

/**
 * @deprecated
 */
class NanoMempool extends Observable {
    /**
     * @param {IBlockchain} blockchain
     */
    constructor(blockchain) {
        super();

        /** @type {IBlockchain} */
        this._blockchain = blockchain;

        // Our pool of transactions.
        /** @type {HashMap.<Hash, Transaction>} */
        this._transactionsByHash = new HashMap();
        /** @type {HashMap.<Address, MempoolTransactionSet>} */
        this._transactionSetBySender = new HashMap();
        /** @type {HashMap.<Address, HashSet.<Transaction>>} */
        this._transactionSetByRecipient = new HashMap();
    }

    /**
     * @param {Transaction} transaction
     * @fires Mempool#transaction-added
     * @returns {Promise.<Mempool.ReturnCode>}
     */
    async pushTransaction(transaction) {
        // Check if we already know this transaction.
        const hash = transaction.hash();
        if (this._transactionsByHash.contains(hash)) {
            Log.v(Mempool, () => `Ignoring known transaction ${hash.toBase64()}`);
            return Mempool.ReturnCode.KNOWN;
        }

        // Check validity based on startHeight.
        if (this._blockchain.height >= transaction.validityStartHeight + Policy.TRANSACTION_VALIDITY_WINDOW) {
            Log.v(Mempool, () => `Ignoring expired transaction ${hash.toBase64()}`);
            return Mempool.ReturnCode.EXPIRED;
        }

        // Verify transaction.
        if (!transaction.verify()) {
            return Mempool.ReturnCode.INVALID;
        }

        // Transaction is valid, add it to the mempool.
        this._transactionsByHash.put(hash, transaction);
        const set = this._transactionSetBySender.get(transaction.sender) || new MempoolTransactionSet();
        set.add(transaction);
        this._transactionSetBySender.put(transaction.sender, set);
        const recs = this._transactionSetByRecipient.get(transaction.recipient) || new HashSet();
        recs.add(transaction);
        this._transactionSetByRecipient.put(transaction.recipient, recs);

        // Tell listeners about the new transaction we received.
        this.fire('transaction-added', transaction);

        return Mempool.ReturnCode.ACCEPTED;
    }

    /**
     * @param {Hash} hash
     * @returns {Transaction}
     */
    getTransaction(hash) {
        return this._transactionsByHash.get(hash);
    }

    /**
     * @param {number} maxCount
     * @returns {Array.<Transaction>}
     */
    getTransactions(maxCount = 5000) {
        return this._transactionsByHash.values().sort((a, b) => a.compare(b)).slice(0, maxCount);
    }

    /**
     * @param {Address} address
     * @return {Array.<Transaction>}
     */
    getPendingTransactions(address) {
        return this.getTransactionsBySender(address);
    }

    /**
     * @param {Address} address
     * @return {Array.<Transaction>}
     */
    getTransactionsBySender(address) {
        /** @type {MempoolTransactionSet} */
        const set = this._transactionSetBySender.get(address);
        return set ? set.transactions : [];
    }

    /**
     * @param {Address} address
     * @return {Array.<Transaction>}
     */
    getTransactionsByRecipient(address) {
        /** @type {HashSet.<Transaction>} */
        const set = this._transactionSetByRecipient.get(address);
        if (!set) {
            return [];
        }

        return set.values();
    }

    /**
     * @param {Array.<Address>} addresses
     * @param {number} [maxTransactions]
     * @return {Array.<Transaction>}
     */
    getTransactionsByAddresses(addresses, maxTransactions = Infinity) {
        const transactions = [];
        for (const address of addresses) {
            // Fetch transactions by sender first
            /** @type {Array.<Transaction>} */
            const bySender = this.getTransactionsBySender(address);
            for (const tx of bySender) {
                if (transactions.length >= maxTransactions) return transactions;
                transactions.push(tx);
            }

            // Fetch transactions by recipient second
            /** @type {Array.<Transaction>} */
            const byRecipient = this.getTransactionsByRecipient(address);
            for (const tx of byRecipient) {
                if (transactions.length >= maxTransactions) return transactions;
                transactions.push(tx);
            }
        }
        return transactions;
    }

    /**
     * @param {Block} block
     * @param {Array.<Transaction>} transactions
     */
    async changeHead(block, transactions) {
        await this._evictTransactions(block, transactions);
    }

    /**
     * @param {Transaction} transaction
     */
    removeTransaction(transaction) {
        this._transactionsByHash.remove(transaction.hash());

        /** @type {MempoolTransactionSet} */
        const set = this._transactionSetBySender.get(transaction.sender);
        set.remove(transaction);

        if (set.length === 0) {
            this._transactionSetBySender.remove(transaction.sender);
        }

        const recs = this._transactionSetByRecipient.get(transaction.recipient);
        recs.remove(transaction);

        if (recs.length === 0) {
            this._transactionSetByRecipient.remove(transaction.recipient);
        }

        this.fire('transaction-removed', transaction);
    }

    /**
     * @param {Array.<Address>} addresses
     */
    evictExceptAddresses(addresses) {
        const addressSet = new HashSet();
        addressSet.addAll(addresses);
        for (const /** @type {Transaction} */ tx of this._transactionsByHash.values()) {
            if (!addressSet.contains(tx.sender) && !addressSet.contains(tx.recipient)) {
                this.removeTransaction(tx);
            }
        }
    }

    /**
     * @param {Block} block
     * @param {Array.<Transaction>} transactions
     * @private
     */
    async _evictTransactions(block, transactions) {
        // Remove expired transactions.
        for (const /** @type {Transaction} */ tx of this._transactionsByHash.values()) {
            if (block.height >= tx.validityStartHeight + Policy.TRANSACTION_VALIDITY_WINDOW) {
                this.removeTransaction(tx);

                this.fire('transaction-expired', tx);
            }
        }

        // Remove mined transactions.
        for (const /** @type {Transaction} */ tx of transactions) {
            const txHash = tx.hash();
            if (this._transactionsByHash.contains(txHash)) {
                this.removeTransaction(tx);

                this.fire('transaction-mined', tx, block);
            }
        }
    }

    /** @type {number} */
    get length() {
        return this._transactionsByHash.length;
    }
}
Class.register(NanoMempool);

class PicoChain extends BaseChain {
    /**
     * @param {Time} time
     * @returns {Promise.<PicoChain>}
     */
    constructor(time) {
        super(ChainDataStore.createVolatile());

        /** @type {Time} */
        this._time = time;

        this._synchronizer = new Synchronizer();

        /** @type {ChainData} */
        this._mainChain = null;

        return this._init();
    }

    async reset() {
        this._mainChain = await ChainData.initial(GenesisConfig.GENESIS_BLOCK);
        await this._store.putChainData(GenesisConfig.GENESIS_HASH, this._mainChain);
    }

    async _init() {
        await this.reset();

        return this;
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     */
    async pushBlock(block) {
        return this._synchronizer.push(() => {
            return this._pushBlock(block);
        });
    }

    /**
     * @param {Block} block
     * @returns {Promise.<number>}
     */
    async _pushBlock(block) {
        if (await this._store.getChainData(block.hash())) return PicoChain.OK_KNOWN;

        if (!(await block.verify(this._time))) {
            return PicoChain.ERR_INVALID;
        }

        const prevChainData = await this._store.getChainData(block.prevHash);
        if (this.height <= 1) {
            // Still at genesis, accept anything
            this._mainChain = await ChainData.initial(block);
            await this._store.putChainData(this._mainChain.head.hash(), this._mainChain);

            Log.d(PicoChain, `Choosing initial block height=${block.height}, hash=${block.hash().toHex()}`);
            this.fire('head-changed', this.head);

            await this.fire('block', block.hash());
            await this.fire('extended', this.head);
            return PicoChain.OK_EXTENDED;
        } else if (await block.isImmediateSuccessorOf(this.head)) {
            this._mainChain.mainChainSuccessor = block.hash();
            await this._store.putChainData(this._mainChain.head.hash(), this._mainChain);

            this._mainChain = await this._mainChain.nextChainData(block);
            this._mainChain.onMainChain = true;
            await this._store.putChainData(this._mainChain.head.hash(), this._mainChain);

            Log.d(PicoChain, `Appending block height=${block.height}, hash=${block.hash().toHex()}`);
            this.fire('head-changed', this.head);

            await this.fire('block', block.hash());
            await this.fire('extended', this.head);
            return PicoChain.OK_EXTENDED;
        } else if (await this.head.isImmediateSuccessorOf(block)) {
            const tempChain = await ChainData.initial(block);
            tempChain.mainChainSuccessor = this.head.hash();
            await this._store.putChainData(tempChain.head.hash(), tempChain);

            this._mainChain = await tempChain.nextChainData(this.head);
            this._mainChain.onMainChain = true;
            await this._store.putChainData(this._mainChain.head.hash(), this._mainChain);

            Log.d(PicoChain, `Prepending block height=${block.height}, hash=${block.hash().toHex()}`);
            await this.fire('block', block.hash());
            return PicoChain.OK_KNOWN;
        } else if (prevChainData) {
            // The block is on a fork that we could resolve.
            const newChainData = await prevChainData.nextChainData(block);
            await this._store.putChainData(block.hash(), newChainData);
            Log.d(PicoChain, `Storing block height=${block.height}, hash=${block.hash().toHex()}`);

            if (newChainData.totalWork.gt(this._mainChain.totalWork)) {
                try {
                    await this._rebranch(block.hash(), newChainData);
                } catch (e) {
                    Log.w(PicoChain, 'Error while rebranching', e);
                    return PicoChain.ERR_INCONSISTENT;
                }

                return PicoChain.OK_REBRANCHED;
            }

            await this.fire('block', block.hash());
            return PicoChain.OK_FORKED;
        }

        Log.w(PicoChain, `Inconsistency between block height=${block.height}, hash=${block.hash().toHex()} and block height=${this.height}, hash=${this.headHash.toHex()}`);
        return PicoChain.ERR_INCONSISTENT;
    }

    /**
     * @param {Hash} blockHash
     * @param {ChainData} chainData
     * @returns {Promise}
     * @private
     */
    async _rebranch(blockHash, chainData) {
        Log.d(PicoChain, `Rebranching to fork ${blockHash}, height=${chainData.head.height}, totalDifficulty=${chainData.totalDifficulty}, totalWork=${chainData.totalWork}`);

        // Find the common ancestor between our current main chain and the fork chain.
        // Walk up the fork chain until we find a block that is part of the main chain.
        // Store the chain along the way.
        const forkChain = [];
        const forkHashes = [];

        let curData = chainData;
        let curHash = blockHash;
        while (!curData.onMainChain) {
            forkChain.push(curData);
            forkHashes.push(curHash);

            curHash = curData.head.prevHash;
            curData = await this._store.getChainData(curHash); // eslint-disable-line no-await-in-loop
            Assert.that(!!curData, 'Failed to find fork predecessor while rebranching');
        }

        Log.v(PicoChain, () => `Found common ancestor ${curHash.toBase64()} ${forkChain.length} blocks up`);

        /** @type {ChainData} */
        const ancestorData = curData;
        /** @type {Hash} */
        const ancestorHash = curHash;

        /** @type {ChainDataStore} */
        const chainTx = this._store.synchronousTransaction(false);
        /** @type {Array.<ChainData>} */
        const revertChain = [];
        /** @type {Hash} */
        let headHash = this.headHash;
        /** @type {ChainData} */
        let headData = this._mainChain;

        // Unset onMainChain flag / mainChainSuccessor on the current main chain up to (excluding) the common ancestor.
        while (!headHash.equals(ancestorHash)) {
            headData.onMainChain = false;
            headData.mainChainSuccessor = null;
            chainTx.putChainDataSync(headHash, headData);
            revertChain.push(headData);

            headHash = headData.head.prevHash;
            headData = await this._store.getChainData(headHash);
            Assert.that(!!headData, 'Failed to find main chain predecessor while rebranching');
        }

        // Update the mainChainSuccessor of the common ancestor block.
        ancestorData.mainChainSuccessor = forkHashes[forkHashes.length - 1];
        chainTx.putChainDataSync(ancestorHash, ancestorData);

        // Set onMainChain flag / mainChainSuccessor on the fork.
        for (let i = forkChain.length - 1; i >= 0; i--) {
            const forkData = forkChain[i];
            forkData.onMainChain = true;
            forkData.mainChainSuccessor = i > 0 ? forkHashes[i - 1] : null;
            chainTx.putChainDataSync(forkHashes[i], forkData);
        }

        await chainTx.commit();

        // Fire block-reverted event for each block reverted during rebranch
        const revertBlocks = [];
        for (const revertedData of revertChain) {
            this.fire('block-reverted', revertedData.head);
            revertBlocks.push(revertedData.head);
        }

        // Fire head-changed event for each fork block.
        const forkBlocks = [];
        for (let i = forkChain.length - 1; i >= 0; i--) {
            this._mainChain = forkChain[i];
            this.fire('head-changed', this.head, /*rebranching*/ i > 0);
            forkBlocks.push(this.head);
        }

        // Tell listeners that we have rebranched.
        await this.fire('block', blockHash);
        await this.fire('rebranched', revertBlocks, forkBlocks, blockHash);
    }

    /**
     * @type {Block}
     */
    get head() {
        return this._mainChain.head;
    }

    /**
     * @type {Hash}
     */
    get headHash() {
        return this.head.hash();
    }

    /**
     * @type {number}
     */
    get height() {
        return this.head.height;
    }
}
PicoChain.ERR_INCONSISTENT = -2;
PicoChain.ERR_INVALID = -1;
PicoChain.OK_KNOWN = 0;
PicoChain.OK_EXTENDED = 1;
PicoChain.OK_REBRANCHED = 2;
PicoChain.OK_FORKED = 3;
Class.register(PicoChain);

class PicoConsensusAgent extends BaseMiniConsensusAgent {
    /**
     * @param {PicoConsensus} consensus
     * @param {Peer} peer
     * @param {Subscription} targetSubscription
     */
    constructor(consensus, peer, targetSubscription) {
        super(consensus.blockchain, consensus.mempool, consensus.network.time, peer, consensus.invRequestManager, targetSubscription);
        this._consensus = consensus;
    }

    /**
     * @param {Hash} hash
     * @param {Block} block
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processBlock(hash, block) {
        if (this._peer.headHash.equals(hash)) {
            const result = await this._blockchain.pushBlock(block);
            if (result === PicoChain.ERR_INVALID) {
                this._peer.channel.close(CloseType.INVALID_BLOCK, 'received invalid block');
            } else if (result === PicoChain.ERR_INCONSISTENT) {
                this.fire('consensus-failed');
            } else if (this._syncing) {
                this._syncFinished();
            }
        } else {
            if (await this._blockchain.pushBlock(block) === PicoChain.ERR_INVALID) {
                this._peer.channel.close(CloseType.INVALID_BLOCK, 'received invalid block');
            }
        }
    }

    async syncBlockchain() {
        this._syncing = true;

        const headBlock = await this._getBlock(this._peer.headHash, /*includeForks*/ true);
        if (!headBlock) {
            try {
                const hash = this._peer.headHash;
                const block = await this.requestBlock(hash);
                await this._processBlock(hash, block);
            } catch (e) {
                this._peer.channel.close(CloseType.ABORTED_SYNC, 'aborted sync');
            }
        } else {
            this._syncFinished();
        }
    }

    /**
     * @returns {void}
     * @private
     */
    _syncFinished() {
        this._syncing = false;
        this._synced = true;

        this.requestMempool();

        this.fire('sync');
    }

    /**
     * @param {Hash} hash
     * @param {Transaction} transaction
     * @returns {Promise.<void>}
     * @protected
     * @override
     */
    async _processTransaction(hash, transaction) {
        await this._consensus.mempool.pushTransaction(transaction);
    }

    /**
     *
     * @param {Hash} hash
     * @param {boolean} [includeForks = false]
     * @param {boolean} [includeBody = false]
     * @returns {Promise.<?Block>}
     * @protected
     * @override
     */
    _getBlock(hash, includeForks = false, includeBody = false) {
        return this._blockchain.getBlock(hash, includeForks, includeBody);
    }

    /**
     * @param {Hash} hash
     * @param {boolean} [includeForks = false]
     * @returns {Promise.<?Uint8Array>}
     * @protected
     * @override
     */
    _getRawBlock(hash, includeForks = false) {
        return this._blockchain.getRawBlock(hash, includeForks);
    }

    /**
     * @param {Hash} hash
     * @returns {Transaction}
     * @protected
     * @override
     */
    _getTransaction(hash) {
        return this._consensus.mempool.getTransaction(hash);
    }
}

Class.register(PicoConsensusAgent);

class PicoConsensus extends BaseMiniConsensus {

    /**
     * @param {PicoChain} blockchain
     * @param {NanoMempool} mempool
     * @param {Network} network
     */
    constructor(blockchain, mempool, network) {
        super(blockchain, mempool, network);
        /** @type {PicoChain} */
        this._blockchain = blockchain;
        /** @type {NanoMempool} */
        this._mempool = mempool;
        /** @type {boolean} */
        this._failed = false;
    }

    /**
     * @param {Peer} peer
     * @returns {BaseConsensusAgent}
     * @override
     */
    _newConsensusAgent(peer) {
        return new PicoConsensusAgent(this, peer, this._subscription);
    }

    /**
     * @param {Peer} peer
     * @override
     */
    _onPeerJoined(peer) {
        const agent = super._onPeerJoined(peer);
        agent.on('consensus-failed', () => this._onConsensusFailed());

        if (this._agents.length >= 3) {
            this._syncBlockchain();
        }

        return agent;
    }

    /**
     * @param {Peer} peer
     * @override
     */
    async _onPeerLeft(peer) {
        super._onPeerLeft(peer);

        if (this._agents.length === 0) {
            // Reset chain state to allow to recover from connectivity loss.
            await this._blockchain.reset();
        }
    }

    /**
     * @override
     */
    _syncBlockchain() {
        if (this._failed) return;
        super._syncBlockchain();
    }

    /**
     * @param {number} numSyncedFullNodes
     * @param {number} numSyncedNodes
     * @return {boolean}
     * @override
     */
    _hasEnoughPeers(numSyncedFullNodes, numSyncedNodes) {
        return super._hasEnoughPeers(numSyncedFullNodes, numSyncedNodes) && numSyncedNodes >= PicoConsensus.MIN_SYNCED_NODES;
    }

    /**
     * @private
     */
    _onConsensusFailed() {
        this._failed = true;
        this._syncPeer = null;
        this.fire('consensus-failed');
    }

    /** @type {PicoChain} */
    get blockchain() {
        return this._blockchain;
    }

    /** @type {NanoMempool} */
    get mempool() {
        return this._mempool;
    }
}
PicoConsensus.MIN_SYNCED_NODES = 3;

Class.register(PicoConsensus);

class ConsensusDB extends JDB.JungleDB {
    /**
     * @param {string} [dbPrefix]
     * @returns {Promise.<ConsensusDB>}
     */
    static async getFull(dbPrefix = '') {
        if (!ConsensusDB._instance) {
            ConsensusDB._instance = await new ConsensusDB(dbPrefix, /*light*/ false);
        }
        return ConsensusDB._instance;
    }

    /**
     * @param {string} dbPrefix
     * @returns {Promise.<ConsensusDB>}
     */
    static async getLight(dbPrefix = '') {
        if (!ConsensusDB._instance) {
            ConsensusDB._instance = await new ConsensusDB(dbPrefix, /*light*/ true);
        }
        return ConsensusDB._instance;
    }

    /**
     * @param {string} dbPrefix
     * @param {boolean} light
     * @returns {Promise.<ConsensusDB>}
     */
    constructor(dbPrefix, light) {
        // Start with 500MB and resize at least 1GB at a time.
        super(ConsensusDB._getDbName(dbPrefix, light), ConsensusDB.VERSION, {
            maxDbSize: ConsensusDB.INITIAL_DB_SIZE,
            autoResize: true,
            useWritemap: PlatformUtils.isNodeJs() && PlatformUtils.isWindows(),
            minResize: ConsensusDB.MIN_RESIZE,
            onUpgradeNeeded: ConsensusDB._onUpgradeNeeded.bind(null, light)
        });
        return this._init();
    }

    /**
     * @returns {Promise.<ConsensusDB>}
     * @private
     */
    async _init() {
        // Initialize object stores.
        AccountsTreeStore.initPersistent(this);
        ChainDataStore.initPersistent(this);
        TransactionStore.initPersistent(this);

        // Establish connection to database.
        await this.connect();

        return this;
    }

    /**
     * @param {string} dbPrefix
     * @param {boolean} light
     * @returns {string}
     * @private
     */
    static _getDbName(dbPrefix, light) {
        return dbPrefix + (light ? 'light' : 'full') + '-consensus';
    }

    /**
     * @param {boolean} light
     * @param {number} oldVersion
     * @param {number} newVersion
     * @param {ConsensusDB} db
     * @returns {Promise.<void>}
     * @private
     */
    static async _onUpgradeNeeded(light, oldVersion, newVersion, jdb) {
        // No upgrade needed for empty database.
        if (oldVersion === 0) {
            return;
        }

        Log.i(ConsensusDB, `Upgrade needed: version ${oldVersion} -> ${newVersion}`);

        if (oldVersion < 7) {
            if (!light) {
                // Recompute totalDifficulty / totalWork for full nodes.
                Log.i(ConsensusDB, 'Upgrading database, this may take a while...');
                await UpgradeHelper.recomputeTotals(jdb);
            } else {
                // Truncate chain / accounts for light nodes.
                /** @type {ObjectStore} */
                const accountStore = jdb.getObjectStore('Accounts');
                const accountTx = accountStore.transaction(false);
                await accountTx.truncate();

                /** @type {ObjectStore} */
                const chainDataStore = jdb.getObjectStore('ChainData');
                const chainDataTx = chainDataStore.transaction(false);
                await chainDataTx.truncate();

                /** @type {ObjectStore} */
                const blockStore = jdb.getObjectStore('Block');
                const blockTx = blockStore.transaction(false);
                await blockTx.truncate();

                await JDB.JungleDB.commitCombined(accountTx, chainDataTx, blockTx);
            }
        }

        if (oldVersion < 8) {
            if (!light) {
                Log.i(ConsensusDB, 'Upgrading transaction store, this may take a while...');
                await UpgradeHelper.restoreTransactions(jdb);
            }
        }
    }
}
ConsensusDB._instance = null;
ConsensusDB.VERSION = 8;
ConsensusDB.INITIAL_DB_SIZE = 1024*1024*500; // 500 MB initially
ConsensusDB.MIN_RESIZE = 1 << 30; // 1 GB
Class.register(ConsensusDB);


class UpgradeHelper {
    /**
     * @param {ConsensusDB} jdb
     * @returns {Promise.<void>}
     */
    static async recomputeTotals(jdb) {
        const store = ChainDataStore.getPersistent(jdb);
        const transaction = store.synchronousTransaction(false);
        try {
            await this._recomputeTotals(transaction, GenesisConfig.GENESIS_BLOCK, new BigNumber(0), new BigNumber(0));
            return transaction.commit();
        } catch (e) {
            await transaction.abort();
            throw e;
        }
    }

    /**
     * @param {ChainDataStore} transaction
     * @param {Block} block
     * @param {BigNumber} totalDifficulty
     * @param {BigNumber} totalWork
     * @returns {Promise.<void>}
     * @private
     */
    static async _recomputeTotals(transaction, block, totalDifficulty, totalWork) {
        /** @type {Hash} */
        const hash = block.hash();
        /** @type {ChainData} */
        const chainData = await transaction.getChainData(hash);
        // In the empty database, the Genesis block is not present.
        if (!chainData) {
            return Promise.resolve();
        }

        const newTotalDifficulty = totalDifficulty.plus(block.difficulty);
        const newTotalWork = totalWork.plus(BlockUtils.realDifficulty(await block.pow()));

        chainData._totalDifficulty = newTotalDifficulty;
        chainData._totalWork = newTotalWork;
        transaction.putChainDataSync(hash, chainData, /*includeBody*/ false);

        /** @type {Array.<Block>} */
        const successors = await transaction.getSuccessorBlocks(block);
        /** @type {Array.<Promise>} */
        const promises = successors.map(successor => UpgradeHelper._recomputeTotals(transaction, successor, newTotalDifficulty, newTotalWork));
        return Promise.all(promises);
    }

    /**
     * @param {ConsensusDB} jdb
     * @returns {Promise.<void>}
     */
    static async restoreTransactions(jdb) {
        const chainDataStore = ChainDataStore.getPersistent(jdb);
        const transactionStore = TransactionStore.getPersistent(jdb);
        const txSize = 1000;
        let tx = transactionStore.transaction(false);

        // Determine head for progress.
        const headHash = await chainDataStore.getHead();
        const headBlock = await chainDataStore.getBlock(headHash);
        const headHeight = headBlock.height;

        try {
            let nextHash = GenesisConfig.GENESIS_HASH;
            let currentHeight = 0;

            // Put whole main chain into transaction store again.
            while (nextHash) {
                const currentChainData = await chainDataStore.getChainData(nextHash, /*includeBody*/ true);
                nextHash = currentChainData.mainChainSuccessor;
                currentHeight = currentChainData.head.height;
                await tx.put(currentChainData.head);

                if (currentHeight % txSize === 0) {
                    await tx.commit();
                    tx = transactionStore.transaction(false);
                    Log.i(UpgradeHelper, `Upgrade at ${Math.round(currentHeight / headHeight * 100)}% (block ${currentHeight}/${headHeight})`);
                }
            }

            if (currentHeight % txSize !== 0) {
                await tx.commit();
                Log.i(UpgradeHelper, `Upgrade at ${Math.round(currentHeight / headHeight * 100)}% (block ${currentHeight}/${headHeight})`);
            }
            Log.i(UpgradeHelper, 'Upgrade finished');
        } catch (e) {
            await tx.abort();
            throw e;
        }
    }
}

class Consensus {
    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<FullConsensus>}
     */
    static async full(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_FULL, Services.ACCEPTS_FULL);
        await netconfig.initPersistent();

        /** @type {Time} */
        const time = new Time();
        /** @type {ConsensusDB} */
        const db = await ConsensusDB.getFull(`${GenesisConfig.NETWORK_NAME}-`);
        /** @type {Accounts} */
        const accounts = await Accounts.getPersistent(db);
        /** @type {TransactionStore} */
        const transactionStore = await TransactionStore.getPersistent(db);
        /** @type {FullChain} */
        const blockchain = await FullChain.getPersistent(db, accounts, time, transactionStore);
        /** @type {Mempool} */
        const mempool = new Mempool(blockchain, accounts);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new FullConsensus(blockchain, mempool, network);
    }

    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<LightConsensus>}
     */
    static async light(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_LIGHT, Services.ACCEPTS_LIGHT);
        await netconfig.initPersistent();

        /** @type {Time} */
        const time = new Time();
        /** @type {ConsensusDB} */
        const db = await ConsensusDB.getLight(`${GenesisConfig.NETWORK_NAME}-`);
        /** @type {Accounts} */
        const accounts = await Accounts.getPersistent(db);
        /** @type {LightChain} */
        const blockchain = await LightChain.getPersistent(db, accounts, time);
        /** @type {Mempool} */
        const mempool = new Mempool(blockchain, accounts);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new LightConsensus(blockchain, mempool, network);
    }

    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<NanoConsensus>}
     */
    static async nano(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_NANO, Services.ACCEPTS_NANO);
        await netconfig.initPersistent();

        /** @type {Time} */
        const time = new Time();
        /** @type {NanoChain} */
        const blockchain = await new NanoChain(time);
        /** @type {NanoMempool} */
        const mempool = new NanoMempool(blockchain);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new NanoConsensus(blockchain, mempool, network);
    }

    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<PicoConsensus>}
     */
    static async pico(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_PICO, Services.ACCEPTS_PICO);
        await netconfig.initPersistent();

        /** @type {Time} */
        const time = new Time();
        /** @type {PicoChain} */
        const blockchain = await new PicoChain(time);
        /** @type {NanoMempool} */
        const mempool = new NanoMempool(blockchain);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new PicoConsensus(blockchain, mempool, network);
    }
    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<FullConsensus>}
     */
    static async volatileFull(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_FULL, Services.ACCEPTS_FULL);
        await netconfig.initVolatile();

        /** @type {Time} */
        const time = new Time();
        /** @type {Accounts} */
        const accounts = await Accounts.createVolatile();
        /** @type {TransactionStore} */
        const transactionStore = await TransactionStore.createVolatile();
        /** @type {FullChain} */
        const blockchain = await FullChain.createVolatile(accounts, time, transactionStore);
        /** @type {Mempool} */
        const mempool = new Mempool(blockchain, accounts);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new FullConsensus(blockchain, mempool, network);
    }

    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<LightConsensus>}
     */
    static async volatileLight(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_LIGHT, Services.ACCEPTS_LIGHT);
        await netconfig.initVolatile();

        /** @type {Time} */
        const time = new Time();
        /** @type {Accounts} */
        const accounts = await Accounts.createVolatile();
        /** @type {LightChain} */
        const blockchain = await LightChain.createVolatile(accounts, time);
        /** @type {Mempool} */
        const mempool = new Mempool(blockchain, accounts);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new LightConsensus(blockchain, mempool, network);
    }

    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<NanoConsensus>}
     */
    static async volatileNano(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_NANO, Services.ACCEPTS_NANO);
        await netconfig.initVolatile();

        /** @type {Time} */
        const time = new Time();
        /** @type {NanoChain} */
        const blockchain = await new NanoChain(time);
        /** @type {NanoMempool} */
        const mempool = new NanoMempool(blockchain);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new NanoConsensus(blockchain, mempool, network);
    }

    /**
     * @param {NetworkConfig} [netconfig]
     * @return {Promise.<PicoConsensus>}
     */
    static async volatilePico(netconfig = NetworkConfig.getDefault()) {
        netconfig.services = new Services(Services.PROVIDES_PICO, Services.ACCEPTS_PICO);
        await netconfig.initVolatile();

        /** @type {Time} */
        const time = new Time();
        /** @type {PicoChain} */
        const blockchain = await new PicoChain(time);
        /** @type {NanoMempool} */
        const mempool = new NanoMempool(blockchain);
        /** @type {Network} */
        const network = new Network(blockchain, netconfig, time);

        return new PicoConsensus(blockchain, mempool, network);
    }
}

Class.register(Consensus);

class Protocol {
}
Protocol.DUMB = 0;
Protocol.WSS = 1;
Protocol.RTC = 2;
Protocol.WS = 4;
Class.register(Protocol);

class Message {
    /**
     * Create a new Message instance. This is usually not called directly but by subclasses.
     * @param {Message.Type} type Message type
     */
    constructor(type) {
        if (!NumberUtils.isUint64(type)) throw new Error('Malformed type');
        /** @type {Message.Type} */
        this._type = type;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {Message.Type}
     */
    static peekType(buf) {
        // Store current read position.
        const pos = buf.readPos;

        // Set read position past the magic to the beginning of the type string.
        buf.readPos = 4;

        // Read the type.
        const type = buf.readVarUint();

        // Reset the read position to original.
        buf.readPos = pos;

        return /** @type {Message.Type} */ type;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {number}
     */
    static peekLength(buf) {
        // Store current read position.
        const pos = buf.readPos;

        // Set read position past the magic to the beginning of the type string.
        buf.readPos = 4;

        // Read the type and ignore it.
        buf.readVarUint();
        // Read the length.
        const length = buf.readUint32();

        // Reset the read position to original.
        buf.readPos = pos;

        return length;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {Message}
     */
    static unserialize(buf) {
        // XXX Direct buffer manipulation currently requires this.
        Assert.that(buf.readPos === 0, 'Message.unserialize() requires buf.readPos == 0');

        const magic = buf.readUint32();
        const type = buf.readVarUint();
        buf.readUint32(); // length is ignored
        const checksum = buf.readUint32();

        // Validate magic.
        if (magic !== Message.MAGIC) throw new Error('Malformed magic');

        // Validate checksum.
        Message._writeChecksum(type, buf, 0);
        const calculatedChecksum = CRC32.compute(buf);
        if (checksum !== calculatedChecksum) throw new Error('Invalid checksum');

        return new Message(type);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        // XXX Direct buffer manipulation currently requires this.
        Assert.that(buf.writePos === 0, 'Message.serialize() requires buf.writePos == 0');

        buf.writeUint32(Message.MAGIC);
        buf.writeVarUint(this._type);
        buf.writeUint32(this.serializedSize);
        buf.writeUint32(0); // written later by _setChecksum()

        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*magic*/ 4
            + /*type*/ SerialBuffer.varUintSize(this._type)
            + /*length*/ 4
            + /*checksum*/ 4;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {void}
     * @protected
     */
    _setChecksum(buf) {
        const checksum = CRC32.compute(buf);
        Message._writeChecksum(this._type, buf, checksum);
    }

    /**
     * @param {Message.Type} type
     * @param {SerialBuffer} buf
     * @param {number} value
     * @returns {void}
     * @private
     */
    static _writeChecksum(type, buf, value) {
        // Store current write position.
        const pos = buf.writePos;

        // Set write position past the magic, type, and length fields to the
        // beginning of the checksum value.
        buf.writePos = /*magic*/ 4
            + /*type*/ SerialBuffer.varUintSize(type)
            + /*length*/ 4;

        // Write the checksum value.
        buf.writeUint32(value);

        // Reset the write position to original.
        buf.writePos = pos;
    }

    /** @type {Message.Type} */
    get type() {
        return this._type;
    }

    /** @returns {string} */
    toString() {
        return `Message{type=${this.type}, size=${this.serializedSize}}`;
    }
}
Message.MAGIC = 0x42042042;
/**
 * Enum for message types.
 * @enum {number}
 */
Message.Type = {
    VERSION:    0,
    INV:        1,
    GET_DATA:   2,
    GET_HEADER: 3,
    NOT_FOUND:  4,
    GET_BLOCKS: 5,
    BLOCK:      6,
    HEADER:     7,
    TX:         8,
    MEMPOOL:    9,
    REJECT:     10,
    SUBSCRIBE:  11,

    ADDR:       20,
    GET_ADDR:   21,
    PING:       22,
    PONG:       23,

    SIGNAL:     30,

    GET_CHAIN_PROOF:                       40,
    CHAIN_PROOF:                           41,
    GET_ACCOUNTS_PROOF:                    42,
    ACCOUNTS_PROOF:                        43,
    GET_ACCOUNTS_TREE_CHUNK:               44,
    ACCOUNTS_TREE_CHUNK:                   45,
    /** @deprecated **/
    GET_TRANSACTIONS_PROOF:                47,
    GET_TRANSACTIONS_PROOF_BY_ADDRESSES:   47,
    TRANSACTIONS_PROOF:                    48,
    /** @deprecated **/
    GET_TRANSACTION_RECEIPTS:              49,
    GET_TRANSACTION_RECEIPTS_BY_ADDRESS:   49,
    TRANSACTION_RECEIPTS:                  50,
    GET_BLOCK_PROOF:                       51,
    BLOCK_PROOF:                           52,
    GET_TRANSACTIONS_PROOF_BY_HASHES:      53,
    GET_TRANSACTION_RECEIPTS_BY_HASHES:    54,
    GET_BLOCK_PROOF_AT:                    55,

    GET_HEAD:   60,
    HEAD:       61,

    VERACK:   90
};
Class.register(Message);

class AddrMessage extends Message {
    /**
     * @param {Array.<PeerAddress>} addresses
     */
    constructor(addresses) {
        super(Message.Type.ADDR);
        if (!addresses || !NumberUtils.isUint16(addresses.length)
            || addresses.length > AddrMessage.ADDRESSES_MAX_COUNT
            || addresses.some(it => !(it instanceof PeerAddress))) throw new Error('Malformed addresses');
        this._addresses = addresses;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {AddrMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > AddrMessage.ADDRESSES_MAX_COUNT) throw new Error('Malformed count');
        const addresses = new Array(count);
        for (let i = 0; i < count; i++) {
            addresses[i] = PeerAddress.unserialize(buf);
        }
        return new AddrMessage(addresses);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint16(this._addresses.length);
        for (const addr of this._addresses) {
            addr.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let size = super.serializedSize
            + /*count*/ 2;
        for (const addr of this._addresses) {
            size += addr.serializedSize;
        }
        return size;
    }

    /** @type {Array.<PeerAddress>} */
    get addresses() {
        return this._addresses;
    }

    toString() {
        return `AddrMessage{size=${this._addresses.length}}`;
    }
}
AddrMessage.ADDRESSES_MAX_COUNT = 1000;
Class.register(AddrMessage);

class BlockMessage extends Message {
    /**
     * @param {Block} block
     */
    constructor(block) {
        super(Message.Type.BLOCK);
        // TODO Bitcoin block messages start with a block version
        /** @type {Block} */
        this._block = block;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {BlockMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const block = Block.unserialize(buf);
        return new BlockMessage(block);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._block.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._block.serializedSize;
    }

    /** @type {Block} */
    get block() {
        return this._block;
    }

    toString() {
        return `BlockMessage{height=${this._block.height}, hash=${this._block.hash()}}`;
    }
}
Class.register(BlockMessage);

class RawBlockMessage extends Message {
    /**
     * @param {Uint8Array} block
     */
    constructor(block) {
        super(Message.Type.BLOCK);
        /** @type {Uint8Array} */
        this._block = block;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.write(this._block);
        super._setChecksum(buf);
        return buf;
    }

    /*
        unserialize is not implemented,
        because this message will serialize
        to a BlockMessage
     */

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._block.length;
    }

    /** @type {Block} */
    get block() {
        return Block.unserialize(new SerialBuffer(this._block));
    }
}
Class.register(RawBlockMessage);

class GetAddrMessage extends Message {
    /**
     * @param {number} protocolMask
     * @param {number} serviceMask
     * @param {number} maxResults
     */
    constructor(protocolMask, serviceMask, maxResults) {
        super(Message.Type.GET_ADDR);
        if (!NumberUtils.isUint8(protocolMask)) throw new Error('Malformed protocolMask');
        if (!NumberUtils.isUint32(serviceMask)) throw new Error('Malformed serviceMask');
        if (!NumberUtils.isUint16(maxResults)) throw new Error('Malformed maxResults');
        this._protocolMask = protocolMask;
        this._serviceMask = serviceMask;
        this._maxResults = maxResults;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {GetAddrMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const protocolMask = buf.readUint8();
        const serviceMask = buf.readUint32();

        // XXX optional maxResults argument.
        let maxResults = NetworkAgent.NUM_ADDR_PER_REQUEST;
        if (buf.readPos !== buf.byteLength) {
            maxResults = buf.readUint16();
        }

        return new GetAddrMessage(protocolMask, serviceMask, maxResults);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint8(this._protocolMask);
        buf.writeUint32(this._serviceMask);
        buf.writeUint16(this._maxResults);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*protocolMask*/ 1
            + /*serviceMask*/ 4
            + /*maxResults*/ 2;
    }

    /** @type {number} */
    get protocolMask() {
        return this._protocolMask;
    }

    /** @type {number} */
    get serviceMask() {
        return this._serviceMask;
    }

    /** @type {number} */
    get maxResults() {
        return this._maxResults;
    }

    toString() {
        return `GetAddrMessage{protocol=${this._protocolMask}, services=${this._serviceMask}, maxResults=${this._maxResults}}`;
    }
}
Class.register(GetAddrMessage);

class GetBlocksMessage extends Message {
    /**
     * @param {Array.<Hash>} locators
     * @param {number} maxInvSize
     * @param {GetBlocksMessage.Direction} direction
     */
    constructor(locators, maxInvSize=BaseInventoryMessage.VECTORS_MAX_COUNT, direction=GetBlocksMessage.Direction.FORWARD) {
        super(Message.Type.GET_BLOCKS);
        if (!locators || !NumberUtils.isUint16(locators.length)
            || locators.length > GetBlocksMessage.LOCATORS_MAX_COUNT
            || locators.some(it => !Hash.isHash(it))) throw new Error('Malformed locators');
        if (!NumberUtils.isUint16(maxInvSize)) throw new Error('Malformed maxInvSize');
        if (!NumberUtils.isUint8(direction)) throw new Error('Malformed direction');
        /** @type {Array.<Hash>} */
        this._locators = locators;
        this._maxInvSize = maxInvSize;
        this._direction = direction;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {GetBlocksMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > GetBlocksMessage.LOCATORS_MAX_COUNT) throw new Error('Malformed count');
        const locators = new Array(count);
        for (let i = 0; i < count; i++) {
            locators[i] = Hash.unserialize(buf);
        }
        const maxInvSize = buf.readUint16();
        const direction = buf.readUint8();
        return new GetBlocksMessage(locators, maxInvSize, direction);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint16(this._locators.length);
        for (const locator of this._locators) {
            locator.serialize(buf);
        }
        buf.writeUint16(this._maxInvSize);
        buf.writeUint8(this._direction);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let size = super.serializedSize
            + /*count*/ 2
            + /*direction*/ 1
            + /*maxInvSize*/ 2;
        for (const locator of this._locators) {
            size += locator.serializedSize;
        }
        return size;
    }

    /** @type {Array.<Hash>} */
    get locators() {
        return this._locators;
    }

    /** @type {GetBlocksMessage.Direction} */
    get direction() {
        return this._direction;
    }

    /** @type {number} */
    get maxInvSize() {
        return this._maxInvSize;
    }

    toString() {
        return `GetBlocksMessage{direction=${this._direction === GetBlocksMessage.Direction.FORWARD ? 'forward' : 'backward'}, maxInvSize=${this._maxInvSize}}`;
    }
}
/**
 * @enum {number}
 */
GetBlocksMessage.Direction = {
    FORWARD: 0x1,
    BACKWARD: 0x2
};
/**
 * @type {number}
 */
GetBlocksMessage.LOCATORS_MAX_COUNT = 128;
Class.register(GetBlocksMessage);

class HeaderMessage extends Message {
    /**
     * @param {BlockHeader} header
     */
    constructor(header) {
        super(Message.Type.HEADER);
        /** @type {BlockHeader} */
        this._header = header;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {HeaderMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const header = BlockHeader.unserialize(buf);
        return new HeaderMessage(header);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._header.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._header.serializedSize;
    }

    /** @type {BlockHeader} */
    get header() {
        return this._header;
    }

    toString() {
        return `HeaderMessage{height=${this._header.height}, hash=${this._header.hash()}}`;
    }
}
Class.register(HeaderMessage);

class InvVector {
    /**
     * @param {Block} block
     * @returns {InvVector}
     */
    static fromBlock(block) {
        const hash = block.hash();
        return new InvVector(InvVector.Type.BLOCK, hash);
    }

    /**
     * @param {BlockHeader} header
     * @returns {InvVector}
     */
    static fromHeader(header) {
        const hash = header.hash();
        return new InvVector(InvVector.Type.BLOCK, hash);
    }

    /**
     * @param {Transaction} tx
     * @returns {InvVector}
     */
    static fromTransaction(tx) {
        const hash = tx.hash();
        return new InvVector(InvVector.Type.TRANSACTION, hash);
    }

    /**
     * @param {InvVector.Type} type
     * @param {Hash} hash
     */
    constructor(type, hash) {
        // TODO validate type
        if (!Hash.isHash(hash)) throw new Error('Malformed hash');
        /** @type {InvVector.Type} */
        this._type = type;
        /** @type {Hash} */
        this._hash = hash;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {InvVector}
     */
    static unserialize(buf) {
        const type = InvVector.Type.unserialize(buf);
        const hash = Hash.unserialize(buf);
        return new InvVector(type, hash);
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint32(this._type);
        this._hash.serialize(buf);
        return buf;
    }

    /**
     * @param {InvVector} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof InvVector
            && this._type === o.type
            && this._hash.equals(o.hash);
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return `${this._type}|${this._hash.toBase64()}`;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `InvVector{type=${this._type}, hash=${this._hash}}`;
    }

    /** @type {number} */
    get serializedSize() {
        return /*invType*/ 4
            + this._hash.serializedSize;
    }

    /** @type {InvVector.Type} */
    get type() {
        return this._type;
    }

    /** @type {Hash} */
    get hash() {
        return this._hash;
    }
}
/**
 * @enum {number}
 */
InvVector.Type = {
    ERROR: 0,
    TRANSACTION: 1,
    BLOCK: 2,

    /**
     * @param {SerialBuffer} buf
     * @returns {InvVector.Type}
     */
    unserialize: function (buf) {
        return /** @type {InvVector.Type} */ (buf.readUint32());
    }
};
Class.register(InvVector);

class BaseInventoryMessage extends Message {
    /**
     * @param {Message.Type} type
     * @param {Array.<InvVector>} vectors
     */
    constructor(type, vectors) {
        super(type);
        if (!Array.isArray(vectors) || !NumberUtils.isUint16(vectors.length)
            || vectors.length > BaseInventoryMessage.VECTORS_MAX_COUNT
            || vectors.some(it => !(it instanceof InvVector))) throw new Error('Malformed vectors');
        /** @type {Array.<InvVector>} */
        this._vectors = vectors;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint16(this._vectors.length);
        for (const vector of this._vectors) {
            vector.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let size = super.serializedSize
            + /*count*/ 2;
        for (const vector of this._vectors) {
            size += vector.serializedSize;
        }
        return size;
    }

    /** @type {Array.<InvVector>} */
    get vectors() {
        return this._vectors;
    }

    // noinspection JSCheckFunctionSignatures
    toString(subtype = 'InventoryMessage') {
        return `${subtype}{transactions=${this._vectors.filter(vector => vector.type === InvVector.Type.TRANSACTION).length}, blocks=${this._vectors.filter(vector => vector.type === InvVector.Type.BLOCK).length}}`;
    }
}
BaseInventoryMessage.VECTORS_MAX_COUNT = 1000;
Class.register(BaseInventoryMessage);

class InvMessage extends BaseInventoryMessage {
    /**
     * @param {Array.<InvVector>} vectors
     */
    constructor(vectors) {
        super(Message.Type.INV, vectors);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {InvMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > BaseInventoryMessage.VECTORS_MAX_COUNT) throw new Error('Malformed count');
        const vectors = new Array(count);
        for (let i = 0; i < count; i++) {
            vectors[i] = InvVector.unserialize(buf);
        }
        return new InvMessage(vectors);
    }

    toString() {
        return super.toString('InvMessage');
    }
}
Class.register(InvMessage);

class GetDataMessage extends BaseInventoryMessage {
    /**
     * @param {Array.<InvVector>} vectors
     */
    constructor(vectors) {
        super(Message.Type.GET_DATA, vectors);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetDataMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > BaseInventoryMessage.VECTORS_MAX_COUNT) throw new Error('Malformed count');
        const vectors = new Array(count);
        for (let i = 0; i < count; i++) {
            vectors[i] = InvVector.unserialize(buf);
        }
        return new GetDataMessage(vectors);
    }

    toString() {
        return super.toString('GetDataMessage');
    }
}
Class.register(GetDataMessage);

class GetHeaderMessage extends BaseInventoryMessage {
    /**
     * @param {Array.<InvVector>} vectors
     */
    constructor(vectors) {
        super(Message.Type.GET_HEADER, vectors);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetHeaderMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > BaseInventoryMessage.VECTORS_MAX_COUNT) throw new Error('Malformed count');
        const vectors = new Array(count);
        for (let i = 0; i < count; i++) {
            vectors[i] = InvVector.unserialize(buf);
        }
        return new GetHeaderMessage(vectors);
    }

    toString() {
        return super.toString('GetHeaderMessage');
    }
}
Class.register(GetHeaderMessage);

class NotFoundMessage extends BaseInventoryMessage {
    /**
     * @param {Array.<InvVector>} vectors
     */
    constructor(vectors) {
        super(Message.Type.NOT_FOUND, vectors);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {NotFoundMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > BaseInventoryMessage.VECTORS_MAX_COUNT) throw new Error('Malformed count');
        const vectors = new Array(count);
        for (let i = 0; i < count; i++) {
            vectors[i] = InvVector.unserialize(buf);
        }
        return new NotFoundMessage(vectors);
    }

    toString() {
        return super.toString('NotFoundMessage');
    }
}
Class.register(NotFoundMessage);

class MempoolMessage extends Message {
    constructor() {
        super(Message.Type.MEMPOOL);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {MempoolMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        return new MempoolMessage();
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize;
    }

    toString() {
        return 'MempoolMessage{}';
    }
}
Class.register(MempoolMessage);

class PingMessage extends Message {
    /**
     * @param {number} nonce
     */
    constructor(nonce) {
        super(Message.Type.PING);
        if (!NumberUtils.isUint32(nonce)) throw new Error('Malformed nonce');
        /** @type {number} */
        this._nonce = nonce;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {PingMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const nonce = buf.readUint32();
        return new PingMessage(nonce);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint32(this._nonce);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*nonce*/ 4;
    }

    /** @type {number} */
    get nonce() {
        return this._nonce;
    }

    toString() {
        return `PingMessage{nonce=${this._nonce}}`;
    }
}
Class.register(PingMessage);

class PongMessage extends Message {
    /**
     * @param {number} nonce
     */
    constructor(nonce) {
        super(Message.Type.PONG);
        if (!NumberUtils.isUint32(nonce)) throw new Error('Malformed nonce');

        this._nonce = nonce;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {PongMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const nonce = buf.readUint32();
        return new PongMessage(nonce);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint32(this._nonce);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*nonce*/ 4;
    }

    /** @type {number} */
    get nonce() {
        return this._nonce;
    }

    toString() {
        return `PongMessage{nonce=${this._nonce}}`;
    }
}
Class.register(PongMessage);

class RejectMessage extends Message {
    /**
     * @param {Message.Type} messageType
     * @param {RejectMessage.Code} code
     * @param {string} reason
     * @param {Uint8Array} [extraData]
     */
    constructor(messageType, code, reason, extraData=new Uint8Array(0)) {
        super(Message.Type.REJECT);
        if (!NumberUtils.isUint64(messageType)) throw new Error('Malformed type');
        if (!NumberUtils.isUint8(code)) throw new Error('Malformed code');
        if (StringUtils.isMultibyte(reason) || reason.length > 255) throw new Error('Malformed reason');
        if (!(extraData instanceof Uint8Array) || !NumberUtils.isUint16(extraData.byteLength)) throw new Error('Malformed extraData');

        /** @type {Message.Type} */
        this._messageType = messageType;
        /** @type {RejectMessage.Code} */
        this._code = code;
        /** @type {string} */
        this._reason = reason;
        /** @type {Uint8Array} */
        this._extraData = extraData;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {RejectMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const messageType = /** @type {Message.Type} */ buf.readVarUint();
        const code = /** @type {RejectMessage.Code} */ buf.readUint8();
        const reason = buf.readVarLengthString();
        const length = buf.readUint16();
        const extraData = buf.read(length);
        return new RejectMessage(messageType, code, reason, extraData);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeVarUint(this._messageType);
        buf.writeUint8(this._code);
        buf.writeVarLengthString(this._reason);
        buf.writeUint16(this._extraData.byteLength);
        buf.write(this._extraData);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + SerialBuffer.varUintSize(this._messageType)
            + /*code*/ 1
            + SerialBuffer.varLengthStringSize(this._reason)
            + /*extraDataLength*/ 2
            + this._extraData.byteLength;
    }

    /** @type {Message.Type} */
    get messageType() {
        return this._messageType;
    }

    /** @type {RejectMessage.Code} */
    get code() {
        return this._code;
    }

    /** @type {string} */
    get reason() {
        return this._reason;
    }

    /** @type {Uint8Array} */
    get extraData() {
        return this._extraData;
    }

    toString() {
        return `RejectMessage{type=${this._messageType}, code=${this._code}, reason=${this._reason}}`;
    }
}
/**
 * @enum {number}
 */
RejectMessage.Code = {
    REJECT_MALFORMED: 0x01,
    REJECT_INVALID: 0x10,
    REJECT_OBSOLETE: 0x11,
    REJECT_DOUBLE: 0x12,
    REJECT_DUST: 0x41,
    REJECT_INSUFFICIENT_FEE: 0x42
};
Class.register(RejectMessage);

class SignalMessage extends Message {
    /**
     * @param {PeerId} senderId
     * @param {PeerId} recipientId
     * @param {number} nonce
     * @param {number} ttl
     * @param {SignalMessage.Flag|number} flags
     * @param {Uint8Array} [payload]
     * @param {PublicKey} [senderPubKey]
     * @param {Signature} [signature]
     */
    constructor(senderId, recipientId, nonce, ttl, flags = 0, payload = new Uint8Array(0), senderPubKey, signature) {
        super(Message.Type.SIGNAL);
        if (!(senderId instanceof PeerId)) throw new Error('Malformed senderId');
        if (!(recipientId instanceof PeerId)) throw new Error('Malformed recipientId');
        if (!NumberUtils.isUint32(nonce)) throw new Error('Malformed nonce');
        if (!NumberUtils.isUint8(ttl)) throw new Error('Malformed ttl');
        if (!NumberUtils.isUint8(flags)) throw new Error('Malformed flags');
        if (!(payload instanceof Uint8Array) || !NumberUtils.isUint16(payload.byteLength)) throw new Error('Malformed payload');
        const hasPayload = payload.byteLength > 0;
        if (hasPayload && !(signature instanceof Signature)) throw new Error('Malformed signature');
        if (hasPayload && !(senderPubKey instanceof PublicKey)) throw new Error('Malformed public key');

        // Note that the signature is NOT verified here.
        // Callers must explicitly invoke verifySignature() to check it.

        /** @type {PeerId} */
        this._senderId = senderId;
        /** @type {PeerId} */
        this._recipientId = recipientId;
        /** @type {number} */
        this._nonce = nonce;
        /** @type {number} */
        this._ttl = ttl;
        /** @type {SignalMessage.Flag|number} */
        this._flags = flags;
        /** @type {Uint8Array} */
        this._payload = payload;
        /** @type {PublicKey} */
        this._senderPubKey = hasPayload ? senderPubKey : undefined;
        /** @type {Signature} */
        this._signature = hasPayload ? signature : undefined;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {SignalMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const senderId = PeerId.unserialize(buf);
        const recipientId = PeerId.unserialize(buf);
        const nonce = buf.readUint32();
        const ttl = buf.readUint8();
        const flags = buf.readUint8();
        const length = buf.readUint16();
        const payload = buf.read(length);
        const senderPubKey = length > 0 ? PublicKey.unserialize(buf) : undefined;
        const signature = length > 0 ? Signature.unserialize(buf) : undefined;
        return new SignalMessage(senderId, recipientId, nonce, ttl, flags, payload, senderPubKey, signature);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._senderId.serialize(buf);
        this._recipientId.serialize(buf);
        buf.writeUint32(this._nonce);
        buf.writeUint8(this._ttl);
        buf.writeUint8(this._flags);
        buf.writeUint16(this._payload.byteLength);
        buf.write(this._payload);
        if (this._payload.byteLength > 0) {
            this._senderPubKey.serialize(buf);
            this._signature.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*senderId*/ this._senderId.serializedSize
            + /*recipientId*/ this._recipientId.serializedSize
            + /*nonce*/ 4
            + /*ttl*/ 1
            + /*flags*/ 1
            + /*payloadLength*/ 2
            + this._payload.byteLength
            + (this._payload.byteLength > 0 ? this._senderPubKey.serializedSize : 0)
            + (this._payload.byteLength > 0 ? this._signature.serializedSize : 0);
    }

    /**
     * @return {boolean}
     */
    verifySignature() {
        if (!this._signature) {
            return false;
        }

        return this._signature.verify(this._senderPubKey, this._payload)
            && this._senderId.equals(this._senderPubKey.toPeerId());
    }

    /** @type {PeerId} */
    get senderId() {
        return this._senderId;
    }

    /** @type {PeerId} */
    get recipientId() {
        return this._recipientId;
    }

    /** @type {number} */
    get nonce() {
        return this._nonce;
    }

    /** @type {number} */
    get ttl() {
        return this._ttl;
    }

    /** @type {SignalMessage.Flag|number} */
    get flags() {
        return this._flags;
    }

    /** @type {Uint8Array} */
    get payload() {
        return this._payload;
    }

    /** @type {Signature} */
    get signature() {
        return this._signature;
    }

    /** @type {PublicKey} */
    get senderPubKey() {
        return this._senderPubKey;
    }

    /**
     * @returns {boolean}
     */
    hasPayload() {
        return this._payload.byteLength > 0;
    }

    /**
     * @returns {boolean}
     */
    isUnroutable() {
        return (this._flags & SignalMessage.Flag.UNROUTABLE) !== 0;
    }

    /**
     * @returns {boolean}
     */
    isTtlExceeded() {
        return (this._flags & SignalMessage.Flag.TTL_EXCEEDED) !== 0;
    }

    toString() {
        return `SignalMessage{sender=${this._senderId}, recipient=${this._recipientId}, nonce=${this._nonce}, ttl=${this._ttl}, flags=${this._flags}}`;
    }
}
/**
 * @enum {number}
 */
SignalMessage.Flag = {
    UNROUTABLE: 0x1,
    TTL_EXCEEDED: 0x2
};
Class.register(SignalMessage);

class SubscribeMessage extends Message {
    constructor(subscription) {
        super(Message.Type.SUBSCRIBE);
        this._subscription = subscription;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {SubscribeMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const subscription = Subscription.unserialize(buf);
        return new SubscribeMessage(subscription);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._subscription.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._subscription.serializedSize;
    }

    /** @type {Subscription} */
    get subscription() {
        return this._subscription;
    }

    toString() {
        return `SubscribeMessage{${this._subscription}}`;
    }
}
Class.register(SubscribeMessage);

class TxMessage extends Message {
    /**
     * @param {Transaction} transaction
     * @param {?AccountsProof} [accountsProof]
     */
    constructor(transaction, accountsProof) {
        super(Message.Type.TX);
        /** @type {Transaction} */
        this._transaction = transaction;
        /** @type {AccountsProof} */
        this._accountsProof = accountsProof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {TxMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const transaction = Transaction.unserialize(buf);
        const hasAccountsProof = buf.readUint8();
        if (hasAccountsProof === 1) {
            const accountsProof = AccountsProof.unserialize(buf);
            return new TxMessage(transaction, accountsProof);
        }
        return new TxMessage(transaction);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._transaction.serialize(buf);
        buf.writeUint8(this._accountsProof ? 1 : 0);
        if (this._accountsProof) {
            this._accountsProof.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        let size = super.serializedSize
            + this._transaction.serializedSize
            + /*hasAccountsProof*/ 1;
        if (this._accountsProof) {
            size += this._accountsProof.serializedSize;
        }
        return size;
    }

    /** @type {Transaction} */
    get transaction() {
        return this._transaction;
    }

    /** @type {boolean} */
    get hasAccountsProof() {
        return !!this._accountsProof;
    }

    /** @type {AccountsProof} */
    get accountsProof() {
        return this._accountsProof;
    }

    toString() {
        return `TxMessage{hash=${this._transaction.hash()}}`;
    }
}
Class.register(TxMessage);

class VersionMessage extends Message {
    /**
     * @param {number} version
     * @param {PeerAddress} peerAddress
     * @param {Hash} genesisHash
     * @param {Hash} headHash
     * @param {Uint8Array} challengeNonce
     * @param {string} [userAgent]
     */
    constructor(version, peerAddress, genesisHash, headHash, challengeNonce, userAgent) {
        super(Message.Type.VERSION);
        if (!NumberUtils.isUint32(version)) throw new Error('Malformed version');
        if (!(peerAddress instanceof PeerAddress)) throw new Error('Malformed peerAddress');
        if (!Hash.isHash(genesisHash)) throw new Error('Malformed genesisHash');
        if (!Hash.isHash(headHash)) throw new Error('Malformed headHash');
        if (!(challengeNonce instanceof Uint8Array) || challengeNonce.byteLength !== 32) throw new Error('Malformed challenge nonce');
        if (userAgent && (typeof userAgent !== 'string' || StringUtils.isMultibyte(userAgent) || !NumberUtils.isUint8(userAgent.length))) throw new Error('Malformed user agent');

        /** @type {number} */
        this._version = version;
        /** @type {PeerAddress} */
        this._peerAddress = peerAddress;
        /** @type {Hash} */
        this._genesisHash = genesisHash;
        /** @type {Hash} */
        this._headHash = headHash;
        /** @type {Uint8Array} */
        this._challengeNonce = challengeNonce;
        /** @type {?string} */
        this._userAgent = userAgent;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {VersionMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const version = buf.readUint32();
        const peerAddress = PeerAddress.unserialize(buf);
        const genesisHash = Hash.unserialize(buf);
        const headHash = Hash.unserialize(buf);
        const challengeNonce = buf.read(VersionMessage.CHALLENGE_SIZE);
        const userAgent = (buf.readPos !== buf.byteLength) ? buf.readVarLengthString() : undefined;
        return new VersionMessage(version, peerAddress, genesisHash, headHash, challengeNonce, userAgent);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint32(this._version);
        this._peerAddress.serialize(buf);
        this._genesisHash.serialize(buf);
        this._headHash.serialize(buf);
        buf.write(this._challengeNonce);
        if (this._userAgent) buf.writeVarLengthString(this._userAgent);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*version*/ 4
            + this._peerAddress.serializedSize
            + this._genesisHash.serializedSize
            + this._headHash.serializedSize
            + VersionMessage.CHALLENGE_SIZE
            + (this._userAgent ? SerialBuffer.varLengthStringSize(this._userAgent) : 0);
    }

    /** @type {number} */
    get version() {
        return this._version;
    }

    /** @type {PeerAddress} */
    get peerAddress() {
        return this._peerAddress;
    }

    /** @type {Hash} */
    get genesisHash() {
        return this._genesisHash;
    }

    /** @type {Hash} */
    get headHash() {
        return this._headHash;
    }

    /** @type {Uint8Array} */
    get challengeNonce() {
        return this._challengeNonce;
    }

    /** @type {?string} */
    get userAgent() {
        return this._userAgent;
    }

    toString() {
        return `VersionMessage{version=${this._version}, peer=${this._peerAddress}, genesis=${this._genesisHash}, head=${this._headHash}, userAgent=${this._userAgent}}`;
    }
}

VersionMessage.CHALLENGE_SIZE = 32;
Class.register(VersionMessage);

class VerAckMessage extends Message {
    /**
     * @param {PublicKey} publicKey
     * @param {Signature} signature
     */
    constructor(publicKey, signature) {
        super(Message.Type.VERACK);
        /** @type {PublicKey} */
        this._publicKey = publicKey;
        /** @type {Signature} */
        this._signature = signature;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {VerAckMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const publicKey = PublicKey.unserialize(buf);
        const signature = Signature.unserialize(buf);
        return new VerAckMessage(publicKey, signature);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this.publicKey.serialize(buf);
        this.signature.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._publicKey.serializedSize
            + this._signature.serializedSize;
    }

    /** @type {PublicKey} */
    get publicKey() {
        return this._publicKey;
    }

    /** @type {Signature} */
    get signature() {
        return this._signature;
    }

    toString() {
        return 'VerAckMessage{}';
    }
}
Class.register(VerAckMessage);

class AccountsProofMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {AccountsProof} [accountsProof]
     */
    constructor(blockHash, accountsProof=null) {
        super(Message.Type.ACCOUNTS_PROOF);
        if (!(blockHash instanceof Hash)) throw new Error('Malformed blockHash');
        if (accountsProof && !(accountsProof instanceof AccountsProof)) throw new Error('Malformed proof');
        /** @type {Hash} */
        this._blockHash = blockHash;
        /** @type {AccountsProof} */
        this._accountsProof = accountsProof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {AccountsProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const hasProof = buf.readUint8();
        let accountsProof = null;
        if (hasProof !== 0) {
            accountsProof = AccountsProof.unserialize(buf);
        }
        return new AccountsProofMessage(blockHash, accountsProof);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint8(this.hasProof() ? 1 : 0);
        if (this.hasProof()) {
            this._accountsProof.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*success bit*/ 1
            + this._blockHash.serializedSize
            + (this.hasProof() ? this._accountsProof.serializedSize : 0);
    }

    /**
     * @return {boolean}
     */
    hasProof() {
        return !!this._accountsProof;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {AccountsProof} */
    get proof() {
        return this._accountsProof;
    }
}
Class.register(AccountsProofMessage);

class GetAccountsProofMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     */
    constructor(blockHash, addresses) {
        super(Message.Type.GET_ACCOUNTS_PROOF);
        if (!blockHash || !(blockHash instanceof Hash)) throw new Error('Malformed block hash');
        if (!addresses || !NumberUtils.isUint16(addresses.length)
            || addresses.length < 1
            || addresses.length > GetAccountsProofMessage.ADDRESSES_MAX_COUNT
            || addresses.some(it => !(it instanceof Address))) throw new Error('Malformed addresses');
        this._blockHash = blockHash;
        /** @type {Array.<Address>} */
        this._addresses = addresses;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetAccountsProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const count = buf.readUint16();
        const addresses = [];
        for (let i = 0; i < count; i++) {
            addresses.push(Address.unserialize(buf));
        }
        return new GetAccountsProofMessage(blockHash, addresses);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint16(this._addresses.length);
        for (const address of this._addresses) {
            address.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._blockHash.serializedSize
            + /*count*/ 2
            + this._addresses.reduce((sum, address) => sum + address.serializedSize, 0);
    }

    /** @type {Array.<Address>} */
    get addresses() {
        return this._addresses;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }
}

/**
 * @type {number}
 */
GetAccountsProofMessage.ADDRESSES_MAX_COUNT = 256;
Class.register(GetAccountsProofMessage);

class ChainProofMessage extends Message {
    /**
     * @param {ChainProof} proof
     */
    constructor(proof) {
        super(Message.Type.CHAIN_PROOF);
        if (!(proof instanceof ChainProof)) throw new Error('Malformed chainProof');

        /** @type {ChainProof} */
        this._proof = proof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {ChainProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const proof = ChainProof.unserialize(buf);
        return new ChainProofMessage(proof);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._proof.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._proof.serializedSize;
    }

    /** @type {ChainProof} */
    get proof() {
        return this._proof;
    }
}
Class.register(ChainProofMessage);

class GetChainProofMessage extends Message {
    constructor() {
        super(Message.Type.GET_CHAIN_PROOF);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetChainProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        return new GetChainProofMessage();
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize;
    }
}
Class.register(GetChainProofMessage);

class AccountsTreeChunkMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {AccountsTreeChunk} [accountsTreeChunk]
     */
    constructor(blockHash, accountsTreeChunk=null) {
        super(Message.Type.ACCOUNTS_TREE_CHUNK);
        if (!(blockHash instanceof Hash)) throw new Error('Malformed blockHash');
        if (accountsTreeChunk && !(accountsTreeChunk instanceof AccountsTreeChunk)) throw new Error('Malformed chunk');
        /** @type {Hash} */
        this._blockHash = blockHash;
        /** @type {AccountsTreeChunk} */
        this._accountsTreeChunk = accountsTreeChunk;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {AccountsTreeChunkMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const hasChunk = buf.readUint8();
        let accountsTreeChunk = null;
        if (hasChunk !== 0) {
            accountsTreeChunk = AccountsTreeChunk.unserialize(buf);
        }
        return new AccountsTreeChunkMessage(blockHash, accountsTreeChunk);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint8(this.hasChunk() ? 1 : 0);
        if (this.hasChunk()) {
            this._accountsTreeChunk.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*success bit*/ 1
            + this._blockHash.serializedSize
            + (this.hasChunk() ? this._accountsTreeChunk.serializedSize : 0);
    }

    /**
     * @return {boolean}
     */
    hasChunk() {
        return !!this._accountsTreeChunk;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {AccountsTreeChunk} */
    get chunk() {
        return this._accountsTreeChunk;
    }
}
Class.register(AccountsTreeChunkMessage);

class GetAccountsTreeChunkMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {string} startPrefix
     */
    constructor(blockHash, startPrefix) {
        super(Message.Type.GET_ACCOUNTS_TREE_CHUNK);
        if (!blockHash || !(blockHash instanceof Hash)) throw new Error('Malformed block hash');
        if (StringUtils.isMultibyte(startPrefix)
            || !NumberUtils.isUint8(startPrefix.length)) throw new Error('Malformed start prefix');
        /** @type {Hash} */
        this._blockHash = blockHash;
        this._startPrefix = startPrefix;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetAccountsTreeChunkMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const startPrefix = buf.readVarLengthString();
        return new GetAccountsTreeChunkMessage(blockHash, startPrefix);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeVarLengthString(this._startPrefix);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._blockHash.serializedSize
            + SerialBuffer.varLengthStringSize(this._startPrefix);
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {string} */
    get startPrefix() {
        return this._startPrefix;
    }
}
Class.register(GetAccountsTreeChunkMessage);

class TransactionsProofMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {TransactionsProof} [proof]
     */
    constructor(blockHash, proof=null) {
        super(Message.Type.TRANSACTIONS_PROOF);
        if (!(blockHash instanceof Hash)) throw new Error('Malformed blockHash');
        if (proof && !(proof instanceof TransactionsProof)) throw new Error('Malformed proof');
        /** @type {Hash} */
        this._blockHash = blockHash;
        /** @type {TransactionsProof} */
        this._proof = proof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {TransactionsProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const hasProof = buf.readUint8();
        let proof = null;
        if (hasProof !== 0) {
            proof = TransactionsProof.unserialize(buf);
        }
        return new TransactionsProofMessage(blockHash, proof);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint8(this.hasProof() ? 1 : 0);
        if (this.hasProof()) {
            this._proof.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*success bit*/ 1
            + this._blockHash.serializedSize
            + (this.hasProof() ? this._proof.serializedSize : 0);
    }

    /**
     * @return {boolean}
     */
    hasProof() {
        return !!this._proof;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {TransactionsProof} */
    get proof() {
        return this._proof;
    }
}
Class.register(TransactionsProofMessage);

class GetTransactionsProofByAddressesMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     */
    constructor(blockHash, addresses) {
        super(Message.Type.GET_TRANSACTIONS_PROOF_BY_ADDRESSES);
        if (!blockHash || !(blockHash instanceof Hash)) throw new Error('Malformed block hash');
        if (!Array.isArray(addresses) || !NumberUtils.isUint16(addresses.length)
            || addresses.length > GetTransactionsProofByAddressesMessage.ADDRESSES_MAX_COUNT
            || addresses.some(it => !(it instanceof Address))) throw new Error('Malformed addresses');
        this._blockHash = blockHash;
        /** @type {Array.<Address>} */
        this._addresses = addresses;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetTransactionsProofByAddressesMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const count = buf.readUint16();
        if (count > GetTransactionsProofByAddressesMessage.ADDRESSES_MAX_COUNT) throw new Error('Malformed count');
        const addresses = new Array(count);
        for (let i = 0; i < count; i++) {
            addresses[i] = Address.unserialize(buf);
        }
        return new GetTransactionsProofByAddressesMessage(blockHash, addresses);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint16(this._addresses.length);
        for (const address of this._addresses) {
            address.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._blockHash.serializedSize
            + /*count*/ 2
            + this._addresses.reduce((sum, address) => sum + address.serializedSize, 0);
    }

    /** @type {Array.<Address>} */
    get addresses() {
        return this._addresses;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }
}
/**
 * @type {number}
 */
GetTransactionsProofByAddressesMessage.ADDRESSES_MAX_COUNT = 255;
Class.register(GetTransactionsProofByAddressesMessage);

class GetTransactionsProofByHashesMessage extends Message {
    /**
     * @param {Hash} blockHash
     * @param {Array.<Hash>} hashes
     */
    constructor(blockHash, hashes) {
        super(Message.Type.GET_TRANSACTIONS_PROOF_BY_HASHES);
        if (!blockHash || !(blockHash instanceof Hash)) throw new Error('Malformed block hash');
        if (!Array.isArray(hashes) || hashes.length === 0 || !NumberUtils.isUint16(hashes.length)
            || hashes.length > GetTransactionsProofByHashesMessage.HASHES_MAX_COUNT
            || hashes.some(hash => !(hash instanceof Hash))) throw new Error('Malformed hashes');
        this._blockHash = blockHash;
        /** @type {Array.<Hash>} */
        this._hashes = hashes;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetTransactionsProofByHashesMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHash = Hash.unserialize(buf);
        const count = buf.readUint16();
        if (count > GetTransactionsProofByHashesMessage.HASHES_MAX_COUNT) throw new Error('Malformed count');
        const hashes = new Array(count);
        for (let i = 0; i < count; i++) {
            hashes[i] = Hash.unserialize(buf);
        }
        return new GetTransactionsProofByHashesMessage(blockHash, hashes);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHash.serialize(buf);
        buf.writeUint16(this._hashes.length);
        for (const address of this._hashes) {
            address.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._blockHash.serializedSize
            + /*count*/ 2
            + this._hashes.reduce((sum, hash) => sum + hash.serializedSize, 0);
    }

    /** @type {Array.<Hash>} */
    get hashes() {
        return this._hashes;
    }

    /** @type {Hash} */
    get blockHash() {
        return this._blockHash;
    }
}
/**
 * @type {number}
 */
GetTransactionsProofByHashesMessage.HASHES_MAX_COUNT = 255;
Class.register(GetTransactionsProofByHashesMessage);

class GetTransactionReceiptsByAddressMessage extends Message {
    /**
     * @param {Address} address
     * @param {number} [offset]
     */
    constructor(address, offset = 0) {
        super(Message.Type.GET_TRANSACTION_RECEIPTS_BY_ADDRESS);
        if (!(address instanceof Address)) throw new Error('Malformed address');
        if (!NumberUtils.isUint32(offset)) throw new Error('Malformed offset');
        /** @type {Address} */
        this._address = address;
        /** @type {number} */
        this._offset = offset;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {GetTransactionReceiptsByAddressMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const address = Address.unserialize(buf);
        const offset = buf.readUint32();
        return new GetTransactionReceiptsByAddressMessage(address, offset);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._address.serialize(buf);
        buf.writeUint32(this._offset);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._address.serializedSize
            + /*offset*/ 4;
    }

    /** @type {Address} */
    get address() {
        return this._address;
    }

    /** @type {number} */
    get offset() {
        return this._offset;
    }
}
Class.register(GetTransactionReceiptsByAddressMessage);

class GetTransactionReceiptsByHashesMessage extends Message {
    /**
     * @param {Array.<Hash>} hashes
     */
    constructor(hashes) {
        super(Message.Type.GET_TRANSACTION_RECEIPTS_BY_HASHES);
        if (!Array.isArray(hashes) || hashes.length === 0 || !NumberUtils.isUint16(hashes.length)
            || hashes.length > GetTransactionReceiptsByHashesMessage.HASHES_MAX_COUNT
            || hashes.some(hash => !(hash instanceof Hash))) throw new Error('Malformed hashes');
        /** @type {Array.<Hash>} */
        this._hashes = hashes;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {GetTransactionReceiptsByHashesMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const count = buf.readUint16();
        if (count > GetTransactionReceiptsByHashesMessage.HASHES_MAX_COUNT) throw new Error('Malformed count');
        const hashes = new Array(count);
        for (let i = 0; i < count; i++) {
            hashes[i] = Hash.unserialize(buf);
        }
        return new GetTransactionReceiptsByHashesMessage(hashes);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint16(this._hashes.length);
        for (const address of this._hashes) {
            address.serialize(buf);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*count*/ 2
            + this._hashes.reduce((sum, hash) => sum + hash.serializedSize, 0);
    }

    /** @type {Array.<Hash>} */
    get hashes() {
        return this._hashes;
    }
}
GetTransactionReceiptsByHashesMessage.HASHES_MAX_COUNT = 255;
Class.register(GetTransactionReceiptsByHashesMessage);

class TransactionReceiptsMessage extends Message {
    /**
     * @param {Array.<TransactionReceipt>} [receipts]
     */
    constructor(receipts = null) {
        super(Message.Type.TRANSACTION_RECEIPTS);
        if (receipts && (!Array.isArray(receipts) || !NumberUtils.isUint16(receipts.length)
            || receipts.length > TransactionReceiptsMessage.RECEIPTS_MAX_COUNT
            || receipts.some(it => !(it instanceof TransactionReceipt)))) throw new Error('Malformed receipts');
        /** @type {Array.<TransactionReceipt>} */
        this._receipts = receipts;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {TransactionReceiptsMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const hasReceipts = buf.readUint8();
        let receipts = null;
        if (hasReceipts !== 0) {
            const count = buf.readUint16();
            if (count > TransactionReceiptsMessage.RECEIPTS_MAX_COUNT) throw new Error('Malformed count');
            receipts = new Array(count);
            for (let i = 0; i < count; i++) {
                receipts[i] = TransactionReceipt.unserialize(buf);
            }
        }
        return new TransactionReceiptsMessage(receipts);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint8(this.hasReceipts() ? 1 : 0);
        if (this.hasReceipts()) {
            buf.writeUint16(this._receipts.length);
            for (const receipt of this._receipts) {
                receipt.serialize(buf);
            }
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*success bit*/ 1
            + (this.hasReceipts()
                ? /*count*/ 2 + this._receipts.reduce((sum, receipt) => sum + receipt.serializedSize, 0)
                : 0);
    }

    /**
     * @returns {boolean}
     */
    hasReceipts() {
        return !!this._receipts;
    }

    /** @type {Array.<TransactionReceipt>} */
    get receipts() {
        return this._receipts;
    }
}
Class.register(TransactionReceiptsMessage);
TransactionReceiptsMessage.RECEIPTS_MAX_COUNT = 500;

class GetBlockProofMessage extends Message {
    /**
     * @param {Hash} blockHashToProve
     * @param {Hash} knownBlockHash
     */
    constructor(blockHashToProve, knownBlockHash) {
        super(Message.Type.GET_BLOCK_PROOF);
        if (!(blockHashToProve instanceof Hash)) throw new Error('Malformed blockHashToProve');
        if (!(knownBlockHash instanceof Hash)) throw new Error('Malformed knownBlockHash');
        /** @type {Hash} */
        this._blockHashToProve = blockHashToProve;
        /** @type {Hash} */
        this._knownBlockHash = knownBlockHash;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {GetBlockProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHashToProve = Hash.unserialize(buf);
        const knownBlockHash = Hash.unserialize(buf);
        return new GetBlockProofMessage(blockHashToProve, knownBlockHash);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._blockHashToProve.serialize(buf);
        this._knownBlockHash.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._blockHashToProve.serializedSize
            + this._knownBlockHash.serializedSize;
    }

    /** @type {Hash} */
    get blockHashToProve() {
        return this._blockHashToProve;
    }

    /** @type {Hash} */
    get knownBlockHash() {
        return this._knownBlockHash;
    }
}
Class.register(GetBlockProofMessage);

class GetBlockProofAtMessage extends Message {
    /**
     * @param {number} blockHeightToProve
     * @param {Hash} knownBlockHash
     */
    constructor(blockHeightToProve, knownBlockHash) {
        super(Message.Type.GET_BLOCK_PROOF_AT);
        if (!NumberUtils.isUint32(blockHeightToProve)) throw new Error('Malformed blockHeightToProve');
        if (!(knownBlockHash instanceof Hash)) throw new Error('Malformed knownBlockHash');
        /** @type {number} */
        this._blockHeightToProve = blockHeightToProve;
        /** @type {Hash} */
        this._knownBlockHash = knownBlockHash;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {GetBlockProofAtMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const blockHeightToProve = buf.readUint32();
        const knownBlockHash = Hash.unserialize(buf);
        return new GetBlockProofAtMessage(blockHeightToProve, knownBlockHash);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeUint32(this._blockHeightToProve);
        this._knownBlockHash.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + 4 /*blockHeightToProve*/
            + this._knownBlockHash.serializedSize;
    }

    /** @type {number} */
    get blockHeightToProve() {
        return this._blockHeightToProve;
    }

    /** @type {Hash} */
    get knownBlockHash() {
        return this._knownBlockHash;
    }
}
Class.register(GetBlockProofAtMessage);

class BlockProofMessage extends Message {
    /**
     * @param {BlockChain} [proof]
     */
    constructor(proof) {
        super(Message.Type.BLOCK_PROOF);
        if (proof && !(proof instanceof BlockChain)) throw new Error('Malformed proof');
        /** @type {BlockChain} */
        this._proof = proof;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {BlockProofMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const hasProof = buf.readUint8() === 1;
        if (hasProof) {
            const proof = BlockChain.unserialize(buf);
            return new BlockProofMessage(proof);
        }
        return new BlockProofMessage();
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        if (this._proof) {
            buf.writeUint8(1);
            this._proof.serialize(buf);
        } else {
            buf.writeUint8(0);
        }
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + /*found*/ 1
            + (this._proof ? this._proof.serializedSize : 0);
    }

    /**
     * @returns {boolean}
     */
    hasProof() {
        return !!this._proof;
    }

    /** @type {BlockChain} */
    get proof() {
        return this._proof;
    }
}
Class.register(BlockProofMessage);

class GetHeadMessage extends Message {
    constructor() {
        super(Message.Type.GET_HEAD);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {GetHeadMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        return new GetHeadMessage();
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    toString() {
        return 'GetHeadMessage{}';
    }
}
Class.register(GetHeadMessage);

class HeadMessage extends Message {
    /**
     * @param {BlockHeader} header
     */
    constructor(header) {
        super(Message.Type.HEAD);
        /** @type {BlockHeader} */
        this._header = header;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {HeadMessage}
     */
    static unserialize(buf) {
        Message.unserialize(buf);
        const header = BlockHeader.unserialize(buf);
        return new HeadMessage(header);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        this._header.serialize(buf);
        super._setChecksum(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + this._header.serializedSize;
    }

    /** @type {BlockHeader} */
    get header() {
        return this._header;
    }

    toString() {
        return `HeadMessage{height=${this._header.height}, hash=${this._header.hash()}}`;
    }
}
Class.register(HeadMessage);

class MessageFactory {
    /**
     * @param {SerialBuffer} buf
     * @returns {Message.Type}
     */
    static peekType(buf) {
        return Message.peekType(buf);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {Message}
     */
    static parse(buf) {
        const type = Message.peekType(buf);
        const clazz = MessageFactory.CLASSES[type];
        if (!clazz || !clazz.unserialize) throw new Error(`Invalid message type: ${type}`);
        return clazz.unserialize(buf);
    }
}
/**
 * @dict 
 * @type {object}
 */
MessageFactory.CLASSES = {};
MessageFactory.CLASSES[Message.Type.VERSION] = VersionMessage;
MessageFactory.CLASSES[Message.Type.INV] = InvMessage;
MessageFactory.CLASSES[Message.Type.GET_DATA] = GetDataMessage;
MessageFactory.CLASSES[Message.Type.GET_HEADER] = GetHeaderMessage;
MessageFactory.CLASSES[Message.Type.NOT_FOUND] = NotFoundMessage;
MessageFactory.CLASSES[Message.Type.BLOCK] = BlockMessage;
MessageFactory.CLASSES[Message.Type.HEADER] = HeaderMessage;
MessageFactory.CLASSES[Message.Type.TX] = TxMessage;
MessageFactory.CLASSES[Message.Type.GET_BLOCKS] = GetBlocksMessage;
MessageFactory.CLASSES[Message.Type.MEMPOOL] = MempoolMessage;
MessageFactory.CLASSES[Message.Type.REJECT] = RejectMessage;
MessageFactory.CLASSES[Message.Type.SUBSCRIBE] = SubscribeMessage;
MessageFactory.CLASSES[Message.Type.ADDR] = AddrMessage;
MessageFactory.CLASSES[Message.Type.GET_ADDR] = GetAddrMessage;
MessageFactory.CLASSES[Message.Type.PING] = PingMessage;
MessageFactory.CLASSES[Message.Type.PONG] = PongMessage;
MessageFactory.CLASSES[Message.Type.SIGNAL] = SignalMessage;
MessageFactory.CLASSES[Message.Type.GET_CHAIN_PROOF] = GetChainProofMessage;
MessageFactory.CLASSES[Message.Type.CHAIN_PROOF] = ChainProofMessage;
MessageFactory.CLASSES[Message.Type.GET_ACCOUNTS_PROOF] = GetAccountsProofMessage;
MessageFactory.CLASSES[Message.Type.ACCOUNTS_PROOF] = AccountsProofMessage;
MessageFactory.CLASSES[Message.Type.GET_ACCOUNTS_TREE_CHUNK] = GetAccountsTreeChunkMessage;
MessageFactory.CLASSES[Message.Type.ACCOUNTS_TREE_CHUNK] = AccountsTreeChunkMessage;
MessageFactory.CLASSES[Message.Type.GET_TRANSACTIONS_PROOF_BY_ADDRESSES] = GetTransactionsProofByAddressesMessage;
MessageFactory.CLASSES[Message.Type.TRANSACTIONS_PROOF] = TransactionsProofMessage;
MessageFactory.CLASSES[Message.Type.GET_TRANSACTION_RECEIPTS_BY_ADDRESS] = GetTransactionReceiptsByAddressMessage;
MessageFactory.CLASSES[Message.Type.TRANSACTION_RECEIPTS] = TransactionReceiptsMessage;
MessageFactory.CLASSES[Message.Type.GET_BLOCK_PROOF] = GetBlockProofMessage;
MessageFactory.CLASSES[Message.Type.BLOCK_PROOF] = BlockProofMessage;
MessageFactory.CLASSES[Message.Type.GET_TRANSACTIONS_PROOF_BY_HASHES] = GetTransactionsProofByHashesMessage;
MessageFactory.CLASSES[Message.Type.GET_TRANSACTION_RECEIPTS_BY_HASHES] = GetTransactionReceiptsByHashesMessage;
MessageFactory.CLASSES[Message.Type.GET_BLOCK_PROOF_AT] = GetBlockProofAtMessage;
MessageFactory.CLASSES[Message.Type.GET_HEAD] = GetHeadMessage;
MessageFactory.CLASSES[Message.Type.HEAD] = HeadMessage;
MessageFactory.CLASSES[Message.Type.VERACK] = VerAckMessage;
Class.register(MessageFactory);

class WebRtcConnector extends Observable {
    /**
     * @constructor
     * @param {NetworkConfig} networkConfig
     */
    constructor(networkConfig) {
        super();

        /** @type {NetworkConfig} */
        this._networkConfig = networkConfig;

        /** @type {HashMap.<PeerId,PeerConnector>} */
        this._connectors = new HashMap();

        /** @type {Timers} */
        this._timers = new Timers();
    }

    /**
     * @param {PeerAddress} peerAddress
     * @param {PeerChannel} signalChannel
     * @returns {boolean}
     */
    connect(peerAddress, signalChannel) {
        if (peerAddress.protocol !== Protocol.RTC) throw new Error('Malformed peerAddress');

        const peerId = peerAddress.peerId;
        if (this._connectors.contains(peerId)) {
            return false;
        }

        // Check connector limit.
        if (this._connectors.length >= WebRtcConnector.CONNECTORS_MAX) {
            return false;
        }

        const connector = new OutboundPeerConnector(this._networkConfig, peerAddress, signalChannel);
        connector.on('connection', conn => this._onConnection(conn, peerId));
        this._connectors.put(peerId, connector);

        this._timers.setTimeout(`connect_${peerId}`, () => {
            this._connectors.remove(peerId);
            this._timers.clearTimeout(`connect_${peerId}`);

            connector.close();

            this.fire('error', peerAddress, 'timeout');
        }, WebRtcConnector.CONNECT_TIMEOUT);

        return true;
    }

    isValidSignal(msg) {
        return this._connectors.contains(msg.senderId) && this._connectors.get(msg.senderId).nonce === msg.nonce;
    }

    /**
     * @param {PeerChannel} channel
     * @param {SignalMessage} msg
     */
    onSignal(channel, msg) {
        // Check if we received an unroutable/ttl exceeded response from one of the signaling peers.
        if (msg.isUnroutable() || msg.isTtlExceeded()) {
            // Clear the timeout early if we initiated the connection.
            if (this.isValidSignal(msg) && this._connectors.get(msg.senderId) instanceof OutboundPeerConnector) {
                const connector = this._connectors.get(msg.senderId);
                const peerAddress = connector.peerAddress;

                this._connectors.remove(msg.senderId);
                this._timers.clearTimeout(`connect_${msg.senderId}`);

                connector.close();

                // XXX Reason needs to be adapted when more flags are added.
                const reason = msg.isUnroutable() ? 'unroutable' : 'ttl exceeded';
                this.fire('error', peerAddress, reason);
            }

            return;
        }

        let payload;
        try {
            payload = JSON.parse(BufferUtils.toAscii(msg.payload));
        } catch (e) {
            Log.e(WebRtcConnector, `Failed to parse signal payload from ${msg.senderId}`);
            return;
        }

        if (!payload) {
            Log.d(WebRtcConnector, `Discarding signal from ${msg.senderId} - empty payload`);
            return;
        }

        if (payload.type === 'offer') {
            // Check if we have received an offer on an ongoing connection.
            // This can happen if two peers initiate connections to one another
            // simultaneously. Resolve this by having the peer with the higher
            // peerId discard the offer while the one with the lower peerId
            // accepts it.
            /** @type {PeerConnector} */
            let connector = this._connectors.get(msg.senderId);
            if (connector) {
                if (msg.recipientId.compare(msg.senderId) > 0) {
                    // Discard the offer.
                    Log.d(WebRtcConnector, `Simultaneous connection, discarding offer from ${msg.senderId} (<${msg.recipientId})`);
                    return;
                } else if (connector instanceof InboundPeerConnector) {
                    // We have already seen an offer from this peer. Forward it to the existing connector.
                    Log.w(WebRtcConnector, `Duplicate offer received from ${msg.senderId}`);
                    connector.onSignal(payload);
                    return;
                } else {
                    // We are going to accept the offer. Clear the connect timeout
                    // from our previous outbound connection attempt to this peer.
                    Log.d(WebRtcConnector, `Simultaneous connection, accepting offer from ${msg.senderId} (>${msg.recipientId})`);
                    this._timers.clearTimeout(`connect_${msg.senderId}`);

                    // Abort the outbound connection attempt.
                    connector.close();

                    // Let listeners know that the connection attempt was aborted.
                    this.fire('error', connector.peerAddress, 'simultaneous inbound connection');
                }
            }

            // Check connector limit.
            if (this._connectors.length >= WebRtcConnector.CONNECTORS_MAX) {
                Log.d(WebRtcConnector, `Rejecting offer from ${msg.senderId} - max connectors exceeded`);
                return;
            }

            // Check inbound connector limit.
            if (this._connectors.length >= WebRtcConnector.INBOUND_CONNECTORS_MAX) {
                let numInboundConnectors = 0;
                for (const c of this._connectors.valueIterator()) {
                    if (c instanceof InboundPeerConnector) {
                        numInboundConnectors++;
                    }
                }
                if (numInboundConnectors >= WebRtcConnector.INBOUND_CONNECTORS_MAX) {
                    Log.d(WebRtcConnector, `Rejecting offer from ${msg.senderId} - max inbound connectors exceeded`);
                    return;
                }
            }

            // Accept the offer.
            connector = new InboundPeerConnector(this._networkConfig, channel, msg.senderId, payload);
            connector.on('connection', conn => this._onConnection(conn, msg.senderId));
            this._connectors.put(msg.senderId, connector);

            this._timers.setTimeout(`connect_${msg.senderId}`, () => {
                this._timers.clearTimeout(`connect_${msg.senderId}`);
                this._connectors.remove(msg.senderId);
                connector.close();
            }, WebRtcConnector.CONNECT_TIMEOUT);
        }

        // If we are already establishing a connection with the sender of this
        // signal, forward it to the corresponding connector.
        else if (this._connectors.contains(msg.senderId)) {
            this._connectors.get(msg.senderId).onSignal(payload);
        }

        // If none of the above conditions is met, the signal is invalid and we discard it.
    }

    _onConnection(conn, peerId) {
        // Clear the connect timeout.
        this._timers.clearTimeout(`connect_${peerId}`);

        // Clean up when this connection closes.
        conn.on('close', () => this._onClose(peerId));

        // Tell listeners about the new connection.
        this.fire('connection', conn);
    }

    _onClose(peerId) {
        this._connectors.remove(peerId);
        this._timers.clearTimeout(`connect_${peerId}`);
    }
}

WebRtcConnector.CONNECT_TIMEOUT = 8000; // ms
WebRtcConnector.CONNECTORS_MAX = 6;
WebRtcConnector.INBOUND_CONNECTORS_MAX = 3;
Class.register(WebRtcConnector);

class PeerConnector extends Observable {
    /**
     * @param {NetworkConfig} networkConfig
     * @param {PeerChannel} signalChannel
     * @param {PeerId} peerId
     * @param {PeerAddress} peerAddress
     */
    constructor(networkConfig, signalChannel, peerId, peerAddress) {
        super();
        /** @type {NetworkConfig} */
        this._networkConfig = networkConfig;
        /** @type {PeerChannel} */
        this._signalChannel = signalChannel;
        /** @type {PeerId} */
        this._peerId = peerId;
        /** @type {PeerAddress} */
        this._peerAddress = peerAddress; // null for inbound connections

        /** @type {number} */
        this._nonce = NumberUtils.randomUint32();

        /** @type {RTCPeerConnection} */
        this._rtcConnection = WebRtcFactory.newPeerConnection(this._networkConfig.rtcConfig);
        this._rtcConnection.onicecandidate = e => this._onIceCandidate(e);
        this._rtcConnection.onconnectionstatechange = e => this._onConnectionStateChange(e);
        this._rtcConnection.onicegatheringstatechange = e => this._onIceGatheringStateChange(e);

        this._lastIceCandidate = null;
        this._iceCandidateQueue = [];
        this._localIceCandidates = [];

        this._timers = new Timers();
    }

    /**
     * @param {*} signal
     */
    onSignal(signal) {
        if (!this._rtcConnection) return;
        if (signal.sdp) {
            this._rtcConnection.setRemoteDescription(WebRtcFactory.newSessionDescription(signal))
                .then(() => {
                    if (signal.type === 'offer') {
                        this._rtcConnection.createAnswer()
                            .then(description => this._onDescription(description))
                            .catch(Log.e.tag(PeerConnector));
                    }

                    this._handleCandidateQueue().catch(Log.w.tag(PeerConnector));
                })
                .catch(Log.e.tag(PeerConnector));
        } else if (signal.candidate) {
            // Parse other candidates if present and keep original order.
            if (signal.otherCandidates) {
                for (const iceCandidate of signal.otherCandidates) {
                    this._addIceCandidate(iceCandidate).catch(Log.w.tag(PeerConnector));
                }
            }
            this._addIceCandidate(signal).catch(Log.w.tag(PeerConnector));
        }
    }

    _onConnectionStateChange(e) {
        if (!this._rtcConnection) return;
        switch (this._rtcConnection.connectionState) {
            case 'failed':
            case 'disconnected':
            case 'closed':
                this.close();
        }
    }

    close() {
        if (!this._rtcConnection) return;

        this._rtcConnection.onicecandidate = null;
        this._rtcConnection.onconnectionstatechange = null;
        this._rtcConnection.onicegatheringstatechange = null;
        this._rtcConnection.close();

        this._rtcConnection = null;
        this._signalChannel = null;

        this._timers.clearAll();
        this._offAll();
    }

    /**
     * @param {*} signal
     * @returns {Promise}
     * @private
     */
    _addIceCandidate(signal) {
        if (!this._rtcConnection) return Promise.resolve();
        this._lastIceCandidate = WebRtcFactory.newIceCandidate(signal);

        // Do not try to add ICE candidates before the remote description is set.
        if (!this._rtcConnection.remoteDescription || !this._rtcConnection.remoteDescription.type) {
            this._iceCandidateQueue.push(signal);
            return Promise.resolve();
        }

        return this._rtcConnection.addIceCandidate(this._lastIceCandidate)
            .catch(Log.e.tag(PeerConnector));
    }

    async _handleCandidateQueue() {
        if (!this._rtcConnection) return;
        // Handle ICE candidates if they already arrived.
        for (const candidate of this._iceCandidateQueue) {
            await this._addIceCandidate(candidate);
        }
        this._iceCandidateQueue = [];
    }

    _signal(signal) {
        if (!this._rtcConnection) return;
        const payload = BufferUtils.fromAscii(JSON.stringify(signal));
        const keyPair = this._networkConfig.keyPair;
        const peerId = this._networkConfig.peerId;
        this._signalChannel.signal(
            peerId,
            this._peerId,
            this._nonce,
            Network.SIGNAL_TTL_INITIAL,
            0, /*flags*/
            payload,
            keyPair.publicKey,
            Signature.create(keyPair.privateKey, keyPair.publicKey, payload)
        );
    }

    _onIceCandidate(event) {
        if (!this._rtcConnection) return;
        if (event.candidate !== null) {
            this._localIceCandidates.push(event.candidate);
            if (!this._timers.timeoutExists('ice-gathering')) {
                this._timers.setTimeout('ice-gathering', this._sendIceCandidates.bind(this),
                    PeerConnector.ICE_GATHERING_TIMEOUT);
            }
        }
    }

    _onIceGatheringStateChange(event) {
        if (!this._rtcConnection) return;
        if (this._rtcConnection.iceGatheringState === 'complete') {
            this._sendIceCandidates();
        }
    }

    _sendIceCandidates() {
        this._timers.clearTimeout('ice-gathering');

        if (this._localIceCandidates.length > 0) {
            // Build backwards compatible structure:
            // We assume the last ice candidate to be the most promising one for old clients.
            let lastIceCandidate = this._localIceCandidates.pop();
            // Not all browsers support toJSON.
            lastIceCandidate = lastIceCandidate.toJSON ? lastIceCandidate.toJSON() : JSON.parse(JSON.stringify(lastIceCandidate));
            // Embed other candidates in this one ice candidate.
            lastIceCandidate.otherCandidates = this._localIceCandidates;

            // Send ice candidate.
            this._signal(lastIceCandidate);

            // Reset local candidates.
            this._localIceCandidates = [];
        }
    }

    _onDescription(description) {
        if (!this._rtcConnection) return;
        this._rtcConnection.setLocalDescription(description)
            .then(() => this._signal(this._rtcConnection.localDescription))
            .catch(Log.e.tag(PeerConnector));
    }

    _onDataChannel(event) {
        if (!this._rtcConnection) return;
        const channel = new WebRtcDataChannel(event.channel || event.target);

        // Make sure to close the corresponding RTCPeerConnection when the RTCDataChannel is closed
        channel.on('close', () => {
            if (!this._rtcConnection) return;
            this.close();
        });

        // There is no API to get the remote IP address. As a crude heuristic, we parse the IP address
        // from the last ICE candidate seen before the connection was established.
        let netAddress = null;
        if (this._lastIceCandidate) {
            try {
                netAddress = WebRtcUtils.candidateToNetAddress(this._lastIceCandidate);
            } catch (e) {
                Log.w(PeerConnector, `Failed to parse IP from ICE candidate: ${this._lastIceCandidate}`);
            }
        } else {
            Log.d(PeerConnector, 'No ICE candidate seen for RTC connection');
        }

        const conn = new NetworkConnection(channel, Protocol.RTC, netAddress, this._peerAddress);
        this.fire('connection', conn);
    }

    get nonce() {
        return this._nonce;
    }

    get peerAddress() {
        return this._peerAddress;
    }
}
PeerConnector.ICE_GATHERING_TIMEOUT = 1000;
PeerConnector.CONNECTION_OPEN_DELAY = 200;
Class.register(PeerConnector);

class OutboundPeerConnector extends PeerConnector {
    constructor(webRtcConfig, peerAddress, signalChannel) {
        super(webRtcConfig, signalChannel, peerAddress.peerId, peerAddress);
        this._peerAddress = peerAddress;

        // Create offer.
        this._channel = this._rtcConnection.createDataChannel('data-channel');
        this._channel.binaryType = 'arraybuffer';
        this._channel.onopen = e => this._onDataChannel(e);
        this._rtcConnection.createOffer()
            .then(description => this._onDescription(description))
            .catch(Log.e.tag(OutboundPeerConnector));
    }

    close() {
        super.close();
        if (!this._channel) return;
        this._channel.onopen = null;
        this._channel = null;
    }
}

Class.register(OutboundPeerConnector);

class InboundPeerConnector extends PeerConnector {
    constructor(webRtcConfig, signalChannel, peerId, offer) {
        super(webRtcConfig, signalChannel, peerId, null);
        this._rtcConnection.ondatachannel = event => {
            event.channel.onopen = e => this._onDataChannel(e);
        };
        this.onSignal(offer);
    }
}

Class.register(InboundPeerConnector);

class WebRtcDataChannel extends DataChannel {
    /**
     * @param {RTCDataChannel} nativeChannel
     */
    constructor(nativeChannel) {
        super();
        // We expect WebRtc data channels to be ordered.
        Assert.that(nativeChannel.ordered, 'WebRtc data channel not ordered');
        /** @type {RTCDataChannel} */
        this._channel = nativeChannel;

        this._channel.onmessage = msg => this._onMessage(msg.data || msg);
        this._channel.onclose = () => this.close();
        this._channel.onerror = e => this.fire('error', e, this);
    }

    /**
     * @param {ArrayBuffer} msg
     * @protected
     * @override
     */
    _onMessage(msg) {
        // FIXME It seems that Firefox still sometimes receives blobs instead of ArrayBuffers on RTC connections.
        // FIXME FileReader is async and may RE-ORDER MESSAGES!
        if (msg instanceof Blob) {
            const reader = new FileReader();
            reader.onloadend = () => super._onMessage(reader.result);
            reader.readAsArrayBuffer(msg);
        } else {
            super._onMessage(msg);
        }
    }
    /**
     * @override
     */
    sendChunk(msg) {
        if (!this._channel) throw new Error('Channel is dead');
        this._channel.send(msg);
    }

    /**
     * @override
     */
    _close() {
        this._channel.onmessage = null;
        this._channel.onclose = null;
        this._channel.onerror = null;

        this._channel.close();
        this._channel = null;
    }

    /**
     * @override
     */
    get readyState() {
        return DataChannel.ReadyState.fromString(this._channel.readyState);
    }
}

Class.register(WebRtcDataChannel);

class WebRtcUtils {
    /**
     * @param {RTCIceCandidate} candidate
     */
    static candidateToNetAddress(candidate) {
        // TODO XXX Ad-hoc parsing of candidates - Improve!
        const parts = candidate.candidate.split(' ');
        if (parts.length < 6) {
            return null;
        }
        // XXX The IP obtained from the ice candidate is not really reliable.
        // But for the time being, we treat it as such as it only affects browser clients,
        // which cannot obtain a more reliable form of net addresses.
        return NetAddress.fromIP(parts[4], true);
    }
}
Class.register(WebRtcUtils);

class WebSocketConnector extends Observable {
    /**
     * @constructor
     * @param {number} protocol
     * @param {string} protocolPrefix
     * @param {NetworkConfig} networkConfig
     * @listens WebSocketServer#connection
     */
    constructor(protocol, protocolPrefix, networkConfig) {
        super();
        this._protocol = protocol;
        this._protocolPrefix = protocolPrefix;
        this._networkConfig = networkConfig;

        if (networkConfig.peerAddress.protocol === this._protocol) {
            this._wss = WebSocketFactory.newWebSocketServer(networkConfig);
            this._wss.on('connection', (ws, req) => this._onConnection(ws, req));

            Log.d(WebSocketConnector, `${this._protocolPrefix.toUpperCase()}-Connector listening on port ${networkConfig.peerAddress.port}`);
        }

        /** @type {HashMap.<PeerAddress, WebSocket>} */
        this._sockets = new HashMap();

        /** @type {Timers} */
        this._timers = new Timers();
    }

    /**
     * @fires WebSocketConnector#connection
     * @fires WebSocketConnector#error
     * @param {PeerAddress} peerAddress
     * @returns {boolean}
     */
    connect(peerAddress) {
        if (peerAddress.protocol !== this._protocol) throw new Error('Malformed peerAddress');

        const timeoutKey = `connect_${peerAddress}`;
        if (this._timers.timeoutExists(timeoutKey)) {
            Log.w(WebSocketConnector, `Already connecting to ${peerAddress}`);
            return false;
        }

        const ws = WebSocketFactory.newWebSocket(`${this._protocolPrefix}://${peerAddress.host}:${peerAddress.port}`, {
            handshakeTimeout: WebSocketConnector.CONNECT_TIMEOUT
        }, this._networkConfig);
        ws.binaryType = 'arraybuffer';
        ws.onopen = () => {
            this._timers.clearTimeout(timeoutKey);
            this._sockets.remove(peerAddress);

            // Don't fire error events after the connection has been established.
            ws.onerror = () => {};

            // There is no way to determine the remote IP in the browser ... thanks for nothing, WebSocket API.
            const netAddress = (ws._socket && ws._socket.remoteAddress) ? NetAddress.fromIP(ws._socket.remoteAddress, true) : null;
            const conn = new NetworkConnection(new WebSocketDataChannel(ws), this._protocol, netAddress, peerAddress);
            this.fire('connection', conn);
        };
        ws.onerror = e => {
            this._timers.clearTimeout(timeoutKey);
            this._sockets.remove(peerAddress);

            /**
             * Tell listeners that an error has ocurred.
             * @event WebSocketConnector#error
             */
            this.fire('error', peerAddress, e);
        };

        this._sockets.put(peerAddress, ws);

        this._timers.setTimeout(timeoutKey, () => {
            this._timers.clearTimeout(timeoutKey);
            this._sockets.remove(peerAddress);

            // We don't want to fire the error event again if the websocket
            // connect fails at a later time.
            ws.onerror = () => {};

            // If the connection succeeds after we have fired the error event,
            // close it.
            ws.onopen = () => {
                Log.d(WebSocketConnector, () => `Connection to ${peerAddress} succeeded after timeout - closing it`);
                ws.close();
            };

            /**
             * Tell listeners that a timeout error has occurred.
             * @event WebSocketConnector#error
             */
            this.fire('error', peerAddress, 'timeout');
        }, WebSocketConnector.CONNECT_TIMEOUT);

        return true;
    }

    /**
     * @param {PeerAddress} peerAddress
     * @fires WebSocketConnector#error
     * @returns {void}
     */
    abort(peerAddress) {
        const ws = this._sockets.get(peerAddress);
        if (!ws) {
            return;
        }

        this._timers.clearTimeout(`connect_${peerAddress}`);
        this._sockets.remove(peerAddress);

        ws.onerror = () => {};
        ws.onopen = () => {
            Log.d(WebSocketConnector, () => `Connection to ${peerAddress} succeeded after aborting - closing it`);
            ws.close();
        };
        ws.close();

        /**
         * Tell listeners that the connection attempt has been aborted.
         * @event WebSocketConnector#error
         */
        this.fire('error', peerAddress, 'aborted');
    }

    /**
     * @fires WebSocketConnector#connection
     * @param {WebSocket} ws
     * @param {http.IncomingMessage} req
     * @returns {void}
     */
    _onConnection(ws, req) {
        let remoteAddress = req.connection.remoteAddress;
        if (!remoteAddress) {
            Log.e(WebSocketConnector, 'Expected req.connection.remoteAddress to be set and it is not: closing the connection');
            ws.close();
            return;
        }

        // If we're behind a reverse proxy, the peer's IP will be in the header set by the reverse proxy, not in the req.connection object
        if (this._networkConfig.reverseProxy.enabled) {
            const reverseProxyAddresses = this._networkConfig.reverseProxy.addresses;
            if (reverseProxyAddresses.includes(remoteAddress)) {
                const reverseProxyHeader = this._networkConfig.reverseProxy.header;
                if (req.headers[reverseProxyHeader]) {
                    remoteAddress = req.headers[reverseProxyHeader].split(/\s*,\s*/)[0];
                } else {
                    Log.e(WebSocketConnector, `Expected header '${reverseProxyHeader}' to contain the real IP from the connecting client: closing the connection`);
                    ws.close();
                    return;
                }
            } else {
                Log.e(WebSocketConnector, `Received connection from ${remoteAddress} when all connections were expected from the reverse proxy at ${reverseProxyAddresses}: closing the connection`);
                ws.close();
                return;
            }
        }

        try {
            const netAddress = NetAddress.fromIP(remoteAddress, true);
            const conn = new NetworkConnection(new WebSocketDataChannel(ws), this._protocol, netAddress, /*peerAddress*/ null);

            /**
             * Tell listeners that an initial connection to a peer has been established.
             * @event WebSocketConnector#connection
             */
            this.fire('connection', conn);
        } catch (e) {
            Log.e(WebSocketConnector, `Error on connection from ${remoteAddress}: ${e.message || e}`);
            ws.close();
        }
    }
}
WebSocketConnector.CONNECT_TIMEOUT = 1000 * 5; // 5 seconds
Class.register(WebSocketConnector);

class WebSocketDataChannel extends DataChannel {
    /**
     * @param {WebSocket} ws
     */
    constructor(ws) {
        super();
        /** @type {WebSocket} */
        this._ws = ws;
        this._ws.onmessage = msg => this._onMessage(msg.data || msg);
        this._ws.onclose = () => this.close();
        this._ws.onerror = e => this.fire('error', e);
    }

    /**
     * @override
     */
    _close() {
        this._ws.onmessage = null;
        this._ws.onclose = null;
        this._ws.onerror = null;

        this._ws.close();
        this._ws = null;
    }

    /**
     * @override
     * @param {Uint8Array} msg
     */
    sendChunk(msg) {
        this._ws.send(msg);
    }

    /**
     * @override
     * @type {DataChannel.ReadyState}
     */
    get readyState() {
        return /** @type {DataChannel.ReadyState} */ this._ws.readyState;
    }
}

Class.register(WebSocketDataChannel);

class NetAddress {
    /**
     * @param {string} ip
     * @param {boolean} reliable
     * @return {NetAddress}
     */
    static fromIP(ip, reliable = false) {
        const saneIp = NetUtils.ipToBytes(ip);
        const type = NetUtils.isIPv4Address(saneIp) ? NetAddress.Type.IPv4 : NetAddress.Type.IPv6;
        return new NetAddress(type, saneIp, reliable);
    }

    /**
     * @param {NetAddress.Type} type
     * @param {Uint8Array} ipArray
     * @param {boolean} reliable
     */
    constructor(type, ipArray = null, reliable = false) {
        switch (type) {
            case NetAddress.Type.IPv4:
                if (!(ipArray instanceof Uint8Array) || ipArray.length !== NetUtils.IPv4_LENGTH) throw new Error('Malformed ip');
                break;
            case NetAddress.Type.IPv6:
                if (!(ipArray instanceof Uint8Array) || ipArray.length !== NetUtils.IPv6_LENGTH) throw new Error('Malformed ip');
                break;
            case NetAddress.Type.UNKNOWN:
            case NetAddress.Type.UNSPECIFIED:
                ipArray = null;
                break;
            default:
                throw new Error('Malformed type');
        }

        /** @type {NetAddress.Type} */
        this._type = type;
        /** @type {Uint8Array} */
        this._ip = ipArray;
        /** @type {boolean} */
        this._reliable = reliable;
    }

    /**
     * @param {SerialBuffer} buf
     * @return {NetAddress}
     */
    static unserialize(buf) {
        const type = /** @type {NetAddress.Type} */ buf.readUint8();

        let ipArray = null;
        switch (type) {
            case NetAddress.Type.IPv4:
                ipArray = buf.read(NetUtils.IPv4_LENGTH);
                break;
            case NetAddress.Type.IPv6:
                ipArray = buf.read(NetUtils.IPv6_LENGTH);
                break;
        }

        return new NetAddress(type, ipArray);
    }

    /**
     * @param {?SerialBuffer} [buf]
     * @return {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._type);
        if (this._ip) {
            buf.write(this._ip);
        }
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*type*/ 1
            + (this._ip ? this._ip.length : 0);
    }

    /**
     * @param {NetAddress} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof NetAddress
            && this._type === o._type
            && BufferUtils.equals(this._ip, o.ip);
    }

    hashCode() {
        return this.toString();
    }

    /**
     * @return {string}
     */
    toString() {
        if (this._type === NetAddress.Type.UNKNOWN) return '<unknown>';
        if (this._type === NetAddress.Type.UNSPECIFIED) return '';
        return NetUtils.bytesToIp(this._ip);
    }

    /** @type {Uint8Array} */
    get ip() {
        return this._ip;
    }

    /** @type {NetAddress.Type} */
    get type() {
        return this._type;
    }

    /** @type {boolean} */
    get reliable() {
        return this._reliable;
    }

    /**
     * @return {boolean}
     */
    isPseudo() {
        return !this._ip;
    }

    /**
     * @return {boolean}
     */
    isPrivate() {
        return this.isPseudo() || NetUtils.isPrivateIP(this._ip);
    }

    /**
     * @return {boolean}
     */
    isIPv6() {
        return this._ip && NetUtils.isIPv6Address(this._ip);
    }

    /**
     * @return {boolean}
     */
    isIPv4() {
        return this._ip && NetUtils.isIPv4Address(this._ip);
    }

    /**
     * @param {number} bitCount
     * @return {NetAddress}
     */
    subnet(bitCount) {
        const ip = this._ip ? NetUtils.ipToSubnet(this._ip, bitCount) : null;
        return new NetAddress(this._type, ip, this._reliable);
    }
}
/** @enum {number} */
NetAddress.Type = {
    IPv4: 0,
    IPv6: 1,
    UNSPECIFIED: 2,
    UNKNOWN: 3
};
NetAddress.UNSPECIFIED = new NetAddress(NetAddress.Type.UNSPECIFIED);
NetAddress.UNKNOWN = new NetAddress(NetAddress.Type.UNKNOWN);
Class.register(NetAddress);

class PeerId extends Serializable {
    /**
     * @param {PeerId} o
     * @returns {PeerId}
     */
    static copy(o) {
        if (!o) return o;
        const obj = new Uint8Array(o._obj);
        return new PeerId(obj);
    }

    constructor(arg) {
        super();
        if (!(arg instanceof Uint8Array)) throw new Error('Primitive: Invalid type');
        if (arg.length !== PeerId.SERIALIZED_SIZE) throw new Error('Primitive: Invalid length');
        this._obj = arg;
    }

    /**
     * Create Address object from binary form.
     * @param {SerialBuffer} buf Buffer to read from.
     * @return {PeerId} Newly created Account object.
     */
    static unserialize(buf) {
        return new PeerId(buf.read(PeerId.SERIALIZED_SIZE));
    }

    /**
     * Serialize this Address object into binary form.
     * @param {?SerialBuffer} [buf] Buffer to write to.
     * @return {SerialBuffer} Buffer from `buf` or newly generated one.
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        buf.write(this._obj);
        return buf;
    }

    subarray(begin, end) {
        return this._obj.subarray(begin, end);
    }

    /**
     * @type {number}
     */
    get serializedSize() {
        return PeerId.SERIALIZED_SIZE;
    }

    /**
     * @param {Serializable} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof PeerId
            && super.equals(o);
    }

    /**
     * @returns {string}
     * @override
     */
    toString() {
        return this.toHex();
    }

    /**
     * @param {string} base64
     * @return {PeerId}
     */
    static fromBase64(base64) {
        return new PeerId(BufferUtils.fromBase64(base64));
    }

    /**
     * @param {string} hex
     * @return {PeerId}
     */
    static fromHex(hex) {
        return new PeerId(BufferUtils.fromHex(hex));
    }
}

PeerId.SERIALIZED_SIZE = 16;
Class.register(PeerId);

class PeerAddress {
    /**
     * @param {number} protocol
     * @param {number} services
     * @param {number} timestamp
     * @param {NetAddress} netAddress
     * @param {PublicKey} publicKey
     * @param {number} distance
     * @param {Signature} [signature]
     */
    constructor(protocol, services, timestamp, netAddress, publicKey, distance, signature) {
        if (!NumberUtils.isUint8(distance)) throw new Error('Malformed distance');
        if (publicKey !== null && !(publicKey instanceof PublicKey)) throw new Error('Malformed publicKey');

        /** @type {number} */
        this._protocol = protocol;
        /** @type {number} */
        this._services = services;
        /** @type {number} */
        this._timestamp = timestamp;
        /** @type {NetAddress} */
        this._netAddress = netAddress || NetAddress.UNSPECIFIED;
        /** @type {PublicKey} */
        this._publicKey = publicKey;
        /** @type {number} */
        this._distance = distance;
        /** @type {?Signature} */
        this._signature = signature;
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {PeerAddress}
     */
    static unserialize(buf) {
        const protocol = buf.readUint8();
        switch (protocol) {
            case Protocol.WSS:
                return WssPeerAddress.unserialize(buf);

            case Protocol.RTC:
                return RtcPeerAddress.unserialize(buf);

            case Protocol.WS:
                return WsPeerAddress.unserialize(buf);

            case Protocol.DUMB:
                return DumbPeerAddress.unserialize(buf);

            default:
                throw `Malformed PeerAddress protocol ${protocol}`;
        }
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        if (!this._publicKey) throw new Error('PeerAddress without publicKey may not be serialized.');
        if (!this._signature) throw new Error('PeerAddress without signature may not be serialized.');

        buf = buf || new SerialBuffer(this.serializedSize);
        buf.writeUint8(this._protocol);
        buf.writeUint32(this._services);
        buf.writeUint64(this._timestamp);

        // Never serialize private netAddresses.
        if (this._netAddress.isPrivate()) {
            NetAddress.UNSPECIFIED.serialize(buf);
        } else {
            this._netAddress.serialize(buf);
        }

        this._publicKey.serialize(buf);
        buf.writeUint8(this._distance);
        this._signature.serialize(buf);

        return buf;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serializeContent(buf) {
        buf = buf || new SerialBuffer(this.serializedContentSize);

        buf.writeUint8(this._protocol);
        buf.writeUint32(this._services);
        buf.writeUint64(this._timestamp);

        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return /*protocol*/ 1
            + /*services*/ 4
            + /*timestamp*/ 8
            + this._netAddress.serializedSize
            + this._publicKey.serializedSize
            + /*distance*/ 1
            + this._signature.serializedSize;
    }

    /** @type {number} */
    get serializedContentSize() {
        return /*protocol*/ 1
            + /*services*/ 4
            + /*timestamp*/ 8;
    }

    /**
     * @param {PeerAddress|*} o
     * @returns {boolean}
     */
    equals(o) {
        // We consider peer addresses to be equal if the public key or peer id is not known on one of them:
        // Peers from the network always contain a peer id and public key, peers without peer id or public key
        // are always set by the user.
        return o instanceof PeerAddress
            && this.protocol === o.protocol
            && (!this.publicKey || !o.publicKey || this.publicKey.equals(o.publicKey))
            && (!this.peerId || !o.peerId || this.peerId.equals(o.peerId))
            /* services is ignored */
            /* timestamp is ignored */
            /* netAddress is ignored */
            /* distance is ignored */;
    }

    /**
     * @returns {string}
     */
    hashCode() {
        throw new Error('unimplemented');
    }

    /**
     * @returns {boolean}
     */
    verifySignature() {
        if (this._signatureVerified === undefined) {
            this._signatureVerified = this.signature.verify(this.publicKey, this.serializeContent());
        }
        return this._signatureVerified;
    }

    /** @type {number} */
    get protocol() {
        return this._protocol;
    }

    /** @type {number} */
    get services() {
        return this._services;
    }

    /** @type {number} */
    get timestamp() {
        return this._timestamp;
    }

    /** @type {NetAddress} */
    get netAddress() {
        return this._netAddress.isPseudo() ? null : this._netAddress;
    }

    /** @type {NetAddress} */
    set netAddress(value) {
        this._netAddress = value || NetAddress.UNSPECIFIED;
    }

    /** @type {PublicKey} */
    get publicKey() {
        return this._publicKey;
    }

    /** @type {PeerId} */
    get peerId() {
        return this._publicKey ? this._publicKey.toPeerId() : null;
    }

    /** @type {number} */
    get distance() {
        return this._distance;
    }

    /** @type {Signature} */
    get signature() {
        return this._signature;
    }

    /** @type {Signature} */
    set signature(signature) {
        // Never change the signature of a remote address.
        if (this._distance !== 0) {
            return;
        }

        this._signature = signature;
        this._signatureVerified = undefined;
    }

    // Changed when passed on to other peers.
    /** @type {number} */
    set distance(value) {
        this._distance = value;
    }

    /**
     * @returns {boolean}
     */
    isSeed() {
        return this._timestamp === 0;
    }

    /**
     * @returns {boolean}
     */
    exceedsAge() {
        // Seed addresses are never too old.
        if (this.isSeed()) {
            return false;
        }

        const age = Date.now() - this.timestamp;
        switch (this.protocol) {
            case Protocol.WSS:
                return age > PeerAddressBook.MAX_AGE_WEBSOCKET;

            case Protocol.RTC:
                return age > PeerAddressBook.MAX_AGE_WEBRTC;

            case Protocol.WS:
                return age > PeerAddressBook.MAX_AGE_WEBSOCKET;

            case Protocol.DUMB:
                return age > PeerAddressBook.MAX_AGE_DUMB;
        }
        return false;
    }
}
Class.register(PeerAddress);

class WsBasePeerAddress extends PeerAddress {
    /**
     * @param {number} protocol
     * @param {number} services
     * @param {number} timestamp
     * @param {NetAddress} netAddress
     * @param {PublicKey} publicKey
     * @param {number} distance
     * @param {string} host
     * @param {number} port
     * @param {Signature} [signature]
     */
    constructor(protocol, services, timestamp, netAddress, publicKey, distance, host, port, signature) {
        if (protocol !== Protocol.WS && protocol !== Protocol.WSS) throw new Error('Malformed protocol');
        super(protocol, services, timestamp, netAddress, publicKey, distance, signature);
        if (!host) throw new Error('Malformed host');
        if (!NumberUtils.isUint16(port)) throw new Error('Malformed port');
        this._host = host;
        this._port = port;
    }

    /**
     * @param {string} str
     * @returns {WsPeerAddress|WssPeerAddress}
     */
    static fromSeedString(str) {
        const matches = /^(wss?:)\/\/([^:/?#]+):([0-9]{1,5})\/?([a-f0-9]*)$/i.exec(str);
        if (!matches) throw new Error(`Malformed PeerAddress ${str}`);

        try {
            const [_, protocol, host, port, publicKeyHex] = matches;
            const addressType = protocol === 'ws:' ? WsPeerAddress : WssPeerAddress;
            return addressType.seed(host, parseInt(port), publicKeyHex);
        } catch (e) {
            throw new Error(`Malformed PeerAddress ${str}`);
        }
    }

    /**
     * @returns {string}
     */
    toSeedString() {
        return `${this.protocolPrefix}://${this._host}:${this._port}/${this.publicKey ? this.publicKey.toHex() : ''}`;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        buf.writeVarLengthString(this._host);
        buf.writeUint16(this._port);
        return buf;
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serializeContent(buf) {
        buf = buf || new SerialBuffer(this.serializedContentSize);
        super.serializeContent(buf);
        buf.writeVarLengthString(this._host);
        buf.writeUint16(this._port);
        return buf;
    }

    /**
     * @returns {boolean}
     */
    globallyReachable() {
        return NetUtils.hostGloballyReachable(this.host);
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize
            + SerialBuffer.varLengthStringSize(this._host)
            + /*port*/ 2;
    }

    /** @type {number} */
    get serializedContentSize() {
        return super.serializedContentSize
            + SerialBuffer.varLengthStringSize(this._host)
            + /*port*/ 2;
    }

    /**
     * @override
     * @param {PeerAddress|*} o
     * @returns {boolean}
     */
    equals(o) {
        return super.equals(o)
            && ((!!this.peerId && !!o.peerId) || (this._host === o.host && this._port === o.port));
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this.peerId
            ? `${this.protocolPrefix}:///${this.peerId}`
            : `${this.protocolPrefix}://${this._host}:${this._port}/`;
    }

    /**
     * @returns {string}
     */
    toString() {
        return `${this.protocolPrefix}://${this._host}:${this._port}/${this.peerId ? this.peerId : ''}`;
    }

    /** @type {string} */
    get host() {
        return this._host;
    }

    /** @type {number} */
    get port() {
        return this._port;
    }

    /** @type {string} */
    get protocolPrefix() {
        return this.protocol === Protocol.WS ? 'ws' : 'wss';
    }
}
Class.register(WsBasePeerAddress);

class WssPeerAddress extends WsBasePeerAddress {
    /**
     * @param {string} host
     * @param {number} port
     * @param {string} [publicKeyHex]
     * @returns {WssPeerAddress}
     */
    static seed(host, port, publicKeyHex) {
        const publicKey = publicKeyHex ? new PublicKey(BufferUtils.fromHex(publicKeyHex)) : null;
        return new WssPeerAddress(Services.PROVIDES_FULL, /*timestamp*/ 0, NetAddress.UNSPECIFIED, publicKey, 0, host, port);
    }

    /**
     * @param {number} services
     * @param {number} timestamp
     * @param {NetAddress} netAddress
     * @param {PublicKey} publicKey
     * @param {number} distance
     * @param {string} host
     * @param {number} port
     * @param {Signature} [signature]
     */
    constructor(services, timestamp, netAddress, publicKey, distance, host, port, signature) {
        super(Protocol.WSS, services, timestamp, netAddress, publicKey, distance, host, port, signature);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {WssPeerAddress}
     */
    static unserialize(buf) {
        const services = buf.readUint32();
        const timestamp = buf.readUint64();
        const netAddress = NetAddress.unserialize(buf);
        const publicKey = PublicKey.unserialize(buf);
        const distance = buf.readUint8();
        const signature = Signature.unserialize(buf);
        const host = buf.readVarLengthString();
        const port = buf.readUint16();
        return new WssPeerAddress(services, timestamp, netAddress, publicKey, distance, host, port, signature);
    }

    /**
     * @override
     * @param {PeerAddress|*} o
     * @returns {boolean}
     */
    equals(o) {
        return super.equals(o)
            && o instanceof WssPeerAddress;
    }

    /**
     * @returns {WssPeerAddress}
     */
    withoutId() {
        return new WssPeerAddress(this.services, this.timestamp, this.netAddress, null, this.distance, this.host, this.port);
    }
}
Class.register(WssPeerAddress);

class WsPeerAddress extends WsBasePeerAddress {
    /**
     * @param {string} host
     * @param {number} port
     * @param {string} [publicKeyHex]
     * @returns {WsPeerAddress}
     */
    static seed(host, port, publicKeyHex) {
        const publicKey = publicKeyHex ? new PublicKey(BufferUtils.fromHex(publicKeyHex)) : null;
        return new WsPeerAddress(Services.PROVIDES_FULL, /*timestamp*/ 0, NetAddress.UNSPECIFIED, publicKey, 0, host, port);
    }

    /**
     * @param {number} services
     * @param {number} timestamp
     * @param {NetAddress} netAddress
     * @param {PublicKey} publicKey
     * @param {number} distance
     * @param {string} host
     * @param {number} port
     * @param {Signature} [signature]
     */
    constructor(services, timestamp, netAddress, publicKey, distance, host, port, signature) {
        super(Protocol.WS, services, timestamp, netAddress, publicKey, distance, host, port, signature);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {WsPeerAddress}
     */
    static unserialize(buf) {
        const services = buf.readUint32();
        const timestamp = buf.readUint64();
        const netAddress = NetAddress.unserialize(buf);
        const publicKey = PublicKey.unserialize(buf);
        const distance = buf.readUint8();
        const signature = Signature.unserialize(buf);
        const host = buf.readVarLengthString();
        const port = buf.readUint16();
        return new WsPeerAddress(services, timestamp, netAddress, publicKey, distance, host, port, signature);
    }

    /**
     * @returns {boolean}
     */
    globallyReachable() {
        return ((NetUtils.isIPv4Address(this.host) || NetUtils.isIPv6Address(this.host)) && !NetUtils.isPrivateIP(this.host)) || NetUtils.hostGloballyReachable(this.host);
    }

    /**
     * @override
     * @param {PeerAddress|*} o
     * @returns {boolean}
     */
    equals(o) {
        return super.equals(o)
            && o instanceof WsPeerAddress;
    }

    /**
     * @returns {WsPeerAddress}
     */
    withoutId() {
        return new WsPeerAddress(this.services, this.timestamp, this.netAddress, null, this.distance, this.host, this.port);
    }
}
Class.register(WsPeerAddress);

class RtcPeerAddress extends PeerAddress {
    /**
     * @param {number} services
     * @param {number} timestamp
     * @param {NetAddress} netAddress
     * @param {PublicKey} publicKey
     * @param {number} distance
     * @param {Signature} [signature]
     */
    constructor(services, timestamp, netAddress, publicKey, distance, signature) {
        super(Protocol.RTC, services, timestamp, netAddress, publicKey, distance, signature);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {RtcPeerAddress}
     */
    static unserialize(buf) {
        const services = buf.readUint32();
        const timestamp = buf.readUint64();
        const netAddress = NetAddress.unserialize(buf);
        const publicKey = PublicKey.unserialize(buf);
        const distance = buf.readUint8();
        const signature = Signature.unserialize(buf);
        return new RtcPeerAddress(services, timestamp, netAddress, publicKey, distance, signature);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize;
    }

    /**
     * @override
     * @param {PeerAddress|*} o
     * @returns {boolean}
     */
    equals(o) {
        return super.equals(o)
            && o instanceof RtcPeerAddress;
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this.toString();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `rtc:///${this.peerId}`;
    }
}
Class.register(RtcPeerAddress);

class DumbPeerAddress extends PeerAddress {
    /**
     * @param {number} services
     * @param {number} timestamp
     * @param {NetAddress} netAddress
     * @param {PublicKey} publicKey
     * @param {number} distance
     * @param {Signature} [signature]
     */
    constructor(services, timestamp, netAddress, publicKey, distance, signature) {
        super(Protocol.DUMB, services, timestamp, netAddress, publicKey, distance, signature);
    }

    /**
     * @param {SerialBuffer} buf
     * @returns {DumbPeerAddress}
     */
    static unserialize(buf) {
        const services = buf.readUint32();
        const timestamp = buf.readUint64();
        const netAddress = NetAddress.unserialize(buf);
        const publicKey = PublicKey.unserialize(buf);
        const distance = buf.readUint8();
        const signature = Signature.unserialize(buf);
        return new DumbPeerAddress(services, timestamp, netAddress, publicKey, distance, signature);
    }

    /**
     * @param {SerialBuffer} [buf]
     * @returns {SerialBuffer}
     */
    serialize(buf) {
        buf = buf || new SerialBuffer(this.serializedSize);
        super.serialize(buf);
        return buf;
    }

    /** @type {number} */
    get serializedSize() {
        return super.serializedSize;
    }

    /**
     * @override
     * @param {PeerAddress} o
     * @returns {boolean}
     */
    equals(o) {
        return super.equals(o)
            && o instanceof DumbPeerAddress;
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this.toString();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `dumb:///${this.peerId}`;
    }
}
Class.register(DumbPeerAddress);

class PeerAddressState {
    /**
     * @param {PeerAddress} peerAddress
     */
    constructor(peerAddress) {
        /** @type {PeerAddress} */
        this.peerAddress = peerAddress;

        /** @type {number} */
        this.state = PeerAddressState.NEW;
        /** @type {number} */
        this.lastConnected = -1;
        /** @type {number} */
        this.bannedUntil = -1;
        /** @type {number} */
        this.banBackoff = PeerAddressBook.INITIAL_FAILED_BACKOFF;

        /** @type {SignalRouter} */
        this._signalRouter = new SignalRouter(peerAddress);

        /** @type {number} */
        this._failedAttempts = 0;

        /**
         * Map from closeType to number of occurrences
         * @type {Map.<number,number>}
         * @private
         */
        this._closeTypes = new Map();

        /**
         * @type {HashSet.<NetAddress>}
         * @private
         */
        this._addedBy = new HashSet();
    }

    /** @type {SignalRouter} */
    get signalRouter() {
        return this._signalRouter;
    }

    /** @type {number} */
    get maxFailedAttempts() {
        switch (this.peerAddress.protocol) {
            case Protocol.RTC:
                return PeerAddressBook.MAX_FAILED_ATTEMPTS_RTC;
            case Protocol.WS:
            case Protocol.WSS:
                return PeerAddressBook.MAX_FAILED_ATTEMPTS_WS;
            default:
                return 0;
        }
    }

    /** @type {number} */
    get failedAttempts() {
        if (this._signalRouter.bestRoute) {
            return this._signalRouter.bestRoute.failedAttempts;
        } else {
            return this._failedAttempts;
        }
    }

    /** @type {number} */
    set failedAttempts(value) {
        if (this._signalRouter.bestRoute) {
            this._signalRouter.bestRoute.failedAttempts = value;
            this._signalRouter.updateBestRoute(); // scores may have changed
        } else {
            this._failedAttempts = value;
        }
    }

    /**
     * @param {number} type
     */
    close(type) {
        if (!type) return;

        if (this._closeTypes.has(type)) {
            this._closeTypes.set(type, this._closeTypes.get(type) + 1);
        } else {
            this._closeTypes.set(type, 1);
        }

        if (this.state === PeerAddressState.BANNED) {
            return;
        }

        if (CloseType.isBanningType(type)) {
            this.state = PeerAddressState.BANNED;
        } else if (CloseType.isFailingType(type)) {
            this.state = PeerAddressState.FAILED;
        } else {
            this.state = PeerAddressState.TRIED;
        }
    }

    /**
     * @param {PeerAddressState|*} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof PeerAddressState
            && this.peerAddress.equals(o.peerAddress);
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this.peerAddress.hashCode();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `PeerAddressState{peerAddress=${this.peerAddress}, state=${this.state}, `
            + `lastConnected=${this.lastConnected}, failedAttempts=${this.failedAttempts}, `
            + `bannedUntil=${this.bannedUntil}}`;
    }

    /** @type {HashSet.<NetAddress>} */
    get addedBy() {
        return this._addedBy;
    }
}
PeerAddressState.NEW = 1;
PeerAddressState.ESTABLISHED = 2;
PeerAddressState.TRIED = 3;
PeerAddressState.FAILED = 4;
PeerAddressState.BANNED = 5;
Class.register(PeerAddressState);

class SignalRouter {
    /**
     * @constructor
     * @param {PeerAddress} peerAddress
     */
    constructor(peerAddress) {
        /** @type {PeerAddress} */
        this.peerAddress = peerAddress;

        /** @type {SignalRoute} */
        this._bestRoute = null;
        /** @type {HashSet.<SignalRoute>} */
        this._routes = new HashSet();
    }

    /** @type {SignalRoute} */
    get bestRoute() {
        return this._bestRoute;
    }

    /**
     * @param {PeerChannel} signalChannel
     * @param {number} distance
     * @param {number} timestamp
     * @returns {boolean} whether we have a new best route
     */
    addRoute(signalChannel, distance, timestamp) {
        const oldRoute = this._routes.get(signalChannel);
        const newRoute = new SignalRoute(signalChannel, distance, timestamp);

        if (oldRoute) {
            // Do not reset failed attempts.
            newRoute.failedAttempts = oldRoute.failedAttempts;
        }
        this._routes.add(newRoute);

        if (!this._bestRoute || newRoute.score > this._bestRoute.score
            || (newRoute.score === this._bestRoute.score && timestamp > this._bestRoute.timestamp)) {

            this._bestRoute = newRoute;
            this.peerAddress.distance = this._bestRoute.distance;
            return true;
        }
        return false;
    }

    /**
     * @returns {void}
     */
    deleteBestRoute() {
        if (this._bestRoute) {
            this.deleteRoute(this._bestRoute.signalChannel);
        }
    }

    /**
     * @param {PeerChannel} signalChannel
     * @returns {void}
     */
    deleteRoute(signalChannel) {
        this._routes.remove(signalChannel); // maps to same hashCode
        if (this._bestRoute && this._bestRoute.signalChannel.equals(signalChannel)) {
            this.updateBestRoute();
        }
    }

    /**
     * @returns {void}
     */
    deleteAllRoutes() {
        this._bestRoute = null;
        this._routes = new HashSet();
    }

    /**
     * @returns {boolean}
     */
    hasRoute() {
        return this._routes.length > 0;
    }

    /**
     * @returns {void}
     * @private
     */
    updateBestRoute() {
        let bestRoute = null;
        // Choose the route with minimal distance and maximal timestamp.
        for (const route of this._routes.valueIterator()) {
            if (bestRoute === null || route.score > bestRoute.score
                || (route.score === bestRoute.score && route.timestamp > bestRoute.timestamp)) {

                bestRoute = route;
            }
        }
        this._bestRoute = bestRoute;
        if (this._bestRoute) {
            this.peerAddress.distance = this._bestRoute.distance;
        } else {
            this.peerAddress.distance = PeerAddressBook.MAX_DISTANCE + 1;
        }
    }

    /**
     * @param {PeerAddressState|*} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof PeerAddressState
            && this.peerAddress.equals(o.peerAddress);
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this.peerAddress.hashCode();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `PeerAddressState{peerAddress=${this.peerAddress}, state=${this.state}, `
            + `lastConnected=${this.lastConnected}, failedAttempts=${this.failedAttempts}, `
            + `bannedUntil=${this.bannedUntil}}`;
    }
}
Class.register(SignalRouter);

class SignalRoute {
    /**
     * @param {PeerChannel} signalChannel
     * @param {number} distance
     * @param {number} timestamp
     */
    constructor(signalChannel, distance, timestamp) {
        this.failedAttempts = 0;
        this.timestamp = timestamp;
        this._signalChannel = signalChannel;
        this._distance = distance;
    }

    /** @type {PeerChannel} */
    get signalChannel() {
        return this._signalChannel;
    }

    /** @type {number} */
    get distance() {
        return this._distance;
    }

    /** @type {number} */
    get score() {
        return ((PeerAddressBook.MAX_DISTANCE - this._distance) / 2) * (1 - (this.failedAttempts / PeerAddressBook.MAX_FAILED_ATTEMPTS_RTC));
    }

    /**
     * @param {SignalRoute} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof SignalRoute
            && this._signalChannel.equals(o._signalChannel);
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this._signalChannel.hashCode();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `SignalRoute{signalChannel=${this._signalChannel}, distance=${this._distance}, timestamp=${this.timestamp}, failedAttempts=${this.failedAttempts}}`;
    }
}
Class.register(SignalRoute);

class SeedList {
    /**
     * @param {string} url
     * @param {PublicKey} [publicKey]
     * @returns {Promise.<SeedList>}
     */
    static async retrieve(url, publicKey) {
        return SeedList.parse(await HttpRequest.get(url, SeedList.REQUEST_TIMEOUT, SeedList.MAX_SIZE), publicKey);
    }

    /**
     * @param {string} listStr
     * @param {PublicKey} [publicKey]
     * @returns {SeedList}
     * @private
     */
    static parse(listStr, publicKey) {
        const seeds = [];

        // Filter empty and comment lines.
        const lines = listStr
            .split(/\r\n|\n|\r/)
            .filter(line => line.length > 0 && !line.startsWith('#'));

        // Read seed addresses. Ignore the last line here.
        for (let i = 0; i < lines.length - 1; i++) {
            const line = lines[i];
            try {
                seeds.push(WsBasePeerAddress.fromSeedString(line.trim()));
            } catch (e) {
                Log.w(SeedList, `Ignoring malformed seed address ${line}`);
            }
        }

        // Try to parse the last line as a signature.
        const lastLine = lines[lines.length - 1];
        let signature = null;
        try {
            signature = new Signature(BufferUtils.fromHex(lastLine.trim()));
        } catch (e) {
            // ignore
        }

        // If the last line doesn't parse as a signature, try to parse it as a PeerAddress.
        if (!signature) {
            try {
                seeds.push(WsBasePeerAddress.fromSeedString(lastLine.trim()));
            } catch (e) {
                Log.w(SeedList, `Ignoring malformed signature/seed address ${lastLine}`);
            }
        }

        // If we don't have a public key, skip the signature check.
        if (!publicKey) {
            return new SeedList(seeds, null, signature);
        }

        // We have a public key, but no signature. Fail.
        if (!signature) {
            throw new Error('Missing signature');
        }

        // Verify signature.
        const data = SeedList._serializeSeeds(seeds);
        if (!signature.verify(publicKey, data)) {
            throw new Error('Invalid signature');
        }

        // Signature ok.
        return new SeedList(seeds, publicKey, signature);
    }

    /**
     * @param {Array.<PeerAddress>} seeds
     * @returns {Uint8Array}
     */
    static _serializeSeeds(seeds) {
        return BufferUtils.fromAscii(seeds.map(seed => seed.toSeedString()).join('\n'));
    }

    /**
     * @param {Array.<PeerAddress>} seeds
     * @param {PublicKey} [publicKey]
     * @param {Signature} [signature]
     */
    constructor(seeds, publicKey, signature) {
        this._seeds = seeds;
        this._publicKey = publicKey;
        this._signature = signature;
    }

    /**
     * @returns {Uint8Array}
     */
    serializeContent() {
        return SeedList._serializeSeeds(this._seeds);
    }

    /**
     * @type {Array.<PeerAddress>}
     */
    get seeds() {
        return this._seeds;
    }

    /**
     * @type {PublicKey}
     */
    get publicKey() {
        return this._publicKey;
    }

    /**
     * @type {Signature}
     */
    get signature() {
        return this._signature;
    }
}
SeedList.MAX_SIZE = 1024 * 128; // 128 kb
SeedList.REQUEST_TIMEOUT = 8000; // 8 seconds
Class.register(SeedList);

class SeedListUrl {
    /**
     * @param {string} url
     * @param {string} [publicKeyHex]
     */
    constructor(url, publicKeyHex) {
        this._url = url;
        this._publicKey = publicKeyHex ? new PublicKey(BufferUtils.fromHex(publicKeyHex)) : null;
    }

    /**
     * @type {string}
     */
    get url() {
        return this._url;
    }

    /**
     * @returns {PublicKey}
     */
    get publicKey() {
        return this._publicKey;
    }
}
Class.register(SeedListUrl);

class PeerAddressSeeder extends Observable {
    /**
     * @returns {Promise.<void>}
     */
    async collect() {
        if (!GenesisConfig.SEED_LISTS) {
            this.fire('end');
            return;
        }

        const promises = [];
        for (const listUrl of GenesisConfig.SEED_LISTS) {
            promises.push(SeedList.retrieve(listUrl.url, listUrl.publicKey)
                .then(seedList => {
                    Log.i(PeerAddressSeeder, `Got ${seedList.seeds.length} seed peers from ${listUrl.url}`
                        + (seedList.publicKey && seedList.signature ? ' (signed)' : ''));
                    this.fire('seeds', seedList.seeds);
                })
                .catch(e => Log.w(PeerAddressSeeder, `Failed to retrieve seed list from ${listUrl.url}: ${e.message || e}`)));
        }

        await Promise.all(promises);
        this.fire('end');
    }
}
Class.register(PeerAddressSeeder);

class PeerAddressBook extends Observable {
    /**
     * @constructor
     * @param {NetworkConfig} netconfig
     */
    constructor(netconfig) {
        super();

        /**
         * @type {NetworkConfig}
         * @private
         */
        this._networkConfig = netconfig;

        /**
         * Set of PeerAddressStates of all peerAddresses we know.
         * @type {HashSet.<PeerAddressState>}
         * @private
         */
        this._store = new HashSet();

        /**
         * @type {HashSet}
         * @private
         */
        this._wsStates = new HashSet();

        /**
         * Set of only WSS states.
         * @type {HashSet}
         * @private
         */
        this._wssStates = new HashSet();

        /**
         * @type {HashSet}
         * @private
         */
        this._rtcStates = new HashSet();

        /**
         * Map from peerIds to RTC peerAddresses.
         * @type {HashMap.<PeerId,PeerAddressState>}
         * @private
         */
        this._stateByPeerId = new HashMap();

        /**
         * @type {HashMap.<NetAddress,Set.<PeerAddressState>>}
         * @private
         */
        this._statesByNetAddress = new HashMap();

        /**
         * @type {boolean}
         * @private
         */
        this._seeded = false;

        // Init hardcoded seed peers.
        this.add(/*channel*/ null, GenesisConfig.SEED_PEERS);

        // Collect more seed peers from seed lists.
        const seededCallback = () => {
            this._seeded = true;
            this.fire('seeded');
        };
        const seeder = new PeerAddressSeeder();
        seeder.on('seeds', seeds => this.add(/*channel*/ null, seeds));
        seeder.on('end', seededCallback);
        seeder.collect().catch(Log.e.tag(PeerAddressBook));

        // Wait at most PeerAddressBook.SEEDING_TIMEOUT for seeding.
        setTimeout(seededCallback, PeerAddressBook.SEEDING_TIMEOUT);

        // Setup housekeeping interval.
        setInterval(() => this._housekeeping(), PeerAddressBook.HOUSEKEEPING_INTERVAL);
    }

    /**
     * @returns {Iterator.<PeerAddressState>}
     */
    iterator() {
        return this._store.valueIterator();
    }

    /**
     * @returns {Iterator.<PeerAddressState>}
     */
    wsIterator() {
        return this._wsStates.valueIterator();
    }

    /**
     * @returns {Iterator.<PeerAddressState>}
     */
    wssIterator() {
        return this._wssStates.valueIterator();
    }

    /**
     * @returns {Iterator.<PeerAddressState>}
     */
    rtcIterator() {
        return this._rtcStates.valueIterator();
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {?PeerAddressState}
     * @private
     */
    _get(peerAddress) {
        if (peerAddress instanceof WssPeerAddress || peerAddress instanceof WsPeerAddress) {
            const localPeerAddress = this._store.get(peerAddress.withoutId());
            if (localPeerAddress) return localPeerAddress;
        }
        return this._store.get(peerAddress);
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {?PeerAddressState}
     */
    getState(peerAddress) {
        return this._get(peerAddress);
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {?PeerAddress}
     */
    get(peerAddress) {
        /** @type {PeerAddressState} */
        const peerAddressState = this._get(peerAddress);
        return peerAddressState ? peerAddressState.peerAddress : null;
    }

    /**
     * @param {PeerId} peerId
     * @returns {?PeerAddress}
     */
    getByPeerId(peerId) {
        /** @type {PeerAddressState} */
        const peerAddressState = this._stateByPeerId.get(peerId);
        return peerAddressState ? peerAddressState.peerAddress : null;
    }

    /**
     * @param {PeerId} peerId
     * @returns {PeerChannel}
     */
    getChannelByPeerId(peerId) {
        const peerAddressState = this._stateByPeerId.get(peerId);
        if (peerAddressState && peerAddressState.signalRouter.bestRoute) {
            return peerAddressState.signalRouter.bestRoute.signalChannel;
        }
        return null;
    }

    /**
     * @param {number} protocolMask
     * @param {number} serviceMask
     * @param {number} maxAddresses
     * @returns {Array.<PeerAddress>}
     */
    query(protocolMask, serviceMask, maxAddresses = NetworkAgent.MAX_ADDR_PER_MESSAGE) {
        let it, numAddresses;
        // Important: this switches over a *mask*.
        switch (protocolMask) {
            case Protocol.WSS:
                it = this.wssIterator();
                numAddresses = this.knownWssAddressesCount;
                break;
            case Protocol.WS:
                it = this.wsIterator();
                numAddresses = this.knownWsAddressesCount;
                break;
            case Protocol.WS | Protocol.WSS:
                it = IteratorUtils.alternate(this.wsIterator(), this.wssIterator());
                numAddresses = this.knownWsAddressesCount + this.knownWssAddressesCount;
                break;
            case Protocol.RTC:
                it = this.rtcIterator();
                numAddresses = this.knownRtcAddressesCount;
                break;
            case Protocol.RTC | Protocol.WS:
                it = IteratorUtils.alternate(this.rtcIterator(), this.wsIterator());
                numAddresses = this.knownRtcAddressesCount + this.knownWsAddressesCount;
                break;
            case Protocol.RTC | Protocol.WSS:
                it = IteratorUtils.alternate(this.rtcIterator(), this.wssIterator());
                numAddresses = this.knownRtcAddressesCount + this.knownWssAddressesCount;
                break;
            default:
                it = this.iterator();
                numAddresses = this.knownAddressesCount;
        }

        // Pick a random start index if we have a lot of addresses.
        let startIndex = 0, endIndex = numAddresses;
        if (numAddresses > maxAddresses) {
            startIndex = Math.floor(Math.random() * numAddresses);
            endIndex = (startIndex + maxAddresses) % numAddresses;
        }
        const overflow = startIndex > endIndex;

        // XXX inefficient linear scan
        const addresses = [];
        let index = -1;
        for (const peerAddressState of it) {
            index++;
            if (!overflow && index < startIndex) continue;
            if (!overflow && index >= endIndex) break;
            if (overflow && (index >= endIndex && index < startIndex)) continue;

            // Never return banned or failed addresses.
            if (peerAddressState.state === PeerAddressState.BANNED
                    || peerAddressState.state === PeerAddressState.FAILED) {
                continue;
            }

            // Never return seed peers.
            const address = peerAddressState.peerAddress;
            if (address.isSeed()) {
                continue;
            }

            // Only return addresses matching the protocol mask.
            if ((address.protocol & protocolMask) === 0) {
                continue;
            }

            // Only return addresses matching any of legacy service mask if present.
            const legacyServices = serviceMask & Services.ALL_LEGACY;
            if (legacyServices > 0 && (address.services & legacyServices) === 0) {
                continue;
            }

            // Only return addresses matching all of current service mask if present.
            const currentServices = serviceMask & Services.ALL_CURRENT;
            if (currentServices > 0 && (address.services & currentServices) !== currentServices) {
                continue;
            }

            // XXX Why is this here?
            // Update timestamp for connected peers.
            // if (peerAddressState.state === PeerAddressState.ESTABLISHED) {
            //     // Also update timestamp for RTC connections
            //     if (peerAddressState.signalRouter.bestRoute) {
            //         peerAddressState.signalRouter.bestRoute.timestamp = now;
            //     }
            // }

            // Exclude RTC addresses that are already at MAX_DISTANCE.
            if (address.protocol === Protocol.RTC && address.distance >= PeerAddressBook.MAX_DISTANCE) {
                continue;
            }

            // Never return addresses that are too old.
            if (address.exceedsAge()) {
                continue;
            }

            // Return this address.
            addresses.push(address);
        }
        return addresses;
    }

    /**
     * @param {PeerChannel} channel
     * @param {PeerAddress|Array.<PeerAddress>} arg
     * @fires PeerAddressBook#added
     */
    add(channel, arg) {
        const peerAddresses = Array.isArray(arg) ? arg : [arg];
        const newAddresses = [];

        for (const addr of peerAddresses) {
            if (this._add(channel, addr)) {
                newAddresses.push(addr);
            }
        }

        // Tell listeners that we learned new addresses.
        if (newAddresses.length) {
            this.fire('added', newAddresses, this);
        }
    }

    /**
     * @param {PeerChannel} channel
     * @param {PeerAddress|RtcPeerAddress} peerAddress
     * @returns {boolean}
     * @private
     */
    _add(channel, peerAddress) {
        // Ignore our own address.
        if (this._networkConfig.peerAddress.equals(peerAddress)) {
            return false;
        }

        // Ignore address if it is too old.
        // Special case: allow seed addresses (timestamp == 0) via null channel.
        if (channel && peerAddress.exceedsAge()) {
            Log.v(PeerAddressBook, () => `Ignoring address ${peerAddress} - too old (${new Date(peerAddress.timestamp)})`);
            return false;
        }

        // Ignore address if its timestamp is too far in the future.
        if (peerAddress.timestamp > Date.now() + PeerAddressBook.MAX_TIMESTAMP_DRIFT) {
            Log.v(PeerAddressBook, () => `Ignoring addresses ${peerAddress} - timestamp in the future`);
            return false;
        }

        // Increment distance values of RTC addresses.
        if (peerAddress.protocol === Protocol.RTC) {
            peerAddress.distance++;

            // Ignore address if it exceeds max distance.
            if (peerAddress.distance > PeerAddressBook.MAX_DISTANCE) {
                Log.v(PeerAddressBook, () => `Ignoring address ${peerAddress} - max distance exceeded`);
                // Drop any route to this peer over the current channel. This may prevent loops.
                const peerAddressState = this._get(peerAddress);
                if (peerAddressState) {
                    peerAddressState.signalRouter.deleteRoute(channel);
                }
                return false;
            }
        }

        // Get the (reliable) netAddress of the peer that sent us this address.
        const netAddress = channel && channel.netAddress && channel.netAddress.reliable ? channel.netAddress : null;

        // Check if we already know this address.
        let peerAddressState = this._get(peerAddress);
        let knownAddress = null;
        let changed = false;
        if (peerAddressState) {
            // Update address.
            knownAddress = peerAddressState.peerAddress;

            // Ignore address if it is banned.
            if (peerAddressState.state === PeerAddressState.BANNED) {
                return false;
            }

            // Never update seed peers.
            if (knownAddress.isSeed()) {
                return false;
            }

            // Never erase NetAddresses and never overwrite reliable addresses.
            if (knownAddress.netAddress && (!peerAddress.netAddress || knownAddress.netAddress.reliable)) {
                peerAddress.netAddress = knownAddress.netAddress;
            }
        } else {
            // New address, check max book size.
            if (this._store.length >= PeerAddressBook.MAX_SIZE) {
                return false;
            }
            // Check max size per protocol.
            switch (peerAddress.protocol) {
                case Protocol.WSS:
                    if (this._wssStates.length >= PeerAddressBook.MAX_SIZE_WSS) {
                        return false;
                    }
                    break;
                case Protocol.WS:
                    if (this._wsStates.length >= PeerAddressBook.MAX_SIZE_WS) {
                        return false;
                    }
                    break;
                case Protocol.RTC:
                    if (this._rtcStates.length >= PeerAddressBook.MAX_SIZE_RTC) {
                        return false;
                    }
                    break;
                default:
                // Dumb addresses are only part of global limit.
            }

            // If we know the IP address of the sender, check that we don't exceed the maximum number of addresses per IP.
            if (netAddress) {
                const states = this._statesByNetAddress.get(netAddress);
                if (states && states.size >= PeerAddressBook.MAX_SIZE_PER_IP) {
                    Log.v(PeerAddressBook, () => `Ignoring address ${peerAddress} - max count per IP ${netAddress} reached`);
                    return false;
                }
            }

            // Add new peerAddressState.
            peerAddressState = new PeerAddressState(peerAddress);
            this._addToStore(peerAddressState);
            changed = true;
        }

        // Update address if we do not know this address or it has a more recent timestamp.
        if (!knownAddress || knownAddress.timestamp < peerAddress.timestamp) {
            peerAddressState.peerAddress = peerAddress;
            changed = true;
        }

        // Add route.
        if (peerAddress.protocol === Protocol.RTC) {
            changed = peerAddressState.signalRouter.addRoute(channel, peerAddress.distance, peerAddress.timestamp) || changed;
        }

        // Track which IP address send us this address.
        this._trackByNetAddress(peerAddressState, netAddress);


        return changed;
    }

    /**
     * @param {PeerAddressState} peerAddressState
     * @private
     */
    _addToStore(peerAddressState) {
        this._store.add(peerAddressState);

        // Index by peerId.
        if (peerAddressState.peerAddress.peerId) {
            this._stateByPeerId.put(peerAddressState.peerAddress.peerId, peerAddressState);
        }

        // Index by protocol.
        switch (peerAddressState.peerAddress.protocol) {
            case Protocol.WSS:
                this._wssStates.add(peerAddressState);
                break;
            case Protocol.WS:
                this._wsStates.add(peerAddressState);
                break;
            case Protocol.RTC:
                this._rtcStates.add(peerAddressState);
                break;
            default:
                // Dumb addresses are ignored.
        }
    }

    /**
     * @param {PeerAddressState} peerAddressState
     * @param {NetAddress} netAddress
     * @private
     */
    _trackByNetAddress(peerAddressState, netAddress) {
        if (!netAddress) {
            return;
        }

        peerAddressState.addedBy.add(netAddress);

        let states = this._statesByNetAddress.get(netAddress);
        if (!states) {
            states = new Set();
            this._statesByNetAddress.put(netAddress, states);
        }
        states.add(peerAddressState);
    }

    /**
     * Called when a connection to this peerAddress has been established.
     * The connection might have been initiated by the other peer, so address
     * may not be known previously.
     * If it is already known, it has been updated by a previous version message.
     * @param {PeerChannel} channel
     * @param {PeerAddress|RtcPeerAddress} peerAddress
     * @returns {void}
     */
    established(channel, peerAddress) {
        let peerAddressState = this._get(peerAddress);

        if (!peerAddressState) {
            peerAddressState = new PeerAddressState(peerAddress);
            this._addToStore(peerAddressState);
        }

        // Get the (reliable) netAddress of the peer that sent us this address.
        const netAddress = channel && channel.netAddress && channel.netAddress.reliable ? channel.netAddress : null;
        this._trackByNetAddress(peerAddressState, netAddress);

        peerAddressState.state = PeerAddressState.ESTABLISHED;
        peerAddressState.lastConnected = Date.now();
        peerAddressState.failedAttempts = 0;
        peerAddressState.bannedUntil = -1;
        peerAddressState.banBackoff = PeerAddressBook.INITIAL_FAILED_BACKOFF;

        if (!peerAddressState.peerAddress.isSeed()) {
            peerAddressState.peerAddress = peerAddress;
        }

        // Add route.
        if (peerAddress.protocol === Protocol.RTC) {
            peerAddressState.signalRouter.addRoute(channel, peerAddress.distance, peerAddress.timestamp);
        }
    }

    /**
     * Called when a connection to this peerAddress is closed.
     * @param {PeerChannel} channel
     * @param {PeerAddress} peerAddress
     * @param {?number} type
     * @returns {void}
     */
    close(channel, peerAddress, type = null) {
        const peerAddressState = this._get(peerAddress);
        if (!peerAddressState) {
            return;
        }

        // register the type of disconnection
        peerAddressState.close(type);

        // Delete all addresses that were signalable over the disconnected peer.
        if (channel) {
            this._removeBySignalChannel(channel);
        }

        if (CloseType.isBanningType(type)){
            this._ban(peerAddress);
        }
        else if (CloseType.isFailingType(type)) {
            peerAddressState.failedAttempts++;

            if (peerAddressState.failedAttempts >= peerAddressState.maxFailedAttempts) {
                // Remove address only if we have tried the maximum number of backoffs.
                if (peerAddressState.banBackoff >= PeerAddressBook.MAX_FAILED_BACKOFF) {
                    this._removeFromStore(peerAddress);
                } else {
                    peerAddressState.bannedUntil = Date.now() + peerAddressState.banBackoff;
                    peerAddressState.banBackoff = Math.min(PeerAddressBook.MAX_FAILED_BACKOFF, peerAddressState.banBackoff * 2);
                }
            }
        }

        // Immediately delete dumb addresses, since we cannot connect to those anyway.
        if (peerAddress.protocol === Protocol.DUMB) {
            this._removeFromStore(peerAddress);
        }
    }

    /**
     * Called when a message has been returned as unroutable.
     * @param {PeerChannel} channel
     * @param {PeerAddress} peerAddress
     * @returns {void}
     */
    unroutable(channel, peerAddress) {
        if (!peerAddress) {
            return;
        }

        const peerAddressState = this._get(peerAddress);
        if (!peerAddressState) {
            return;
        }

        if (!peerAddressState.signalRouter.bestRoute || !peerAddressState.signalRouter.bestRoute.signalChannel.equals(channel)) {
            Log.d(PeerAddressBook, () => `Got unroutable for ${peerAddress} on a channel other than the best route.`);
            return;
        }

        peerAddressState.signalRouter.deleteBestRoute();
        if (!peerAddressState.signalRouter.hasRoute()) {
            this._removeFromStore(peerAddressState.peerAddress);
        }
    }

    /**
     * @param {PeerAddress} peerAddress
     * @param {number} [duration] in milliseconds
     * @returns {void}
     * @private
     */
    _ban(peerAddress, duration = PeerAddressBook.DEFAULT_BAN_TIME) {
        let peerAddressState = this._get(peerAddress);
        if (!peerAddressState) {
            peerAddressState = new PeerAddressState(peerAddress);
            this._store.add(peerAddressState);
        }

        peerAddressState.state = PeerAddressState.BANNED;
        peerAddressState.bannedUntil = Date.now() + duration;

        // Drop all routes to this peer.
        peerAddressState.signalRouter.deleteAllRoutes();
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {boolean}
     */
    isBanned(peerAddress) {
        const peerAddressState = this._get(peerAddress);
        return peerAddressState
            && peerAddressState.state === PeerAddressState.BANNED
            // XXX Never consider seed peers to be banned. This allows us to use
            // the banning mechanism to prevent seed peers from being picked when
            // they are down, but still allows recovering seed peers' inbound
            // connections to succeed.
            && !peerAddressState.peerAddress.isSeed();
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {void}
     * @private
     */
    _removeFromStore(peerAddress) {
        const peerAddressState = this._get(peerAddress);
        if (!peerAddressState) {
            return;
        }

        // Never delete seed addresses, ban them instead for a couple of minutes.
        if (peerAddressState.peerAddress.isSeed()) {
            this._ban(peerAddress, peerAddressState.banBackoff);
            return;
        }

        // Delete from peerId index.
        if (peerAddress.peerId) {
            this._stateByPeerId.remove(peerAddress.peerId);
        }

        // Delete from netAddress index.
        for (const netAddress of peerAddressState.addedBy) {
            const states = this._statesByNetAddress.get(netAddress);
            if (states) {
                states.delete(peerAddressState);
                if (states.size === 0) {
                    this._statesByNetAddress.remove(netAddress);
                }
            }
        }

        // Remove from protocol index.
        switch (peerAddressState.peerAddress.protocol) {
            case Protocol.WSS:
                this._wssStates.remove(peerAddressState);
                break;
            case Protocol.WS:
                this._wsStates.remove(peerAddressState);
                break;
            case Protocol.RTC:
                this._rtcStates.remove(peerAddressState);
                break;
            default:
                // Dumb addresses are ignored.
        }

        // Don't delete bans.
        if (peerAddressState.state === PeerAddressState.BANNED) {
            return;
        }

        // Delete the address.
        this._store.remove(peerAddress);
    }

    /**
     * Delete all RTC-only routes that are signalable over the given peer.
     * @param {PeerChannel} channel
     * @returns {void}
     * @private
     */
    _removeBySignalChannel(channel) {
        // XXX inefficient linear scan
        for (const peerAddressState of this._store.valueIterator()) {
            if (peerAddressState.peerAddress.protocol === Protocol.RTC) {
                peerAddressState.signalRouter.deleteRoute(channel);
                if (!peerAddressState.signalRouter.hasRoute()) {
                    this._removeFromStore(peerAddressState.peerAddress);
                }
            }
        }
    }

    /**
     * @returns {void}
     * @private
     */
    _housekeeping() {
        const now = Date.now();
        const unbannedAddresses = [];

        for (/** @type {PeerAddressState} */ const peerAddressState of this._store.valueIterator()) {
            const addr = peerAddressState.peerAddress;

            switch (peerAddressState.state) {
                case PeerAddressState.NEW:
                case PeerAddressState.TRIED:
                case PeerAddressState.FAILED:
                    // Delete all new peer addresses that are older than MAX_AGE.
                    if (addr.exceedsAge()) {
                        this._removeFromStore(addr);
                        continue;
                    }

                    // Reset failed attempts after bannedUntil has expired.
                    if (peerAddressState.state === PeerAddressState.FAILED
                        && peerAddressState.failedAttempts >= peerAddressState.maxFailedAttempts
                        && peerAddressState.bannedUntil > 0 && peerAddressState.bannedUntil <= now) {

                        peerAddressState.bannedUntil = -1;
                        peerAddressState.failedAttempts = 0;
                        unbannedAddresses.push(addr);
                    }

                    break;

                case PeerAddressState.BANNED:
                    if (peerAddressState.bannedUntil <= now) {
                        // Don't remove seed addresses, unban them.
                        if (addr.isSeed()) {
                            // Restore banned seed addresses to the NEW state.
                            peerAddressState.state = PeerAddressState.NEW;
                            peerAddressState.failedAttempts = 0;
                            peerAddressState.bannedUntil = -1;
                            unbannedAddresses.push(addr);
                        } else {
                            // Delete expired bans.
                            this._removeFromStore(addr);
                        }
                    }
                    break;

                case PeerAddressState.ESTABLISHED:
                    // Also update timestamp for RTC connections
                    if (peerAddressState.signalRouter.bestRoute) {
                        peerAddressState.signalRouter.bestRoute.timestamp = now;
                    }
                    break;

                default:
                    // TODO What about peers who are stuck connecting? Can this happen?
                    // Do nothing for CONNECTING peers.
            }
        }

        if (unbannedAddresses.length) {
            this.fire('added', unbannedAddresses, this);
        }
    }

    /** @type {number} */
    get knownAddressesCount() {
        return this._store.length;
    }

    /** @type {number} */
    get knownWsAddressesCount() {
        return this._wsStates.length;
    }

    /** @type {number} */
    get knownWssAddressesCount() {
        return this._wssStates.length;
    }

    /** @type {number} */
    get knownRtcAddressesCount() {
        return this._rtcStates.length;
    }

    /** @type {boolean} */
    get seeded() {
        return this._seeded;
    }
}
PeerAddressBook.MAX_AGE_WEBSOCKET = 1000 * 60 * 30; // 30 minutes
PeerAddressBook.MAX_AGE_WEBRTC = 1000 * 60 * 15; // 10 minutes
PeerAddressBook.MAX_AGE_DUMB = 1000 * 60; // 1 minute
PeerAddressBook.MAX_DISTANCE = 4;
PeerAddressBook.MAX_FAILED_ATTEMPTS_WS = 3;
PeerAddressBook.MAX_FAILED_ATTEMPTS_RTC = 2;
PeerAddressBook.MAX_TIMESTAMP_DRIFT = 1000 * 60 * 10; // 10 minutes
PeerAddressBook.HOUSEKEEPING_INTERVAL = 1000 * 60; // 1 minute
PeerAddressBook.DEFAULT_BAN_TIME = 1000 * 60 * 10; // 10 minutes
PeerAddressBook.INITIAL_FAILED_BACKOFF = 1000 * 30; // 30 seconds
PeerAddressBook.MAX_FAILED_BACKOFF = 1000 * 60 * 10; // 10 minutes
PeerAddressBook.MAX_SIZE_WS = PlatformUtils.isBrowser() ? 1000 : 10000;
PeerAddressBook.MAX_SIZE_WSS = PlatformUtils.isBrowser() ? 1000 : 10000;
PeerAddressBook.MAX_SIZE_RTC = PlatformUtils.isBrowser() ? 1000 : 10000;
PeerAddressBook.MAX_SIZE = PlatformUtils.isBrowser() ? 2500 : 20500; // Includes dumb peers
PeerAddressBook.MAX_SIZE_PER_IP = 250;
PeerAddressBook.SEEDING_TIMEOUT = 1000 * 3; // 3 seconds
Class.register(PeerAddressBook);

class GenesisConfig {
    static main() {
        GenesisConfig.init(GenesisConfig.CONFIGS['main']);
    }

    static test() {
        GenesisConfig.init(GenesisConfig.CONFIGS['test']);
    }

    static dev() {
        GenesisConfig.init(GenesisConfig.CONFIGS['dev']);
    }

    /**
     * @param {{NETWORK_ID:number,NETWORK_NAME:string,GENESIS_BLOCK:Block,GENESIS_ACCOUNTS:string,SEED_PEERS:Array.<PeerAddress>}} config
     */
    static init(config) {
        if (GenesisConfig._config) throw new Error('GenesisConfig already initialized');
        if (!config.NETWORK_ID) throw new Error('Config is missing network id');
        if (!config.NETWORK_NAME) throw new Error('Config is missing network name');
        if (!config.GENESIS_BLOCK) throw new Error('Config is missing genesis block');
        if (!config.GENESIS_ACCOUNTS) throw new Error('Config is missing genesis accounts');
        if (!config.SEED_PEERS) throw new Error('Config is missing seed peers');

        GenesisConfig._config = config;
    }

    /**
     * @type {number}
     */
    static get NETWORK_ID() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        return GenesisConfig._config.NETWORK_ID;
    }

    /**
     * @type {string}
     */
    static get NETWORK_NAME() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        return GenesisConfig._config.NETWORK_NAME;
    }

    /**
     * @type {Block}
     */
    static get GENESIS_BLOCK() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        return GenesisConfig._config.GENESIS_BLOCK;
    }

    /**
     * @type {Hash}
     */
    static get GENESIS_HASH() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        if (!GenesisConfig._config.GENESIS_HASH) {
            GenesisConfig._config.GENESIS_HASH = GenesisConfig._config.GENESIS_BLOCK.hash();
        }
        return GenesisConfig._config.GENESIS_HASH;
    }

    /**
     * @type {string}
     */
    static get GENESIS_ACCOUNTS() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        return GenesisConfig._config.GENESIS_ACCOUNTS;
    }

    /**
     * @type {Array.<PeerAddress>}
     */
    static get SEED_PEERS() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        return GenesisConfig._config.SEED_PEERS;
    }

    /**
     * @type {Array.<SeedList>}
     */
    static get SEED_LISTS() {
        if (!GenesisConfig._config) throw new Error('GenesisConfig not initialized');
        return GenesisConfig._config.SEED_LISTS;
    }

    /**
     * @param {number} networkId
     * @return {string}
     */
    static networkIdToNetworkName(networkId) {
        for (const key of Object.keys(GenesisConfig.CONFIGS)) {
            const config = GenesisConfig.CONFIGS[key];
            if (networkId === config.NETWORK_ID) {
                return config.NETWORK_NAME;
            }
        }
        throw new Error(`Unable to find networkName for networkId ${networkId}`);
    }

    /**
     * @param {number|string} networkId
     * @return {number}
     */
    static networkIdFromAny(networkId) {
        if (typeof networkId === 'number') return networkId;
        if (GenesisConfig.CONFIGS[networkId]) {
            return GenesisConfig.CONFIGS[networkId].NETWORK_ID;
        }
        throw new Error(`Unable to find networkId for ${networkId}`);
    }
}
Class.register(GenesisConfig);

GenesisConfig.CONFIGS = {
    'main': {
        NETWORK_ID: 42,
        NETWORK_NAME: 'main',
        SEED_PEERS: [
            WssPeerAddress.seed('seed-1.nimiq.com', 8443, 'b70d0c3e6cdf95485cac0688b086597a5139bc4237173023c83411331ef90507'),
            WssPeerAddress.seed('seed-2.nimiq.com', 8443, '8580275aef426981a04ee5ea948ca3c95944ef1597ad78db9839f810d6c5b461'),
            WssPeerAddress.seed('seed-3.nimiq.com', 8443, '136bdec59f4d37f25ac8393bef193ff2e31c9c0a024b3edbf77fc1cb84e67a15'),
            WssPeerAddress.seed('seed-4.nimiq-network.com', 8443, 'aacf606335cdd92d0dd06f27faa3b66d9bac0b247cd57ade413121196b72cd73'),
            WssPeerAddress.seed('seed-5.nimiq-network.com', 8443, '110a81a033c75976643d4b8f34419f4913b306a6fc9d530b8207ddbd5527eff6'),
            WssPeerAddress.seed('seed-6.nimiq-network.com', 8443, '26c1a4727cda6579639bdcbaecb1f6b97be3ac0e282b43bdd1a2df2858b3c23b'),
            WssPeerAddress.seed('seed-7.nimiq.network', 8443, '82fcebdb4e2a7212186d1976d7f685cc86cdf58beffe1723d5c3ea5be00c73e1'),
            WssPeerAddress.seed('seed-8.nimiq.network', 8443, 'b7ac8cc1a820761df4e8a42f4e30c870e81065c4e29f994ebb5bdceb48904e7b'),
            WssPeerAddress.seed('seed-9.nimiq.network', 8443, '4429bf25c8d296c0f1786647d8f7d4bac40a37c67caf028818a65a9cc7865a48'),
            WssPeerAddress.seed('seed-10.nimiq.network', 8443, 'e8e99fb8633d660d4f2d48edb6cc294681b57648b6ec6b28af8f85b2d5ec4e68'),
            WssPeerAddress.seed('seed-11.nimiq.network', 8443, 'a76f0edabacfe701750036bad473ff92fa0e68ef655ab93135f0572af6e5baf8'),
            WssPeerAddress.seed('seed-12.nimiq.network', 8443, 'dca57704191306ac1315e051b6dfef6c174fb2af011a52a3d922fbfaec2be41a'),
            WssPeerAddress.seed('seed-13.nimiq-network.com', 8443, '30993f92f148da125a6f8bc191b3e746fab39e109220daa0966bf6432e909f3f'),
            WssPeerAddress.seed('seed-14.nimiq-network.com', 8443, '6e7f904fabfadb194d6c74b16534bacb69892d80909cf959e47d3c8f5f330ad2'),
            WssPeerAddress.seed('seed-15.nimiq-network.com', 8443, '7cb662a686144c17ae4153fbf7ce359f7e9da39dc072eb11092531f9104fbdf6'),
            WssPeerAddress.seed('seed-16.nimiq.com', 8443, '0dfd11939947101197e3c3768a086e65ef1e893e71bfcf4bd5ed222957825212'),
            WssPeerAddress.seed('seed-17.nimiq.com', 8443, 'c7120f4f88b70a38daa9783e30e89c1c55c3d80d0babed44b4e2ddd09052664a'),
            WssPeerAddress.seed('seed-18.nimiq.com', 8443, 'c15a2d824a52837fa7165dc232592be35116661e7f28605187ab273dd7233711'),
            WssPeerAddress.seed('seed-19.nimiq.com', 8443, '98a24d4b05158314b36e0bd6ce3b42ac5ac061f4bb9664d783eb930caa9315b6'),
            WssPeerAddress.seed('seed-20.nimiq.com', 8443, '1fc33f93273d94dd2cf7470274c27ecb1261ec983e43bdbb281803c0a09e68d5')
        ],
        SEED_LISTS: [
            new SeedListUrl('https://nimiq.community/seeds.txt', '8b4ae04557f490102036ce3e570b39058c92fc5669083fb9bbb6effc91dc3c71')
        ],
        GENESIS_BLOCK: new Block(
            new BlockHeader(
                new Hash(null),
                new Hash(null),
                Hash.fromBase64('fNqaf98GZVkFrl29nFNUUUcbB4+m898OKH5bD7R6Vzo='),
                Hash.fromBase64('H+/UTx+pcYX9oh6VdUXJfcdkP6fk792G4KpCRNHgvFw='),
                BlockUtils.difficultyToCompact(1),
                1,
                1523727000,
                137689,
                BlockHeader.Version.V1),
            new BlockInterlink([], new Hash(null)),
            new BlockBody(Address.fromBase64('AAAAAAAAAAAAAAAAAAAAAAAAAAA='), [], BufferUtils.fromBase64('bG92ZSBhaSBhbW9yIG1vaGFiYmF0IGh1YnVuIGNpbnRhIGx5dWJvdiBiaGFsYWJhc2EgYW1vdXIga2F1bmEgcGknYXJhIGxpZWJlIGVzaHEgdXBlbmRvIHByZW1hIGFtb3JlIGthdHJlc25hbiBzYXJhbmcgYW5wdSBwcmVtYSB5ZXU='))
        ),
        GENESIS_ACCOUNTS:
            'BXQP6DJYG/agiSQSrPuWUbRRxQmDHQAAAAAF2/KlRxjOcKZctsfgir1rJDc7M1dOFucNAAAAAARkWKRA' +
            'MGEIuQcr/LWZhPrQ7LpebB3kYYcBAAAAIE+qFOAgACDQKQvjUPndEmPJ2RXL4jv7OwAAAAEAAfpAAAAA' +
            'ECfVCnAAAAAgT6oU4FqGT/vMwX1XZ07g22eMw0fskoHqAAAAAAAuoDAQhhvJ39JLpqnCXaqIO2RDsEtW' +
            'bAMAAAAAAAg9hxCItdtDSvA4XiTc8SZ2okGR9PBiwAAAAAABH2oD+KHGLvyhzKpotDO+dRikL1JF4dLb' +
            'AAAAAATjspIApt0GGBRqQArhsPlqcx3aLD61cgMAAAAAAxn5S2j4oBTAQRu6fkRwfYzj7NL2x48m0AAA' +
            'AAAH0bUABhGUdOEECf6HAU8PNzKZQvJk1B5DAAAAAAAF9eEAEzDJsAfbsuquQ7B4gsI0eERLC/EAAAAA' +
            'ADq+IDIh/nPeSKVyjryg33EX1lzOu95fEQAAAAAAdTr8gCjXjzONl/+2PUcddEA6O8JlGhAKAAAAAAFr' +
            'f4y1KTNYzGYsScrZ1FKyaNQV7uj5NbUAAAAAAaPyx381GhQi6QebQBQ2bbN2ln8dOOD+2gAAAAAU9GsE' +
            'ADoBEcCjv8uoWrt/wVxwzHbZxhP4AAAAAADNOALyWKUQu5O7Qy8/IPd1ul0kzWwiAcMAAAAAAS2TXoBZ' +
            'CuTUV/1qLW/xoCraX2Jv9XUK4AAAAAAER9Flj2F9+ZRM1KWMIUMFrR+E/YMogAWuAAAAAASOmvvgd9uc' +
            'qO/K73xO5z33Q04Mn1WrpMEAAAAAHAJev86Ckcs9bc1qV+Qcm1pX0+Ek9NPhDAAAAAAMOT5tAIY+MD4j' +
            '7Vx6pcKmWrfmLAV/eB+HAAAAAAgmKZ4AtSpJmecTzccCWIUeUna2nAHdhvQAAAAAA9jV64BlM7tVnlMn' +
            '4rSTVuBrGd/rc3LEWQEAAAACTYyuwLxA3NNyqJySg9OvuK+zQDxcCLWeAAAAAQAB+kAAAAABJsZXYAAA' +
            'AAJNjK7A2ojzYWi7PGsNZ2QrnwZF0YWZ4gwAAAAAAkR9WMDbGZ3g0hzz+ZDBqbHOr7MV6Mc8OgAAAAAC' +
            'xB3Y6OFhpAbpXKTJsngcVryISMP2ph2TAAAAAABqZPBA/8H6Ndvkl+uBXVdN81U8igZhMlsAAAAAAVMO' +
            'jbAOfIZDbkvc3A9Tm6bBvbxfIb2KPwAAAAAAaE7hgBvONkYFyxcWNrWuSszaXQWNJnpZAAAAAEAJGmRY' +
            'IDpIPQPthk7FP8hQNSKchk+TbNsAAAAAAxw69rUn1x/KoirmOwb1VaNyQLz0qW7aoQAAAAAAaguUpCy2' +
            'zHWyiLqY9ck2Knq1+kmpIkY4AAAAAABVoxCwRoTV8sZ+c5Hz3h9NhYzXLR1DDokAAAAAAf8cHcBGxpCv' +
            'b/1yLjmIEJ4rglDFLFOx2gAAAAACCYpngGvbqPKY+bN3c7jIpBFsP/M/QfkjAAAAAAAaE7hgc0Zf375Y' +
            'UsXC0d+tncI0X6RlqUUAAAAAASCMQ4CBNEMJOG90CFKRAyOfDIMQaMylPQAAAAAFpLqBHZFiRK5ASY3P' +
            'fZOEKGU0WqiQLl5/AAAAAAQTFM8AlhV73DcjjfUjNWVo2z8hoj5k/1gAAAAAAYxe8oCtVJ6hZEduKuMO' +
            'uAvyUMnx/Gj8PgAAAAABZaC8AOqY2XqSH5XeVxPpNdrO+WiuUuGUAAAAAAukO3QA9oiDBRLWgn7Tbr7r' +
            'oYbSdd2GxLwAAAAAAU3JOAASJmSsEswZHmevydrROlWjwwGZKAAAAAAAhyXBTyWjUVSBLgXs/89DE3+X' +
            'vpLxNLa9AAAAAAHVYvbAPAEuS0r8tJop5K5KbCkTX5S4ZPUAAAAAATotE8BMietfyhCwcpFR4PV49Rtc' +
            'ucx40gAAAABFvWcxAGA/EmgHq7ZQtKBh/DmXDlmfF24NAAAAAAOlXb+cbx8jXvA/fxzzLbZ6MV/6I0ej' +
            'kQkAAAAAAExagkAc0AzEdzdoRgKtfTtlM5HnsVgbzAEAAAGXdCDcAG+w+UExRfut8gFGthlImKYgQq5e' +
            'AAAAAQAD9IAAAABD6LAkqwAAAZd0INwAdMn2fqUMqw3JzYVZCwa5jVq/V3gAAAAAAGempxiCcHNsFwdc' +
            '1XhMjOqrJgh2AXJ3wAAAAAAAOsxNvpTk2KGPeovysqU+hB7BtmJNP9f0AAAAAAAuYYyCluk9tmHW5NWz' +
            'V1th8r4irStTqF0AAAAAAaE7hgDH7Ie78axtcP1Wma23f+5IgxkM0wAAAAABDzN9gOkVFantKnQNmROv' +
            'fRODXSl5XsP3AAAAAAFHsFQy8vZKgy0XKFdJP21+8iwJE/qP8L0AAAAABQL9b0AHf4b4nZr+T6Wt0yNL' +
            'PE47WENakwAAAAACCYpngBUiyNIB7fOkkQfApVuhBqWb+DmjAAAAAAABMS0AF0OyTc7e81kJOa5YrvE7' +
            'unefdWUAAAAAAIrfnE1JwQz5BndIzrH6D4EZWW5ErUeA4AAAAAAA/7yFPVE7F9SQJi+5H3ix9IqhZVaz' +
            '35zeAAAAAABx2EmAXVwR9uccLyWANgANtPpCZEB+VYkAAAAAAYpPI6Jjl1WEynZMWqqkB+E0k4DQtlCd' +
            'kAAAAAABoTuGAHS4jo1JVVycYGl8CXU0nee82Cu7AAAAAABoTuGAereFP6l3pPLGXtE1g/axb+pPyG0A' +
            'AAAAAACYloB9xzt7uBipx0GD7hK006DEpK669QAAAAAMQJzHWYEm9YYnmqW+169XCpmtbEO3RfGcAAAA' +
            'AABG8lOYhWpnK90aMzgR83f2/IgdRlt7vOYAAAAAAYAswp+H2AinILDPyxB2qjRZCP0ewWm1IwAAAAAE' +
            'ExTPAN3adKUUCkLLN6EWndNItAdzl+s9AQAAABFgHCAgjbtMhy3nJnljk5LVSC4m7+b0SF4AAAABAAH6' +
            'QAAAAAiwDhAQAAAAEWAcICCQCsooRxBXgtiIL7P0PqBa3pxk7wAAAAAAFSIiCaDPCEG7MDrkdUByESqV' +
            'nXLNe0AKAAAAAADuT7DA0dGzTVsvKzNiaBCWQxE8ZTZCaSkAAAAAAHx6dIDsFfcWirZDtnNiA4WL80DL' +
            'aQoYnwAAAAABKrqMMu2g1TgGJgGtuPc/kXQIcTLlH4d9AAAAAAFZZgTqIeg1kQE3f0EIrhyCsXqij0HA' +
            'RLgAAAAAADQncMBQjggzDtHn3751PTERlbvHAAjlRgAAAAACcan7oFc/b76ZNqmRfG+ucmVyP4Ii4nyU' +
            'AAAAAAAxW0M0Y3Fkyhqd4z/tW3FHQ5Rq3S3ZJi0AAAAAATe7d4B+/dAGT0o79Q35pncTIn4gs4gj4wAA' +
            'AAAFMSY3tI/RYT1Y81PwDwHges0TgZCH8MyVAAAAAAbDZtUJkoh6ZBlpZ5HodJeE/gVWjF5A4cwAAAAA' +
            'AGHzJbqbIEWrzff4Or1QbSAzhB8oPP3YRgAAAAABoTuGAL0hW/hz1ZvTRRXxNYms0jHoisGUAAAAAAYc' +
            'nzaAwaHojiy+P4VVU50myij3MtJCrvoAAAAAA/44O4DHTOg3ne4wgI3+wHyL5dMPOIvZcQAAAAAAn9zE' +
            '2cfWEDGeWHsx1+jGWA+EFi5K5d0pAAAAAADGL3lA9wTfUaCVBaoUq2hAvFbG8sAR97IAAAAAAGempxj6' +
            '8idB+LdO1kgFiy6bMJ7LeqpegwAAAAAAIR17kQzK7aAajjg4ibtBYT5SYsuJQwy7AAAAAADQncMAEFnF' +
            '7Oay4k00xmP6msPCdL5epuQAAAAAD0/YOYARZR+yMfK9BJ6Z/QDDe04O+i4ubgAAAAABjtMp6hLkJZht' +
            'X8p2jumSh4Kpq+csi7c7AAAAAAaupz8AFt16S3HPi/GyXIctHoJ0WekQrcMAAAAAAGlJEo0XuFhSizsv' +
            'YgkGuYnjk721z8PtJQAAAAAA73BiUCcmGWW5t0DB17reYUdI4lwwqoi2AAAAAAGhO4YAyByPwMIQxqzt' +
            '6ram101EshjCttEBAAAAExyEIYBSt4dGCADSJ0TcqwBM9vo+bOHuoQAAAAEAAfpAAAAACY5CEMAAAAAT' +
            'HIQhgF3HmG72xGIZ3XOaa3rxP1sZ477hAAAAAAOqxe2Aah+Y9dYScXR+jn/ISclPhl75gl4AAAAAC5C8' +
            'Wj2C6jSdcLl2RaAmHaUp8nrRJDwHLQAAAAADQncMAJAGXWu8PODQ9FECJeKl0bBEXU/TAAAAAAA5uvvW' +
            'oBTIuWbqaV7R0vXkf/UMlbqHGVMAAAAAAaDcudShfE3QDAkqiiAExfdRjJrLRkOxSQAAAAAAGUFDLqsB' +
            'AFzy529v/o5VtPcN1CZGO4ydAAAAAAASejmA13UqmEAcXBia4HFMnQj9Jupr4rMAAAAAAD1X3ZTZdfTf' +
            'RNSoVt6wOE45WRlTAww24gAAAAAfVVI9xO0t4N2Z6zP4S50cjXeSTQ4e4H1IAAAAAADIS6KA9qtkF91G' +
            '2UcMyvGlToEQZQSd/owAAAAAAD/G54D8CrKYJEjE2OMi5j1eOnc9ThELDQAAAAAMOT5tAPw8UCWAf7g+' +
            'glcrMewhlpFUXJBvAAAAAACSq9WtH++SR8Zr1AwXkyLVrRS+4THS7NwAAAAAAPYBWTYg1/jclb2EAdFN' +
            'WZB8wBwc3ref8wAAAAAAFJTcIC3AlicwaGaS4KhvXDOdKYMHzpCIAAAAAAgmKZ4AQZfC9B5J+MHxTa7p' +
            '3CcF6iUQBfgAAAAAAVDikBdjS93ekI/o6BGtNj9PJDUz+fRtlAAAAAACXCTZHKOlf15BXuEjP27s4YS/' +
            'eucg18XkAAAAAAB6SEtqq3nvmfH8cKNgVeIRfiwIfY9JxPEAAAAAAAvrwgDDY1tOJEfilKo4eAP/hb0K' +
            'l1baAwAAAAAA0wykR+PquDXLO497rxOnokyDxjmogciHAAAAAAZ/GcjA5sCI6X3OaNGDAlkoMRHgEMJD' +
            '8R8AAAAAC60sRYD7Rj+OhPerzGbQ5zCCvq5ED0inNgAAAAACOEFNlwYMKQKIRQ19GVaIz8HVueAbEFJn' +
            'AAAAAADwvjaZFAWahV9DBwMhBT/vdT301tng3soAAAAAAGhO4YAlkAIHv6plfslaiKtzdNHNvzoeXgAA' +
            'AABGIHRWizDRSN3ZfO5j8Peyh/ule62jPEgaAAAAAAAR4aMAM2eLjeG1iZuBbQZ3V5gES+/q8IkAAAAA' +
            'AYe0LyA7h5pKlWbESlxFCnsD/P848houkgAAAAAFlkn0zEncK2DDq1LCcw3JRi7poP2eRG7+AAAAAAML' +
            '6xT1StmpJNJbT4uHK6zBRciMrrJRM+gAAAAAAI8NGABNTUUPX9bsZRa1sil7Qt0aIqnyCwAAAAABY9b4' +
            'gGolT7+1xaEmP4+ApoaIlTum8oxjAAAAAABIPlx2ajJfnsii1+UGiWAZpT+RhxWxXugAAAAACno1ggB1' +
            'y6sOnm5GM8fcP12pc13i+2cPMQAAAAAByuuWx4gOo0G9eIxWy3tBWGzXxksH5etJAAAAAAC1fwNAqIGY' +
            'KCQbQBPmZzCA3o2F7T9Ca0YAAAAAATaQZQCrrPaC5gR8fWMiqexuFOd04rTBkAAAAAAAqxC5gK2J/OGb' +
            'KU6xCYvsqfvvdX9Zw/2HAAAAAAFkb48A4JT1Yfr3RO/5STcOyEaWlo3GqdYAAAAAAAExLQDQ8Ol29l24' +
            'w6kpvgSXUUTgcbfIOgEAAApoDv94IO4Jfo4ozTSGMmVSBEgJhqstuV2yAAAAAQAB+kAAAAU0B3+8EAAA' +
            'CmgO/3ggMxdVSo6qgupOEDhgHDmqKyuiTeYAAAAAAF4KKc49h3hfxED9UOpj9bv5IJnwYI+YeAAAAAAC' +
            'AClN/UDvEPrcHqPlgJXiKQiiMjZnxv/+AAAAAAEz3rKA2OqCrB+MYzlQaVEeTt4bJkho9eQBAAAAVuCJ' +
            'k2BC64a45gg3QHEZwy0MPL/1bDFZDQAAAAEAAfpAAAAAK3BEybAAAABW4ImTYGo7/+Jg7f7Q6M6ULdUI' +
            'ZqbgzQujAAAAAAElyQugbRpUUqykggqBfxpJHmYcKQzqykwAAAAAAEXeWkCS1hloC6Fi4iT2GkFy+MFf' +
            'SnrVfQAAAAAGGw6rcJ7J8I4usaiC4y9WIq4q0LQJPbI/AAAAAAG6v/awoLyfT8BlDcynhgIbBFvio2Ye' +
            '2+AAAAAADBRn+nOm9GrfEmSbyfGbY9DNh3RkKOJ1DwAAAAAAAjBW6MHXRjpVg32Tzhkqg11esdt6t4TM' +
            'AAAAAAJUC+QAwiSK8SK3betXxYMjRP5Op5CA4cUAAAAACazb6GvTCqOI27p5t5t/Z9AYettHvmU4gAAA' +
            'AAAFYEVwgNZQEcp2VTzKsI/tPR0xHWkhPn0iAAAAAGvrHcUI6lQWRUSZUjOCVxM8b69i/dFrjKEAAAAA' +
            'ARC0SrYMTemU0dXbH8vLbO3oAgI7JMbyXwAAAAADlelaACBZJizBpfuj5PS+hev3uLyqLYgBAAAAAABf' +
            'XhAAIWFcGh8nvD0ZTzVBK5YVRLcBAckAAAAAAZ8kgj1rJEVTb7XfSMhgFkSPemmYss9uIgAAAAABLn5a' +
            'wG9OTNYHXwYUs4BItCPCuYig8FHeAAAAAAE47KSAmY3H4hu8QNRxnZQR1tnvR3f8/xMAAAAAAnyXX1ja' +
            'UxWlDe8Rta5UzvRtnBJMVxs6VQAAAAAAPSeEgOB7uBcED+cSaJryyfGVjfCWZGLCAAAAAAN+EdYA6w1a' +
            '6DOXOar2z3ZPDKH7m0Rz9BEAAAAAAMXHtyT6uFii47Vo57nOq/jEAaUBzSkkoAAAAAAAC/4+HB+adiuH' +
            'F+7CpadvbYdkyLO7bw80AAAAAAAPpW6gMo4Lg0vjiMcHDsjqEG+ERBPE110AAAAAGHqk12bL81Dy7h0G' +
            '7XEKtSfYcOYIHwdaLAEAAAAECfSwIF0ChtnDy8jOy5Dwn+unbNS7k8uKAAAAAQAB+kAAAAACBPpYEAAA' +
            'AAQJ9LAggG8cRl3MybZy7dTm1wUtEb/urmQAAAAAAFe+wuaMftON+6q4NmoJLjOb7GGXeqDcNQAAAAAA' +
            'ZnQ1DqdnqclzqxupFPrEGi5DTzPeq14fAAAAADfxfbowr5bZRvPrg2hmyV8o6jUh4m/T+4UAAAAAAGzp' +
            'LzfDE1yGZFrJZck9PR4anwwexYahUAAAAAAHlCGVgN5xz8NIeiGJCFdJnWzma/rEIOZFAAAAAAunNmSA' +
            '77Lm36hkuPM2o9RglnI4VTXYwmAAAAAAAT5J7wAAh4uMzA+j7uf+Kjj1wHORL0MuUgAAAAACiws2PUg+' +
            '31GmD47OnjWMFDFQ88zl4WKvAQAAABFPkc/ABXgilYS3kbMbsHD0cwOoMy4SpYQAAAABAAH6QAAAAAin' +
            'yOfgAAAAEU+Rz8Aulyf31NcP3UWmoEYILwfsQWXErAAAAAAAbzGbyDMeeWkL8oxG4561pboJPpp5rkfe' +
            'AAAAAAFg/bsDSpZXLrQBCYN54RRsdIPh+ANfWNUAAAAAEICIDNtMLHWjr7lnQzfw+vUpPfa5YIIufQAA' +
            'AAACIwD1gE31KHRV9cA5odwO2RX2uKgksacWAAAAAACn8SoATtUae5NPFZEMIpnUuaomCzSEcQoAAAAA' +
            'ANAFLIBRK6srN7v7lfizO5jvR8eOZgZNYwAAAAAG0TNKMmMxER/xXb9Tt7n1zXP9DI8EXqAhAAAAAAAA' +
            'mJaAcx8I0dE3x/JzwPiImp8iY+IK3l0AAAAAHAh/T0igvIIkrN6k3peo8XJGAphgbmQ6tAAAAAAIvAI2' +
            'gK9nYN2sIsfs54DxhtT8pl1tDoveAAAAAAAX14QAysVG+6rQv+NEUa77Tu1pwZOcVwEAAAAAATe2lGzl' +
            'CUWIYZKvjeqHIGMnmOTlBfnsuAAAAAAALTRhNPcw3t6n2Seh5fvn6348Vr060+BBAAAAAAEzlqRU/tNB' +
            'JtfAq0lwEApboSq3d5mMObkAAAAAAaQj02oBg/CuqvFBjFnQP4Dv7mJ8G2P+JAAAAAAAM0ipgAV52XMS' +
            '4j0sQG/dY7VmRkXCviSxAAAAAAAlWmlHDrV//ZydpE6kHjg6MHLSqkxrLxEAAAAB0zue84AaAnj2oC9n' +
            'zDS00UG9ENy4PgNgZgAAAAAAZoUeADCglc+IE18l2MyUut4oD4sZJ79zAAAAAABoTuGAN7xKULE1tUCe' +
            '4gPFOkmT2ghlQ5YAAAAAGAU/TlA+QTSAvhFket1/zPht3jZDH4rgDgAAAAAEee8qC0DQYSFbDDpAnQWd' +
            'zgJIzCZeRJgwAAAAAABCKbXfYYPZKcOP9EUUmvYMLXadvXX+PN8AAAAAEGPttwBi+JHsO9DttaO2kbSJ' +
            'k2aBgzSU7wAAAAAEqBfIAITf1HMI+8veQ26p5d3w28Jy//B6AAAAAABdQ21grP0G4b4KmM8130MnjCdk' +
            '0sjawGoAAAAAAAL68IDSr3UQK1eXPD0Ehwhdz8oHALRDuAAAAAAA0J3DADPdVyDo0q86YI0I5Tq3o77n' +
            '5xGcAAAAAACseb7KNd9EEoRlHaeWxcZgFQIPaz2ZH9QAAAAAAFxE4vgqLY7Y65NL2XTweCPft2wEApSr' +
            'iQEAAAARYBwgIDsRGsSB2Z1mwUyCSZ1BVVNkqHkrAAAAAQAB+kAAAAAIsA4QEAAAABFgHCAgYSBYHopT' +
            '3+TRVHZx0hwspeX9xzcAAAAAB1WL2wByZ9uzoigpcn8Jl/DWZJZRhHxTdwAAAAAulsjTwYNVFLixtZuW' +
            'B3s3B7tMwFgQkXkYAAAAAAf6GD2BuYuM7Or6S2+RCTsNd38uABX//zQAAAAAAALkDSDMWV/4Z5Ee+Eaq' +
            'fwIAnBrE0FPIqQAAAAAAaE7hgNOxCDg2GonCbXUsXJtevJodXS+6AAAAAAIJimeA1G2vMllRVOBQQrgq' +
            'DfGYSwVONCEAAAAAADUyeCDZkX0IV6PEeAwBn/WeHUP+lNuI8gAAAAB4MuXagA2ljSnUdQm0D6VHXsDd' +
            's0SQGedTAAAAAABmaaBWJvKEiTVjVkzNwN4+qua48RG2fE8AAAAAAM4f8cA3QEH5QFLqCyXjWmjnVlWK' +
            'BSk2eAAAAAALpDt0AEaQYgjro6DUnQce8e47JU7epfNnAAAAAABhoSFGdQD0lQ8VI/ODH36gQcN5jUVM' +
            'zOQAAAAAGRHETaCwoXywgm5TJMFQtzMY46QebiFvaAAAAAAAJApINbtelU8DGJ02ZGI3Sp8bfgp5kc/h' +
            'AAAAAAkGiAVF4lkhySzm61y3KYk+tjtjg7qwlZoAAAAAAJOFgMD9zSa0i1YM3NcchML/Y2hlzOze6gAA' +
            'AAACQe+RO/+jGV4o+ieUqxqk/sZmB6dc4017AAAAAAAAmJaAFZAup+xBqYC1ShVkdvJ8rumjPSQAAAAA' +
            'ADMcaWAe3T1/4t27OTt03zcLAbz+sKUnvQAAAAAAQJrFyCQ+rUALZ8VKNtYeC2IoIJiQeXniAAAAAAAA' +
            'mJaAPLDomQ+CYRkpvEdEl8pbrPXDMOgAAAAABSrIb0yATiiSBamVc69e/cv8Z4zSD52tCwAAAAAAD6Vu' +
            'oJfiX5BnDyyiCYsdzAtBWgwzxWpoAAAAAAAjw0YA2Gq/6H3iCvWr4JWRU8+cTqP6PgIAAAAAAGeuqeDZ' +
            '83FcB2ddGwMklsiJxV9tvfguXAAAAAAT2MzXmdyiN6g4r3uWf1upeXY5/OUYGVvXAAAAAAB4eh6D868A' +
            'DWMw/SCbQHE4sERYuX3XF6MAAAAAAeSV9IACT84yMGw0vH+OGpLRC5wqUkYLKQAAAAAAyAgdWAgTNnDb' +
            'tAPyoH3iw5xj+VOdSfH9AAAAAAA3zs3gIAAAZOsi91YM6XJD1wJuiI6zuCwAAAAAASoF8gAfcLAllNDx' +
            'haXtGZq6SD7NpnBXGAEAAAAI1BnQwJ1RS59Q5V67R1QlekaiouUXoktPAAAAAQAB+kAAAAAEagzoYAAA' +
            'AAjUGdDApe9Bc7emHEbezzTC6ynOsYy76IMAAAAAAHK9K0CmigrSsSDurXLSlRvD3u1XN9aS4AAAAAAA' +
            '3bqyALz4J23WfxrT4ELVR8Nu5qD0ztBDAAAAAAAVLK9Q09sk5O3vApKxqMgwWVeL7a3Nk/QAAAAABBMU' +
            'zwDXBOcdFghZRUcGIAbexQJ9V/snAAAAAAAEIQiZfuRxsiwlmzXhWo/AYiOb3ZoURSxIAAAAAADsWxe0' +
            '5/PXQHf8/Z4GRBS6/a46l6NwipEAAAAAAUxLv8ACBiAPMdEkx8E+0ZPBKMn3X+kgqAAAAAABOOykgAwf' +
            'QwlvZlJMrzw13SPR5sBubhBrAAAAAALnMj+UEkQKTFnQ5DVx1AkwgsSfKyAWcI0AAAAAAGhO4YAZi39e' +
            'kyj75PrrsaYOV5X0VoNOQgAAAAABCj7VYxwUuhtwzxYVJ+cHkvVfH3E3tmsfAAAAAEDI/g6AQH0pRBlP' +
            'hUVWuL6KTBcMMekFJIQAAAAAAJx2UkBP5LXcx4HcDfy8h9SFSre7ne1qpQAAAAA7k61Pi1MIWuC4pZCi' +
            'wcGirNn1LJGhNn0vAAAAAAFA9wN5ZKE4zdtpTgwNn4oESCffW7BAfjAAAAAAAyB9iYBl4xKkftaBVGvr' +
            'ZxrL2bMD/U+shgAAAAAAcctmq2bfraIhdSUq02ds5jnR3o+kyZjUAAAAAABoTuGALI0MybifrIaBJbdT' +
            '7dDoRAJ9WCwBAAAACBPq5uBypjJGVsUlowVm1TjbDVg3qLkWLwAAAAEAAfpAAAAABAn1c3AAAAAIE+rm' +
            '4JKdyCA10jfskbHUwivK0vxNmNGpAAAAAAI1Z6d2qlB4dvmwHdfBb329FMf3pxQoeM4AAAAAADlelaAK' +
            '/FDpOaSQ3VL8gsLYLuw4xQ3M4AEAAACLsslwAN7CXQJCB0aDhGWcjpNT5yzvwtGKAAAAAQAB+kAAAABF' +
            '2WS4AAAAAIuyyXAA7qq6tmxNmApHsIQXzneGSvYoMKMAAAAAAgmKZ4D0NAT/jorO50rnay0G8FvQR0Jc' +
            'XQAAAAAAXGMfgPX2cp9VJmaQAOF2e8zh2R8sIV8wAAAAAALFI+rACKoF+3UTRLbv4M8kfbsfQx09rBwA' +
            'AAAAAD6VuoAeLi9MQRljJN8+NyRQMojD2EoufAAAAAB0alKIACrgGaneSjG7WFJwfVVxteiBg8VJAAAA' +
            'AAw8EEZYLpuSd8UvXmRsGWW2lxTuOUOG9UQAAAAAAJurwXRCNlwlfYdu0pX0dhPcnNuVASxR3QAAAAAA' +
            'O0bdoHm0YUQVhvuYEtQE7MFbTni3mr4fAAAAAAPRUqJLfzOW2PJv/2z5EcuCh+NJa3eL76MAAAAAAJTK' +
            'O7qw5LcP4kZV+W7rCEUKB4rZ8b5Y7QAAAAADsj4C/7Zte1Bt5FhMOuFnkSruPVLFtHP8AAAAAABJ9RsA' +
            'wVwH5/VSx+jhc7JlgzU/EYDzZfYAAAAAATKqeEDRKsahY3IZy2HK9K26rOWsCcOkeQAAAAAAaE7hgNE9' +
            'Y35EtqahaNTIFIPey6JDzq8cAAAAAASoF8gA0Z5fbIKe6RREnHFuQMaFybGGGugAAAAAAA+KurDnnFuf' +
            'WCQG8EviguiZ4gTUT8zgxgAAAAAAaE7hgP8i7iigUbnU2CoHGjq1wfkyzZMyAAAAACeVxs1BBd5Q7dWQ' +
            'OGrP1E1QIOft3pnnTYYAAAAAAaVgo80GIByQjXn6g2LaXQS34V8aWghylAAAAAABOOykgArf0nyVXS2Q' +
            'U03/Yq+7Q1DD9E7aAAAAAAAPSVUkIfPCwI2Gf4/TP2tizWO23ZrFz+4AAAAAAJLdqABXjaWzqEuG9+7N' +
            'BlPl9jYHwBm1+gAAAAACVQMVQH/oAHW8LfzK1/VO2DcNz4ShvxQYAAAAAASS2W60m1X1uKcoMHB6AiRb' +
            'YFPaYHvZC4wAAAAAAACYloCeA5rQG+GuY1xyYiZW97i82CCZ5QAAAABl3Qg3AKlTzGlzkMQy/OaeqmHj' +
            'M3G1qVnmAAAAAel4IjpJrGOEp9t27pxkZG9gi3msZjIkbXQAAAAAAS5+WsC3KTPxIZ7cdWzq8UIUq1Pu' +
            '6ehDfgAAAAACx3fFe8K/tyfbqrHQ/Jz7LodGrHW4QH98AAAAAAmM+4cAxUrq07WsHuIF2iVrQYBEN/eA' +
            'JA4AAAAAEExTPADU9UsBOpncCMzm0q1kLTV4el5CuQAAAAAA0qpyVvJRgePPMb0hm4dnkfwy/Rgg5crY' +
            'AAAAAAOcLpOA9LeuTIA9xMB7vGx+ktUXi/liwNgAAAAAABoTuGCPtA0sdhlvcFbQJbX/8iwIhoSpSgEA' +
            'AAARYBwgIPVu8ChItazx+UNbySJOiX0Sh9SbAAAAAQAB+kAAAAAIsA4QEAAAABFgHCAgCIggXpt8eJbc' +
            '3rw4vH5BZXXx8rwAAAAAAJx2UkAPgKTBTlPNq6TNecNqCQF9t6/IugAAAAAAAmz4lxCDGMMJ623L9PqF' +
            'NGdz1kNBJa2pAAAAAAEJIQ4EFck7GerFK/oE2IDUy4IjZmnbUu8AAAAAAKR1g27CPleEST9+StJSGecM' +
            'bkSHrL2HAQEAAAC2cSH6IDhds3pSZ1iicjZ9YdpIbhZUudluAAAAAQAB+kAAAABbOJD9EAAAALZxIfog' +
            'PUEmpo2G/1PlkI0CGiLFP5jCH9UAAAAAABLGhMBIyjmB58UvK5NT/hFjg1za/l8vEgAAAAABpd6EZktw' +
            '7mS3TObPcT6vjhFlUWcL4+b6AAAAAABl8qIAe84Ubxc906HoQnbWJbdhdxd27lsAAAAAADA8CjigTlWk' +
            'ADeZ5DXUe/6qOz5qalejSgAAAAAXEpyXIKMTB0vHpapDVxshRXvW0BKdeDb3AAAAAIBGbrNmpWNFsDy0' +
            'yGDBkro94fqOVk7IUeAAAAAAAHzDRLG8BrmwY6tMTL1BcYkqdmmnBbJDnAAAAAAAAJiWgL1Pb/FrZGwS' +
            '/IQWrtr9SyilDeZYAAAAAABkI8If0WFokq1pWY/M+hN7LphHvVYzmm4AAAAAAA5fUQ0Xv2Y+e+a4wsfR' +
            'H1i3QmsZHspROAAAAAABoTuGABltDJUJ+z6zPPU+5YbJgN+5OSn1AAAAAAQTFM8AJUqGrrHugw4qvogU' +
            'Zem0SqoGFvkAAAAAA1y/RM6M1MWFGBq2EflDjErdfB12K8oMvAEAAAAi7LJcAHBBEPfSCpDdmJVuzahO' +
            'TQbFBS9SAAAAAQAB+kAAAAARdlkuAAAAACLsslwAm8mef7EUmV1h3ZcC1loKBgTvTMAAAAAAAAW42ACn' +
            'FzbEa9w1t/NMoRC3oMW8dGLbWQAAAAADQncMAKiaH5mrhjK188SSm0zW4TTl7RInAAAAAASJoxrKz/DB' +
            'V/2V9A5PVfwzeRZLqJ+3A1gAAAAABEy9lkPSMTuFav7kZeozTU2ToBfUK7zdOQAAAAADAAF/QOtXtd20' +
            '9rSybckE60d0+1TBA8UEAAAAAAABMS0A9rHijnL/PCoYNd5jo/OdD9DwI50AAAAAAB3NZQD/56QOYHUT' +
            'zzGK7/05KdNYTv+3bgAAAAASoF8gAA0FnL6U2Vu6AaJA1S1UazQ3MyJ1AAAAAABoTuGAI4DwCm3qnE7T' +
            'AlsiheV4KUbaZUwAAAAAADlkO1gvBTLj+oEe+juTKi3a7b1w6T4J9wAAAAAATQ+LgTXW23aPlzKTKG5v' +
            'tfvjPrOa06zuAAAAAAD4jr3ZQ4aIv79y4FNiNThwSb49YWmZY6EAAAAABg7j8+lFDK+JkWUAC3YIdacy' +
            'kx6HIZshOwAAAAAACm5JwE5LftlDarTof3S8mcX9KGwJOQADAAAAAAHcTsFcbYcm4zaGR7q2wnf8q+VM' +
            '5jciR/kAAAAAABl0TZWitrCZSmOErO+MOAZnnAfhKzeougAAAAAAIuL4ILlmrquxqpn/VhYao7LoHFXw' +
            'gIcxAAAAAADQncMA0xU2UfCqJL8/yT82bOD1GuqgpOYAAAAAATjspID+SR11QTImsYhBmJvUtU/tG5Uy' +
            'twAAAABMK3oFnQJm5O799ZLTxwPW/mJjn3g7Wcx3AAAAAAA4U45Ae2bZjSafmhZ6QNWXs/YNr6piEeAA' +
            'AAAAAADaM2B9y5x6w/T5GqxPylApfMe7zzuxeAAAAAAAaE7hgILBG8AG+D5BcGmoqC9GuKXlxc19AAAA' +
            'AEhHoSCOiQoUIDiGyaIBfIyPU4OUjF3x/owAAAAABiJpCDTIZ66SOPNsYaiSiyii1M+F6h/r3QAAAAAB' +
            'oTuGAM3kgEXoJ+RE43xulMd6uZoJx58HAAAAAAGPdQStz/2Yxo27Z92vHfPpPNI0jiZZJfkAAAAAAGjU' +
            'ZTDs4V93S1nbEGenYw2DvW0rZgkTlgAAAAAAnHZSQALyjUqjj7Q8SJ9geflmGyyCgUpBAAAAAAgmVQNC' +
            '/ApCG350YYaLIuo8qXkE4+ANAqwBAAAmMuMUoAAHoKVVnvfEkZZBqsP64m7eODzuhAAAAAEAA/SAAAAB' +
            '6PHBCAAAACYy4xSgABWUAfGKhyn7HLj5sQnTofl716SZAAAAAAA1DFKAVN+tFqLOsipJT3U2M8o+ya7m' +
            'g6oAAAAAABoTuGBdtcG56yHxr4+RG/L9gJZTWNQbvQAAAAAAAWd/QIQNsBw7FWHrg6iM31RKT6niODMO' +
            'AAAAAAE47KSAmnQn+d03FK9xRnlVI6Ui8vBoK0oAAAAAG1iQxoCvzTE3W5xM/zxqiu8xcuuo0a0KDAAA' +
            'AAABYk0L47U0P/OVCpss33GuMglm/mAQ0b3gAAAAAAKgo5qzxLmg7KYIrJThxoH+M7EGNVmHPlAAAAAA' +
            'AJIICIDJP1SlDcNi6eHmVzW/IAhlxKJL7wAAAAAAdk6L8P5dqvAz50OcgWq8sJp61Th+02l1AAAAAAAA' +
            'mJaAAT+VqcjeLZgKfCcnPs+Dw2KLsrsAAAAAAsbIZAoob7QBmRNT35GEpC0xI8yp4QgrmwAAAAAAlkSA' +
            'FHtS2j5qACr3EKUpSKL4CQohDkwaAAAAACi9nukAi+uSRxEXX/ToEqb8IeCP7G8ihOEAAAAAAA+lbqCU' +
            'BiDp2sKaJqC4Q8uvKt5DqwbhdQAAAAABoTuGAJ1LISplTTp/UpGujgHgR+3mQjV7AAAAACIT3MFZu5RF' +
            'u+l7TGCYeq076jR7wcxmPUsAAAAAABZaC8C+6Ppod9ZjjGkboWo4MhVTJkFJrgAAAAAGupMBAMOQWoDI' +
            'WbUe+sZDnGBI6U8wIFE/AAAAAACy0F4AznUkV4Dq7As9bqHBRfvU/PcI59sAAAAACcZt1sp8THwGJ7Vx' +
            'GJpuG6BQRYtgKyPoMQEAAABW4ImTYNDMUnYX2P8/CK5z+BFWrS49GStGAAAAAQAB+kAAAAArcETJsAAA' +
            'AFbgiZNg0xiXg08sy1rzvZTjnlK7ZSO0XOwAAAAAAndQK3DaNw2YFtml01jmqnffmFz6t8zNWAAAAAAB' +
            '0kHcuOKvVVPckUvf71M+exiQxBh/+7KIAAAAAKdKWZCQfZiibudnJvk0RcZX1zAlAk2Mt7YBAAAA2GKm' +
            'RgDoJbLOZdYZhAwSj/k5d/Ff7cOsqwAAAAEAAfpAAAAAbDFTIwAAAADYYqZGAC3DFJ1kPXMLDszkWeuH' +
            'j8gnWdDuAAAAAAFrJGTwcTAA2RCtYF6C0NjCY7mPdfQQc8EAAAAAB2iqQI51GWl0tj3SdKtkR2qF5GXt' +
            '0oOjKQAAAAAARBs0zqPCkFXkCuNMvvUjEVVDi7fdKs9GAAAAAAO+oSt51likF9Ok1fYRTZcjKvOXgGhF' +
            '3dUAAAAAAAX2qT/ZkfnLCDmIDYdlrpxB8gFWMkdimgAAAAALcYwbcN5Q/OM/1wthkKlmXVXIFrK4xIrU' +
            'AAAAABNa7yKA3vEVbRPKB9ekJf5okgmwEmi236YAAAAAAO3GytrkVOFL4GFbmyqzY+4dv0rZAJYsxQAA' +
            'AAAAZjLYLwg91lygmm9ppZ7cK8mNOeptYht2AAAAAACw/XLAD6rJR34iEq7216rmCsvoa2W7SMYAAAAA' +
            'ApphQwARUAzdaFKjOD+w9mLkhHpFE5TaPgAAAAABwPotKxTswKmbsK/28SJKY60ZnMvVgI6iAAAAABDJ' +
            '1isOFwvPsoEpBwrvmQyjEHAeXYNC9dsAAAAAAACmUiAX3f5EJYgRwRJ/M/uBbCBCOAWQfQAAAABII6Fo' +
            'hx3FjULD3W5a2oCBJpMT2Nnb3G9jAAAAAABoTuGAIj13CWZISV8aTmfwDqZrLSqep/EAAAAAADMcaWAO' +
            '6ZQeEtEeznMmG2l/NKKA0srv1AEAAAAIp8jn4DHXvxisoV/Y5vp0ea9T5DHfph8eAAAAAQAB+kAAAAAE' +
            'U+Rz8AAAAAinyOfgNGFX86IilC57CcoYsRkeTalPCY0AAAAAABEw7fw01EQ7OanwDC7Tv/mqoCE9gpQ7' +
            'fgAAAAAAlQL5AFqhiBe0dQ+oKZ9evua4ttnj6wVQAAAAAAQTFM8AbsgA6II3ZY1WOUBMk7XTMWwmKRsA' +
            'AAAAAnQdojRyqS1QPybsoeJApvu6Ij2fKilpkwAAAAAAaE7hgIcoZYz/59SFLqD6rRv6tiu8/drgAAAA' +
            'ACKwL92Y3O8r9u+xCGtj+IVWhzno3v3KLqQBAAABl3Qg3ACXnPcPh+wsgHDVyxLgXytqRmtxPAAAAAEA' +
            'A/SAAAAAQ+iwJKsAAAGXdCDcAKcM4lD/xmXau3ryMTVzXarQNZYyAAAAAAA/xueAuHovWaz3mpj8w0PC' +
            'zvIPoMZfMIkAAAAAAA7sDVjeOKPuqAtU0dX1mwpGcTyxbkElpgAAAAABOOykgN6IqVa4LbuB4KohEnfa' +
            'RkXJY/bYAAAAAAA7pXhg3xhaMwp4Mcyx1/+/dVi1s29XEbkAAAAAAACYloDfQxGZNG4KxnKitG5cMmTk' +
            'eFOZQQAAAAADqsXtgDzYQcPoLLbJhT4nEbk0P4oNHXcwAQAAAFbgiZNg+UFtfv8ctLPy5NhebIKf8hHm' +
            'WyAAAAABAAH6QAAAACtwRMmwAAAAVuCJk2AAHwh5cPNKRNAH5szraGEXCDEioAAAAAAThYJV0AFiKmM5' +
            'uHciHp8kiQc//Qq+zQFEAAAAADo1wdqADjjSxYV+ldZJ1ZiOtrTlanr8+e8AAAAAFPdl9IAQtrL+5pg8' +
            'A+l4iFxl6FrX9A0DywAAAAAAPy5RAIR4FjCczDILzX7KG6SQWnDTt/E5AQAAAAOGq63gE1bNDnqzQuRl' +
            'X8L1wLrpjKp6UFkAAAABAAH6QAAAAAHDVdbwAAAAA4arreAeNCkdN0ig58DorfaXAK0hs4jvqAAAAAAC' +
            'Hmb7ACtg7Y42gKcQTeLeZc9R2VCt0GRRAAAAAACAZ6S5Lz337a9vf21GDdysur5nsi1Q+N0AAAAAAAOZ' +
            'oYAym1/UHCNgxaqUbjFnK+tB8GHnIAAAAAAEZelw5zgTnVX2fgGLvDbV0WXNsy9ES/ddAAAAAEPwVkqh' +
            'QBivrgUJfqTl3KWc9+bIyyMKqUEAAAAAAGhO4YBAbYvqplqxGm5+hmJa9P+prO1n7AAAAAAEOS7tH0rG' +
            'o+mc89/hAkqEzeFeErk0Ftg0AAAAABj+7vskUb97Zt1uGZW3p7M5VqhjLtxQ6mMAAAAADEPuU6BnRrV8' +
            'OoyhLM26jiWaVdmnwk1XUgAAAAAA4kRJDJM9kDWS/RDd9jAdioorFPv+aqW0AAAAAAEBL2pCol4vSejh' +
            'D1yIuJIR/gsXgvFjm5UAAAAAAHTTOgCxf87XTpYB0ajapO7erxOJu4WpsgAAAAAIJimeAL0fT8ZrE21l' +
            '8XP1LpAm67K767BwAAAAAAADkBgY2aaeHvvEF2YWFeqXTvB4hgPrqYgAAAAAEEdiKNPxxY8070GWzOi4' +
            'nVDOQUtLQSZL2QAAAAAGwMhZ5hLtKhQTX7ZhovQcphg8+pwxJHCZAAAAAAc73+UgFkkaaOb1UbCIAlTZ' +
            'c4m/0RvvR4IAAAAAADaP5UBY7CYqpGEU9WjM00CLhubUjJbHSgEAAAFhQCrEABtGui7sbwJTKMuHO3vO' +
            'QXvphj0kAAAAAQAB+kAAAACwoBViAAAAAWFAKsQALERmhA7H9NWM86QV9P7Zu7ipoQYAAAAAAhP4sUCS' +
            'TTXnDqRRBKbhw0ZSWYpu5plccwEAAAAi7LJcACz+V6k/c+TlU9wnn9DyeioQDYNEAAAAAQAB+kAAAAAR' +
            'dlkuAAAAACLsslwALWjSIiZ0Rl2HjaJjaXcG4wRK0EQAAAAAANCdwwAt0WaMqIT2ZKA5SsnrCd8OUjxv' +
            'RwAAAAAAaE7hgGlA7sAoSU+R+GaLiNNh07nHnwv5AAAAAAZCsocAcGM9vEMH1rterEOHv7TkxXClU2sA' +
            'AAAABrRYMIdyfEsi1uP+C1EcocPxF+zLfCQu4AAAAAADPR/cAHUxVjjO3paFEQgZTqGIKrrxyiL5AAAA' +
            'ABbGQIhMhwWt+hOpx3jhV+e9Bc5aF0x2OwgAAAAABsCI4gCHSL3lP4BV1JRbHNtkI2zgf4o3cQAAAAAA' +
            'NxZ7N5KT5qeyuuS6MPrWJdj4mLKPv9fdAAAAADEf++eAvQuwb7B9ojSLLO3Rw5Nx4jT0VwEAAAAAACrE' +
            'LmDGMnEWViiaKEr17rkzIAAm90BirgAAAAAFokqIMMc3DacHtOWS2qzTRqDo/+NNXNnkAAAAABjtSW3G' +
            '0Y5cFl7LogFaPJlK0lDdKnIC/8oAAAAAAJx2UkDZCB786mkX4LMp1tapzm6aUmGV5gAAAAAAn9PtGOjW' +
            'qzhPmWH/SRQj8eV535er30vxAAAAAACBV5KA+NrQw9jSs5qYiqHoSKPDxhwpAp8AAAAAAGempxgQj+oj' +
            'h3kCVX5Y+/mVfXb6UDvFeQAAAAABoTuGABf2vN8gQRLlXF8B2lh82N7BzthGAAAAAADXaHiVJZ4JpVtV' +
            'nXVkDcDljqLtmFZPE34AAAAAACiH+gArumS6dlIrjE3Ze2eTSLZtHEY56QAAAAARqpEYtkXdaTsRGkYL' +
            'q4mGVjCar/BrQDkqAAAAAABGRPJtesJPQIGZbRrO+4VVioV1AGYiiHYAAAAAAACYloB+DuWGrEZ8RmLl' +
            'C2w4mrf66TwgvQAAAAADVlu7NX9t8dYtdZ/CaHps0+A+bUCF7DwGAAAAAAAqUb2AlASuwWwYulj5tPWF' +
            'HzOd7mRCMRsAAAAAAA0YDRunE8szjTiA/Ut13qLojqDa4bvxJgAAAAABq2PLtbd3FR5ANud5gnPkeG4M' +
            'xJhHLlRoAAAAAAGMXvKA2U0FR1JQeqyyYzeeryN3PUThzQUAAAAAAOarg4AKuMOiCOJs+5PD8XjJSqIZ' +
            'w3OnWwAAAAABeUwigCqlN2CHRRcRAyjGP7dIfdIsvm3JAAAAABbYqMjuOzzDtmXjJZtNm8u/UaINn00D' +
            '1FoAAAAAAWKly4BFPURZI7cw5E3HIo+Y3QCvfXsvOQAAAAAAnHZSQG+x2ztdD2/grIiGWefQWvJoRbP5' +
            'AAAAAAEN8w5Ajz/0mAQmmEFVdBy1wlrAHok/72IAAAAAABc+7YCqaR/WxpcnbhDvsoL0gwQH5/GQygAA' +
            'AAAAaE7hgKshqM8D0yGg9PG+8EcJZ6lYepc/AAAAAAIIcVxzBtHKSl937L3e2/FvUI+oIuLGdgYBAAAA' +
            '2GKmRgC164aTWw4MuslRIkp1R1rUoR6wNwAAAAEAAfpAAAAAbDFTIwAAAADYYqZGAL+15GoCQl+JY3Pr' +
            'ySK0qzDSWMS7AAAAAEohZ1UA+BQ8TgPB6q8vwjBByPUrqUUzNCoAAAAAAJvOF9j7p43Q+LEzPzjW1lQg' +
            'd+tQc7VoJgAAAAAAFpbkgP62yC+lZ8nSoNgexjkXY2Sew9pTAAAAAAAexVmQB6KfHV2XSDQmxsQA0qGM' +
            'KshSJxkAAAAABBfGGYYHpEXRrJjqyWt3NILt/xrVh+lcoQAAAAABoTuGABX2DPbkIFYRQJ1uZcDCW/m/' +
            'wIoQAAAAAAIJimeAJsvwsvkk9yddDVjQdgD8PaP8xhAAAAAABjF7ygBEoW9UDh8+EBmGyY+EMSQOAfmv' +
            'zAAAAAAF6YELnEbCnL2BVbRsp5qGn309c5vJDm+nAAAAAAFaoW5hlwI1G0HBXUBgzO3a+Hf+IIDvq6oB' +
            'AAAAIuyyXACdQDI74lexHrMHyTfL3aruaueB0gAAAAEAAfpAAAAAEXZZLgAAAAAi7LJcAJ+c4MA3bfw1' +
            'hyypF9qtWfEdjepbAAAAAAALtlogsKUHIyyO0dQ42W0RRRYgPHWojRcAAAAAAGlZ6OCzkQOzkCGN+RJm' +
            'JnwYZMup/r21ogAAAAAD/aWoxL67zvl5WcnAQdS7qyr8TlbRFhrfAAAAAAQTFM8AyjNaMeYJnA0PwAhc' +
            'HqJTX4HcDRIAAAAAA8kFw2DOML8ndcUnOu9euU+y7Rg8M7MysAAAAAALpDt0AKzNGRgoAywinUr0OTao' +
            'FKDao6fdAQAAABFPmveA1HuxltqyapyAHQMw5oEPHHY+cy4AAAABAAH6QAAAAAinzXvAAAAAEU+a94Dg' +
            'L7IuanGPiOTeCFKkptpq4tjBRwAAAAACCYpngOXzSo5awrHNgMNVblMkJpNRNEYAAAAAAABmONLAFJ6s' +
            'XqyVMKN3jx0zR3bk21K0si8AAAAAAUrOR4AdZ0n+tQ8BI8KjEsS3lPC/6lpsigAAAAAAaE7hgB4PrkU8' +
            'jcaLUJaitOKnHfluHEgfAAAAAACxLMAgSLsZvDBRw5BbIfeGrPGgpirY7KgAAAAAADIALXBYocStsNr+' +
            'ebOFiGeGaO3RWmMeiAAAAAADAQkQa15PwMRWgynixxsg0cn4M+CU7hCpAAAAAADQvc4gajwOZlrx6mh/' +
            '2PbDI/fAIrnIS+QAAAAAAEnx7sB/BiCyKcexQ31Tti6eRMd5SK7GFAAAAAAAHoVNW5tzWr8m9PRqHzSY' +
            'pseGFQc3bpuPAAAAAAaE7hgApiTOYlMKJO0qDCjp94Lovbg/pG4AAAAA9HjghAC4oT7cCq/L/MKwNydC' +
            'qM/1RUnSXAAAAAAAWkGbmsJNAIkOC+ORsyWysHdd7Rrb4xNVAAAAAABGtLN+y43Vni0D3euaVzCjLBKR' +
            'WQU5cNkBAAAAKwApS2DZJF61hnKzpGrQMXuLmVe2eq3uYAAAAAEAAfpAAAAAFYAUpbAAAAArAClLYNtp' +
            'iFCZdSzB7Wj3jIUlKUlbiayEAAAAAAEqBfIA57kNHsBQLFahU7/RZn+VtsKl0IYAAAAAABUQ8QwL7Lmi' +
            'JezrvaPDTBdkeKJrZ31uBQAAAAAAjiOiYFxAhOHZOjHEp+W0h51VfLTshEUQAAAAAAFY0xDaZLOrlmAI' +
            'eSuXOR/RuZw9Ebta20QAAAAAAUfTVwBv72wgEbfhoh8qSDIgRg26QWa40QAAAAAThw40t3OZ3iUVFK5C' +
            'dMUxBJsDkNMdM8WHAAAAAAACBsyAgPwT/VG1gT69JUi9K8NbbItSjU0AAAAAAD/G54CC8owlG5D0khP1' +
            'pcgyYoNSTW8t0QAAAAAAH6Tajo6tIX2z7Z2TUCsEE1jT5FPWQTVVAAAAAAE47KSAnTXP1BNHvGXn00vy' +
            'ZWKOts6VcNUAAAAAA3ZGo5qmk8n5SKMzV/g/yqoobhNQBuwzuwAAAAAAATEtAK88xWwfu7PmFLMOqV1x' +
            '0zCHO9KoAAAAAAB7+kgAv3RM6358Uj+qkI2cPW2tzxbjkPoAAAAAAACYloDDE4dsA/ogGsQKIiVFPgMo' +
            'nrKOYgAAAAAAJr42gOXdHpBMOtfLcIiCfMwJrsjfQY8zAAAAAAFvH3Wg9DlP891oZaQzatDlw6Q6Dwjx' +
            'tbMAAAAAAFWIXMBY0iZ+jpBsCPX8thFBbpfguthcuAAAAAAAnMKdgGtwdc6FdEYI9wCck0wY1Y9+VHZP' +
            'AAAAAAJBcZ9ggdYE1EhqZmEMenDxw24L5nHD5pwAAAAAAqGIaGKKw5EOsaEyebhuOuUTQq5YXX1VbgAA' +
            'AAACHTmXGaQhdx0GFq4mGf+Rn7enP/DmFq/lAAAAAADQncMAqrtbayuVggLKjY4lGDNYVRExtb4AAAAA' +
            'AB1PX3roaqGogtTNZIpqxXSP8j8Ry7aQdQAAAAAA2wwMwOnY7BA9aHMt440NNo1KJgYJACLFAAAAAAEV' +
            'AcOb9w96V1s8xOo+9wr4Ux9KpSX7hRkAAAAAAAfSt1D9GW8K7P48nvdYLAD3Kx/w3l08YwAAAAAABMrO' +
            'gP60Szml9ieho9DB7RaS1kRXVzOOAAAAAAFjo8h0AVNirhxbDfG0Z19SoP6jzaNEKpIAAAAAAGdD2iAV' +
            'vWfN5TqKbIY7jDA7KvJvsAiFOAAAAAAB2j1y/RwIRcApXwsJPtXKnj00Kp2GAPvOAAAAAAB9K3UAHBVc' +
            'nUEPyNCxWfpexke6sCiLoOMAAAABvmUrPbseRftdbr1uplgmJPqaM4dEA0jtagAAAAACF8WXwCDnqh/1' +
            'tddXPFz0fUQ1L3XA6E7qAAAAAAcEVVlULJujGh/Y1QlJ92BIGz+XzVjLs50AAAAAbyIV5JovWPYcGVze' +
            '8mM/9zOWeOkfGB5gbwAAAAAdIQ3aKT2qAGk13xeazX+z8E44/0v6wbZdAAAAAAlMnAkAPuaCMTJvuY7V' +
            '3r8VP//9PgeqIQgAAAAAAD6VuoBMme6Wzdy5VuYGMmYHLmSjJ0d2yQAAAAAH2Z03lFKJ6D8nJuAaBGgy' +
            'mrCORAc0tYF3AAAAAAN2+zpRW9Iin3FvHGsJTGORtQisZA+KixkAAAAAABZri5RovaD59ysJnCubH7nq' +
            'rYTkJtgA2QAAAAADLQHiAGoPdsEy9RWIaWFrY03KejBQU3ndAAAAAA83fFJNm2jeVK498YdrI0u1ukDW' +
            'phz1zXMAAAAAAJx2UkCmrAodqMZGWOztZLlUipbNJGLQAQAAAAAMOT5tAMCzSeIWTCYny+IX2vvdkDWG' +
            'o2A1AAAAAAAL68IAw/9DnhZ/K7pb6AMkCsE9BMb6jbwAAAAAAGUphY/auSeS1RMoV/8Jt2PGBXcAvoWe' +
            'pwAAAAAAFGoioNwHm0kLkycNqORvRYkTDW8b6jGaAAAAAAGoYpQA3yDQB4XUINheVo5mVg7K4Kd3CyAA' +
            'AAAAABfdnoDib4+4k/FOVdd00IjyMoGzJALpWgAAAAAGKAKRW/xGPFYd/T9pJXRvSaVbXxkR3AkeAAAA' +
            'AABTNWZMQXzuWAdO/KjMePak+x+asi89bzIAAAAAADQncMBDGMkiS4yyvPIObpEJoXqPwJRqtwAAAAAC' +
            'jIveYoKDhyx0WqczGGK9MiR8jLXIqFnvAAAAAAA8f6vAjMyQSgbzfjVATL8waDmw/SEaIzkAAAAAABrd' +
            '6QK+UOgi2mjxapahG/2AO0hD51jNowAAAAABOOykgOckJEh8Fm9fEquZlyLK7LWxBrFbAAAAAAMD4VGA' +
            '6wnDIT1Z6Q1iQYOalX+3aYi8B6IAAAAAGYKsHKDyoihFfZgAtwVaJz0Z6EJqG7HIHAAAAAAANCdwwAoa' +
            '3q33fQijcK5UzIAn16p+ANpcAAAAAAAAmJaAKzQZ/iSgzV2HE7oRvrKBL7JHfZQAAAAAAAVmckA5hzuz' +
            '4e1roNOuYDCWdYRJFmS8bgAAAAAALS4pgEWZz75i/OOl78PHiYEjNJMRQ3esAAAAAAVuvo1hWrZFcgH/' +
            'f8x6ekObLfxXl3+3Id0AAAAAAA/xXmCBWeaEgp18ATph62hWZ+5mznjBUgAAAAAACmOFz6GF0a/mX62e' +
            'wHvtzKMDYbybty/0AAAAAACpKfggpCG6RAGUXG/brz/GDwJyPl+2ohMAAAAABUDS5wC3FQEWbxEJd/ZH' +
            'dm/PGMnNhHDBYgAAAAABCANHwL2cG+Ld2RJIE9FE3x+vTo4ArQcKAAAAAAE47KSAyJlzjExRF/nYuwV5' +
            'gGNb/7NmiR0AAAAAAACYloDMJfbqZ+J06HjHzIHmI8tCqkU/bgAAAAAByaaCINRWkHkndN3ShixCrvro' +
            'tJU10UBJAAAAAA7k4qIA4Vp8O9+NTc/KltJaFf/f+XHrYvAAAAAAAJWjGs7iw4TO6NjuDbwtK119T21F' +
            'eP7yXAAAAAAAaOd4APYQSBFncvr6qtc1wHZjugi08KerAAAAAARgM9qkCwj3gb5CJAxMNqDWpZDnsegg' +
            'qDQAAAAAACXHBUAeYF5qzCN2hNiHknbVVqRDdOMIAAAAAAAAFXtEgDdA02H9mIfjNShjC50rdtP71pwE' +
            'AAAAAAC7WvOgS8trPO91iTqWSoNaqIh3LagpIFQAAAAAAJA+RQBmgU9XzFW2Md9kxgmPrdWreMGM+gAA' +
            'AAAACm5JwHCO5/bLWAkhPGPbt9MY59Ax5GQbAAAAAABk3Fyuk9+9kbBuddCAtYrnHW9HIvt/dwUAAAAA' +
            'AD03B7DEgDRLN0+Mri201wMEVU233XrSrwAAAAAA0J3DAMnaQ3tai5B+7VXeErriryIh0K5QAAAAAAFV' +
            'J5u6zotxGz8hA8R2NGrnvG+gYvnYczsAAAAABEdoiTHjIaoTra3asaxiAfzw117B2QSo6gAAAAAO9hPp' +
            'gx40nswe+BK+9vwf5kwK1Bm6Pdt6AAAAAAX6xmr3HxOsI0qKY0JSgxa9BcmzH6cvKisAAAAAAlcG1IAh' +
            'ZCjA7B2WKlyHql4PyLKl2Iuf6AAAAAAHFvYggCxFaZUguOE+GGaS48PixxENHgguAAAAAACj0fGgLhMb' +
            'At4TduPnZMXjzJ6GUrR87w4AAAAABSDLCZ9hxLFF82f4wh9hGEDfreme9/0z7gAAAAABlP08rGVdVpkA' +
            '8wUPnWa+TVdVAH3GdKKoAAAAAABBkKsAmAbSD3HW24aUeUACj9brLfaQMb8AAAAAASE+rCKehnWKzNfY' +
            'MRXdoo4hFmzes0iT0AAAAAAAY3edRp/oYH0MqOlr8fKUwUJMXgg+nsHVAAAAAAA/LlEAv7B1ZDXA5ak5' +
            'bEQRpU8xRFO/QzkAAAAAAPpW6gDU4IMVlYRDp2/lI3o2dDron+xP8AAAAAB6PHBCAAh4Ohpv4lJrJMCa' +
            'Y6IVgrI3zv3VAAAAAA42RHwAN5QUR4CR042ogvB6oRyoRX+dhGYAAAAACxWE/Fox6VOYt+EVZcYc9gnY' +
            'uUCzwY1+dwEAAAARdlkuAEdWM17egJS4Wd792TfHIe7ueBPpAAAAAQAB+kAAAAAIuyyXAAAAABF2WS4A' +
            'S/FxIt3vMJHtcR/yBNQHTpo+iHsAAAAAAljaiENsanccYPqPf1JCobg8j5jiZvG/yQAAAAAEH8LAdYbc' +
            'J4rN0aKmL+/JjxZ8ukDzXgnAAAAAAAIDSpNGqD9BkkxyMJAig+AytQTi2mwUqm0AAAAAAYhoPOC5V5ft' +
            'zn52fzE1a/SAjEAzN90XtgAAAAAglffSwM4afOMfGp5V6/hlpD5TntSrFDs+AAAAAAApuScA5uiQdvC5' +
            'Jiew+6tiLOII0lUDLJMAAAAABBMUzwDIuZw81KM982jZbiZm2Sl3a8uK/wEAAAExlxilAPyyXrSISE7r' +
            'f9BNuU3/4mS9UFQwAAAAAQAB+kAAAACYy4xSgAAAATGXGKUACnbTMYXpj8rO8PxGAPgqMR9bn3MAAAAA' +
            'AAewAJhRwX3McUef38JGTvaIFvalPhZpPwAAAAAAnHZSQCyqgL9Ca9wZ3JwA2aQ+LaY1D8c9AQAAABW4' +
            'IsaAYqFTpe6r5Xr2kEliUdnCMEFo21AAAAABAAH6QAAAAArcEWNAAAAAFbgixoB8uzHzdb59Ap5gxYgu' +
            'CKDjLdnHEgAAAAAEYSzoqYsPoNok3JIJAjkJncUVc5QqZ2e3AAAAAAF3l7vAnrTTRyfgdxODbNEPhxGq' +
            'EuZLu9cAAAAAAGhO4YCvleShFfzC46fzrbBervJIXdZ9rgAAAAAAZ0PaINIE3/7pY45J5IgX+xChVQnL' +
            '4klFAAAAAAAPJziE0wnaiivx4cTv5ItpjTzH0e7xobQAAAAAATjspIDf8JJIhuUrHzJyGudR8oeEkCx/' +
            'fAAAAAAALm8NM/2RHEFd1iqWhj65VhkayE+DLbVHAAAAAABnHbSAGsFNbuqwCaNNzZvEHu8gjZOEhzwA' +
            'AAAAAApuScAa4n1yxUgR13KkZlQlFSxq1kC2dgAAAAADqsXtgDCNbdKpIw+U7j+e+xnTLrQLR+p/AAAA' +
            'AABOnlfAMK6MTo8L/IepXVbkGBtywyksc+cAAAAAE9x7RgpC0OQFFRrI/66O63rHXwLoz8ilSQAAAAAA' +
            'LFS5cE0/aiUuDfRCLw+0hXgPsav73Yp/AAAAAAAVe0SAXFKWXddhzOQZHD9yTKLqk83Qk94AAAAAAGhO' +
            '4YBhbaQHI5AiLKT3TfKZaOIOhDqWNwAAAAAANCdwwGpGlArhxNhvNQ/wFlQLUVWwga2WAAAAAB4dcdoq' +
            'dw6zs9tPZVr2RS0VIEZKZJD6lfIAAAAAAEOkV3WWsSfZBSrHB3tBXGqMydzlb3ZWYwAAAAAALLQXgKwn' +
            '9T5u2Mm6mAxHe6rabqwzXcv7AAAAAAAAmJaArz/QdRpnJWDkmhoXhIN08xowNVAAAAAAAe4fAc3Hl6sP' +
            '15thBCGJ2Ueu1c50N7l1qwAAAAAF0GFI69KYVFCATb392c/lhYsVj3pwEmtgAAAAAABoTuGA1o56550f' +
            'dmY+g+9869GASBg3snIAAAAAAITiNl75+Xy5GoMKJyBwcwGAnUaMIMiVBgAAAAAAEbt9YA/TqKQhzYJ0' +
            'DWPyINlo4571IVw3AAAAAABP9apgSrJOFBbL1vuDYIWqZKleN8r/incAAAAAGFxB4C9do0HjDndiDOIs' +
            'gn6nReVTI/KtyQAAAAAJ8k94AHAqU0+grE13Ni/0u3oG04HwS+HBAAAAAAZA3UL0j/FoZ2WeJ5M/1KGC' +
            'kCaIOdf30RkAAAAAAGj0VPOoQeIPGttH1AznFxvTnc1YBYPSGAAAAAABoTuGAKnXW5gu9fLp77t3t+F5' +
            '+Il1fjZqAAAAAAJ9xQsAz4amsmN6xhXTWUCmuxOaxBSMdF0AAAAAANB2PdDx4FJpnC0bz43Lh/8OlrIT' +
            'yYiVnQAAAAAANbf70PkidwCCMLLLTOd+My2uljlXn4aMAAAAAC3LnGSXL2u+/+cwbPGl6vwbpcA55dVH' +
            'S74BAAAAK3BFjQAH185LGbeVJU9RCcIQ/4kvlXSKNwAAAAEAAfpAAAAAFbgixoAAAAArcEWNABydf/KN' +
            'pB1Cta4PCHETG+x4vn/HAAAAAAAGx6/wJpT3fvC2yDCxUYhhFW6tdELT5l8AAAAAA3iSkSotoxg2Nqri' +
            'HCcQtb1EhpA/hUH7gAAAAAAJYARMADcf4DYo9hRqRdyuIs4BC0vccknCAAAAAAIxXOyDVqPQ3Up/1oVT' +
            'sdhCURMWqxmsnjIAAAAAACS2MktfzyOthsTnwsrvlxh4vjteumbVpgAAAAABSSD1KXRpUkjFeYEBUn/o' +
            '1gGKfFLYNMGvAAAAAAAwxlWphQ07SkPKuJVWLlCa8Pw3XFO5NDIAAAAAE+I8lgCoF5b3o2KBy/7Zyt60' +
            'HhOxQfbeJgAAAAAAAJiWgLIlMn+vMt0JUvbTgLXce8AaFT2jAAAAAAuicbCAxkD/4UpPR2KUlCJici14' +
            'qYBj164AAAAAAD9mRUzGRBzo5gptqP1Qpid45iDDQM/+WgAAAAACMFv2+Nmn/wgnusGa19qUctyOYHAh' +
            '9WzfAAAAAAFz8WKh3CwQWGgq2eK3XrWmt36qbn+89ysAAAAAAIeZvsD5zy6f/+z3YLc/yJ2Yy1CkAA96' +
            'VQAAAAAYcLMWgP1FZwlwWUl/cSAYFVkyE1y8I2X3AAAAAAoxBYvAhV/ZaxPMmEQ8u7V3/BR2LUxJLhoB' +
            'AAAAATKo8aAHOXF0KQoaWH/pVeDk9ZrzflqrhwAAAAEAAfpAAAAAAJlUeNAAAAABMqjxoBcYZtttnYD2' +
            'EISuQeOCBV0YNfLRAAAAAAAZ8HEHIMxUCGPmIKY5pzwkODCoMQqz29oAAAAAGNrLu4D2r9PuPhJDswG7' +
            'pFThTtfw+Gl1lgEAAAGXdCDcAE3PCwxwSGQxInsy7rQqL2yjDFuaAAAAAQAD9IAAAABD6LAkqwAAAZd0' +
            'INwAXuL/d1QvY89GF3+c5k8d3eHKeegAAAAAImyQUV9mqM5BMIA+UNpefyHuG4yfJyNYjQAAAABVB53E' +
            'AGz4MSjbXglzGWdyU9xSO267KMw9AAAAAABXUWqwcWadabGkCVFh6gTm5i4UejR6G0YAAAAAGHttq4B6' +
            'JXEjiISBmmFvzV2/e8p0FC5rLQAAAAALxQtTXYKOiOANvDpzXq9oBHSetadRWmnWAAAAAABtbY1ihVoH' +
            'tnpMd/bjB6oaS4t2KywNt4kAAAAAAF5gxECeqOaTWp43iC54PtVlPEChp80N2wAAAABX6AVfLcbpfwA6' +
            '/ez14K/u+xTe0sKc9IzLAAAAAASp3M+XzEE2r9uFEn0C13dyhhQFIAbskSUAAAAAA3WMY/3TwPCKfXpI' +
            'NLHpcxO+bls2A1ZWkgAAAAAATEtAANrDtLqugRadWZPB+pl+aQUi7Ic8AAAAAAH/HB3A6KX/W1Jkqw2B' +
            'kE0tdxytzdYPKZ4AAAAAAB9K3UD4loJdgwoQSiF6mIUWtVGVpTNP8gAAAAAAcvEMgAmYcmo14W8sgQIp' +
            'Zb3WOVo6rlj6AAAAAAIKlW7gCl+NmdwS6UB5SGzRFHrPJZ8tQm0AAAAAAR4aMAAVdqJVi4VUXs0NjQtW' +
            'jTZs0gROFgAAAAAA0J3DABYNhnoX0gMPTKqWdfxwZuyIsPCzAAAAAAAAmJaALJWNzDJeXmORfRWdmgym' +
            'eGrcq1QAAAAAAHm8NnBGHO4rwBsH36QxU74sUU6aYArdkQAAAAACb3bvAFgAoo8xj/Rk4dP9z4M6/m7+' +
            'lmKzAAAAAABOOykgWTM+lWCkoAmMR6AqDfQcrjbGtccAAAAAAEDfqoBynUHnH83UA9whR6GZL1L6wvLQ' +
            'CgAAAAZ18CaSgHf+cbRcws5mSSKxY4Hx4YMoKv/RAAAAAAGyPGi4eyuLgNP9hfXHtUu+fHdROYnDmQUA' +
            'AAAAJiwbFyOFwBsz71iQhrGS0GszpDOO7UOskgAAAAAAAJiWgJavQySjkTOcwTCVL3admLcWiJoCAAAA' +
            'AFpbok6fmPV2e3/pCR9xRu8GfbwGhgeAmXwAAAAAA8Wopc2+PJEHY84MyQ5rvrSGIm+5mxsNnAAAAAAA' +
            'ATEtAOMMm/Vw0VL4fM8jwRPrSax2dCDgAAAAAAQTFM8A5bXqKJkRwKe+ZbOxysOc+R9Rf+0AAAAAF5te' +
            'WyCSMJAXPtp283NEe/OP1Du4JUO0EAEAAACLsslwAAimGNMbf9bEB54k21iYBxuWcEGdAAAAAQAB+kAA' +
            'AABF2WS4AAAAAIuyyXAAEjLpGc8jfIGqE6mm7zCHwE94ZmMAAAAAATDbxHAd64z6FDupl1q9kSoZdUI1' +
            'YFMxVgAAAAACVAvkAB9WWCyLShb3fie8fK16pgwkkb6NAAAAAABoTuGAMwTvShCa/FCnrSsth9K7wXz6' +
            'glgAAAAAADiuBUc+P110voNEoR+NlgIIKiPiRE5hjgAAAAAAU3JOAETAI8PM49sIfQkcX2CMXX+Rnv6Q' +
            'AAAAAABoTuGATEBVz0cqVCQBiyqh3tN9+IaWWQcAAAABQlYpDEBWEw/yWvwdalX8hCUfpafNDmn/EAAA' +
            'AAAAmvjaAFp1bTFxYk5myM4LaPRXQPldKLsHAAAAAABlmve3YZT7ZyuumehgE0zezoZBjV0X+zAAAAAA' +
            'AJx2UkBs80x+F/pRw+s9af7BjNtd2i5dfQAAAAABkJW+YICCucu6o8ENEZZX+A/l9Cuvh35SAAAAAACD' +
            'IFR7JVml1Z+/RexIIzIYyZ64jqDmQiQBAAAAVuCJk2CgBJYA/svHszEsoAUNZgWmf9jVBwAAAAEAAfpA' +
            'AAAAK3BEybAAAABW4ImTYKurl2D5WKFj6q/9memNlmJmox/NAAAAAAErJ9zAsOXclxBxWsFRUPkEpQ6B' +
            '3TYiE58AAAAAAAX14QCy39AECkdcHVWFE6N60V/8pVhOpgAAAAAAUv5z1rtyK1pOX3CzDMhheIjr25b1' +
            '8jXgAAAAAAbscxniBTHOByJVvT3o4lLOJdgxLTAhZ2MBAAAAi7LJcADFURNkEobyVHZrROaAi4eHukof' +
            'zgAAAAEAAfpAAAAARdlkuAAAAACLsslwAMjVkjQLZNGjSi6haKLQv2BaYXX8AAAAAAAewYkAyQr56ToZ' +
            'WsgHjoyTf3UERNvPTGEAAAAABnx7lkfNnCWdQP18rkv+AWQQ8cgVKOXpqwAAAAAEqBfIANlXmsVrHNb/' +
            '9vEj0J25ZCVLbrEYAAAAACi+0BYA7GiU96LN6Ku/VlJLPUy8xYpaO/0AAAAAAHMPkQD2pNvrfeIhzi2m' +
            'OdPXgnmMNr0O0AAAAAAC78yq8C3/RVz8mHF8x7yBtHHA/YFSKV8zAAAAAAkOe+QQNxuNiTspWWCrnR4F' +
            'cW+UTmkv4nkAAAAABzwu5o9Xbwm95RfdAy8mwqLLD7Gfa4aHPQAAAAAAvzpkOFsttPgfh49toN47qQTD' +
            'EeFsgR3uAAAAAADJNp7AjdeTQawktVQjoBemxxLIKL559rEBAAAAdGpSiABgmQFpc/JTZ1heP5Rli9ZP' +
            'Aaf7DgAAAAEAAfpAAAAAOjUpRAAAAAB0alKIALJFHz6UncBQWEXFWaEgZO21hOYcAAAAAAVqAUuUvoeP' +
            'AfRccTf3mvCpUfWZBfvG7poAAAAAAAjw0YDwgHxwzNh6K8gmp8spiyIU5tRHaAAAAAAUCulT/BlSdLKk' +
            'TUFUh8yElr53cWlrhqfcAAAAAAA+UTEiI6bg86xNRyka3IVE+nsFZNDrKzYAAAAACAsG8/WUeoh9kgb5' +
            'gSlGEZU6nSuUGOXjiQEAAAArRu4OAFjvcgF6lWVCEPfL/+eRs5QwMs5dAAAAAQAB+kAAAAAVo3cHAAAA' +
            'ACtG7g4AWeMS8yArJqaS5AsJAb2REBpT6rQAAAAABhyfNoBl3QrJaPw2MU6CkISSCR85VuBWjgAAAAAI' +
            'BUU8Lne96Z1K+cNnHwfrlTIkYRb5KBumAAAAAAAzVjUfxrtW9sl3sxI+taCVcXsx5Iglok4AAAAAAgmK' +
            'Z4ACjY2FiHxCe2qKfPcGODhcPWC/DwAAAAAEe2OwgBXx1+syrli7lTfqNudFqGbX6nLqAAAAAABnGSCg' +
            'L3Nxn0OquZiezZTmGhMOUildLnAAAAAAAAjw0YA6XD/VZXaw+f7B06DU8mI05nCwbAAAAAAAFNyTgGlU' +
            'nzRg2yG3FkV3V3F4fofUQQ7cAAAAAAAINYRIkhdLNnErmx3DXBtXltdlbHKsE1MAAAAAAAJbbaGUqj00' +
            'iBWx4aHY/BEKRwaJJ4Tr3QAAAAAddZeBuKQvoGI3DCItB9dtUtMexdhcqM3dAAAAACi+0BYAt/mR10BL' +
            '/TrCdEvudtQK1Ez6YaYAAAAAAMqC48jISmDKtl6ViWXLWYfS6dgLr3kn+QAAAAAB/F42QNHR7PMJOWxr' +
            'TVDcYZOOkOB3jcLhAAAAAABoTuGA3BxTYhtmd1qJxtmeQdaOETiK+dcAAAAAAP8aE6lMdXqQ7psRovyu' +
            'LGk/pfmOyT3XuwAAAAAALm+yWV0aPXBz7jDBylZghcHkO9fFTX5QAAAAAABoTuGAfbIWdJN+oP01fZYr' +
            'iRXf39Aw8R8AAAAAAOYS7QCkJi7xVAsOvvoDSufbo6OR8S8fAgAAAAAEExTPALRrpRP0cvqFtgxxDvAQ' +
            '44Ji5FYqAAAAAAF551Sixqeo/MshNhw9+Ge2E3xrGHwRfr4AAAAAARhGQHP4ySiEuyH+wktF8Z2HYmTs' +
            'xjgDJwAAAAABKMGyMAUkr7wasLCpAjstPnZVEckynhopAAAAANvXFHcQP4cKfjasS7DlOANuZVOjZVDR' +
            'Z/cAAAAAAxxDMsVHOg6Esnw7YUefhWSBhCzhtCf91AAAAAADQncMAFXTiwF2u0M5rkg9LkiHAIag7wY2' +
            'AAAAAAEo1MUAWc1dgVGKy8tUqT0Urx7BSMi0xAIAAAAACCYpngBgNmbDkJf9OveJe+ngq0ORSwc6ZgAA' +
            'AAAE2SGRiKW3mAudNZjmlhhVXlYCpWCrWxTOAAAAAAuFs+bA1xFjP7Tdv9pGEJ4uYRyuU+NVxIsAAAAA' +
            'Cyw4WETbWFGtCevWyvw3sFrPfjNslnLNtwAAAAAEdPjVBfK56rgmbdT0S/RMuuGfGvGZQMhaAAAAAAQT' +
            'FM8A+V8oGpK9i07PbNTpHjRnisvuIooAAAAAAaFgjZs38GoApJ717rvmFlNB6vA4GGTdyQAAAAAA0J3D' +
            'AFcgfYRcH7QbLisFRip/krikoShgAAAAAAAu1Vetb5nH0FsUWmfj3vlvvTUlp/Yf/1oAAAAAABsf0JqM' +
            'kuo7v+xdlVshZ8vb1x0VAzaLWAAAAAAZq2l+gJ9kwP7SGKCexQKieJet/XQD2a8nAAAAADubYpaApAGL' +
            'LrFTTiddt2Jm5Ll5ytfje/AAAAAAAGZ0lRqnisrli2+Fkp+NXwYGX/n87W8ycAAAAAAIJimeAKpX7g9f' +
            '79sgUGathXezRZOU5Xw/AAAAAAef/rx6wpSbSbsbtmYlJilFYFgd8sXy/wgAAAAAdNsCBPDaPJfqEQPo' +
            'uPa2MxPHLT3dowOU5gAAAAAAhhxKzdwxnXm+A4YPzkl4EIbk18oCRJ3wAAAAAABoTuGA5tqXLeG6d9Bw' +
            'MvIVmichSmzHsvEAAAAAAGhO4YDvLw6UL43cFYWvIiqRhKSh0FaguQAAAAAAVevlyfZV/gSK0eSZFc6T' +
            'Mpf30zl55aF3AAAAAAApuScA//kq9AwX2JkMXAtbIL9zUIOJAzwAAAAAAH0J3H8ATfUSRJERq2C5ch8V' +
            'uybeSE9DEgAAAAAeR3j5cgkg0JzycFxczOQNF+/tm9QBv71BAAAAAAL/l5dGCyjad/rEUjIaqtmeuUUS' +
            'QfoSBOoAAAAAAZljd4AVRkE3ZId38DqJeZu6PnD3goTDPgAAAAAFP0MfQB5KNYtl1CEyP6p50HKP1MTx' +
            'mltIAAAAAAL2ktyJPwn4jH8cGF/8fQ8oQz0asrL7c1AAAAAAACozOQBdYYUHKXa9IhzGmd8lZY7zI+sn' +
            'ZAAAAAGLz+VoAHyZH+ztQQnoC2tOANS+Ty2yeoIMAAAAAABnXo4Qi4u2wmCJK8Yv0M1KsR0VVgpcAAQA' +
            'AAAAO1/HzICZBGc1R0lYOVAmjxvckyuvLh8utAAAAAAAZVoLgJm+eO+Ws/HcruiNnHN+lm8vKd5xAQAA' +
            'AZd0INwAtTJqxH83X7ncuSQijEm3k4uzd3AAAAABAAP0gAAAAEPosCSrAAABl3Qg3ADHK7s+xr1Q9ni0' +
            'X1Z8SXUXc3rA5wAAAAAAaE7hgJGEownhLU6biEVObmQrvdTu/j9oAQAAAAN+EdYA25xq5QlFk6f0jmtm' +
            'n3BgOkINtcgAAAABAAH6QAAAAAG/COsAAAAAA34R1gDw8koVyWw7esB3oLLgPsCliCIM/wAAAAANJfFG' +
            'ySheDCTJ9QFXsu17ep8WEe/Dv+miAAAAAABjCRagL/W6hG1iMGyOI7gDJIpNU75bakQAAAAAAJYQM+NB' +
            'majf8QUJOGsqoXbmOBl38WY3ZAAAAAAK89Hw5EdWd4B8mtUX9H63GTk3xUZOy97wAAAAAAA0J3DATy24' +
            '7duYN72KNWsB3mBTJpRfXUQAAAAAAqZIcSBPY7QSFrqxMx1OK4bRGBTY1VjKIgAAAAAH+MgtzVezFOzv' +
            'YMi28uLBx6douff0BlfnAAAAAAApuScA/DaH+RuLuxzCS1XdZA48m7IyYakBAAAACY5CEMBj3dmrTl0/' +
            't7Qf8qBmR77KL6H1KgAAAAEAAfpAAAAABMchCGAAAAAJjkIQwGnV1jZTlwhT4rAZ/r6ucujd1gClAAAA' +
            'AAAAmJaAa61pIftFU2H2qXLrs94KbWfkpPAAAAAAAAL68ICCpZRzybHLwKPxGd/Z05RF1XsSsgAAAAAC' +
            'kEUfCokwa0GJeABhxyGkOqXxgBtyBjqdAAAAAAGCYaDqiuV1jeOCWK6Xg+1ha54ZWQ++B0QAAAAAAtoo' +
            'KoCSTt3BACO+NbcLquWd4Tcx29iOBQAAAAAA4hSWQKx9ves9mtVvrn8eNjOPoIcN4oL+AAAAAAC7nBei' +
            'rnFfSZVX9aZt99PTlcoPgrWt9+AAAAAAAACYloDPSDpIaRoQUS+eRYL1qPAAf9C5pgAAAAACE1PlwOLc' +
            'N/61GxRqhv9FOBXGP0rkwkuvAAAAAAUsWYIgNJkcx9X201kj4QHhmI6KY2HRN0kBAAAAC6Q7dADsVnd0' +
            'vECuW4MrN42HkfTVZg0zoAAAAAEAAfpAAAAABdIdugAAAAALpDt0AO/FUBI3om/ElXIpqg9qge0bKW5U' +
            'AAAAAAAgL78A9sevD4xiE5ACNflcAHRcqwyEN2kAAAAABhX0kU73yANLutem9i9E7SKOj+Eg6j9LAwAA' +
            'AAAAATEtAAOCJ8bpHMMhRMFkobohg/clbldnAAAAACYYz1xAKBOi/946rLAzkK7las3P1I0AmhoAAAAA' +
            'AgmKZ4Aw0rT5NYRvJgCSHBnuKRqSVeCt/gAAAAE94MnEkVMo9mBP1y7Dii6mcr83kMO5XmM5AAAAAAAJ' +
            'iKbvel41NnFX5DSx88A+VjKt9B9zsvYAAAAAz7r6aNmBzLi9RcVzZvxvmhqK8pHeO/2kuAAAAAACzg4R' +
            '8Kv/C1cKAO5FkkZ+4XDXau6IXQhAAAAAAAON/A4ArQONoDFMwQGFP/3TsX3aeS9i7cgAAAAAAgRzRzSu' +
            'TKFfvte4eMfXJ3A+eBUNtQu3/gAAAAAA0GD+qcx0+fwHlP073/w7UEtViTxGhUiPAAAAAAAVDMnfzYLD' +
            'eQfxoFyc/bdrVRGkDpTb7zcAAAAAAHzApUCxHTB0vOR1ctsOHwbKhEZVsbbJDAEAAAAi7LJcANEzYpe0' +
            '920EwpIeqR3+8jKQ3qeaAAAAAQAB+kAAAAARdlkuAAAAACLsslwA0fqSRhEEAAkJ147vz5n87t7XXdoA' +
            'AAAABBMUzwDXIq/lQPMuAVK7Zd97FPiw0rwcrwAAAAAE9GMIAIh6igk9C0vYYrdB7Ca6i/VXJhgWAQAA' +
            'ACLsslwA3fetsNClR69F/XX1uqoBXSChv1kAAAABAAH6QAAAABF2WS4AAAAAIuyyXADslWGA3PN3HKSh' +
            'LRqFFDKpYEyIBAAAAAAMLZ6hf/xmDrw11N49rmXfdE0v6yXTFefUAAAAABKgXyAAPqsR0yU8LTqzCyKl' +
            '0aW/TGN+TMsAAAAAAGhO4YBBCJMspi0a4e/hRDhS1+ko1cd4/AAAAAACIYgI9GdByaqh7yZCcUWmaVmf' +
            '0J1KdHGeAAAAAAAU3JOAbSi09DWy/neiuTktkIEB3GzFFMQAAAAAAA27oABuR7+3zfHy6jLqvIom7Jd3' +
            'C61LugAAAAAFmX3ggJUjVp2pNh8n1F2LsBxG5aUq81VJAAAAAADQncMAmFVPUm4bTC93Hx1aUDtGrH/x' +
            'm/QAAAAAALaKCqCdbKBXgjgcA3Q3UqM76jOUIwQfzwAAAAAAk1zfRVDKo/k2VbVJC6No4Z6vjK0KnNDI' +
            'AQAAABFgHCAgriawgH7I3UbuzAZXXY/5dPNDVAUAAAABAAH6QAAAAAiwDhAQAAAAEWAcICC0PVjvEbXj' +
            'CZxF69wa7Th3QOHd2gAAAAABeMHPU7XScLYZ+w70HzSo6eFC2q1Hd91gAAAAAAEtSVSK1wFM8wWV/pPb' +
            '/2TXX5W+nO92jtoAAAAACCYpngDkdqWcY1Q7Z0z8Cvb2P1S/2Smx0QAAAAAP47gPQOcK6Rb9qqgx2kiJ' +
            'MtXFpVyHuJWTAAAAAGI62YVc99Sq5PhyFWUqXVIH4PaqiWza7lcAAAAAAJx2UkD4FZrjLwqa1pLUP/Ni' +
            '2r5tQcR0fwAAAAAAHCnHIBkSTzWbNlOF5ROkvSC6XCgJuIuiAAAAAAIEhmZiK3I0Wa1wk5o84/NbOaf0' +
            'Ikwx3KwAAAAAAP0aq31YthrGJFUuQiyrS8fXp7ZI9uNk3wAAAAAVJhOSIWL7ybt6PVcsaE3B5rGa4OHl' +
            'Th7VAAAAAAD0kqCmeha10PGWhw9xC1XqTt7RKfYoKCEAAAAAAThEahiDoj3c/1hKiRUrkv7a/ZfrDM7A' +
            'SQAAAAAA8XGxaY4UOeVeCHX4KZKe+p6cyIuST9gIAAAAAAFoLQwwq0U7+iP0SrV1q1+F3VYXT1WyBl8A' +
            'AAAAAdJEXC62YJT9gtkiFB9U9V7Z3TLl3PxpnQAAAAAAOCO20dYif9uVb1AUYpgim4G9o2P9XQ7VAAAA' +
            'AAR5XFxTWTK4xxkkEol77+v0BheJS+nYToEBAAAGXdCDcADfRJYubFTVZ8a/PAa7VScbKf9nMwAAAAEA' +
            'A/SAAAABD6LAkqsAAAZd0INwAO5pck7Y3wJC3/YGnAfQ2zc5lkTQAAAAABRgBrwA/QyuubeE9t99IopX' +
            'ggXQQ3UqoHsAAAAAA/+30y/ry/Defa5qQtHBKWfbmyKHvy9/DwEAAC+/m9nIAP00q3JloOSMRUzL9MnG' +
            'Hf32j5oiAAAAAQAD9IAAAAJjLjFKAAAAL7+b2cgABPGY7SNbihLFRG8Y3K27cHuKuWwAAAAAADqC81kF' +
            'BsxXnSTr07en8HosJmE/ZBCzfgAAAAAJhEqwJwa15ukBHaP+v8fpUOCWCjh/SM3HAAAAAABXePpuGPkK' +
            'GZBI4NetcmR7f8bsfVdykZkAAAAAAGEDNw1XAP2vuUQrfG4BRtODNf+3nWckTgAAAAAE1pqGy19SNaNa' +
            '9RxTupiFKFAaC/QRYu6XAAAAAAUzChZ3G52Y8Qyb7fygsideGH//zS7wOwIBAAAABdIdugBqkKrRrsAl' +
            'lAHg7yTvCNmJD0x0zwAAAAEAAfpAAAAAAukO3QAAAAAF0h26ALm3pgkELa+45x8KqXhWRBYB8LcWAQAA' +
            'ABg7vy4AjzeZOXQRG+RMAK5RvPUWeWc/SBkAAAABAAH6QAAAAAwd35cAAAAAGDu/LgCRP51DFWrCIiPY' +
            'QXqUF3rqagFsXQAAAAAACPDRgMaPS1vB4UfznQ8NCweEykyuIQntAAAAAAVMAXOAyYOoogtpw+fTGg+Q' +
            'DzKzPOn1uXkAAAAAAc1vrzj74ED0f3B6tVp8mIdGVQxqnL9BhwAAAAAE6yFXYP4CEqca1SZz+DQ11del' +
            'LWqHj1p+AAAAAABbie0qAq33oshMorgikKVG4rd9Yk5nU1sAAAAAAMXFcUcDsaA0ZECCPvEgkGh8nC8g' +
            'an7KPQAAAAABw75cwI1pKkjDshtbKEYWau5uDP/k1buPAAAAAAAjdvrAlo/iz6xGP2nlcxu8LCg/4cuD' +
            'k60AAAAAACy1nYauC9xgbmweFDvJ0A+/9gGeRMGwIQAAAAAEa+RngLWi0b/Xi496UecI9B4dQWKu5UZk' +
            'AAAAAAAaewESxbsCRHOpmcf4fSYEqi/Is+qKuZEAAAAAA173axjF7oLe7BiYHpbHgueponiUSGxMbQAA' +
            'AAAEtN5XEdsOH85OtA6gpO4Ys11O8Rx4uZF2AAAAAAIJimeA4/Lw3beFbEBacMRwr+SYrHPjKW8AAAAA' +
            'BBJ8OIDvMLArT/CCnn70k6EdYWdTXrDIAgAAAAACdBiKoBNUNOHpLHMidNCdKNphM3wXUeg9AAAAAAA0' +
            'H8+gFrxI2Hqk9oEZ9cH/8XXtXUdzPIEAAAAAERM9L846NTGufazmWFPMINSjH8Lm8x0YgAAAAAAAtxwc' +
            'E2BHr1dokM7IOAIWwprSpt/NeRKXAAAAAACDhL5GeOXBOP5MVuQkfcZmQC9aykHAOKYAAAAAAmdq/0CK' +
            'cWLTR/cr68NbH66R93eTGOp4fAAAAAAA/RyseYqRqhYQN6Cy9TAtSkCjmKJfaoJDAAAAAANCdwwAmHG1' +
            'YHwHPr6cC8j9zrfiWRSX/3EAAAAAAAX14QCy43NhzdbUN8RdcyAwuV3lmw75dQAAAAAADQqf7L8P+PRN' +
            'JhrXNV77fEIQrJAD1YBBAAAAAAXCSF1gwmFZp0zGjPx+wuj9Q7+wAdl1/PMAAAAAAGdD2iDO8712Mq4O' +
            'moBoRTlaJHhdgFfm3AAAAAAEYzrEuuPKL1OzijB18ux0iadRZ5Xpl9wDAAAAAAYCpEgp+CWDnm27yH+E' +
            'eje/QqSH1NsgcQ0AAAAAAACYloD9bPe5qBE4+MM8/h9zAaaFdWl1ZwAAAAABLeMvrw+F12gNO/RR/a0y' +
            'VgMePI7wICNHAAAAAAO3uRU+EBkh+VHO1seI/3Tx8gQFFB1wc5oAAAAAAC309RD1+E4h5ZU9RfaiC1/X' +
            'tl1Q4j/KAAEAAAExlxilABEzmtPR+7Xxt2N/sainJYRef6e9AAAAAQAB+kAAAACYy4xSgAAAATGXGKUA' +
            'JDzXNGc4bvMrMfjN4LELPMP0iHQAAAAAASqABAAsAgB6AmlJ1aQO7Up4dNoiUI0iyAAAAAACkFBomDK3' +
            'F+RHYngvk9aHrXsHlivapnwRAAAAAAAQZzgASMV8cnHLNYU3J8i8TXYPKZLxZn4AAAAAAB3NZQBO5t75' +
            'kZqj3K5LxrVXpCz1yKw9XgAAAAAAPzRrgGEkMNstixulCnQOlnUrRbOuUeGdAAAAAAQ72QHng+GQ1HyO' +
            'vJY7BWufWxqUJufKwD4AAAAAAJx2UkCWjXumr3QOJ9NoWFTciZhSINzUxAAAAAAAKbknALmOSnQtCcBj' +
            '34WTLcVvohEvkrQkAAAAAAAdzWUAfHRQooa4Xt660+iQrMoNRT3hAXoBAAAAUX2gLAD9p2iZElWtZs/k' +
            '5dDUCoFAXhw4tQAAAAEAAfpAAAAAKL7QFgAAAABRfaAsAAApv39pcR6F8V8fawA7ZIq0sKmHAAAAAAJS' +
            'QiCAJMHV1iStwTtB/5Hm5yu3ipST05YAAAAAAFshpRApw0BNFnlisrpO9jCHL+MzNwjJYAAAAAAAURMb' +
            'b0+bnWMhR9B/okxrI9m1GdZApmhKAAAAAAIJimeAYsCPvM0mvSN0i33h0ecYWaZxijkAAAAAAFeea4Bp' +
            'R5wsBcnJYcFsDj28ExaHRPnIkwAAAAABX69nmm0OZ88IoYeWc/lBK/Ek1WaLQnQtAAAAAAAJBCKbfiDu' +
            'qDUzlmbcQBGCLwJF9BH3P9cAAAAAARzyKsCOjc02Eq3IGN4zwxAKfFBvnsxsSgAAAAAE811xG9wkrFU4' +
            'uFe6uPKzBjW0s215nonXAQAAAFbgiZNgmz5v2Z+qIS629KrnVtHUzhmXurcAAAABAAH6QAAAACtwRMmw' +
            'AAAAVuCJk2CgII9RgUGPj1WNAJcZQQzdoOGGTwAAAAAAEno5gKJZBzkC5Cy0N3la0y+7nt1qf23GAAAA' +
            'AAEyyvd0qA2PjkfB5wd0Vhkk5Xg0OfcorUMAAAAAB4mzS8CxJbY7+s0YDvGf7P3WnB+6sQNvygAAAAAA' +
            'aE7hgOJ+FOq2wLKt5WnRgotZt5n6uSMUAAAAAAIJimeABIbC/AWAzlo/gaSySYoVIVF6LYgAAAAAo0gq' +
            'L8gKsvEtoxzB8It0HJjfeO5PPjxaGgAAAAADtXRP2xiSR3UA6vuBktver2DPXUTOA5XPAAAAAAVThxxA' +
            'MzFXZUA9M2tzxmP8IMCDZZO0RFAAAAAAACYloAA1jgbLcJHSHZy5DzBTdG875RDdOAAAAAAAHc1lCDmR' +
            '1MC+O/fJmAkYWuBHblw//8L0AAAAAAO05+wAO3VphHgu8GAnmFkdWDjsIvdrxz4AAAAAC9GZ5W9DZ+hW' +
            'XsMTPXg+po+9ieNkJjI7EwAAAAACCYpngEPnuSzCmla2e7SU7ePycEk/mLLFAAAAAAIX9PT3VkSj8OHm' +
            'vmqitZL1msXoJV9W8jkAAAAAAd4EKvNXnf0KLZ5cpXMitseCeyydhSHDRQAAAAAF0h26AGT+s+JQ2x2S' +
            'nq9jxqT3p8p9yWWaAAAAAABTUkE9bft6npBL+lcm+Ri31Vn98wBadTcAAAAAAJx2UkB8iA+PpQS6bzx8' +
            '4rN6z3Hm6yZOQAAAAAAAMgmknYU2uE+rJ4bt2bVonTLri8DcFkqkAAAAAAAw+uiApzAbM1PnypbW9RNC' +
            'ReJwBrzsry0AAAAAAd1/04e22QXWtbaF1Uqrwx6O2BqwJVH7BgAAAAACJHI7krtcZQMpu52U471FiDS0' +
            'A0BsCtmxAAAAAAQTFM8AufVmqTuY+OIB1YyVQ3JoyRj4Q5QBAAAAGfdcPkDK8lJdYhFtH/2fJhZvsnOJ' +
            'OxHWHwAAAAEAAfpAAAAADPuuHyAAAAAZ91w+QNQldXVjL1vuhPHalkI+xSWi6HwsAAAAAArwnJvR2Tvc' +
            '6ygYVSA/FU1VmGO7b6P6X1IAAAAAABTxrwvwSV/HWCXabRlTjNyoecdSnt8F8QAAAAAA0J3DAACLHAnc' +
            'O1qfNSLjyf84vlwjsYlUAAAAAAAUTLNmDZaQbKVHkm7sE3jHIXPXOv/29n4AAAAABhyfNoAPLn2QugI8' +
            'xLvEZgQrVEi4rod/MwAAAAAAah/U8RX3xWYExZYrKZBZQm+0q5tmAmDGAAAAAAGCLgDTIHoVOPGggLag' +
            'BOszdsufUqPqxnMAAAAAAL5CDgA3BPbovxM2iA9GiAu5bmJE+fN4JgAAAAAADcdVz0qIqq0Dj5uCSIZc' +
            'S5JJ78VUlg4WAAAAJk62LLPvZK91w6rFs7Qo0rofBOGU01ZgpYIAAAAACCYpngBlfYZczoB6yCPaFaT7' +
            'HfMK74PrHQAAAAABiMrBaW4pEQTmWPWAc8uMkhN7w41ZOL35AAAAAAAmyWIJjRZ0NbHeIj9JM1Mvzq+g' +
            '8kYBpnwAAAAAAptKj7qPSeeegob/WMvBFEFsDfQHiA2ibAAAAAADibL6cKleNWcteRxU5Pz9rlKIi9Lj' +
            '6s5XAAAAAAAF8U0g3Kkm6obvppkfp+rIRmuEi09RgqUBAAAACBPq5uCvzDc6zXhO33iqUgZj9xE9QOjX' +
            '5gAAAAEAAfpAAAAABAn1c3AAAAAIE+rm4LRfhzkdfb78aNSOJSbIeoTyZIqaAAAAAACQipBA1TwMzZRk' +
            'ACgILTplC+tENhs6n54AAAAABUNNqwDWrDsZC5TSKQIic7QjyuvAdqozLwAAAAAAAJiWgN65jjY/qlRb' +
            'd3yls4evReoHYqmJAAAAAAA7msoA7jnkQwNzvFdRJohbXPcYW17gWWAAAAAAHaixEVLzfG5kNVFbzkOg' +
            'eSgixidaSvdp9wAAAAAAATEtABLrOEhJ87cXoMw0b6yg4nvuO3U4AAAAAAQTFM8AGcu3cAQfTrUr9kmX' +
            '4zFIVAGmXMgAAAAAAGaFHgAocMR5lBNk/X716xnwWpumyHcPaQAAAAAAa6JSQDnUmhTDVdMoZXAZLuCI' +
            'Rgv92MqVAAAAAABmS4PoU8IpmJ26MNwBpHnsWu8UETClZZIAAAAAEhztCW5cM+wCaQP/8sQn1eNaZk4E' +
            'gyUIQQAAAAAHJTbRYpf+CwMLDju54obF+UfPu00olz2lAAAAAAByR60grHlGIMFpaAe3s08XAgQddTJr' +
            'NlIAAAAACf5ta3Ti2AsWAXpCIgjsLehb/yK3cYXDMwAAAAABlB6XAO/7O9cz8EinBV1To/lSnL5PYLTL' +
            'AAAAAAA3CfdA+qGhaZxpE2zJj9MQYkMHg98koo8AAAAAAAX14QAiA4lGyTqVy1NnoNSxfW8VZhdGbAAA' +
            'AAAAAJiWgCyJwA0LJHDvbU7PkYVrK7d7G5aaAAAAAAE47KSANqnbEnO05DEmoe5lzUJJ/fN4D+MAAAAA' +
            'AT5J7wBWa8Fdyd5Y+3Uf4VXWYi3PjHKD4AAAAAAAPE1tEHBL9mNA09iE7Gr0BuNUaSxJvO54AAAAAAh/' +
            'exCxdGQRAGytB1zm+MZqxCBI74HGYSsAAAAAAM/1iJiFiax2XLdju4xTaabnLxRtgNRBIgAAAAAAAJiW' +
            'gJoefs3DFniG4TgDc/zKw15DU3O0AAAAAABoTuGAozhZ46pR8lNZIejA/1U+az3RG/wAAAAAAHnbJHmq' +
            'VD8LJIoNcGBtwgg70W7kR4+v5QAAAAAAZ3Gg4MmPE1MXc9qucerknxn5tQTrPQb/AAAAAAUoOXjz5Iju' +
            'ni/2M1ZSJ+Bk+yuMVQgLd2wAAAAAAVypXJj16YTA4XS9hjIrHIXXrpIY+bf1vAAAAAAAP8bngPdjo2hx' +
            '5T5KhTqnqGvtJB3x2LtMAAAAAWkJ8h7G+LDk6FEsh+iCodAKWXkCJ4nXfzwAAAAAy7oQbgAMySCGyyIF' +
            'qDpQyrmFOrw2fvH/OAAAAAAAKuvaoBSBbyBb+grvRyV46shtKA+R1AcMAAAAAAJ7+0eAA4uwesz1lef0' +
            'YWq2JAXuupCoq+8BAAAAEWAcICAmFJtHf/wy9fF/FZhbnfc5dvxhRQAAAAEAAfpAAAAACLAOEBAAAAAR' +
            'YBwgICyDvTAOzcA8nchTIzc21suA9W7uAAAAAAg6pruwN4rKlfM4r0ExREm+jo9OoKjgpS0AAAAABBMU' +
            'zwBAlNwMg3bWUU+XEIlNY3IoNVvuUQAAAAAA0J3DAEY92ENl05rruOufrlkYKlZEWLv7AAAAAAAstBeA' +
            'T6kvqpsrxmQNMNRNR551vasx6C0AAAAAONiA+qByhs0r+q1WqWsImS+jAbPWJEoWCwAAAAAGGtVzAHNO' +
            'VQ8C8UNMis3pT+5RVsGOc+LxAAAAAANeNgNg2nnSqBQE4k9WxYytLV4Q/35APT0BAAABMZcYpQDdRogU' +
            'ul4x4ZHKbEYhBTx19s56fQAAAAEAAfpAAAAAmMuMUoAAAAExlxilAN2tSXDcuJ27kvKDJgPaApnOujNN' +
            'AAAAAAPlZyfDFcsDXsmMkwjWG4Hwg7DdJlirIOIAAAAACi+0BYAgihilF2kP2uy2oVmGhA1gU0QgaAAA' +
            'AAACcW5SMC7fifN3sr4jPuUtmWFrKipyuOn8AAAAAASF0fpANdYWi6Ro0mR9wScIzAXt6NbKn4YAAAAA' +
            'BUMZM1o/XAQmGNx/kJMExWklLTJPTtpvUgAAAAAXSHboAEPCdoakUkK0Z2qSHNfANaoTXMeqAAAAAAMr' +
            'DCloU6h/kiHElLWlGvyeIYMBawdT3qsAAAAABBMUzwBb3xrq44SnP131F4Efm930l4GI0AAAAAABoTuG' +
            'AGUdv/5/GpHLqbVDpMA+BKmlXXRoAAAAAALaKCqAdF4xEihsILGy532rRPEvLKOd87QAAAAAAlQL5AC7' +
            'UEnBYg7sJSheka0Sc3E+uJLe+QEAAAAA9J+YoIpBfXzOtBsAhDViR9K8DMP3+zRkAAAAAQAB+kAAAAAA' +
            'ek/MUAAAAAD0n5igkiyHzlh87m4v4mfZaiaUCHyVMfAAAAAAAWny/yCZ1PWRSeknMJ6ns0URcyAh1YHg' +
            'CAAAAAAA0J3DALPoYkLRlP9+g3en2cfgsesybjXoAAAAAATNqOm7utuz2TFg6QYSCJCAZ2y/M1cJTuUA' +
            'AAAABPaJyw/HZCOfd+gHlgS8Kcq/JOCnA/w17QAAAAAACGRwAPSW2jQXBntg9X8nheJjA08RpzkxAAAA' +
            'AEXZZLgAFMgExNgLtjmzLwHU0ttaT7KcrW4AAAAABUwBc4AYqsJtvlxU1v5QL/3AsuT9Gd+d3gAAAAA4' +
            'h7SMaE7zmkaMQGk55d/dMzbBDy1ps2IyAAAAAAAGMHkAU17chde10OsMLUM71/QrjMvQ4EcAAAAAAGVT' +
            '8QBe0tUbnLO+2Ql2bszxPBUoJFykmgAAAAAAaE7hgGwlUF6Swqe8MKYYbn00vKjfQk3lAAAAAAAAmJaA' +
            'e6iQS/T9Sby8zMp2ggzvy5830xwAAAAABKgXyACLqA1rvz99pfolxaO3czsnIJiDpAAAAAAC2igqgJ85' +
            '0ubT03jM6Ry87vom3BMi/Jn8AAAAAACXWVuF08bPaLuNe4bcr4B++sPli67r3JYAAAAAANCdwwDj85Hp' +
            'Ye/iW3KZOD8BoPB9i+mDxwAAAAAPF3vRoOtEJrb7RpV7Oi8hUeauB3fNI5JfAAAAADPpJ1DA8UIgF20C' +
            'kWw6N3DYXz6tPyRpMw0AAAAAEFVYxwb7tg9zxeHg59HmQT+O6ijLYqRJaQAAAAAAt4RpMgMnRxXusNr8' +
            'yS1Js9WiQrldLvewAAAAAAFYN4HACX7kdYvHgADyf9+/kdHnC2Ij1JMAAAAABUmwNvobPKvPdwB1ZTT6' +
            'etqMuSpYmq4aAQAAAAAAaE7hgBh/aluqR+8Jicdh6pWBmu2HagHMAQAAACLsslwAKVeEc5Cx9VbzdjwV' +
            'QW6MbszX+AYAAAABAAH6QAAAABF2WS4AAAAAIuyyXABUxn2GlSj1MW+P4THN5HYDU6vghgAAAAAHqvu2' +
            'U2ObgsQjO3coah9Wv8I2a6+8gfveAAAAAALTARyAgnVPRI+BApp8MfeSeXRBa2BY7qoAAAAAAA5OHACH' +
            'Is5QritMgmPKhkSgkFYz/n0pAQAAAAATjspIAIlEXdoBPH5h0I9RUlzHwQoNhIIhAAAAAAcMyfE1i5qh' +
            't3p/Q6wvTZRPdPlMshbCvYQAAAAAADz4Wl4256pYVnNz5RbkkJoBPPNa3xffgwEAAAADfhHWAJEDQDkQ' +
            'Bh6JQWorCZZ7gIVRPWqZAAAAAQAB+kAAAAABvwjrAAAAAAN+EdYAl5F8bF/uBV3xUs49oPgP8SxcXWMA' +
            'AAAAAUh7L8Cclz0X8ksfwdZqioq0qB15VlSMHQAAAAACtx2ebNzUkp7e1zBk9mg4PAZmOUBLs37hAAAA' +
            'AAAs0RVg3SKInvfn6BCbfQLBVHosF1eB/7wAAAAADgVMAxjgPI7S54n57a6PzzWQYzuysKVl9wAAAAAJ' +
            'KSje0Pyx7H+ZP1YaBO+6aDsWUVKOO4ysAAAAAATQkXFG/haxaFZzwW4jzX08w33Fd0jOAloAAAAAEurg' +
            'nIAN6h4saaxUBuO9lqe5SUsnRn7j3AAAAAAAx9q4QC430o1owFHtBfvHf5ARnszB3jCkAAAAAAA9JoFZ' +
            'UZX3p2pirvmQpsX1dHFGHrtQev0AAAAAEExTPABxGHfo9WmP60M+CP4TCNzDAhSuYQAAAAAAjw0YAIYg' +
            '7bfjet9NLQCbHYmcjiwxZvYhAAAAAAOBDMaAlC+8gh/IONi0xwn5byy60HeNz7cAAAAAAGd77Zi6tBJJ' +
            '/U9dk8atxLnJD7mZZC9QRgAAAAAAzd952OkNKRDVRweVQG4gig4jguAHJ+V1AAAAAAcs69yQAGPZe7Pv' +
            '/f7eNTGrqf0IgQNkZYoAAAAAAJGwl6IScCQ8AYD5C+VdEI0ZMfUWcd1X6QAAAAAAXeWY9SndxDPgCn/x' +
            'tfPHKTExouA3y9lXAAAAAAAjw0YALc0sYE/P6WkxYyEMBs/OlQyihmcAAAAAAALSHTw0BbiW5mk44x6n' +
            'tPfyQBqewQp4dQAAAAABkxIotkmqRVmftUkbn717dvISFCke+gC6AAAAAAHfLNzHcGfoPe849Y13ABCk' +
            'KuGlr1axbC8AAAAAZOrH46V3+Nj1joSyxn2iJigJUf0APwW36wAAAAAAstBeAHzuQYtRnBrXCCqP4+Ea' +
            'fhOtk8O+AAAAAAAQpSZukgcJcM1OWFMTK6p9igzkhogkoo8AAAAAAGhO4YCdJBuZ5y5eLXnnggMYm/QL' +
            'O3lSuQAAAAASVqEauAS5li3uNC63wEs0YnqyoOQt+N6nAAAAAADHCMeXDEQAk6lWV6FoEhL6VHLH/CxV' +
            'odYAAAAAAEy0llMYRwURudcgJ0j9yknd5gBTS3jLQgAAAAAAJ6MYQB9CGSaATgZOpoiR7MtDnTFoiGTV' +
            'AAAAAACLh0ygIizpOJlf7iSGXVOii7wN68KrcO8AAAAAAayf6A0tLUjxly0zU8KkRp1r8LlsP02EjQAA' +
            'AAAA0J3DAEQrSciJ2cp2EAzgFW8qaajEsf+vAAAAAAHc1lAARZqIxmDyoEuBmhpeMYyKu0HJVfIAAAAA' +
            'AFn1kzpIHGZawUtSRDzixBkoPHjHtrZEQAAAAAAFnkKUgEmZputqLmz6iARey27U1fbjLsihAAAAAAJx' +
            '2UkATHlhEfPP9DMNSmxSlk2sdIIuKiwAAAAAAV4rIeNc7+/xNH8k+nyH2OiYzb+hKTeXHwAAAAAAZr5W' +
            'cGR0mbFQcC6HLRmQ+l0o72Tv5bl6AAAAAAAAmJaAWsXS0B+KuJGugoEmK0BoY8Ib094BAAAADOwOywC4' +
            'CkANVpwemhZK8zTlPd7lX3hxcAAAAAEAAfpAAAAABnYHZYAAAAAM7A7LALu4BbC9l2JgehXyMb1ykfbq' +
            '6AaTAAAAAAA4LBzqvRy3ljV3xRBysaMWk9Z04oKj1DMBAAAAIuyyXADWaEP7bKXX+eRpBG8r+Q1pGhp6' +
            '1AAAAAEAAfpAAAAAEXZZLgAAAAAi7LJcAN8Z8d6AiBPypFVY/UjjWnjK0RebAAAAAAC+xs5gJtG6GvKX' +
            'FWV/RZ9PqyUITIaAELAAAAAAAjAm1W4+qw0MxBJwWkJAnr9bf+tliaL6cgAAAAADlB+hkF1u+hujGIfe' +
            'QsL84oA1wwDzpb/+AAAAAAAKbknAX6TEdjEbkbKPPSFFI4TZJIvUFUUAAAAAAtk02u5jhM138atuI97c' +
            '6bRc+vn4ocbe1gAAAAAAK2xTU2pmT0ampJGn5IdsGp+JN8PRyRCKAAAAABlr27IGfp+bsS4AgFNoEwYt' +
            'Aw2NtogsZ8IAAAAAAB7+kgCK3cko1PcvASzlmjM1FeYCeXLr4AAAAAAF5Akz3aOjdH0zyfJz/z716v0h' +
            'krg0glnXAAAAAADmconGqG2a+0C/MzwszQrtgE85arI9vrUAAAAAANCdwwC8q3TVe9e1wz+h9s0Y1yI1' +
            'uLft2AAAAAAA0J3DANjPeDqWXQ+NazbdUL5ydI5l9NkRAAAAAAANVwgM9/33uHQ7MUmqw557MVwUWMbZ' +
            'YQEAAAAAGSc5eW//NvbGkNJLirqldITvMlXSw1guYwAAAAB6sT3oef9q96Ll3HAQX3D0CKjrWaML66iI' +
            'AAAAABWKiglaBrrzphdNvzb7AXu2n6D68/4CD1kAAAAAAGfJXdAZqYBoNkY5EhBRQUQUEwjXPpdjJQAA' +
            'AAAAZykmMDUYgMHlzEjWW/hOZfkmiBl7X1ERAAAAAADQncMAQfVdS48jhto/2cpdTCVGRDZ15i8AAAAA' +
            'AACn2MBCQZT5J/fglwG03sr4biFntER6KwAAAAAAoa13IFb2XZjJxXDQGQPzgFLZDgNxSUOMAAAAAABt' +
            'hgZgZPTpD2Fa9a1EdWoYAmwtUSP2RqoAAAAABbEU9y+Tef6K2BWx59LSZW1LLXDDcpjpnQAAAAAAyGHW' +
            'LJ9ELdLVmEp7SjueJqCO3qUhTuuuAAAAAAa/1NwQq+KYrp2X/8496iKSJpu3O9I0Z4kAAAAAAMBpIJyu' +
            'gFqTmEbzWjp4GTE7mfwIu2EvSwAAAAACpgC5wLVjXQnLSqTlPhPIqDo8vnh3Cy7wAAAAAAovtAWA3QGm' +
            'FKpaExKIUNcPnjARiX+rbugAAAAAAMYveUDmn2B8dHayrVUK+9BzRhRF+MVCdAAAAAAAIjaLgBV8SR4C' +
            '0gXH80JNipsmwqHArIY0AAAAAAJb6PxgMf3A6zYQxx3czHw+cNzAff5ecwwAAAAADIwYJIA78BNrcd7z' +
            'ZjPBYoLTU7IaI8sE6AAAAAAMDFkcLkSbfGw/QvZrlZDz7D7X1Ymhk2MxAAAAAAQTFM8AV99ZymVS8C5x' +
            'b8Jotgz5a7ZFo7kAAAAAAGa+8PhaQqkF60uShSoIvwqaDZCfmz5JfgAAAAAAstBeAF0oBFou2Bfepoor' +
            '/p/K7wv4XTgvAAAAAAJRr6SAfVt/C/+ghxIr9FvdchxCNL3nnesAAAAAAcqq5KFhn+67AxwikolDz+9J' +
            'otQ9EixvLAEAAAGXdCDcAH3FrjUyLSAg6e+JZ3gblnqZqVu4AAAAAQAD9IAAAABD6LAkqwAAAZd0INwA' +
            'q0CbTE+UDx3e6CPRSq5EJziyDB0AAAAAHYN/zLquc/YF3Xgp7DTakwALKUr/Bst7EAAAAAABK9snMLZ+' +
            'KdYTu/I8Iq7BkIOh99l+SsDnAAAAAA97kNoAwIGGUDxZaOT5bDF3w3MIT9Ggef8AAAAAAIK7FxvJUulK' +
            'GJ8Ni5dS5EwZFs2t4aPllwAAAAACCYpngNbt4UEnT+qve1n73nTsuVPHH9aIAAAAABwN3r0u6mL5Pdwt' +
            'WrdU/uTNzIpjgzbs0ekAAAAAAQl/wRnym856echp0SYe0mFLjC+IJ8NA1wAAAAAG96tDQPMM/oxQJ2nB' +
            'ZUQNsMx8X3vEsTyuAAAAAABEurwqHHslSv3lBBQe/BJ43X4buuYxd84AAAAAADXgWnolCFrTMwNsiP73' +
            'ZrC/hFuCN8CdcgAAAAAA0UX9aCs5G7mXVX7lvN2AbxSYtMuoje+4AAAAAAE0iTXeMj85sIpp4H3KZRCL' +
            'xG3twEGWXo0AAAAAAcjVWHU2LqMbrwEDD2gzCa6Rpy9UQZJDawAAAAAA1MfaJWAP6N5gwSBFlBqPjinf' +
            'gJ0aWUX8AAAAAAGSaKmgcPLY9JjykCK0XNmNuM3hozG+whQAAAAAAAj7h3+PUZCShZOTBtU/XdegEM/I' +
            'cU8T8AAAAAABcdUTWqmYmCFoVGYmLmwfvAm7HBwtXLlCAAAAAIRsJEeAw9henbay6lJNdB92jx+dOH1i' +
            'I2YAAAAAAEhsLTnaFp2yTr5GOy8/OZ0lBqKB4mSQQQAAAAAA2WOq9ukx5zYFuOAVqvpGwFm0yTilVl6Q' +
            'AAAAAAAyluWw7DVALgyiKx6oUpju4Xe8SekK0QYAAAAAArx12ODw/1jmrXM2uidpoOPWYRT0tTY8DwAA' +
            'AAAAUImtAAk+Q6j1rDxbGvpjiQInRWpkcsbEAAAAAACvPNcAOE9fS92li37jPhQeVWVFtejzhOwAAAAA' +
            'ACYC4cNIsBjzUy1+mbRogkRYdB7qmeFFdAAAAAAL/WDpbVz6oPmwfAFTn0dWI+Qf+XDG1oghAAAAAALu' +
            'bCeAd9IsKzA9RavSd2QPR0OUNEgd9RoAAAAAABXnmuCVYW+W9/uqCFormziQUe/Pvbrt2QAAAAACPbHY' +
            'QKKq/uzwiDn3uhWv/hN7FB7Ndu/AAAAAAAJUpHqArxD04vVD5zhxcC9IFGSeX4LqQGIAAAAAAHTTOgCw' +
            'RIRZ5buxiUE4EBPPShXdqNDWBwAAAAAF2ZkvdLw9X4GLsoni0CQ/qVe8HBkm9fYjAAAAADJ5sOGAzWJM' +
            'tmYfZLe7IEqSep0QcrucJPkAAAAAAIJimeAEnVjtJqRS5uXdbWLkBFFUS7UEkAAAAAAAaE7hgEWUB7J2' +
            'PL9Ld7MDWI4Zp/D082AcAAAAAAAU3JOAVn/+dVVCux7LR75h0D7IRB6InGsAAAAABWAuUCRYKuMSF33K' +
            'OtrjjOWCpJiL7QiSGQAAAAAAZ6anGI0J9bltKAwdqzDvYXaDgHL16DW3AAAAAADQncMAo8a3VLp2DC6g' +
            'X1eH6CQfPtdgo2sAAAAAAA6aZ0CnVM0+kvYdJPSHpj1JFa7NCVltTQAAAAADQncMAKr514x9KsEOlYzl' +
            'Q7lZHa5XUtLiAAAAAAQ8zfYAq23+5Lvmi5g6tHxLRYjY42BpLusAAAAAAFnIzAfKOvs4aF9odXZwwbKb' +
            'hMleBx1THwAAAAAAIXqwItsb5fa7rrbseHNqdQs9aDZ/9fgrAAAAAAAAmJaA3gCGsYgDJ1j69N3eySHj' +
            '8WvNeYoAAAAAAg/0CkrxlI/lO7atzxM7YPHtqGkbHlyDLQEAAAGXdCDcAOM2FlvGoJS6OgLZ8zDzoYFa' +
            'SZoUAAAAAQAD9IAAAABD6LAkqwAAAZd0INwAYVLAgaPEJ4S5+OxR8xIKlRLKEuIBAAAAFbgixoDw2Qz7' +
            'msNwtEXMSzsQYy1uLL2J2QAAAAEAAfpAAAAACtwRY0AAAAAVuCLGgP1l5XRP5PZtxNUE4PuYjT3Tr8Kw' +
            'AAAAAAASxoTABB5XOmiq9vY9Yid6k0cKLbVGxCwAAAAACsS2/oAQqoGhhYLP6gVOmXtfZc9OGneYPwAA' +
            'AAABKhLDQBolWpcrUvTpkL9g74vUXt+yxdiDAAAAAAJbJ4BQIm01f0oxMQgnyBYMbci9xqFRW84AAAAA' +
            'AGhO4YAv4cJ4mgyMnJYYoFJG1vWaPJkZUwAAAAAHxjL3gDUx4Udkri7+gMXDFVYXRTj0pdSSAAAAACL4' +
            'nh4ARgy2EzJ+z+2WnyW5Qk44ZOufTmQAAAAAAGgClkBHPYpXx0E5aQKzx0VLJ73Q1qE0zgAAAAAAIJsr' +
            'AGOjSp+87x5i7aRxGmLyyDnonUuHAAAAAAAAmJaAZFrmQqr9PmJ4fnW4v/mAupUTrkoAAAAAAZwlGMVq' +
            'MO4AULnD9+Kay+YVvOqUmMn1IAAAAAAANZ78aHC1i0PipE0Agm261dVDwdD0HgyBAAAAAAJn1e8QeHYS' +
            'gsN2grgBRz6/xkmoQFNJP6AAAAAAA4EMxoB50gL2LI0FyJ8TpGH/3iXwxwX/WQAAAAAI0MI1fIsGSPJW' +
            'oIbd3Mv1MSrO2o3rgR0rAAAAAAFQDQ2At4FrZC/Px/o70EA8Zh7KhVcQ+soAAAAABBMUzwDH+c2UkjtB' +
            's61PJ0EATe684SoF6gAAAAAAPpW6gNfTQPfre2XK7iOrsVTyA/PpJG5DAAAAAAGRg2Bp5LERSoardGFu' +
            'qbe4Jc4Vkxvx4zsAAAAAADnRBoD0+rKr5KoejH2n+CEE+FFNSKlfRAAAAAAAaE7hgA/Us+q5unJSOA2z' +
            'V5UWWXEv/18FAAAAAAASlr9CJZF4kzrSX4RaAy8QIEz8HVWpuI8AAAAAAFeea4ApkHje58LcRI8cbja1' +
            'BBoLnvZ0xwAAAAAAy7a58D/dEU/dsxaTwcgeg58/1ymaY/AWAAAAAAC2vEUiYYNgTKzRg0YGp3GrNwDu' +
            'mAT6M1oAAAAAAAnoxhBoB3elzeXP4BMNygxzyPBjSlLyiQAAAAAAaE7hgG9JTmsqcX/EzpD6ylIOdauu' +
            '+qSVAAAAAAAL68IAed5ElWGeg+1jYH1x3WW9pB6IUIUAAAAAAHo/xsCad/B4f3j8s1tVcyDLjmf6gCG3' +
            'IwAAAAAADOkNwKVQe9bHmQp8vX1is0uqs57Qr3U3AAAAAAAC+vCAqjsjNCoMveBDrAxPNymYSIG6an0A' +
            'AAAAAGv1e1DVwZrTMaBI8AMFyoBM0t0uQiYpRAAAAAABK9snMOskJq+j7ZCRBb1aKQUNmeZGrELpAAAA' +
            'AAUTSTAAqz3FcVv7MASTyskemfn5sjnGgJ4BAAAAEWAcICDsdAZP1SuYeqORyPES1bX7/RPlowAAAAEA' +
            'AfpAAAAACLAOEBAAAAARYBwgIPtmU8hcpJbNDq1nVJukOwH6GSsAAAAAAAAM1HRQlWwQpF+TpvFVHS1D' +
            'Nsp7eu8XE9sBAAAAUX2gLABGbl+JG1aT7ua3UUzQ1LQbHJyBYQAAAAEAAfpAAAAAKL7QFgAAAABRfaAs' +
            'AFZGizZmo3lPVE+LSA1zBlyFFNV5AAAAAAF5TCKAXUXnx/WZ8vv66VV1S0IMmuzdieQAAAAAAB9K3UBo' +
            'gSr2tGG4/iSxBFgSXF9qZO6y0wAAAAAEstHNzGqtUvT9ITtrVnJDKe/S/KFnvsvlAAAAAABdgf0Ad5Mb' +
            'RMlsar6KW7kr5wNo2Rt8mr8AAAAAFUNuXyCF7Pe0fiNs4Tl3hY3X0g7yaAjPxwAAAAAAA3UCgJ0dhH1T' +
            'tTkbkvyBSGCHC1AUbmq8AAAAAAQrCRu+ni3vwB8Qnzkljsmex88fQNafyJcAAAAAC6Q7dADrzUPu4bw+' +
            'ZSVtt2k7+FRbZGCm+QAAAAABbAkN4OwGZDJR68MgqWeZkJH1/W2SHZV8AAAAAABSoIZ69NpWol8ja+ai' +
            'cuArhkufWeBKHywAAAAADXIrEYD7wfZIo6M5f+nnrJJ8u3Wgpb98zwAAAAAAaVno4P05NwJ/8JxcKV06' +
            '2fH5z4SmMiZAAAAAAAAAp9jAAugQWCLztwOdPa5a/DSu3rKwGG0AAAAAABMdfmAD57/WOzc7Tr/WsuB4' +
            'KHy1XR3Y0gAAAAAOZmkCIBefnfUoFw+MGRqeGooJSH+A/JcqAQAAABWjdwcADk7+zrIRFCgBK6VG7oAc' +
            'iM2HRigAAAABAAH6QAAAAArRu4OAAAAAFaN3BwASqEBYy6PloFfyDuDqlXGmm5VMyAAAAAABl4HrQhUj' +
            '3OUv7F2vlm4qYBQ36Im19xE/AAAAABcy8cWUGEdaGEpIDuimbiYSzhKQzvFsVpMAAAAAAACYloAZqWFo' +
            'se4/aYhovMeeuvgbub7HtAAAAAAApD/Hayic5it8ME0DNzoRn60xcLbxIwTRAAAAAAABvLcoKUTTPJWE' +
            'VctTQacwVkssekk/VQEAAAAABlIaQkUtYxdnKMmUFoQ2fI3yImnUNr1TDAAAAAABDDiNADLrjTQwP+qg' +
            'B92rUdTrNBcfCbGVAAAAAAC+IZg8X+iLd+iJYWqg21+Dyza/AZSrhbQAAAAAA0J3DABiKM20bMHiIlQ8' +
            'HcTrLRdFtYGeqQAAAAAAaE7hgGNXoEwcLMIMWBSNUt/Rd6FgYYoqAAAAAABhHyTMf1OFjrdM0b96K02H' +
            'TFGyC86vX7UAAAAAC9SUb3CIB/JOfGRFJka9YoVxOV/4K/GZCAAAAAAACm5JwIupQnwoc0VTSDqi6+jT' +
            'hSfxXXixAAAAAHo8cEIAkSpoYSLpDbMdEdi3F/QVhcPIEPwAAAAAAmBDLQOsTjr+THXLE+FPPSxFbAxm' +
            'ePifTwAAAAAA0J3DALI/ITXk76zta07Qumc9YgbGHscZAAAAABe+LQZH2KNkezGNQVx78PkJxd0xFJWE' +
            'fHsAAAAAAeBp1wD6D6hZgsj7DV8W2Pvp40PH3d9aTwAAAAAD2KB8J9EuDyTOC6kCr9ct0C2YR5jaiHoU' +
            'AQAAAAAT3cEgJo7py3oqG0+xCjkxY+vxuyU9ypQAAAABAAH6QAAAAAAJ7uCQAAAAABPdwSAtntGGsgLu' +
            'Q4F2s3CZRLNXv5LfLwAAAAACcdlJADKvbmLBIssIiEV1pl/0PvI5sl6KAAAAAABhsTZ8Oby2rLxu7g8G' +
            'NePcXVyCmJ/WEdcAAAAAA5q7daJZwczBhc60XqQrBhbz5DQRQsHr0wAAAAAAvEb5f1vAmV2rlD8Jmzx9' +
            'P/qvMm2kHW9AAAAAAAFgSOOwY8Ii2Xdzg9hKPgXrJtHlsQKqM9EBAAAAATXxtABwu4Ukg68+L8VltXoh' +
            'LpV47JlKCgAAAAEAAfpAAAAAAJr42gAAAAABNfG0AHedB4yX45n/PlLgZqqnpDBfrxF0AAAAAADQncMA' +
            'hxDYae5S9ciWxq9I24hfuzaG5qwAAAAABWAJld9oCT9XJQcMavDlgXxhyQD+wLfXAgEAAACLsslwAKaP' +
            'xRctlLK8F7c0ZpnFJrj3iY16AAAAAQAB+kAAAABF2WS4AAAAAIuyyXAArQsEdX8bEbK88KO9nQWFUlCr' +
            '52AAAAAAAgmKZ4DVIgTftFr0fZruBA1N/U7mWfWdoQAAAAACeGPv8OTO+KKhb6wc4m9YJRz1JsLRYD2p' +
            'AAAAAAA0J3DA/+SLSTLr+Y/+0Hkgk8Y6yeOS14wAAAAAAJtVwcEKWAO+6K2N6gduK4ILQFDMB8EbgQAA' +
            'AAAAstBplytFxuvmm8IQkYMFyjMmY8jVtgFXAAAAAAD+JO+eLNpj8dzQwpznhYyLC1tZkr5yipMAAAAA' +
            'RdlkuABUEecNd5TPOFirCyrej1Z2AexdrgAAAAABSNQH9lXPfK1NA4Hemkg3Mw78wgMfoj02AAAAAAYc' +
            'nzaAj/CSIQK9x8wWwZ0b2K7rRsbW2TwAAAAAAYBGB1qVu/C200Ie5V6SoPmNHrUJaNtKGwAAAAAAXCIb' +
            '17MWOBLa+yJUgdHhDBre/T7Oz+6JAAAAAAXSHboA55Sxb2w1fHCesfem12HmmzQGbmMAAAAAAAwJ66nu' +
            '6pROw/OceBrlzYZ4KPa5RRA2vQAAAAABBMUzwBYtMGt+JGeSXQHlZ0erNcofNc4vAAAAAAI7qx2TGMUu' +
            '97W9uyDG+C0C5+A34TLQQ7gAAAAAAIEJFFEa4V/HQsz4fKgKtjrC4hkv1GtOCQAAAAAaqOtz7DI6R1hK' +
            'UpfSuyJASZpgZcij5PDoAAAAAALaKCqAN7mToGCzhPgP95Qvw+DdPWb1CN4AAAAAAS6jKiFPq7/b7D4V' +
            '6tH+IKvCHWSa0HiNowAAAAABZoWdwFUgU0GQqG1Yv+i/I8JIVYxLojheAAAAAAlQNywjXrFj2wJlMZ8R' +
            'WTJQ2wMSmy9wEpoAAAAAAeNLYrtkFb282q7eaJ/NZ6x4Dkk2Gu01UwAAAAABkt/ttmg7vVuu7d9wYJYX' +
            'Sop232tA+/M7AAAAAAuicbCAkzE5oaV19+9SZrlOsAvhiyPCXGQAAAAAABe1au7AJHEchj3fiBMpNgEZ' +
            'xYY2IfEVlAAAAAAA70CbwMSMtnJoqFW3qSRrLyCVgznhoBQ6AAAAAAED1OBQ/SJwLf8yzbtIEXbMNuG5' +
            '7Kz2eG4BAAAArcEUrWAP4gAPXtu9RZx4YE7JuSO1b8eZOwAAAAEAAfpAAAAAVuCKVrAAAACtwRStYB9L' +
            '+L4jNoJ8iodJVNVdNjiIXUF9AAAAAAAKV2X8JaEaT/MI/fKzs4JGKlNIvJKMlncAAAAAC+CUXeAyOWwA' +
            'V2daVbv7TwqNa5P2A2UAHQAAAAAAHya5QCoQsaQG66H+l7cOIr5o5UvOs++PAQAAAAbna7eANqdqy0Fo' +
            'eqG6RzY2i3Vffpl89k0AAAABAAH6QAAAAANztdvAAAAABudrt4BHOiWjKC80jF9Ch2sHMiISP7/37AAA' +
            'AAABfw+o4HRJ8Hbyh9WPB8+OGTP1FmHGDhO1AAAAAAVxXCs4gpT0W2y6Xz71yETk/LOXRTDpFFEAAAAA' +
            'AaE7hgCq77Xli1AQoZ0aNlqICeGarILedAAAAAABKuebnLJso7BZ36HUUQkgNM7gfFLFUiMMAAAAAAI2' +
            '40qA0nsOpBn/b2hivJIYgSCh5FbTHyEAAAAAHhcEzDPdxD91L49ZbSs6XGoV2EM/Vfyu+QAAAAANChvn' +
            'dlHnZ+5mUH4jfhhMvuGhYufRiEVIAQAAACtG7g4A+WLSVftsi6BrEZL39zEJ9d+EPe0AAAABAAH6QAAA' +
            'ABWjdwcAAAAAK0buDgAD0v736KaDElx101Wm1CMX26Bz8QAAAAAADuLoFPCVIZcnrtRUFeNqK1wZ+1Ap' +
            '6J53AQAAAZd0INwAEUT7D1mh732gOtdkCPx9V+qw5+AAAAABAAP0gAAAAEPosCSrAAABl3Qg3AAnlUbN' +
            'OlMn0VT/iGCz50x0jmPvrAAAAAAAdETFpCgnh+V/A60Jk9iO9wTW+LY9Sh3TAAAAAAEkiiMAO8chaSLb' +
            'FXxd0hlOeX5mX2jXGpsAAAAAANCdwwBAdvS9ygKWG+L91gd4DZQcBFCbjgAAAAAAvVzBYO0yS842t4xm' +
            'vZrqDgAdvkzx640FAQAAAAlZDItgR0iNPsHFIbRISV0nEXy2C//Q/dIAAAABAAH6QAAAAASshkWwAAAA' +
            'CVkMi2BMbBOTfplBAgyEBM2bwpkpB5K8QAAAAAAK4oRjgGCTk3JdGjLG756Ai1N2Lx7xCAWgAAAAAAE4' +
            '7KSAYiQ86OeOf8MeXi0V40PFFNPqNuIAAAAAAGhO4YBkQjfaQT9A9UFrMB29IaMckbzciwAAAAAGHJ82' +
            'gG7mEZ4LZYUpKtNKcSmTFqSC9JCHAAAAAAkxxd8eb7O0zWBS2lYn747wCQ7JeQpDKx8AAAAAAW11gy07' +
            'yidsQ3wcF6QL7A0sUb26T1A4rAEAAAA8ln/dwHKiovl814ZPbPRx2s5ZmBdHyxOxAAAAAQAB+kAAAAAe' +
            'Sz/u4AAAADyWf93Af/t2TEfBFV0rh756/NV9om1nPPAAAAAAAPoLWfuEEmFK2BE6XVTF7zOwemc52Zs9' +
            'EwAAAAAAPUu4IqiqZU6VBuR9KRohm6YyfGr2oYxPAAAAAAAt5ssgsxGzPJ38XfDoF4SHkZQCzUUjoooA' +
            'AAAAAYi+A27AEZ/iHoNTmc0FNXEXW9mVqoroywAAAAAJ55tumsdUkQ2kL+4A64QhDmiYnuPAWiuFAAAA' +
            'AAGfccKAP94z5Tq+QbXDxjxstkHeY57jrEgBAAAAGhApbOAIDqqaofoXXO6EpisTW4HFIRPy9wAAAAEA' +
            'AfpAAAAADQgUtnAAAAAaECls4BAXw8be/oigImYNrwH0qhJFBrvHAAAAAAVMcWWBIS4OcWxSwPVP233Y' +
            'uwtz1ZBafH0AAAAAAFGoioBIDe92+SCeWGD/us+IJlCBQKqZMQAAAAAAH0rdQFkwY/Rk+9Z0TXj2IBVf' +
            'YYX+4iNjAAAAABkhubEAbRup6s3lzUHkHbrzlbwJyqJ/0RQAAAAAAgh/YCB7DPYxPhoY6oyAt/IkbZ2h' +
            'ERWjmwAAAAADCDarRInc83w5pZP76Tt9rZvlvO6V8kS3AAAAAABTXCj7jo9+2t1sgWI3K99p+MKvWdd0' +
            'n+cAAAAAC0clUQ/NX7WWh/oh8J+C0sOS3WSWXkVHqAAAAAABlZuyoOWjlMT7uZc55hJeW8nDcIrqEIgB' +
            'AAAAAAEND4vtCoWfs9zoqCSiUVHzidCnKlNif5UAAAAAAAH7WtAUnviq9tJ1X2/tmhDKEj7JmZUq9wAA' +
            'AAABccW2cCFeJz8p9vDqDwSNYOxgJhStNNYSAQAAACLsslwAKF+jlbe9GxMD8+XnXQFCs8pfOTUAAAAB' +
            'AAH6QAAAABF2WS4AAAAAIuyyXAAtDyyk/7Ii4LRb98rFZv2rgQDopwAAAAAANCdwwEC9T2L3zsnCWIzn' +
            'gJCfmyJmH/0rAAAAAABoTuGAQ1tU9AEhyP+0UA/smwsccvNhpkkAAAAABBMUzwBJNwef9Jdpo6SmQGCe' +
            'rXwZLz09ggAAAATlr45dSE6XaFbAibXoVdRWvvS7VWLForNmAAAAAAsIoCTzW3koUkIaLDz9G8LLdpve' +
            '30xTXBAAAAAAAFPvrSGFWksiBpjU9qsJawHzerQwUwfMOQAAAAAKWNHUFoZ7L/iaDv/NmzJzaK6AzZlb' +
            '4WqkAAAAAAi/etu/htz6VkZNANXC1cHCU1l0GoVvFfUAAAAAAIC+/ACOCo4vaOgITUvd07qEIUKGcPGv' +
            'GAAAAAAAAJiWgI5wE7f0RzLNyKsuXLMeJzfgInixAAAAAAH8ctXMkWJENgb+60tXcF2Q7zJOAROdvcsA' +
            'AAAAADTfzam9dZ5xRhi1rUJRygc+NeE0q/YpvAAAAAAA0J3DABb5q7crphQbOxXVYzEU+kkzgph9AQAA' +
            'ATGXGKUAx/UL61EGbl3vKOH0nZj+tyrgpjEAAAABAAH6QAAAAJjLjFKAAAABMZcYpQDJGty+VDC/nZ9c' +
            '2JMR/WUVG28HbgAAAAAAGtL7pdBkGFEdoW+MtEP0uZmaNq7B0prrAAAAAADZpChPwJORElVzh043nx8K' +
            'kpfKdK5/teIBAAAAK3BFjQAJWONZCiaZFlaefenGMfytbGvXOwAAAAEAAfpAAAAAFbgixoAAAAArcEWN' +
            'ABKpZ8dJ7qYApDKYjkGUiYDsA+yeAAAAAALSHd3WFcEIFIlau+J9rjmDEax6eV5vybUAAAAAAXH7HlAa' +
            'NWtijFevO+2JcC2QSGTYoNTcmAAAAAABk4qUYDPAsmDswqhxXPe3B41gWFrHB6NPAAAAAACx/G8APgmy' +
            'AgK8pKfkX0dogIxtLJJ9/8gAAAAABKgXyABHbwL8pjXeDcusrFVQLqdeHcg2YgAAAAAAezR6ZUgJ6fDo' +
            'l3LGvZlnlODDHMheKFSIAAAAAAG2GBmAaO4cmhSoXsLZYMW1Cvl+R7yJ09MAAAAAABtxJYBqOhoXtH+G' +
            'nxJQosYmUI3eyG6E8gAAAAAEJCKnQHJWMZNPfFm9uHLWP0zrNGcshONrAAAAAAAVycNHdPxE0GxTYHIc' +
            '8VcOA8eReA7zFZ8AAAAAAapaqaGIAJc0Rsq+QjxrMndC9R2lWx+APgAAAAAA0J3DAORG1KWtb3KZE4tr' +
            'Kj/VbxjqIxScAAAAAAB7j7hq6Qm6sgXOn4bCbzYm8fyRZCu+zKEAAAAAAAExLQAE0uOno4PCXqNEvREu' +
            'TUjMKEuDPQAAAAAAhJFOCxIamvXEHhkhyrIxnueWqGlXFnHSAAAAABumbZyLdBLEzha8H8v5YyDwT5NV' +
            'pqBOS38AAAAAAJx2UkDoQqlJI+Dy8grbCH9ST4GusQVXmwEAAAGXdCDcAJdIkna6RP6mcb5TlD5tBxL8' +
            'pYfeAAAAAQAD9IAAAABD6LAkqwAAAZd0INwAoB+7ekrYsxU+DX66BF0/fgwJR1QAAAAAAH+NzwC9DAp0' +
            'oXoTguaWDifw2VzlRcoH5wAAAAAEDR7uAMiWVvXtPkrBPxATxtpfw2Rys4w8AAAAAAKVskB3zGBqS7Jz' +
            '5JpkYD0Dfwg9l8Iv3RMAAAAAB9b15pz6WxnQp7FJqtljFbtDLl4Veyu4WwAAAAAAXxC/UQA5dRqDP0ZB' +
            '9M+kxC0b1Ura/tvnAAAAAABoTuGANNaqPwZFLR4iHg0l40RzrUERcPkAAAAAAAX14QA98+4sG38zR4Vj' +
            'kA/ogDebRnQ+jQAAAAAkMiY2r0q8UCmj9Gl8FkHmx3crQCOkIyFbAAAAAAAzmKsuW3YOtQ8dh0BQj04v' +
            '7wSI+7HoC9YAAAAAAS/70wB+HWsjdSu/1CO0JvV9IWkX+K4AZQAAAAAFjswMc4zP+VyEfyaImf/2q994' +
            'rafxUk9XAAAAAABQoVOwlkMW0TtzZViUSO+i3UTUxduerCQAAAAAAXWfB+SwsnXcypqVmn6cTDzMDmE0' +
            'Tv+e0wAAAAAEExTPANFsDuQNTv78NJGC1aV3lvXsMaTWAAAAAACVlXUA07oyOHfBnnb+XvYJix5b2ekT' +
            'ST8AAAAAAfxeNkBY7JIoxRTvrKCFQ7oJabFF8asDlgEAAAART5HPwOvU7JFL7PhcQVhdUKgdzA9Lrk09' +
            'AAAAAQAB+kAAAAAIp8jn4AAAABFPkc/A72BVjTM+d4OQJvobBXThsPHk0HkAAAAAKepeSBTzpTFQnUbf' +
            'h+BYwnYmcqUTZsPOOwAAAAAAFDRZGA=='
    },

    'test': {
        NETWORK_ID: 1,
        NETWORK_NAME: 'test',
        SEED_PEERS: [
            WssPeerAddress.seed('seed1.nimiq-testnet.com', 8080, '175d5f01af8a5911c240a78df689a76eef782d793ca15d073bdc913edd07c74b'),
            WssPeerAddress.seed('seed2.nimiq-testnet.com', 8080, '2c950d2afad1aa7ad12f01a56527f709b7687b1b00c94da6e0bd8ae4d263d47c'),
            WssPeerAddress.seed('seed3.nimiq-testnet.com', 8080, '03feec9d5316a7b5ebb69c4e709547a28afe8e9ef91ee568df489d29e9845bb8'),
            WssPeerAddress.seed('seed4.nimiq-testnet.com', 8080, '943d5669226d3716a830371d99143af98bbaf84c630db24bdd67e55ccb7a9011')
        ],
        SEED_LISTS: [],
        GENESIS_BLOCK: new Block(
            new BlockHeader(
                new Hash(null),
                new Hash(null),
                Hash.fromBase64('9rorv34UeKIJBXAARx1z+9wo3wtxd0fZKc/egpxBIPY='),
                Hash.fromBase64('LgLaPRYuIPqYICnb3pzCD2tDGrBd8XZPNK9MYqTysz8='),
                BlockUtils.difficultyToCompact(1),
                1,
                1522735199,
                79001,
                BlockHeader.Version.V1),
            new BlockInterlink([], new Hash(null)),
            new BlockBody(Address.fromBase64('AAAAAAAAAAAAAAAAAAAAAAAAAAA='), [], BufferUtils.fromBase64('VGVzdE5ldA=='))
        ),
        GENESIS_ACCOUNTS:
            'AGRtpYhkbK5oQO5sU0S0+SMRztHCSQAAAAI2YQIo76+W/Qdx18mqTunnsgXJOKCOD3tLAAAAAd9ogj9y' +
            'lKw7pwp10pk+949jFlqJxAmT0O0BAAADY/CKKve10FB3Vykom6+T63UZ+l5RdMqVCAAAAAEAABaAAAAD' +
            'Y/CKKvcAAANj8Ioq917gf/WlrJ6y1E8IQ2okMCP6nphjAQAAA+ZJ4h5o2f56lf7OXSVX/+pPPMh1E/V7' +
            'F3MAAAABAAAWgAAAA+ZJ4h5oAAAD5kniHmj1lhDTt0y0ONlmMNJecaymzJJFDAAAAAILzN2PaaO+PKDZ' +
            'QKTKVnNrImV/jtIq1JVnAQAAAl2Pzuo8WJqJbnQMHTNrCIilQtfH+0/l8R4AAAABAAALQAAAAGTtTScK' +
            'AAACXY/O6jxQUKUSMKfMvmGTPwmD1sAScTjceQEAAAD1FNRPHJq+yIJf+QThlgj/uV2zDk8R0/ejAAAA' +
            'AQAAFoAAAAD1FNRPHAAAAPUU1E8ckmdk1CPLIiMkQSldqbWvVZblMQMBAAABW9MKiWkhVWQl5UDggSKP' +
            'KkJQikt4ltYOwwAAAAEAAAtAAAAAOfiBwZIAAAFb0wqJaa1WzaUO7G4NCi8oMKFCwq23XsAbAQAAAjET' +
            'oSPQnzWIh98MHDKYWhEEkO1+hpLrVe8AAAABAAAWgAAAAjEToSPQAAACMROhI9BSc3ly9rKarERDLtgL' +
            '0p1+Z91nmwAAAAFZpzPQK5IydxwdnXub6OYHp1kTgVA39ekBAQAAAk+9TT+9KMQEm2JEquqqHs9sxvEP' +
            'CSPlO1QAAAABAAAWgAAAAk+9TT+9AAACT71NP73r6DhrXOcvSMVlMHjxxJGiY/yRtwEAAAPAAJXcxOA9' +
            'UO5dsui8VI61yzogToSKifxaAAAAAQAAFoAAAAPAAJXcxAAAA8AAldzEWH8rLbLbKoRm321v0VFa5iqt' +
            'X8wBAAABa5+Pz7TVnIzuPKRuDTlBOsxZo7y33K+CjwAAAAEAAAtAAAAAPJqX9/QAAAFrn4/PtDiLaSDO' +
            'gHwkXgxtBKaCir2XDXKjAQAAAnUXHJrKG3/t01eblZWAWkiAzs/VQUA4h9EAAAABAAALQAAAAGjZL28i' +
            'AAACdRccmsrFnj2zLaZ4YvLdcnG0JCdEL1KfOwAAAAD/Em+d805Zn8TJrlep4lagCi+lcLQRWa+xAQAA' +
            'AeVb+PpCZp9dsB/E1OwQmE4GFHdbAhRL7p8AAAABAAALQAAAAFDkqX8LAAAB5Vv4+kIF6ZLAKDNObvGV' +
            'x22Ha9QOFewrcgAAAACDKCKIVQHOe7FSwWolUKvDT9FN8BvChJzmAQAAAIco91buAcOmTPSEHR0RLX93' +
            '8nmIGN3QzBAAAAABAAAWgAAAAIco91buAAAAhyj3Vu52wLbeHNtfyWI8M1rmUfsqZvM8kAAAAACycUQn' +
            '1EWzXlSWfL5j1NKrH1BwyMtnB0+ZAQAAA06PszJanoL7ebkCBwTwhjHB6jEJPnVsZGYAAAABAAALQAAA' +
            'AI0X8zMPAAADTo+zMloJPKLaQ03LThkywi5uAbkpKmeorAAAAAPttNS3OKK6Rk9sgeCCLFfIkFMnlYrx' +
            'iHxGAQAAAKa1mOYVDEuUc+eRf/0xs/O69qteFjrfQJ4AAAABAAAWgAAAAKa1mOYVAAAAprWY5hWyGdnP' +
            'ShceVlIWYr1jNInrFmSY2AAAAAC9GcQvl+FD9rlnVh+dePydT/HcD7JZMpgXAAAAALbBAO91yI6kP1LQ' +
            'kgfoFphhou6w28KrTOcAAAAD/rMPQ994M3FTR2rM5VzivXES6JSQKvWangEAAAHrQmTUYAVFtxMFAfCV' +
            'mOI/CPWw1uF69ie2AAAAAQAAC0AAAABR4GYjZgAAAetCZNRgh4HXIo5PmNiXNZFWh3xn3rv/czQBAAAA' +
            'vTxC6GxF+sNHOpl49EtdTkOc7X7iDrNQ8wAAAAEAAAtAAAAAH4oLJr0AAAC9PELobNAoM3MbWmAIt+jZ' +
            '3IkIkHmr3GrSAQAAALO+pRcvwEYkRnNpJQCXOWFutBiZ9lca2VcAAAABAAALQAAAAB31G4PeAAAAs76l' +
            'Fy/RvUUU3oGlMKTlTij1B0SiWuQkPgEAAAF7brhSaJG6NDLeE/+sz7K5ZGOZivNOntOeAAAAAQAAFoAA' +
            'AAF7brhSaAAAAXtuuFJonLXAwj7WoWE2DCa1W4GxRSYOJYIAAAADJ2oxNjxv3hEIxGMtXeEcBJxFz6n7' +
            'v+QclAEAAAG1a+EcqTKU5FdGvyUJcShqM2k8BjRk9SAyAAAAAQAAFoAAAAG1a+EcqQAAAbVr4RypQsgQ' +
            'WW0xaEsJuYNYKlFw8NpGOzYBAAAAA4toboMznVCwh/1oRz/3WnAoZlJYuQG3ZwAAAAEAABaAAAAAA4to' +
            'boMAAAADi2hug1a/+3i0b34JLF+Ps46aVUJ5JrTfAQAAAVu5f2l/U03YEcxPrclI122VDvHjtGyHeRsA' +
            'AAABAAALQAAAADn0P+brAAABW7l/aX8BqY/x0GFwsSp36hAxu5tFJuPIyAEAAACV8p6fGnPViEhKb0cD' +
            'DhmxXNF+o36tKGjkAAAAAQAAC0AAAAAY/cUahQAAAJXynp8aE8PH5kXg9J8wum/UC7eUytM/4zgBAAAC' +
            '1uw87ooJB9xfdNsCLTwluw52nDQSwatCAAAAAAEAABaAAAAC1uw87ooAAALW7Dzuij0a3qwPjiSXgdCt' +
            'asOASCDhFFrNAQAAAUKQwYjn4/JqJpoTqcVon2u1PFsf6br8xFoAAAABAAAWgAAAAUKQwYjnAAABQpDB' +
            'iOc67iZpZw+cF5hqyKoCPI3SIqczPwAAAALAElVwJOnsXdPfU3OWPgiSBSWFmatwOSp0AQAAATWuW4P0' +
            'nR2J0NWgsELIYprEHLwZA7zE1nYAAAABAAALQAAAADOdD0CpAAABNa5bg/QVNgm5lfTIXCeaAcHFllss' +
            'gcYGpgEAAAPP0jEZczZn15ceEW+6z4L25RdDyVIJmubqAAAAAQAAC0AAAACiowgu6QAAA8/SMRlzkIc9' +
            'WbLDTMQPF2VVqGuX+V4la88AAAADLOZAWTFOqn4vT+pOgOplxa6INDwvtRNQBwAAAAMsVwD1nq8c/smm' +
            'jqcvV9cq8un/zhTOXwDUAQAAAOYWT/u9mNFWv1LvXVNR6nFGYBW/Gf0rXjcAAAABAAALQAAAACZZDVSg' +
            'AAAA5hZP+73sTlo7xlXt8boPoPjmlnYkK6umNgEAAAMO0bYkx508+RS/1ID91Wv36UCE0mDA9g3ZAAAA' +
            'AQAAFoAAAAMO0bYkxwAAAw7RtiTHzT173148/NQiL4OIorQAhaxlq80BAAAARRXX/sh8WYG6g+OYfDLs' +
            'Nv7BV+7wr59eeQAAAAEAABaAAAAARRXX/sgAAABFFdf+yN3L7gDGvez1wUpIw6XpaKkk047lAAAAAeux' +
            'BjMFGoUGJ4pfHsWaxATJ0f1VzPR4tvEBAAADdp/vwBdBJEdEGpq6ln6tuWPD8lWRwKa1MQAAAAEAAAtA' +
            'AAAAk8VSoAQAAAN2n+/AF/V2HS/R/Dac99BojkjeAYwxnFsSAQAAAmPxNB6uVH9bjeFsVEZTftZGQqrC' +
            'JBckKmgAAAABAAAWgAAAAmPxNB6uAAACY/E0Hq4LRv4M59EHEX33FeDxs1HblS54wgAAAAHruSKAPr6i' +
            'V75K1i/LER/K5Fib23KFr2BmAAAAAQkRmkA+DGSuJaRUPeqk3/GIcze6QWIJZw8BAAAD+jADEhLUMDGf' +
            '7IORZDd+0ep9JoiexWPpIAAAAAEAAAtAAAAAqbKrLa4AAAP6MAMSEm/wcvuKgPvR93UC6gg7uLRGD0Cn' +
            'AQAAAbfE4Un/Tth3SP6WtJ9e4cH/Pzpds0otpp0AAAABAAALQAAAAElLeuGrAAABt8ThSf9xbemTSE50' +
            'kxXsbhDIlrTTPwQH0gEAAAJJqEmsdHOahlJLBDNDZyVO/QPk5ZvAe/ByAAAAAQAAC0AAAABhnAxHaQAA' +
            'AkmoSax0Lz6fTZjQY0nJ4XsSPNJYHcw+WkYAAAAD8zk5UlAV+Ugcx25Pq9qm/xDbbtMAeQdbQgEAAAEt' +
            'FcSBcSxB0RnkZXl+UCYK3YFp8AVvZPgUAAAAAQAAFoAAAAEtFcSBcQAAAS0VxIFxgUHH6VKl7R6Xxi+u' +
            'UC97xBX4anUBAAADuGVoFiU6+EzTmr38oz1z3IulyWo/wVRpqAAAAAEAAAtAAAAAnruRWQcAAAO4ZWgW' +
            'JW+ty2ixCIQ8AUfgE2EngV1h0/mOAAAAA/2TgfMeB9iI5gRi6lFt6xgKfvomo9e56WIBAAAASPsH4l3g' +
            '4q/fociq4refm1UI92gL9nhkXAAAAAEAABaAAAAASPsH4l0AAABI+wfiXVw3guq4ZlItQvBtd91YxP84' +
            '632UAQAAAIppTx4Wyiy9+VuiZtmk17xq0mcj7ozk+zQAAAABAAAWgAAAAIppTx4WAAAAimlPHhaov/PM' +
            'vxBsvJXJ2pU9D21cQSA0bgAAAAOaU8VU8iao8HvM6eW28IHG51giSV5NPHlYAAAABA+UpuhjG7yIsumW' +
            'M2hqSA6fuj0xCCCeN68AAAAAMmdwZLBQDurp31G0Lo1OzcI/BXoVKrRIrQEAAAOLqmH2Jpo78+QpFRSy' +
            'Nsc2jRp5vZY3xKWWAAAAAQAAFoAAAAOLqmH2JgAAA4uqYfYm6ngfyqe2caAdaxv4owt504u0tD0BAAAC' +
            '0xsm8PS4UmJXghyK3jFGzuGO+EXU7CEaXgAAAAEAAAtAAAAAeISGfX4AAALTGybw9DGZvJndi55QHQoZ' +
            'qJEDmLH3WufiAAAAAg6tFpRAqVky+V2UV4lwiAdvXsTJ/6DWQEIBAAAEAGwkiVAlWo9aaeMByXaRO16H' +
            'suw+01R3cAAAAAEAAAtAAAAAqrywwY4AAAQAbCSJUAV2ix0LBGomuH01sJsiX7Ieys7IAAAAACCibi1N' +
            'QotobPjZD+MVe53Fm8ID9jELIn0BAAAAk+4tGsTHKqv+0DZPz0LUnUQzoFdzI02LuAAAAAEAABaAAAAA' +
            'k+4tGsQAAACT7i0axDAU+Q7q2KbIbpNZXm3LMMNu+ekDAQAAA9jMyUAmbW9jmFTCzsO9mX57qTp4aECi' +
            'tKMAAAABAAAWgAAAA9jMyUAmAAAD2MzJQCZDJxiOABYC8VI0Knd3ocTMH8d5hgAAAADgfCs1F42jJ5xU' +
            'Cz/+x+hW0shZT+fc1oDtAQAAANg5F3AMLNkLSS6yG2I5Y9McB26kgRxf4k4AAAABAAALQAAAACQJg+gC' +
            'AAAA2DkXcAzvW4MjMmSAgY8dLJKQ/8BGADzWVQAAAALcpPnPMuwRHdERewIASHnutlrHLLjLc1xvAQAA' +
            'AYOT2RlsJath+IZkaytV0CJ35ljVRsIaSokAAAABAAALQAAAAECYpC7oAAABg5PZGWyxIzbC/my+XR6G' +
            'Ju/KrtZE73ZYYgEAAAJSMxQ8Ici1B0WKZ6HcvZU6rKynTexddOkiAAAAAQAAFoAAAAJSMxQ8IQAAAlIz' +
            'FDwhi9kVYzleAvzOpScLxYP6I3PZgpkBAAACk5CpCuE3vlhTO1h+gS4p8NlSvdrBPn/iAAAAAAEAABaA' +
            'AAACk5CpCuEAAAKTkKkK4eLsYBA2PrvNXpUCLnAh/NeoDUwbAQAAAnjO/Ejuj5AbWjuC8jCD3hkySdD3' +
            'vCsqBI8AAAABAAALQAAAAGl31LbTAAACeM78SO7Ig1fjLGT5FhxY8AE9cZQfJpvNPgAAAAHBQnP8HCrB' +
            'bBqoYIu/C4KtzVBr/ctzWlm2AAAAACcmXt9KRHkWXzlqMJoTxMJE34OUoFbau4IBAAAANTXtXH4wCtU7' +
            'yxorHKxU/QyckqEB/0NSiAAAAAEAABaAAAAANTXtXH4AAAA1Ne1cfuHjXwjoZvNc7Fy5FAnAifyyJn8T' +
            'AQAAAHxQ6I+F6IVTXopuOz9QB+vZdqvaMuEQAGAAAAABAAALQAAAABS4JsKXAAAAfFDoj4WT525f3PYm' +
            '83/j53THueEgHZ/faQEAAAGp9duzQDTM9Fd866ppgfGuLMGPfsQgU5XoAAAAAQAAC0AAAABG/k9IiwAA' +
            'Aan127NAC5ArbXKgC+8vqx8QIpRFcilnSXgAAAACjlESpeQDMrGuHehMpWgAsm7qthgaeObVFAAAAAGT' +
            'TWfJen+afpGqsUOhNXFhPBJ3JPgSpEr6AQAAAYN/fuya5Qc83TimGRduqCQX/YrLuSzQbpMAAAABAAAW' +
            'gAAAAYN/fuyaAAABg39+7JoS7//vP72Non9Iek1G5aNau6oeGgAAAAKapDnYzUQyrukN+Qc9Wwz9v4gh' +
            'LyNl71u8AQAAAnLNWV/XywPsi8BGZG+CKy1nw2+xObNJNDoAAAABAAALQAAAAGh3juVPAAACcs1ZX9cJ' +
            '/cMH1zlttVFiiGadwl0Bx/q3mwEAAAEjw58XBvPDv8tMvp43jcqAMli/E8j6jWoHAAAAAQAAFoAAAAEj' +
            'w58XBgAAASPDnxcGYr1tx3m56rnbCQnb+J8f/HMogokBAAABTLgwBl8EGS59TXS+JqdsNhqcLwBl7pzm' +
            'LQAAAAEAABaAAAABTLgwBl8AAAFMuDAGX/EQPIpkc/N55Av4Sbdh3mUsAThlAQAAAzxtX3wL72TYUh7F' +
            'YQMSITHJBHRSaI1GesgAAAABAAALQAAAAIoSOpStAAADPG1ffAtujoENPhZYsIUQgYFU/3HFztRL5AAA' +
            'AALAAz0XFFc6DCzvNOl7tZ2PZQpxA8bk6fsQAQAAAOJuyV+s+WZJFMueRHWG5Sf7EpSwjoeopQkAAAAB' +
            'AAALQAAAACW9IY/yAAAA4m7JX6y0m1xthoQ990S9ZPSJiJZYpnZQ3AEAAAKxCI3UbPt5RqRxj2wqJ+Kx' +
            'C/ZwHjgZUUVmAAAAAQAAFoAAAAKxCI3UbAAAArEIjdRs7Cq6ODYs9WF2hll8W+GWb8oYoUkBAAACyifu' +
            '9bOkg2SLC5uL67m1JmcVDp3LVm5sxgAAAAEAAAtAAAAAdwan054AAALKJ+71s8Y5qvGT75R/Wv75ANQP' +
            '9H8Sr6cbAQAAAFlJobUUoSJyHcj70jR1LoP+zhKRmOAtQqsAAAABAAAWgAAAAFlJobUUAAAAWUmhtRRd' +
            'v9EMhbsoP9ae+qfnk9KFs5ucFQAAAAF2AxI2dSusjJYD6ZgoaP3rOLetSacK2k++AQAAA+6eu5h6s85Q' +
            '+/EMixarDWjt7IGyv2yWxOUAAAABAAALQAAAAKfFH0QVAAAD7p67mHoMtMNYAELvRG0YKYwaVt61Px1O' +
            'xQEAAANTlgPXbArquAHccms33PTISgahBs9VhikxAAAAAQAAFoAAAANTlgPXbAAAA1OWA9dsoqedKVcu' +
            'SahNoD+jz9nBKnQm7I0AAAACvL5HapC9sU53zQABUPJHFl8I2k133lEq8gEAAAGdQiyW3elWejCK4NDE' +
            'y3pRe01EVBAudlMCAAAAAQAAFoAAAAGdQiyW3QAAAZ1CLJbdWykUMZN2YtPFE6u1gpr20fFpcj0BAAAB' +
            'D3x3iZuLTsWjstD9WDAkoIyWPabYoHJbewAAAAEAABaAAAABD3x3iZsAAAEPfHeJmxcC3BsssF43KiT4' +
            'Ts4BxINcbxyAAQAAHp2697bfmslKGkZzY2OiC45SB0ynaYHMQzkAAAABAAALQAAABRpJ0/PQAAAenbr3' +
            'tt8='
    },

    'dev': {
        NETWORK_ID: 2,
        NETWORK_NAME: 'dev',
        SEED_PEERS: [
            WsPeerAddress.seed('dev.nimiq-network.com', 8080, 'e65e39616662f2c16d62dc08915e5a1d104619db8c2b9cf9b389f96c8dce9837')
        ],
        SEED_LISTS: [],
        GENESIS_BLOCK: new Block(
            new BlockHeader(
                new Hash(null),
                new Hash(null),
                Hash.fromBase64('JvMr9c9l2m8HWNdFAGTEastKH+aDZvln9EopXelhVIg='),
                Hash.fromBase64('1t/Zm91tN0p178+ePcxyR5bPxvC6jFLskqiidFFO3wY='),
                BlockUtils.difficultyToCompact(1),
                1,
                1522338300,
                12432,
                BlockHeader.Version.V1),
            new BlockInterlink([], new Hash(null)),
            new BlockBody(Address.fromBase64('AAAAAAAAAAAAAAAAAAAAAAAAAAA='), [], BufferUtils.fromBase64('RGV2TmV0'))
        ),
        GENESIS_ACCOUNTS:
            'AGTHyaGKKYtMW9zm81Nw2UYCIWr2bQAAAAOO9hgWyh/5Ezv+1Ldw9Oid2zwaY+LjRXAjAQAAAdpxepGo' +
            'TVTy25Dj9WOZXg1SAyoCtCmEkgYAAAABAAAWgAAAAdpxepGoAAAB2nF6kagxFAXrnWawCibXmNIocpEN' +
            'bY2M4QAAAACPgR32bdaFsm6G5Bg4H96UDFtJMFclfA8rAQAAA+Z8YTcn7eJ7xhfBV9k79a2bDLpb0SWE' +
            'gSIAAAABAAALQAAAAKZqEDPcAAAD5nxhNyfiENwK3NNQGB6fxKS62kvoApoe4gEAAAKLbf59cM8P40JX' +
            'yIKzSkr749mOqp5n1/ruAAAAAQAAC0AAAABsklUU6AAAAott/n1wZs9N9eWbNeUSLDy5qbhe6CW7Q94B' +
            'AAADLsSIL0WLcA6Nt5Ji+Pu2j2p4wJgN8lpIVwAAAAEAABaAAAADLsSIL0UAAAMuxIgvRXGosRRWBkji' +
            'IyWOFAzp3WZYGhQvAAAAAN+ByO6LKclRKAD8iueyAPGY/ZnTIbM5CbUBAAAAMXEUVZ+h9Kb5BH+lzQTK' +
            'HdVMiFfmRsJBWAAAAAEAAAtAAAAACD2DY5sAAAAxcRRVn+hB476I0A6qQDjCSzzvumwsQHf9AQAAA03B' +
            '6LO6vHPfpZtbnDWtPlN7WlO0l+aw1KIAAAABAAALQAAAAIz1psifAAADTcHos7qSQrji3cQRvdhZEyJa' +
            'a9OF/pUTGwEAAAEJawwO04GTmnyPT2hcnepKTWwqUe3rBlVwAAAAAQAAC0AAAAAsPIICeQAAAQlrDA7T' +
            'Kd6Wv+nDz7vTAMDCu39sALbKiawBAAABJAr6aFtkUf/rcih9aUVHVigY+8UIy2/+QQAAAAEAAAtAAAAA' +
            'MKx/EWUAAAEkCvpoW4oaIYhRvV3BULo9azzYYyKeeCxrAQAAA03cDnJSDjUiPbhnHIY/7aooMW/Y0Epe' +
            'T58AAAABAAAWgAAAA03cDnJSAAADTdwOclKFF7HkvjRHt0g5nwPzP59X9Uge9wEAAAGGEgl7kg2aSBjn' +
            '4A5Od5+0Lh5sBpm6dar7AAAAAQAAFoAAAAGGEgl7kgAAAYYSCXuSk87IwlS6e4YT+koCY6/lL28D3sYB' +
            'AAACjIEYqGyFuGHIpbQDcibbuM8kkiHguhEKAwAAAAEAABaAAAACjIEYqGwAAAKMgRiobCUh+XSo0plb' +
            '6NrVoCXHLwt7XzNZAAAAA1fLvw67icCbQBBXoglPtPMRkeln1StoiSYAAAACFc2B9ywrb3evyXkRn2lI' +
            'r99+cUgwAipdwwEAAAPxDMrFsmKBEu04Bg6LEqHvrJj2ewKnZ3qmAAAAAQAAFoAAAAPxDMrFsgAAA/EM' +
            'ysWyc3iG9qZDzL/uCLJEdhmwKaAHgIMBAAACPUMNm/Uu1vSoi1gBseNjIp1mp154Sw79UAAAAAEAABaA' +
            'AAACPUMNm/UAAAI9Qw2b9YcCc88Iyrx0NUbMZOK3rJdc/ggmAQAAAnsptOZZhrhJa+5Z89rK+wkxjzUt' +
            'hAHVfDoAAAABAAAWgAAAAnsptOZZAAACeym05lkhopvGoZgAsJ38XeT+KI6VFZ6HVQEAAAKZNR0cZ3N/' +
            'V/VlAJ1g1vBkidPGJBfIBQZcAAAAAQAAC0AAAABu3i+EvAAAApk1HRxnwWGEqi7rwr6bZ9df8Uhr5cG3' +
            'nAUAAAAB+ett5xJRyHYmu80aIhgssCKeD9KYKNlI+gEAAAHcmaAZJKAMxD+5u1O+u5ALn65VT4HGDIxw' +
            'AAAAAQAAC0AAAABPbvAEMQAAAdyZoBkkTOyyimPzT9JghHBHVSBRqHTY6qMBAAABMiMv3v3Fqy0Rq/yO' +
            'BHu3RlPy/l121QrKAwAAAAEAABaAAAABMiMv3v0AAAEyIy/e/TyTgfm1ATlfv11vqgZ2mGgLp5I3AAAA' +
            'BB6+ivcGqPmcXVPR6jFzANQ/oHcfYAbWLCAAAAACEUzY24RQtw7fskPYnAuOCrVYvYWjy/Sq2QEAAAA1' +
            'ejIu8T103OAjQ6dOO7R1qdl9voiJTyMzAAAAAQAAC0AAAAAI6bMH0wAAADV6Mi7xMF78LO+AmQt47Q2F' +
            '8lJOtFmP+8sBAAADIrN3lvTLTPW10LenULSqINB8dhRMCjZoqgAAAAEAAAtAAAAAhciT7n4AAAMis3eW' +
            '9PfpWIeCkAqinftTYf+jyT/iAxE2AAAAACtXQrrG1ENyC6MF0IZJhxjw1atz1xqHhPwBAAAAvi3c14rV' +
            'Vkylvnz2LXDSnAd0Ap9o6EcHkwAAAAEAAAtAAAAAH7JPeUIAAAC+LdzXityvfksBfLlWNu3IzdEXOAKK' +
            'juLqAAAAAWKGyagmDA2tPlgh/4bnCAHEUTy6X43XlxYAAAABpZApuaLoMq3LP2zjV1NWvIyyZ9WXhbjK' +
            'rgAAAAOSnw31GpWdLCHuiuqqRiU+c6/7QpNNu415AQAAA/PO43ur9pEsqZCx+ctQ0uLZPiPcQtZ4AtoA' +
            'AAABAAALQAAAAKiiez9IAAAD887je6ty7kyqfDlYpexa6zO61+OPc7PemgEAAAFVhN0jTzdIVM9Xza9g' +
            'EHJEU/NTXLDe1iXFAAAAAQAAC0AAAAA463owjgAAAVWE3SNP895JOb/wZK4ieF/UWFZvxGiH5yMAAAAB' +
            'WtMtyhV1iFBda1GZC0OkOSwt9AADUTkavAEAAAGLTWokGsi+QGXG5VciJh0XKhgY2Ffw3nFhAAAAAQAA' +
            'C0AAAABB4jxbWgAAAYtNaiQaxyj4UkPRXmdB4RUJOmY0/+DGi2sAAAABmtptM00N3PW8TiZSDGq75w65' +
            'ENAqIvV17gEAAAPVauIkr0eeRNW8s9uvLImxBON8OZc+nrJLAAAAAQAAC0AAAACjkdBbcwAAA9Vq4iSv' +
            'LMTqFpsInyV7LXX07AVlLB4LwK8AAAACVOJQdF94lWhUD0pOtwPsSpOcOfVM4c3lYAEAAAJZhQlPED5v' +
            'd70C9VJcR9E0/6kVRjND3chpAAAAAQAAC0AAAABkQNbigwAAAlmFCU8Q5+bT5k92M+EdyU87fjVCIOHg' +
            'JvQBAAABLAh445G4HY/gCBp8Ww86DjZzqu2656S1WwAAAAEAABaAAAABLAh445EAAAEsCHjjkfGu/x1G' +
            'ALyflu5s6H/RjA0uF2FJAQAAAfUQ1yISxqLt9R+tekR4gPOI6gjm8GCCewkAAAABAAAWgAAAAfUQ1yIS' +
            'AAAB9RDXIhLmoPJPmFOfClWZtRtz8SIHZV+RYgEAAAGb6NZw6ik9LhWvYkCsjo753C4xml4yhuLkAAAA' +
            'AQAAFoAAAAGb6NZw6gAAAZvo1nDq0lWfSarsXeQhGik+Wy00hFQPYNIBAAAC4wlfg1nMx6ncdUeIXQp/' +
            'MHyEH0Q1GZoNiAAAAAEAAAtAAAAAeyw6leUAAALjCV+DWRJzvcMi6fQ+RMgH4p3thxoZkT3KAQAAAplo' +
            'xifaQHmEokpWgPZUy2JkLz0fIsjxIz4AAAABAAALQAAAAG7my7FPAAACmWjGJ9ojMPo7C9y8Ib/ncXPh' +
            'wUC60bh5vwAAAACNnQv2v4inBpnu2xVZInd7VAlMXKKdYgukAQAAApBN6CyLt+TdIz09e58DxUKFW4PK' +
            '6+lckmcAAAABAAALQAAAAG1iUVzCAAACkE3oLIs/W2vCON/csGZ+BrXXzOfPf3+nwgAAAABdcEFzteZa' +
            'aSm87wyRZwS2rvearhLJb0wSAQAAA5l3BvfWMZXszk+sOGOzYCH6Scso0530ACEAAAABAAAWgAAAA5l3' +
            'BvfWAAADmXcG99Yn1+CSxVm0b9VEmdXSPU9MLZ6euQEAAACc7CZPBZWabWnc3dRvBQIYMyDgLCyx2AtM' +
            'AAAAAQAAC0AAAAAaJ1u31wAAAJzsJk8FMsv+RNrEAeMhkxQQ7swlQm/MWcsBAAAEFqz9ZzfxBC8ZD/h5' +
            'XbP5/TW158EyNFjtDwAAAAEAAAtAAAAArnIqO98AAAQWrP1nN9WW44AbwcH3rC9B0LDZEGH/6LGWAAAA' +
            'A0/mTvNyq+e4MxN7UI6LWMDrHl4bIjVbRqkBAAAADwRE4OfGbkb1M4LvJTsug5Guwv4UipUglQAAAAEA' +
            'AAtAAAAAAoC2JXwAAAAPBETg5xXn4XxmjRL8H7qyrMKtPOQ68d9gAQAAA+kpJjZRO8ds5r5Z15bsaAvU' +
            'z1Hi+igym+wAAAABAAALQAAAAKbcMQkOAAAD6SkmNlFtNRkkOze3mxqbEGn8LmugDYG9AAEAAAIeKgo/' +
            '6Q3VK9Fh4+5mvtU/qnCGKcL5eZe6AAAAAQAAC0AAAABaXFcKpwAAAh4qCj/pVkOr82XeobTRYSqMwBit' +
            '+DK26L0AAAADExdE1KGweTGwMNtOUr0mkTMuJZPdUx/lFgEAAAIYnmRDO5Us7NZLbPKbfSqFz9Qcz12x' +
            'p7EIAAAAAQAAC0AAAABZb7tgigAAAhieZEM7QJBbpsW5TySU3AOaRq0w6StqDbkBAAAAQYtUtY+neTkG' +
            'p0FX3yBWlI9VfXL9rY2T0AAAAAEAABaAAAAAQYtUtY8AAABBi1S1j6CfjxyppAST/5j+yNsnpZ4mb+LM' +
            'AQAAAwd7a4MeZabvmCauqJUxc/dnJt9Qdbu0C+sAAAABAAALQAAAAIE/PJXbAAADB3trgx6XwCRFCATy' +
            '6PT5xzl/tTynPq+pVwEAAAP3RVI223cMsae0V7OPJkgsuqVbHiDuSfwpAAAAAQAAFoAAAAP3RVI22wAA' +
            'A/dFUjbbqciNZ2beiMn+kVcprmWvCo0qNNYAAAAAp/x8AiuP0gOSmGXc+PyW+ma3l4h07YsKpAEAAAKh' +
            'uMUSlEiZItBpeLfj6hIFvBR6t0/1Zyh2AAAAAQAAFoAAAAKhuMUSlAAAAqG4xRKUMbR0l40dlxXJiTEF' +
            'uHD29zmRDB8BAAAC0qDOUYnujJP0QRa7dQ2AJ0h1cIE0IkEehgAAAAEAABaAAAAC0qDOUYkAAALSoM5R' +
            'iepA5phgkMYQo9vghvEMs6W2EXiXAQAAAsKfyTSX6ZAOU+orXNxOz0wdBuAqVHbOiV0AAAABAAAWgAAA' +
            'AsKfyTSXAAACwp/JNJcBVoZ5gIarGpvmG5G4a1OXW3821QEAAANETmvLWBcBCeyCAd6ZLaV8GnQ8Da54' +
            'gAyrAAAAAQAAFoAAAANETmvLWAAAA0ROa8tY+JrQTn9k06PB7If9N0CfYchk/C0BAAACrhSVuS2ezk3S' +
            'ZrOTLlI6dWuGTC76mwagfAAAAAEAAAtAAAAAcljDnt0AAAKuFJW5LYlQAlhiQPsfkWnHfepiRbygaVcw' +
            'AQAAAbh/Gb8NJqE45Cy7l+FzX6ekgF3R/5Mtr+4AAAABAAAWgAAAAbh/Gb8NAAABuH8Zvw0P094GHr/6' +
            'AsV1AwxF7c61Qq2RSAAAAAJQwqsff2pLw8MLHSdj/TYI/vua9S1qFloyAQAAAZMy1gvR0p1S/3oRAOZ8' +
            'nDanLv73M3Fv150AAAABAAAWgAAAAZMy1gvRAAABkzLWC9F4DlJe82PbL79kI4++HW6Glhr8OAEAAAAc' +
            'Kk11+SFNxI4R9S/ebQHQO2V5jHpCMS1hAAAAAQAAC0AAAAAEsbeTqgAAABwqTXX5sSvBMuNoUTbS19Um' +
            'etiaDp8t/vsBAAABkaKnSL2M6hWXx8/DUkVUtGxAV3Xd9gtcfAAAAAEAABaAAAABkaKnSL0AAAGRoqdI' +
            'vTi9K8WL24O90wK1LIuwvNvkRR9iAQAAAQ5MDkLw77e4PHxSapULV3EHaCWnRV0ELfQAAAABAAAWgAAA' +
            'AQ5MDkLwAAABDkwOQvB45gZiCw5zStBMXeShepM6iLltkgAAAAHfl0LN8u7wC1h8uhyRIY5s1I1gZPfF' +
            '1qn+AAAAA8xCKTupigAMUEItvNB1XfJi5d20TA4oijkBAAABheDAya/Vr7/+aeXTjjrLIAY/8G9+ps7j' +
            'DAAAAAEAAAtAAAAAQPrKzEgAAAGF4MDJrySGgRI77yf0Ksrs7U5YU1v43lFrAAAAAkrmY2OrF77xscYd' +
            'oQqK/Kr8Sc5nR/w91goBAAADoIlPx03C0gM7wMgvzaUglns4BJzvq8fWUQAAAAEAABaAAAADoIlPx00A' +
            'AAOgiU/HTR059QJNJ6egySnjQ5ssU/g987fwAQAAAOSjwgS4txd+4xsScIOZ2jJ8gm6PFGb4IPcAAAAB' +
            'AAALQAAAACYbSwDKAAAA5KPCBLgEEiPQ5L80JKvaQkZUqVTQVFocRQEAAAAgrZivoOKiOJFwOp94dsp2' +
            'dceiRnJRp2BDAAAAAQAAC0AAAAAFckQdRgAAACCtmK+gCouuvquET79GQpJvlDjxodZmWlIBAAADdflm' +
            'IVtOxwzhUy9DP2U/1dg443ziW+44fAAAAAEAAAtAAAAAk6mRBZAAAAN1+WYhW7W78iEqRWPDm9L0+nV1' +
            'sgxvC7aAAAAAAnjT5GbwylWQC2KwtxExw7D10y49vKcooJ0AAAADf6VG1QRSW6oEqsV40bK3bkmqzoXd' +
            'ot6i4gEAAAEy6r22pwWExn95sjo6xoCdI0e/eYKD/GftAAAAAQAAFoAAAAEy6r22pwAAATLqvbanD5Iv' +
            '+2lMo8wGu38cLQnhQWGpZEoBAAAB3Wk4Pnb/keSDfMbiKmBGXEB/R75Sm81yZQAAAAEAABaAAAAB3Wk4' +
            'PnYAAAHdaTg+dlD3NG/nQX9YueouG07G0GevJx2cAQAAASDQ25ZqoHTmauLeC1uxbbJc9puYK7ibUGQA' +
            'AAABAAAWgAAAASDQ25ZqAAABINDblmrDxe/R9ACThqXry6xBd28gwzmBbAAAAAA3JtwFy7gOad2nnAuf' +
            '4c9a2JDr8h65bBqxAQAAApIfgNiYaB9nad26DD093xiYPxcQq2fLUB0AAAABAAALQAAAAG2v6s7EAAAC' +
            'kh+A2JhP0wpVAIQo7aaYGJz1q+BQ/JvaAQEAAAELaF0K71KfkeqRPM7T8QipPJ8FVXyve5YUAAAAAQAA' +
            'FoAAAAELaF0K7wAAAQtoXQrvJ/jj56GUsaHxN9mDMXP5RsX08l8AAAADE1QMtlVNL/Tr3lfTfZGZ4SRd' +
            '7Ko1EbsleAEAAAKN3l0bwt3bQiKYf+QXt0o8YjRC4DeZwDgRAAAAAQAAC0AAAABs+mTZ9gAAAo3eXRvC' +
            'VJEHZ0qy+F1pvTVulg0P1CdMCToAAAACfGL6o0cNbRO/RL5C/tljM1b4X9GibgKJhgEAAAPEPtTYFS70' +
            'hIR9vGG5Bss2KK0fyL/Q7ZfwAAAAAQAAFoAAAAPEPtTYFQAAA8Q+1NgVjxMxbNwbSqmxFnDEgA2J2Io6' +
            'Q14AAAAB0Fl8OgAV2mEYfjb3jRucPYtRg9szNOY5LAEAAADjj9fBEDJIdjKxmX0e1aiPEla5rtes80Lh' +
            'AAAAAQAAC0AAAAAl7U6gLgAAAOOP18EQBkYuU4gvkHTrVpgVrymqlmeIV3cBAAAA2NjC3v910c484H8c' +
            'iZmr9lYIo66SCeFyQwAAAAEAAAtAAAAAJCQgeoAAAADY2MLe/1PF67K3QcuQJ+m4P7tOiIrVmdFhAQAA' +
            'AukCHDJUZrnHmLoVULR6r8HDBaygNH/gNE8AAAABAAAWgAAAAukCHDJUAAAC6QIcMlS4diPveIAR8ciq' +
            'f6WfLVCvxGQ1MQAAAAJlQHbfixmoGC8hAefMDjnblFS989zLCxhKAQAAA+519/AhViOdiXDAAdtc5/ue' +
            'TM0syon8VYoAAAABAAAWgAAAA+519/AhAAAD7nX38CH0clyiOijE/jV+sOwm6ZB5i5GvYQEAAAGy/GNM' +
            'TQyzah076TeqMT+jyMJhGgese8vbAAAAAQAAC0AAAABIf2XiDQAAAbL8Y0xNr/JNzMvTszgQcqMcDBEz' +
            'tfKONfgAAAARpIlShW0='
    }
};

class CloseType {
    /**
     * @param {number} closeType
     * @return {boolean}
     */
    static isBanningType(closeType){
        return closeType >= 100 && closeType < 200;
    }

    /**
     * @param {number} closeType
     * @return {boolean}
     */
    static isFailingType(closeType){
        return closeType >= 200;
    }
}

// Regular Close Types

CloseType.GET_BLOCKS_TIMEOUT = 1;
CloseType.GET_HEADER_TIMEOUT = 2;
CloseType.GET_CHAIN_PROOF_TIMEOUT = 3;
CloseType.GET_ACCOUNTS_PROOF_TIMEOUT = 4;
CloseType.GET_ACCOUNTS_TREE_CHUNK_TIMEOUT = 5;
CloseType.GET_TRANSACTIONS_PROOF_TIMEOUT = 6;
CloseType.GET_TRANSACTION_RECEIPTS_TIMEOUT = 7;

CloseType.SENDING_PING_MESSAGE_FAILED = 10;
CloseType.SENDING_OF_VERSION_MESSAGE_FAILED = 11;

CloseType.SIMULTANEOUS_CONNECTION = 20;
CloseType.DUPLICATE_CONNECTION = 21;
CloseType.INVALID_CONNECTION_STATE = 22;

CloseType.PEER_BANNED = 30;
CloseType.IP_BANNED = 31;

CloseType.MAX_PEER_COUNT_REACHED = 40;
CloseType.PEER_CONNECTION_RECYCLED = 41;
CloseType.PEER_CONNECTION_RECYCLED_INBOUND_EXCHANGE = 42;
CloseType.INBOUND_CONNECTIONS_BLOCKED = 43;

CloseType.MANUAL_NETWORK_DISCONNECT = 50;
CloseType.MANUAL_WEBSOCKET_DISCONNECT = 51;
CloseType.MANUAL_PEER_DISCONNECT = 52;


// Ban Close Types

CloseType.INCOMPATIBLE_VERSION = 100;
CloseType.DIFFERENT_GENESIS_BLOCK = 101;
CloseType.INVALID_PEER_ADDRESS_IN_VERSION_MESSAGE = 102;
CloseType.UNEXPECTED_PEER_ADDRESS_IN_VERSION_MESSAGE = 103;
CloseType.INVALID_PUBLIC_KEY_IN_VERACK_MESSAGE = 104;
CloseType.INVALID_SIGNATURE_IN_VERACK_MESSAGE = 105;

CloseType.ADDR_MESSAGE_TOO_LARGE = 110;
CloseType.ADDR_NOT_GLOBALLY_REACHABLE = 111;
CloseType.INVALID_ADDR = 112;
CloseType.INVALID_SIGNAL_TTL = 113;

CloseType.INVALID_BLOCK = 120;
CloseType.INVALID_HEADER = 121;
CloseType.INVALID_ACCOUNTS_TREE_CHUNCK = 122;
CloseType.INVALID_ACCOUNTS_PROOF = 123;
CloseType.INVALID_CHAIN_PROOF = 124;
CloseType.INVALID_TRANSACTION_PROOF = 125;
CloseType.INVALID_BLOCK_PROOF = 126;
CloseType.INVALID_TRANSACTION_RECEIPTS = 127;

CloseType.RATE_LIMIT_EXCEEDED = 130;

CloseType.BLOCKCHAIN_SYNC_FAILED = 140;

CloseType.MANUAL_PEER_BAN = 150;


// Fail Close Types

CloseType.CONNECTION_FAILED = 200;
CloseType.CLOSED_BY_REMOTE = 201;
CloseType.NETWORK_ERROR = 202;
CloseType.CHANNEL_CLOSING = 203;

CloseType.VERSION_TIMEOUT = 210;
CloseType.VERACK_TIMEOUT = 211;
CloseType.PING_TIMEOUT = 212;

CloseType.CONNECTION_LIMIT_PER_IP = 220;
CloseType.CONNECTION_LIMIT_DUMB = 221;

CloseType.FAILED_TO_PARSE_MESSAGE_TYPE = 230;
CloseType.UNEXPECTED_ACCOUNTS_TREE_CHUNK = 231;
CloseType.UNEXPECTED_HEADER = 232;
CloseType.TRANSACTION_NOT_MATCHING_SUBSCRIPTION = 233;

CloseType.ABORTED_SYNC = 240;

CloseType.MANUAL_PEER_FAIL = 250;

Class.register(CloseType);

class NetworkConnection extends Observable {
    /**
     * @param {DataChannel} channel
     * @param {number} protocol
     * @param {NetAddress} netAddress
     * @param {PeerAddress} peerAddress
     */
    constructor(channel, protocol, netAddress, peerAddress) {
        super();
        /** @type {DataChannel} */
        this._channel = channel;

        /** @type {number} */
        this._protocol = protocol;
        /** @type {NetAddress} */
        this._netAddress = netAddress;
        /** @type {PeerAddress} */
        this._peerAddress = peerAddress;

        /** @type {number} */
        this._bytesSent = 0;
        /** @type {number} */
        this._bytesReceived = 0;

        /** @type {boolean} */
        this._inbound = !peerAddress;

        /** @type {boolean} */
        this._closed = false;

        /** @type {*} */
        this._lastError = null;

        // Unique id for this connection.
        /** @type {number} */
        this._id = NetworkConnection._instanceCount++;

        this._channel.on('message', msg => this._onMessage(msg));
        this._channel.on('error', e => this._onError(e));
        this._channel.on('close', () => this._close(CloseType.CLOSED_BY_REMOTE, 'Closed by remote'));
    }

    /**
     * @param {Uint8Array} msg
     * @private
     */
    _onMessage(msg) {
        // Don't emit events if this channel is closed.
        if (this._closed) {
            return;
        }

        this._bytesReceived += msg.byteLength || msg.length;
        this.fire('message', msg, this);
    }

    /**
     * @param {*} e
     * @private
     */
    _onError(e) {
        // Don't emit events if this channel is closed.
        if (this._closed) {
            return;
        }

        this._lastError = e;
        this.fire('error', e, this);
    }

    /**
     * @param {number} [type]
     * @param {string} [reason]
     * @private
     */
    _close(type, reason) {
        // Don't emit events if this channel is closed.
        if (this._closed) {
            return;
        }

        // Mark this connection as closed.
        this._closed = true;

        // Close DataChannel.
        this._channel.close();
        this._channel = null;

        // Propagate last network error.
        if (type === CloseType.CLOSED_BY_REMOTE && this._lastError) {
            type = CloseType.NETWORK_ERROR;
            reason = this._lastError;
        }
        // Convert ErrorEvents to strings.
        if (reason && typeof reason !== 'string') {
            reason = typeof reason.message === 'string' ? reason.message : '';
        }

        // Tell listeners that this connection has closed.
        this.fire('close', type, reason, this);

        // Remove all listeners.
        this._offAll();
    }

    /**
     * @param {number} [type]
     * @param {string} [reason]
     */
    close(type, reason) {
        if (!this._closed) {
            const connType = this._inbound ? 'inbound' : 'outbound';
            Log.d(NetworkConnection, `Closing ${connType} connection #${this._id} ${this._peerAddress || this._netAddress}` + (reason ? ` - ${reason}` : '') + ` (${type})`);
        }
        this._close(type, reason);
    }

    /**
     * @return {boolean}
     * @private
     */
    _isChannelOpen() {
        return this._channel && this._channel.readyState === DataChannel.ReadyState.OPEN;
    }

    /**
     * @return {boolean}
     * @private
     */
    _isChannelClosing() {
        return this._channel && this._channel.readyState === DataChannel.ReadyState.CLOSING;
    }

    /**
     * @return {boolean}
     * @private
     */
    _isChannelClosed() {
        return !this._channel || this._channel.readyState === DataChannel.ReadyState.CLOSED;
    }

    /**
     * @param {Uint8Array} msg
     * @return {boolean}
     */
    send(msg) {
        const logAddress = this._peerAddress || this._netAddress;
        if (this._closed) {
            return false;
        }

        // Fire close event (early) if channel is closing/closed.
        if (this._isChannelClosing() || this._isChannelClosed()) {
            Log.d(NetworkConnection, () => `Not sending data to ${logAddress} - channel closing/closed (${this._channel.readyState})`);
            this._close(CloseType.CHANNEL_CLOSING, 'channel closing');
            return false;
        }

        // Don't attempt to send if channel is not (yet) open.
        if (!this._isChannelOpen()) {
            Log.d(NetworkConnection, () => `Not sending data to ${logAddress} - channel not open (${this._channel.readyState})`);
            return false;
        }

        try {
            this._channel.send(msg);
            this._bytesSent += msg.byteLength || msg.length;
            return true;
        } catch (e) {
            Log.e(NetworkConnection, `Failed to send data to ${logAddress}: ${e.message || e}`);
            return false;
        }
    }

    /**
     * @param {Message.Type|Array.<Message.Type>} types
     * @param {function()} timeoutCallback
     * @param {number} [msgTimeout]
     * @param {number} [chunkTimeout]
     */
    expectMessage(types, timeoutCallback, msgTimeout, chunkTimeout) {
        if (this._closed) {
            return;
        }
        this._channel.expectMessage(types, timeoutCallback, msgTimeout, chunkTimeout);
    }

    /**
     * @param {Message.Type} type
     * @returns {boolean}
     */
    isExpectingMessage(type) {
        if (this._closed) {
            return false;
        }
        return this._channel.isExpectingMessage(type);
    }

    /**
     * @param {Message.Type} type
     * @param {boolean} success
     */
    confirmExpectedMessage(type, success) {
        if (this._closed) {
            return;
        }
        this._channel.confirmExpectedMessage(type, success);
    }

    /**
     * @param {NetworkConnection} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof NetworkConnection
            && this._id === o.id;
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this._id.toString();
    }

    /**
     * @return {string}
     */
    toString() {
        return `NetworkConnection{id=${this._id}, protocol=${this._protocol}, peerAddress=${this._peerAddress}, netAddress=${this._netAddress}}`;
    }

    /** @type {number} */
    get id() {
        return this._id;
    }

    /** @type {number} */
    get protocol() {
        return this._protocol;
    }

    /** @type {PeerAddress} */
    get peerAddress() {
        return this._peerAddress;
    }

    /** @type {PeerAddress} */
    set peerAddress(value) {
        this._peerAddress = value;
    }

    /** @type {NetAddress} */
    get netAddress() {
        return this._netAddress;
    }

    /** @type {NetAddress} */
    set netAddress(value) {
        this._netAddress = value;
    }

    /** @type {number} */
    get bytesSent() {
        return this._bytesSent;
    }

    /** @type {number} */
    get bytesReceived() {
        return this._bytesReceived;
    }

    /** @type {boolean} */
    get inbound() {
        return this._inbound;
    }

    /** @type {boolean} */
    get outbound() {
        return !this._inbound;
    }

    /** @type {boolean} */
    get closed() {
        return this._closed;
    }

    /** @type {number} */
    get lastMessageReceivedAt() {
        if (this._closed) {
            return 0;
        }
        return this._channel.lastMessageReceivedAt;
    }
}
// Used to generate unique NetworkConnection ids.
NetworkConnection._instanceCount = 0;
Class.register(NetworkConnection);

class PeerChannel extends Observable {
    /**
     * @listens NetworkConnection#message
     * @param {NetworkConnection} connection
     */
    constructor(connection) {
        super();
        this._conn = connection;
        this._conn.on('message', msg => this._onMessage(msg));

        // Forward specified events on the connection to listeners of this Observable.
        this.bubble(this._conn, 'close', 'error');
    }

    /**
     * @param {Uint8Array} rawMsg
     * @private
     */
    async _onMessage(rawMsg) {
        const start = Date.now();
        let msg = null, type = null;

        try {
            const buf = new SerialBuffer(rawMsg);
            type = MessageFactory.peekType(buf);
            msg = MessageFactory.parse(buf);
        } catch(e) {
            Log.d(PeerChannel, () => `Failed to parse '${PeerChannel.Event[type]}' message from ${this.peerAddress || this.netAddress}`, e.message || e);

            // Confirm that message arrived but could not be parsed successfully.
            this._conn.confirmExpectedMessage(type, false);

            // From the Bitcoin Reference:
            //  "Be careful of reject message feedback loops where two peers
            //   each dont understand each others reject messages and so keep
            //   sending them back and forth forever."

            // If the message does not make sense at a whole or we fear to get into a reject loop,
            // we ban the peer instead.
            if (type === null || type === Message.Type.REJECT) {
                this.close(CloseType.FAILED_TO_PARSE_MESSAGE_TYPE, 'Failed to parse message type');
                return;
            }

            // Otherwise inform other node and ignore message.
            this.reject(type, RejectMessage.Code.REJECT_MALFORMED, e.message || e);
            return;
        }

        if (!msg) return;

        // Confirm that message was successfully parsed.
        this._conn.confirmExpectedMessage(type, true);

        try {
            await this.fire(PeerChannel.Event[msg.type], msg, this);
            this.fire('message-log', msg, this, Date.now() - start, rawMsg.byteLength);
        } catch (e) {
            Log.w(PeerChannel, `Error while processing '${PeerChannel.Event[msg.type]}' message from ${this.peerAddress || this.netAddress}: ${e}`);
        }
    }

    /**
     * @param {Message.Type|Array.<Message.Type>} types
     * @param {function()} timeoutCallback
     * @param {number} [msgTimeout]
     * @param {number} [chunkTimeout]
     */
    expectMessage(types, timeoutCallback, msgTimeout, chunkTimeout) {
        this._conn.expectMessage(types, timeoutCallback, msgTimeout, chunkTimeout);
    }

    /**
     * @param {Message.Type} type
     * @returns {boolean}
     */
    isExpectingMessage(type) {
        return this._conn.isExpectingMessage(type);
    }

    /**
     * @param {Message} msg
     * @return {boolean}
     * @private
     */
    _send(msg) {
        return this._conn.send(msg.serialize());
    }

    /**
     * @param {number} [type]
     * @param {string} [reason]
     */
    close(type, reason) {
        this._conn.close(type, reason);
        this._offAll();
    }

    /**
     * @param {PeerAddress} peerAddress
     * @param {Hash} headHash
     * @param {Uint8Array} challengeNonce
     * @param {string} [appAgent]
     * @return {boolean}
     */
    version(peerAddress, headHash, challengeNonce, appAgent) {
        return this._send(new VersionMessage(Version.CODE, peerAddress, GenesisConfig.GENESIS_HASH, headHash, challengeNonce, Version.createUserAgent(appAgent)));
    }

    /**
     * @param {PublicKey} publicKey
     * @param {Signature} signature
     * @returns {boolean}
     */
    verack(publicKey, signature) {
        return this._send(new VerAckMessage(publicKey, signature));
    }

    /**
     * @param {Array.<InvVector>} vectors
     * @return {boolean}
     */
    inv(vectors) {
        return this._send(new InvMessage(vectors));
    }

    /**
     * @param {Array.<InvVector>} vectors
     * @return {boolean}
     */
    notFound(vectors) {
        return this._send(new NotFoundMessage(vectors));
    }

    /**
     * @param {Array.<InvVector>} vectors
     * @return {boolean}
     */
    getData(vectors) {
        return this._send(new GetDataMessage(vectors));
    }

    /**
     * @param {Array.<InvVector>} vectors
     * @return {boolean}
     */
    getHeader(vectors) {
        return this._send(new GetHeaderMessage(vectors));
    }

    /**
     * @param {Block} block
     * @return {boolean}
     */
    block(block) {
        return this._send(new BlockMessage(block));
    }

    /**
     * @param {Uint8Array} block
     * @return {boolean}
     */
    rawBlock(block) {
        return this._send(new RawBlockMessage(block));
    }

    /**
     * @param {BlockHeader} header
     * @return {boolean}
     */
    header(header) {
        return this._send(new HeaderMessage(header));
    }

    /**
     * @param {Transaction} transaction
     * @param {?AccountsProof} [accountsProof]
     * @return {boolean}
     */
    tx(transaction, accountsProof) {
        return this._send(new TxMessage(transaction, accountsProof));
    }

    /**
     * @param {Array.<Hash>} locators
     * @param {number} maxInvSize
     * @param {boolean} [ascending]
     * @return {boolean}
     */
    getBlocks(locators, maxInvSize=BaseInventoryMessage.VECTORS_MAX_COUNT, ascending=true) {
        return this._send(new GetBlocksMessage(locators, maxInvSize, ascending ? GetBlocksMessage.Direction.FORWARD : GetBlocksMessage.Direction.BACKWARD));
    }

    /**
     * @return {boolean}
     */
    mempool() {
        return this._send(new MempoolMessage());
    }

    /**
     * @param {Message.Type} messageType
     * @param {RejectMessage.Code} code
     * @param {string} reason
     * @param {Uint8Array} [extraData]
     * @return {boolean}
     */
    reject(messageType, code, reason, extraData) {
        return this._send(new RejectMessage(messageType, code, reason, extraData));
    }

    /**
     * @param {Subscription} subscription
     * @returns {boolean}
     */
    subscribe(subscription) {
        return this._send(new SubscribeMessage(subscription));
    }

    /**
     * @param {Array.<PeerAddress>} addresses
     * @return {boolean}
     */
    addr(addresses) {
        return this._send(new AddrMessage(addresses));
    }

    /**
     * @param {number} protocolMask
     * @param {number} serviceMask
     * @param {number} maxResults
     * @return {boolean}
     */
    getAddr(protocolMask, serviceMask, maxResults) {
        return this._send(new GetAddrMessage(protocolMask, serviceMask, maxResults));
    }

    /**
     * @param {number} nonce
     * @return {boolean}
     */
    ping(nonce) {
        return this._send(new PingMessage(nonce));
    }

    /**
     * @param {number} nonce
     * @return {boolean}
     */
    pong(nonce) {
        return this._send(new PongMessage(nonce));
    }

    /**
     * @param {PeerId} senderId
     * @param {PeerId} recipientId
     * @param {number} nonce
     * @param {number} ttl
     * @param {SignalMessage.Flag|number} flags
     * @param {Uint8Array} [payload]
     * @param {PublicKey} [senderPubKey]
     * @param {Signature} [signature]
     * @return {boolean}
     */
    signal(senderId, recipientId, nonce, ttl, flags, payload, senderPubKey, signature) {
        return this._send(new SignalMessage(senderId, recipientId, nonce, ttl, flags, payload, senderPubKey, signature));
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @return {boolean}
     */
    getAccountsProof(blockHash, addresses) {
        return this._send(new GetAccountsProofMessage(blockHash, addresses));
    }

    /**
     * @param {Hash} blockHash
     * @param {AccountsProof} [proof]
     * @return {boolean}
     */
    accountsProof(blockHash, proof) {
        return this._send(new AccountsProofMessage(blockHash, proof));
    }

    /**
     * @return {boolean}
     */
    getChainProof() {
        return this._send(new GetChainProofMessage());
    }

    /**
     * @param {ChainProof} proof
     * @return {boolean}
     */
    chainProof(proof) {
        return this._send(new ChainProofMessage(proof));
    }

    /**
     * @param {Hash} blockHash
     * @param {string} startPrefix
     * @return {boolean}
     */
    getAccountsTreeChunk(blockHash, startPrefix) {
        return this._send(new GetAccountsTreeChunkMessage(blockHash, startPrefix));
    }

    /**
     * @param {Hash} blockHash
     * @param {AccountsTreeChunk} [chunk]
     * @return {boolean}
     */
    accountsTreeChunk(blockHash, chunk) {
        return this._send(new AccountsTreeChunkMessage(blockHash, chunk));
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @return {boolean}
     * @deprecated
     */
    getTransactionsProof(blockHash, addresses) {
        return this.getTransactionsProofByAddresses(blockHash, addresses);
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Address>} addresses
     * @return {boolean}
     */
    getTransactionsProofByAddresses(blockHash, addresses) {
        return this._send(new GetTransactionsProofByAddressesMessage(blockHash, addresses));
    }

    /**
     * @param {Hash} blockHash
     * @param {Array.<Hash>} hashes
     * @return {boolean}
     */
    getTransactionsProofByHashes(blockHash, hashes) {
        return this._send(new GetTransactionsProofByHashesMessage(blockHash, hashes));
    }

    /**
     * @param {Hash} blockHash
     * @param {TransactionsProof} [proof]
     * @return {boolean}
     */
    transactionsProof(blockHash, proof) {
        return this._send(new TransactionsProofMessage(blockHash, proof));
    }


    /**
     * @param {Address} address
     * @returns {boolean}
     * @deprecated
     */
    getTransactionReceipts(address) {
        return this.getTransactionReceiptsByAddress(address);
    }

    /**
     * @param {Address} address
     * @returns {boolean}
     */
    getTransactionReceiptsByAddress(address) {
        return this._send(new GetTransactionReceiptsByAddressMessage(address));
    }

    /**
     * @param {Array.<Hash>} hashes
     * @returns {boolean}
     */
    getTransactionReceiptsByHashes(hashes) {
        return this._send(new GetTransactionReceiptsByHashesMessage(hashes));
    }

    /**
     * @param {?Array.<TransactionReceipt>} transactionReceipts
     * @returns {boolean}
     */
    transactionReceipts(transactionReceipts) {
        return this._send(new TransactionReceiptsMessage(transactionReceipts));
    }

    /**
     * @param {Hash} blockHashToProve
     * @param {Hash} knownBlockHash
     * @returns {boolean}
     */
    getBlockProof(blockHashToProve, knownBlockHash) {
        return this._send(new GetBlockProofMessage(blockHashToProve, knownBlockHash));
    }

    /**
     * @param {number} blockHeightToProve
     * @param {Hash} knownBlockHash
     * @returns {boolean}
     */
    getBlockProofAt(blockHeightToProve, knownBlockHash) {
        return this._send(new GetBlockProofAtMessage(blockHeightToProve, knownBlockHash));
    }

    /**
     * @param {BlockChain} [proof]
     * @returns {boolean}
     */
    blockProof(proof) {
        return this._send(new BlockProofMessage(proof));
    }

    /**
     * @returns {boolean}
     */
    getHead() {
        return this._send(new GetHeadMessage());
    }

    /**
     * @param {BlockHeader} header
     * @returns {boolean}
     */
    head(header) {
        return this._send(new HeadMessage(header));
    }

    /**
     * @param {PeerChannel} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof PeerChannel
            && this._conn.equals(o.connection);
    }

    /**
     * @returns {string}
     */
    hashCode() {
        return this._conn.hashCode();
    }

    /**
     * @return {string}
     */
    toString() {
        return `PeerChannel{conn=${this._conn}}`;
    }

    /** @type {NetworkConnection} */
    get connection() {
        return this._conn;
    }

    /** @type {number} */
    get id() {
        return this._conn.id;
    }

    /** @type {number} */
    get protocol() {
        return this._conn.protocol;
    }

    /** @type {PeerAddress} */
    get peerAddress() {
        return this._conn.peerAddress;
    }

    /** @type {PeerAddress} */
    set peerAddress(value) {
        this._conn.peerAddress = value;
    }

    /** @type {NetAddress} */
    get netAddress() {
        return this._conn.netAddress;
    }

    /** @type {NetAddress} */
    set netAddress(value) {
        this._conn.netAddress = value;
    }

    /** @type {boolean} */
    get closed() {
        return this._conn.closed;
    }

    /** @type {number} */
    get lastMessageReceivedAt() {
        return this._conn.lastMessageReceivedAt;
    }
}
Class.register(PeerChannel);

PeerChannel.Event = {};
PeerChannel.Event[Message.Type.VERSION] = 'version';
PeerChannel.Event[Message.Type.INV] = 'inv';
PeerChannel.Event[Message.Type.GET_DATA] = 'get-data';
PeerChannel.Event[Message.Type.GET_HEADER] = 'get-header';
PeerChannel.Event[Message.Type.NOT_FOUND] = 'not-found';
PeerChannel.Event[Message.Type.GET_BLOCKS] = 'get-blocks';
PeerChannel.Event[Message.Type.BLOCK] = 'block';
PeerChannel.Event[Message.Type.HEADER] = 'header';
PeerChannel.Event[Message.Type.TX] = 'tx';
PeerChannel.Event[Message.Type.MEMPOOL] = 'mempool';
PeerChannel.Event[Message.Type.REJECT] = 'reject';
PeerChannel.Event[Message.Type.SUBSCRIBE] = 'subscribe';
PeerChannel.Event[Message.Type.ADDR] = 'addr';
PeerChannel.Event[Message.Type.GET_ADDR] = 'get-addr';
PeerChannel.Event[Message.Type.PING] = 'ping';
PeerChannel.Event[Message.Type.PONG] = 'pong';
PeerChannel.Event[Message.Type.SIGNAL] = 'signal';
PeerChannel.Event[Message.Type.GET_CHAIN_PROOF] = 'get-chain-proof';
PeerChannel.Event[Message.Type.CHAIN_PROOF] = 'chain-proof';
PeerChannel.Event[Message.Type.GET_ACCOUNTS_PROOF] = 'get-accounts-proof';
PeerChannel.Event[Message.Type.ACCOUNTS_PROOF] = 'accounts-proof';
PeerChannel.Event[Message.Type.GET_ACCOUNTS_TREE_CHUNK] = 'get-accounts-tree-chunk';
PeerChannel.Event[Message.Type.ACCOUNTS_TREE_CHUNK] = 'accounts-tree-chunk';
PeerChannel.Event[Message.Type.GET_TRANSACTIONS_PROOF_BY_ADDRESSES] = 'get-transactions-proof';
PeerChannel.Event[Message.Type.TRANSACTIONS_PROOF] = 'transactions-proof';
PeerChannel.Event[Message.Type.GET_TRANSACTION_RECEIPTS_BY_ADDRESS] = 'get-transaction-receipts';
PeerChannel.Event[Message.Type.TRANSACTION_RECEIPTS] = 'transaction-receipts';
PeerChannel.Event[Message.Type.GET_BLOCK_PROOF] = 'get-block-proof';
PeerChannel.Event[Message.Type.BLOCK_PROOF] = 'block-proof';
PeerChannel.Event[Message.Type.GET_TRANSACTIONS_PROOF_BY_HASHES] = 'get-transactions-proof-by-hashes';
PeerChannel.Event[Message.Type.GET_TRANSACTION_RECEIPTS_BY_HASHES] = 'get-transaction-receipts-by-hashes';
PeerChannel.Event[Message.Type.GET_BLOCK_PROOF_AT] = 'get-block-proof-at';
PeerChannel.Event[Message.Type.GET_HEAD] = 'get-head';
PeerChannel.Event[Message.Type.HEAD] = 'head';
PeerChannel.Event[Message.Type.VERACK] = 'verack';

class NetworkAgent extends Observable {
    /**
     * @param {IBlockchain} blockchain
     * @param {PeerAddressBook} addresses
     * @param {NetworkConfig} networkConfig
     * @param {PeerChannel} channel
     *
     * @listens PeerChannel#version
     * @listens PeerChannel#verack
     * @listens PeerChannel#addr
     * @listens PeerChannel#getAddr
     * @listens PeerChannel#ping
     * @listens PeerChannel#pong
     * @listens PeerChannel#close
     */
    constructor(blockchain, addresses, networkConfig, channel) {
        super();
        /** @type {IBlockchain} */
        this._blockchain = blockchain;
        /** @type {PeerAddressBook} */
        this._addresses = addresses;
        /** @type {NetworkConfig} */
        this._networkConfig = networkConfig;
        /** @type {PeerChannel} */
        this._channel = channel;

        /**
         * The peer object we create after the handshake completes.
         * @type {Peer}
         * @private
         */
        this._peer = null;

        /**
         * Helper object to keep track of timeouts & intervals.
         * @type {Timers}
         * @private
         */
        this._timers = new Timers();

        /**
         * True if we have received the peer's version message.
         * @type {boolean}
         * @private
         */
        this._versionReceived = false;

        /**
         * True if we have received the peer's verack message.
         * @type {boolean}
         * @private
         */
        this._verackReceived = false;

        /**
         * True if we have successfully sent our version message.
         * @type {boolean}
         * @private
         */
        this._versionSent = false;

        /**
         * True if we have successfully sent our verack message.
         * @type {boolean}
         * @private
         */
        this._verackSent = false;

        /**
         * Number of times we have tried to send out the version message.
         * @type {number}
         * @private
         */
        this._versionAttempts = 0;

        /**
         * @type {boolean}
         * @private
         */
        this._peerAddressVerified = false;

        /**
         * @type {Uint8Array}
         * @private
         */
        this._peerChallengeNonce = null;

        /**
         * @type {Map.<number, number>}
         * @private
         */
        this._pingTimes = new Map();

        /**
         * @type {{maxResults:number}}
         * @private
         */
        this._addressRequest = null;

        /**
         * @type {RateLimit}
         * @private
         */
        this._getAddrLimit = new RateLimit(NetworkAgent.GETADDR_RATE_LIMIT);

        /** @type {Uint8Array} */
        this._challengeNonce = new Uint8Array(VersionMessage.CHALLENGE_SIZE);
        CryptoWorker.lib.getRandomValues(this._challengeNonce);

        // Listen to network/control messages from the peer.
        channel.on('version', msg => this._onVersion(msg));
        channel.on('verack', msg => this._onVerAck(msg));
        channel.on('addr', msg => this._onAddr(msg));
        channel.on('get-addr', msg => this._onGetAddr(msg));
        channel.on('ping', msg => this._onPing(msg));
        channel.on('pong', msg => this._onPong(msg));

        // Clean up when the peer disconnects.
        channel.on('close', () => this._onClose());
    }

    /* Handshake */

    handshake() {
        if (this._versionSent) {
            // Version already sent, no need to handshake again.
            return;
        }

        // Kick off the handshake by telling the peer our version, network address & blockchain head hash.
        // Some browsers (Firefox, Safari) send the data-channel-open event too early, so sending the version message might fail.
        // Try again in this case.
        if (!this._channel.version(this._networkConfig.peerAddress, this._blockchain.headHash, this._challengeNonce, this._networkConfig.appAgent)) {
            this._versionAttempts++;
            if (this._versionAttempts >= NetworkAgent.VERSION_ATTEMPTS_MAX || this._channel.closed) {
                this._channel.close(CloseType.SENDING_OF_VERSION_MESSAGE_FAILED, 'sending of version message failed');
                return;
            }

            setTimeout(this.handshake.bind(this), NetworkAgent.VERSION_RETRY_DELAY);
            return;
        }

        this._versionSent = true;

        // Drop the peer if it doesn't send us a version message.
        // Only do this if we haven't received the peer's version message already.
        if (!this._versionReceived) {
            this._timers.setTimeout('version', () => {
                this._timers.clearTimeout('version');
                this._channel.close(CloseType.VERSION_TIMEOUT, 'version timeout');
            }, NetworkAgent.HANDSHAKE_TIMEOUT);
        } else if (this._peerAddressVerified) {
            this._sendVerAck();
        }

        this._timers.setTimeout('verack', () => {
            this._timers.clearTimeout('verack');
            this._channel.close(CloseType.VERACK_TIMEOUT, 'verack timeout');
        }, NetworkAgent.HANDSHAKE_TIMEOUT * 2);
    }

    /**
     * @param {VersionMessage} msg
     * @private
     */
    _onVersion(msg) {
        Log.v(NetworkAgent, () => `[VERSION] ${msg.peerAddress} ${msg.headHash.toBase64()}`);

        const now = Date.now();

        // Make sure this is a valid message in our current state.
        if (!this._canAcceptMessage(msg)) {
            return;
        }

        // Ignore duplicate version messages.
        if (this._versionReceived) {
            Log.d(NetworkAgent, () => `Ignoring duplicate version message from ${this._channel.peerAddress}`);
            return;
        }

        // Clear the version timeout.
        this._timers.clearTimeout('version');

        // Check if the peer is running a compatible version.
        if (!Version.isCompatible(msg.version)) {
            this._channel.reject(Message.Type.VERSION, RejectMessage.Code.REJECT_OBSOLETE, `incompatible version (ours=${Version.CODE}, theirs=${msg.version})`);
            this._channel.close(CloseType.INCOMPATIBLE_VERSION, `incompatible version (ours=${Version.CODE}, theirs=${msg.version})`);
            return;
        }

        // Check if the peer is working on the same genesis block.
        if (!GenesisConfig.GENESIS_HASH.equals(msg.genesisHash)) {
            this._channel.close(CloseType.DIFFERENT_GENESIS_BLOCK, `different genesis block (${msg.genesisHash})`);
            return;
        }

        // Check that the given peerAddress is correctly signed.
        if (!msg.peerAddress.verifySignature()) {
            this._channel.close(CloseType.INVALID_PEER_ADDRESS_IN_VERSION_MESSAGE, 'invalid peerAddress in version message');
            return;
        }

        // TODO check services?

        // Check that the given peerAddress matches the one we expect.
        // In case of inbound WebSocket connections, this is the first time we
        // see the remote peer's peerAddress.
        const peerAddress = msg.peerAddress;
        if (this._channel.peerAddress) {
            if (!this._channel.peerAddress.equals(peerAddress)) {
                this._channel.close(CloseType.UNEXPECTED_PEER_ADDRESS_IN_VERSION_MESSAGE, 'unexpected peerAddress in version message');
                return;
            }
            this._peerAddressVerified = true;
        }

        // The client might not send its netAddress. Set it from our address database if we have it.
        if (!peerAddress.netAddress) {
            /** @type {PeerAddress} */
            const storedAddress = this._addresses.get(peerAddress);
            if (storedAddress && storedAddress.netAddress) {
                peerAddress.netAddress = storedAddress.netAddress;
            }
        }

        // Set/update the channel's peer address.
        this._channel.peerAddress = peerAddress;

        // Create peer object. Since the initial version message received from the
        // peer contains their local timestamp, we can use it to calculate their
        // offset to our local timestamp and store it for later (last argument).
        this._peer = new Peer(
            this._channel,
            msg.version,
            msg.headHash,
            peerAddress.timestamp - now,
            msg.userAgent
        );

        this._peerChallengeNonce = msg.challengeNonce;
        this._versionReceived = true;

        // Tell listeners that we received this peer's version information.
        // Listeners registered to this event might close the connection to this peer.
        this.fire('version', this._peer, this);

        // Abort handshake if the connection was closed.
        if (this._channel.closed) {
            return;
        }

        if (!this._versionSent) {
            this.handshake();
            return;
        }

        if (this._peerAddressVerified) {
            this._sendVerAck();
        }

        if (this._verackReceived) {
            this._finishHandshake();
        }
    }

    _sendVerAck() {
        Assert.that(this._peerAddressVerified);

        const data = BufferUtils.concatTypedArrays(this._channel.peerAddress.peerId.serialize(), this._peerChallengeNonce);
        const signature = Signature.create(this._networkConfig.keyPair.privateKey, this._networkConfig.keyPair.publicKey, data);
        this._channel.verack(this._networkConfig.keyPair.publicKey, signature);

        this._verackSent = true;
    }

    /**
     * @param {VerAckMessage} msg
     * @private
     */
    _onVerAck(msg) {
        Log.v(NetworkAgent, () => `[VERACK] from ${this._channel.peerAddress}`);

        // Make sure this is a valid message in our current state.
        if (!this._canAcceptMessage(msg)) {
            return;
        }

        // Ignore duplicate verack messages.
        if (this._verackReceived) {
            Log.d(NetworkAgent, () => `Ignoring duplicate verack message from ${this._channel.peerAddress}`);
            return;
        }

        // Clear the verack timeout.
        this._timers.clearTimeout('verack');

        // Verify public key
        if (!msg.publicKey.toPeerId().equals(this._channel.peerAddress.peerId)) {
            this._channel.close(CloseType.INVALID_PUBLIC_KEY_IN_VERACK_MESSAGE, 'Invalid public key in verack message');
            return;
        }

        // Verify signature
        const data = BufferUtils.concatTypedArrays(this._networkConfig.peerAddress.peerId.serialize(), this._challengeNonce);
        if (!msg.signature.verify(msg.publicKey, data)) {
            this._channel.close(CloseType.INVALID_SIGNATURE_IN_VERACK_MESSAGE, 'Invalid signature in verack message');
            return;
        }

        if (!this._peerAddressVerified) {
            this._peerAddressVerified = true;
            this._sendVerAck();
        }

        this._verackReceived = true;

        if (this._verackSent) {
            this._finishHandshake();
        }
    }

    _finishHandshake() {
        // Setup regular connectivity check.
        // TODO randomize interval?
        this._timers.setInterval('connectivity',
            () => this._checkConnectivity(),
            NetworkAgent.CONNECTIVITY_CHECK_INTERVAL);

        // Regularly announce our address.
        this._timers.setInterval('announce-addr',
            () => this._channel.addr([this._networkConfig.peerAddress]),
            NetworkAgent.ANNOUNCE_ADDR_INTERVAL);

        // Tell listeners that the handshake with this peer succeeded.
        this.fire('handshake', this._peer, this);

        // Request new network addresses from the peer.
        this.requestAddresses();
    }


    /* Addresses */

    requestAddresses(maxResults = NetworkAgent.NUM_ADDR_PER_REQUEST) {
        Log.d(Network, () => `Requesting addresses from ${this._peer.peerAddress}`);

        this._addressRequest = {
            maxResults
        };

        // Request only legacy services from older peers
        let acceptedServices = this._networkConfig.services.accepted;
        if (this._peer.version < 2) {
            acceptedServices &= Services.ALL_LEGACY;
        }

        // Request addresses from peer.
        this._channel.getAddr(this._networkConfig.protocolMask, acceptedServices, maxResults);

        // We don't use a timeout here. The peer will not respond with an addr message if
        // it doesn't have any new addresses.
    }

    /**
     * @param {AddrMessage} msg
     * @private
     */
    _onAddr(msg) {
        // Make sure this is a valid message in our current state.
        if (!this._canAcceptMessage(msg)) {
            return;
        }

        // Reject unsolicited address messages unless it is the peer's own address.
        const isOwnAddress = msg.addresses.length === 1 && this._peer.peerAddress.equals(msg.addresses[0]);
        if (!this._addressRequest && !isOwnAddress) {
            return;
        }

        const { maxResults = NetworkAgent.MAX_ADDR_PER_REQUEST } = this._addressRequest || {};
        if (!isOwnAddress) {
            this._addressRequest = null;
        }

        // Reject messages that contain more than 1000 addresses, ban peer (bitcoin).
        if (msg.addresses.length > NetworkAgent.MAX_ADDR_PER_MESSAGE) {
            Log.w(NetworkAgent, 'Rejecting addr message - too many addresses');
            this._channel.close(CloseType.ADDR_MESSAGE_TOO_LARGE, 'addr message too large');
            return;
        }

        Log.v(NetworkAgent, () => `[ADDR] ${msg.addresses.length} addresses from ${this._peer.peerAddress}`);

        // XXX Discard any addresses beyond the ones we requested.
        // TODO reject addr messages not matching our request.
        const addresses = msg.addresses.slice(0, maxResults);

        // Check the addresses the peer send us.
        for (const addr of addresses) {
            if (!addr.verifySignature()) {
                this._channel.close(CloseType.INVALID_ADDR, 'invalid addr');
                return;
            }

            if ((addr.protocol === Protocol.WS || addr.protocol === Protocol.WSS) && !addr.globallyReachable()) {
                this._channel.close(CloseType.ADDR_NOT_GLOBALLY_REACHABLE, 'addr not globally reachable');
                return;
            }
        }

        // Put the new addresses in the address pool.
        this._addresses.add(this._channel, addresses);

        // Update peer with new address.
        if (isOwnAddress) {
            this._peer.peerAddress = addresses[0];
        }

        // Tell listeners that we have received new addresses.
        this.fire('addr', addresses, this);
    }

    /**
     * @private
     * @param {GetAddrMessage} msg
     * @return {void}
     */
    _onGetAddr(msg) {
        // Make sure this is a valid message in our current state.
        if (!this._canAcceptMessage(msg)) {
            return;
        }

        if (!this._getAddrLimit.note()) {
            Log.w(NetworkAgent, 'Rejecting getaddr message - rate limit exceeded');
            return;
        }

        // Find addresses that match the given protocolMask & serviceMask.
        const numResults = Math.min(msg.maxResults, NetworkAgent.MAX_ADDR_PER_REQUEST);
        const addresses = this._addresses.query(msg.protocolMask, msg.serviceMask, numResults);
        this._channel.addr(addresses);
    }


    /* Connectivity Check */

    _checkConnectivity() {
        // Generate random nonce.
        const nonce = NumberUtils.randomUint32();

        // Send ping message to peer.
        // If sending the ping message fails, assume the connection has died.
        if (!this._channel.ping(nonce)) {
            this._channel.close(CloseType.SENDING_PING_MESSAGE_FAILED, 'sending ping message failed');
            return;
        }

        // Save ping timestamp to detect the speed of the connection.
        const startTime = Date.now();
        this._pingTimes.set(nonce, startTime);

        // Expect the peer to answer with a pong message if we haven't heard anything from it
        // within the last CONNECTIVITY_CHECK_INTERVAL. Drop the peer otherwise.
        if (this._channel.lastMessageReceivedAt < startTime - NetworkAgent.CONNECTIVITY_CHECK_INTERVAL) {
            this._timers.setTimeout(`ping_${nonce}`, () => {
                this._timers.clearTimeout(`ping_${nonce}`);
                this._pingTimes.delete(nonce);
                this._channel.close(CloseType.PING_TIMEOUT, 'ping timeout');
            }, NetworkAgent.PING_TIMEOUT);
        }
    }

    /**
     * @param {PingMessage} msg
     * @private
     */
    _onPing(msg) {
        // Make sure this is a valid message in our current state.
        if (!this._canAcceptMessage(msg)) {
            return;
        }

        // Respond with a pong message
        this._channel.pong(msg.nonce);
    }

    /**
     * @param {PongMessage} msg
     * @fires NetworkAgent#ping-pong
     * @private
     */
    _onPong(msg) {
        // Clear the ping timeout for this nonce.
        this._timers.clearTimeout(`ping_${msg.nonce}`);

        /** @type {number} */
        const startTime = this._pingTimes.get(msg.nonce);
        if (startTime) {
            const delta = Date.now() - startTime;
            if (delta > 0) {
                this.fire('ping-pong', delta);
            }
            this._pingTimes.delete(msg.nonce);
        }
    }

    /**
     * @private
     */
    _onClose() {
        // Clear all timers and intervals when the peer disconnects.
        this._timers.clearAll();
    }

    /**
     * @param {Message} msg
     * @return {boolean}
     * @private
     */
    _canAcceptMessage(msg) {
        // The first message must be the version message.
        if (!this._versionReceived && msg.type !== Message.Type.VERSION) {
            Log.w(NetworkAgent, `Discarding '${PeerChannel.Event[msg.type] || msg.type}' message from ${this._channel.peerAddress || this._channel.netAddress}`
                + ' - no version message received previously');
            return false;
        }
        if (this._versionReceived && !this._verackReceived && msg.type !== Message.Type.VERACK) {
            Log.w(NetworkAgent, `Discarding '${PeerChannel.Event[msg.type] || msg.type}' message from ${this._channel.peerAddress || this._channel.netAddress}`
                + ' - no verack message received previously');
            return false;
        }
        return true;
    }

    /** @type {PeerChannel} */
    get channel() {
        return this._channel;
    }

    /** @type {Peer} */
    get peer() {
        return this._peer;
    }
}
NetworkAgent.HANDSHAKE_TIMEOUT = 1000 * 4; // 4 seconds
NetworkAgent.PING_TIMEOUT = 1000 * 10; // 10 seconds
NetworkAgent.CONNECTIVITY_CHECK_INTERVAL = 1000 * 60; // 1 minute
NetworkAgent.ANNOUNCE_ADDR_INTERVAL = 1000 * 60 * 10; // 10 minutes
NetworkAgent.VERSION_ATTEMPTS_MAX = 10;
NetworkAgent.VERSION_RETRY_DELAY = 500; // 500 ms
NetworkAgent.GETADDR_RATE_LIMIT = 3; // per minute
NetworkAgent.MAX_ADDR_PER_MESSAGE = 1000;
NetworkAgent.MAX_ADDR_PER_REQUEST = 500;
NetworkAgent.NUM_ADDR_PER_REQUEST = 200;
Class.register(NetworkAgent);

class PeerConnectionStatistics {
    /**
     * @constructor
     */
    constructor() {
        /**
         * @type {Array<number>}
         * @private
         */
        this._latencies = [];

        /**
         * @type {HashMap<number, number>}
         * @private
         */
        this._messages = new HashMap();
    }

    /**
     * @returns {void}
     */
    reset() {
        this._latencies = [];
        this._messages = new HashMap();
    }

    /**
     * @param {number} latency
     * @returns {void}
     */
    addLatency(latency) {
        this._latencies.push(latency);
    }

    /**
     * @param {Message} msg
     * @returns {void}
     */
    addMessage(msg) {
        this._messages.put(msg.type, this._messages.contains(msg.type) ? this._messages.get(msg.type) + 1 : 1);
    }

    /**
     * @param {number} msgType
     * @returns {number}
     */
    getMessageCount(msgType) {
        return this._messages.contains(msgType) ? this._messages.get(msgType) : 0;
    }

    /** @type {number} */
    get latencyMedian() {
        const length = this._latencies.length;

        if (length === 0) {
            return 0;
        }

        this._latencies.sort((a, b) => a - b);
        let median;
        if ((length % 2) === 0) {
            median = Math.round((this._latencies[(length / 2) - 1] + this._latencies[length / 2]) / 2);
        } else {
            median = this._latencies[(length - 1) / 2];
        }
        return median;
    }

}
Class.register(PeerConnectionStatistics);

class PeerConnection {
    /**
     * @param {PeerAddress} peerAddress
     * @returns {PeerConnection}
     */
    static getOutbound(peerAddress) {
        const peerConnection = new PeerConnection();
        peerConnection._peerAddress = peerAddress;
        peerConnection._state = PeerConnectionState.CONNECTING;
        return peerConnection;
    }

    /**
     * @param {NetworkConnection} networkConnection
     * @returns {PeerConnection}
     */
    static getInbound(networkConnection) {
        const peerConnection = new PeerConnection();
        peerConnection._networkConnection = networkConnection;
        return peerConnection;
    }

    /**
     * @constructor
     */
    constructor() {
        // Unique id for this connection.
        /** @type {number} */
        this._id = PeerConnection._instanceCount++;

        /**
         * @type {PeerAddress}
         * @private
         */
        this._peerAddress = null;

        // Helper Objects are added during lifecycle
        /**
         * @type {NetworkConnection}
         * @private
         */
        this._networkConnection = null;
 
        /**
         * @type {PeerChannel}
         * @private
         */
        this._peerChannel = null;

        /**
         * @type {NetworkAgent}
         * @private
         */
        this._networkAgent = null;

        /**
         * @type {Peer}
         * @private
         */
        this._peer = null;

        /**
         * Lifecycle state of connection
         * @type {number}
         * @private
         */
        this._state = PeerConnectionState.NEW;

        /**
         * Latest score given, computed by PeerScorer
         * @type {number}
         * @private
         */
        this._score = null;

        /**
         * @type {number}
         * @private
         */
        this._establishedSince = null;

        /**
         * @type {PeerConnectionStatistics}
         * @private
         */
        this._statistics = new PeerConnectionStatistics();
    }

    /** @type {number} */
    get id() {
        return this._id;
    }

    /** @type {number} */
    get state() {
        return this._state;
    }

    /** @type {PeerAddress} */
    get peerAddress() {
        return this._peerAddress;
    }

    /** @param {PeerAddress} value */
    set peerAddress(value) {
        this._peerAddress = value;
    }

    /** @type {NetworkConnection} */
    get networkConnection() {
        return this._networkConnection;
    }

    /** @param {NetworkConnection} value */
    set networkConnection(value) {
        this._networkConnection = value;
        this._state = PeerConnectionState.CONNECTED;
    }

    /** @type {PeerChannel} */
    get peerChannel() {
        return this._peerChannel;
    }

    /** @param {PeerChannel} value */
    set peerChannel(value) {
        this._peerChannel = value;
    }

    /** @type {NetworkAgent} */
    get networkAgent() {
        return this._networkAgent;
    }

    /** @param {NetworkAgent} value */
    set networkAgent(value) {
        this._networkAgent = value;
    }

    /**
     * @returns {void}
     */
    negotiating() {
        Assert.that(this._state === PeerConnectionState.CONNECTED);
        this._state = PeerConnectionState.NEGOTIATING;
    }

    /** @type {Peer} */
    get peer() {
        return this._peer;
    }

    /** @param {Peer} value */
    set peer(value) {
        this._peer = value;
        this._state = PeerConnectionState.ESTABLISHED;
        this._establishedSince = Date.now();

        // start statistics
        this._networkAgent.on('ping-pong', (latency) => this._statistics.addLatency(latency));
        this._peerChannel.on('message-log', (msg) => this._statistics.addMessage(msg));
    }

    /** @type {number} */
    get score() {
        return this._score;
    }

    /** @param {number} value */
    set score(value) {
        this._score = value;
    }

    /** @type {number} */
    get establishedSince() {
        return this._establishedSince;
    }

    /** @type {number} */
    get ageEstablished() {
        return Date.now() - this.establishedSince;
    }

    /** @type {PeerConnectionStatistics} */
    get statistics() {
        return this._statistics;
    }

    /**
     * @returns {void}
     */
    close() {
        this._state = PeerConnectionState.CLOSED;
        this._networkConnection = null;
        this._networkAgent = null;
        this._peerChannel = null;
        this._peer = null;
    }
}
// Used to generate unique PeerConnection ids.
PeerConnection._instanceCount = 0;
Class.register(PeerConnection);

class PeerConnectionState {
}
PeerConnectionState.NEW = 1;
PeerConnectionState.CONNECTING = 2;
PeerConnectionState.CONNECTED = 3;
PeerConnectionState.NEGOTIATING = 4;
PeerConnectionState.ESTABLISHED = 5;
PeerConnectionState.CLOSED = 6;
Class.register(PeerConnectionState);

class SignalProcessor {
    /**
     * @constructor
     * @param {PeerAddressBook} peerAddresses
     * @param {NetworkConfig} networkConfig
     * @param {WebRtcConnector} rtcConnector
     */
    constructor(peerAddresses, networkConfig, rtcConnector) {
        /**
         * @type {PeerAddressBook}
         * @private
         */
        this._addresses = peerAddresses;

        /**
         * @type {NetworkConfig}
         * @private
         */
        this._networkConfig = networkConfig;

        /**
         * @type {WebRtcConnector}
         * @private
         */
        this._rtcConnector = rtcConnector;

        /**
         * @type {SignalStore}
         * @private
         */
        this._forwards = new SignalStore();
    }

    /**
     * @param {PeerChannel} channel
     * @param {SignalMessage} msg
     * @returns {void}
     */
    onSignal(channel, msg) {
        // Discard signals with invalid TTL.
        if (msg.ttl > Network.SIGNAL_TTL_INITIAL) {
            channel.close(CloseType.INVALID_SIGNAL_TTL, 'invalid signal ttl');
            return;
        }

        // Can be undefined for non-rtc nodes.
        const myPeerId = this._networkConfig.peerId;

        // Discard signals from myself.
        if (msg.senderId.equals(myPeerId)) {
            Log.d(SignalProcessor, () => `Received signal from myself to ${msg.recipientId} from ${channel.peerAddress} (myId: ${myPeerId})`);
            return;
        }

        // If the signal has the unroutable flag set and we previously forwarded a matching signal,
        // mark the route as unusable.
        if (msg.isUnroutable() && this._forwards.signalForwarded(/*senderId*/ msg.recipientId, /*recipientId*/ msg.senderId, /*nonce*/ msg.nonce)) {
            const senderAddr = this._addresses.getByPeerId(msg.senderId);
            this._addresses.unroutable(channel, senderAddr);
        }

        // If the signal is intended for us, pass it on to our WebRTC connector.
        if (msg.recipientId.equals(myPeerId)) {
            // Ignore signals if we are not a WebRTC node.
            if (this._networkConfig.protocol !== Protocol.RTC) {
                return;
            }

            // Discard signals that have a payload which is not properly signed.
            if (msg.hasPayload() && !msg.verifySignature()) {
                Log.d(SignalProcessor, () => `Discarding signal from ${msg.senderId} received via ${channel.peerAddress} - invalid signature`);
                return;
            }

            // If we sent out a signal that did not reach the recipient because of TTL
            // or it was unroutable, delete this route.
            if (this._rtcConnector.isValidSignal(msg) && (msg.isUnroutable() || msg.isTtlExceeded())) {
                const senderAddr = this._addresses.getByPeerId(msg.senderId);
                this._addresses.unroutable(channel, senderAddr);
            }

            this._rtcConnector.onSignal(channel, msg);
            return;
        }

        // Discard signals that have reached their TTL.
        if (msg.ttl <= 0) {
            Log.d(SignalProcessor, () => `Discarding signal from ${msg.senderId} to ${msg.recipientId} - TTL reached`);
            // Send signal containing TTL_EXCEEDED flag back in reverse direction.
            if (msg.flags === 0) {
                channel.signal(/*senderId*/ msg.recipientId, /*recipientId*/ msg.senderId, msg.nonce, Network.SIGNAL_TTL_INITIAL, SignalMessage.Flag.TTL_EXCEEDED);
            }
            return;
        }

        // Otherwise, try to forward the signal to the intended recipient.
        const signalChannel = this._addresses.getChannelByPeerId(msg.recipientId);
        if (!signalChannel) {
            Log.d(SignalProcessor, () => `Failed to forward signal from ${msg.senderId} to ${msg.recipientId} - no route found`);
            // If we don't know a route to the intended recipient, return signal to sender with unroutable flag set and payload removed.
            // Only do this if the signal is not already a unroutable response.
            if (msg.flags === 0) {
                channel.signal(/*senderId*/ msg.recipientId, /*recipientId*/ msg.senderId, msg.nonce, Network.SIGNAL_TTL_INITIAL, SignalMessage.Flag.UNROUTABLE);
            }
            return;
        }

        // Discard signal if our shortest route to the target is via the sending peer.
        // XXX Why does this happen?
        if (signalChannel.peerAddress.equals(channel.peerAddress)) {
            Log.d(SignalProcessor, () => `Discarding signal from ${msg.senderId} to ${msg.recipientId} - shortest route via sending peer`);
            // If our best route is via the sending peer, return signal to sender with unroutable flag set and payload removed.
            // Only do this if the signal is not already a unroutable response.
            if (msg.flags === 0) {
                channel.signal(/*senderId*/ msg.recipientId, /*recipientId*/ msg.senderId, msg.nonce, Network.SIGNAL_TTL_INITIAL, SignalMessage.Flag.UNROUTABLE);
            }
            return;
        }

        // Decrement ttl and forward signal.
        signalChannel.signal(msg.senderId, msg.recipientId, msg.nonce, msg.ttl - 1, msg.flags, msg.payload, msg.senderPubKey, msg.signature);

        // We store forwarded messages if there are no special flags set.
        if (msg.flags === 0) {
            this._forwards.add(msg.senderId, msg.recipientId, msg.nonce);
        }

        // XXX This is very spammy!!!
        // Log.v(Network, `Forwarding signal (ttl=${msg.ttl}) from ${msg.senderId} `
        //     + `(received from ${channel.peerAddress}) to ${msg.recipientId} `
        //     + `(via ${signalChannel.peerAddress})`);
    }
}
Class.register(SignalProcessor);

class SignalStore {
    /**
     * @param {number} maxSize maximum number of entries
     */
    constructor(maxSize = 1000) {
        /** @type {number} */
        this._maxSize = maxSize;
        /** @type {UniqueQueue.<ForwardedSignal>} */
        this._queue = new UniqueQueue();
        /** @type {HashMap.<ForwardedSignal, number>} */
        this._store = new HashMap();
    }

    /** @type {number} */
    get length() {
        return this._queue.length;
    }

    /**
     * @param {PeerId} senderId
     * @param {PeerId} recipientId
     * @param {number} nonce
     */
    add(senderId, recipientId, nonce) {
        // If we already forwarded such a message, just update timestamp.
        if (this.contains(senderId, recipientId, nonce)) {
            const signal = new ForwardedSignal(senderId, recipientId, nonce);
            this._store.put(signal, Date.now());
            this._queue.requeue(signal);
            return;
        }

        // Delete oldest if needed.
        if (this.length >= this._maxSize) {
            const oldest = this._queue.dequeue();
            this._store.remove(oldest);
        }
        const signal = new ForwardedSignal(senderId, recipientId, nonce);
        this._queue.enqueue(signal);
        this._store.put(signal, Date.now());
    }

    /**
     * @param {PeerId} senderId
     * @param {PeerId} recipientId
     * @param {number} nonce
     * @return {boolean}
     */
    contains(senderId, recipientId, nonce) {
        const signal = new ForwardedSignal(senderId, recipientId, nonce);
        return this._store.contains(signal);
    }

    /**
     * @param {PeerId} senderId
     * @param {PeerId} recipientId
     * @param {number} nonce
     * @return {boolean}
     */
    signalForwarded(senderId, recipientId, nonce) {
        const signal = new ForwardedSignal(senderId, recipientId, nonce);
        const lastSeen = this._store.get(signal);
        if (!lastSeen) {
            return false;
        }
        const valid = lastSeen + ForwardedSignal.SIGNAL_MAX_AGE > Date.now();
        if (!valid) {
            // Because of the ordering, we know that everything after that is invalid too.
            let signalToDelete;
            do {
                signalToDelete = this._queue.dequeue();
                this._store.remove(signalToDelete);
            } while (this._queue.length > 0 && !signal.equals(signalToDelete));
        }
        return valid;
    }
}
SignalStore.SIGNAL_MAX_AGE = 10 /* seconds */;
Class.register(SignalStore);

class ForwardedSignal {
    /**
     * @param {PeerId} senderId
     * @param {PeerId} recipientId
     * @param {number} nonce
     */
    constructor(senderId, recipientId, nonce) {
        /** @type {PeerId} */
        this._senderId = senderId;
        /** @type {PeerId} */
        this._recipientId = recipientId;
        /** @type {number} */
        this._nonce = nonce;
    }

    /**
     * @param {ForwardedSignal} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof ForwardedSignal
            && this._senderId.equals(o._senderId)
            && this._recipientId.equals(o._recipientId)
            && this._nonce === o._nonce;
    }

    hashCode() {
        return this.toString();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `ForwardedSignal{senderId=${this._senderId}, recipientId=${this._recipientId}, nonce=${this._nonce}}`;
    }
}
Class.register(ForwardedSignal);

class ConnectionPool extends Observable {
    /**
     * @constructor
     * @param {PeerAddressBook} peerAddresses
     * @param {NetworkConfig} networkConfig
     * @param {IBlockchain} blockchain
     * @listens WebSocketConnector#connection
     * @listens WebSocketConnector#error
     * @listens WebRtcConnector#connection
     * @listens WebRtcConnector#error
     */
    constructor(peerAddresses, networkConfig, blockchain) {
        super();

        /**
         * @type {PeerAddressBook}
         * @private
         */
        this._addresses = peerAddresses;

        /**
         * @type {NetworkConfig}
         * @private
         */
        this._networkConfig = networkConfig;

        /**
         * @type {IBlockchain}
         * @private
         */
        this._blockchain = blockchain;

        /**
         * HashMap from peerAddresses to connections.
         * @type {HashMap.<PeerAddress, PeerConnection>}
         * @private
         */
        this._connectionsByPeerAddress = new HashMap();

        /**
         * HashMap from netAddresses to connections.
         * @type {HashMap.<NetAddress, Array.<PeerConnection>>}
         * @private
         */
        this._connectionsByNetAddress = new HashMap();

        /**
         * HashMap from subnet addresses to connections.
         * @type {HashMap.<NetAddress, Array.<PeerConnection>>}
         * @private
         */
        this._connectionsBySubnet = new HashMap();

        // Total bytes sent/received on past connections.
        /** @type {number} */
        this._bytesSent = 0;
        /** @type {number} */
        this._bytesReceived = 0;

        /** @type {WebSocketConnector} */
        this._wssConnector = new WebSocketConnector(Protocol.WSS, 'wss', this._networkConfig);
        this._wssConnector.on('connection', conn => this._onConnection(conn));
        this._wssConnector.on('error', (peerAddr, e) => this._onConnectError(peerAddr, e));

        /** @type {WebSocketConnector} */
        this._wsConnector = new WebSocketConnector(Protocol.WS, 'ws', this._networkConfig);
        this._wsConnector.on('connection', conn => this._onConnection(conn));
        this._wsConnector.on('error', (peerAddr, e) => this._onConnectError(peerAddr, e));

        /** @type {WebRtcConnector} */
        this._rtcConnector = new WebRtcConnector(this._networkConfig);
        this._rtcConnector.on('connection', conn => this._onConnection(conn));
        this._rtcConnector.on('error', (peerAddr, reason) => this._onConnectError(peerAddr, reason));

        // Various counters for established connections.
        /** @type {number} */
        this._peerCountWs = 0;
        /** @type {number} */
        this._peerCountWss = 0;
        /** @type {number} */
        this._peerCountRtc = 0;
        /** @type {number} */
        this._peerCountDumb = 0;
        /** @type {number} */
        this._peerCountFull = 0;
        /** @type {number} */
        this._peerCountLight = 0;
        /** @type {number} */
        this._peerCountNano = 0;
        /** @type {number} */
        this._peerCountOutbound = 0;
        /** @type {number} */
        this._peerCountFullWsOutbound = 0;

        /**
         * Number of ongoing outbound connection attempts.
         * @type {number}
         * @private
         */
        this._connectingCount = 0;

        /**
         * Number of not established inbound connections.
         * @type {number}
         * @private
         */
        this._inboundCount = 0;

        /** @type {SignalProcessor} */
        this._signalProcessor = new SignalProcessor(peerAddresses, networkConfig, this._rtcConnector);

        // When true, send a signal to network to close an established connection for a incoming one
        /** @type {boolean} */
        this._allowInboundExchange = false;

        // Whether we allow inbound connections. Does not apply to WebRTC connections.
        /** @type {boolean} */
        this._allowInboundConnections = false;

        /** @type {HashMap.<NetAddress, number>} */
        this._bannedIPv4IPs = new HashMap();

        /** @type {HashMap.<Uint8Array, number>} */
        this._bannedIPv6IPs = new HashMap();

        setInterval(() => this._checkUnbanIps(), ConnectionPool.UNBAN_IPS_INTERVAL);
    }

    /**
     * @returns {Array.<PeerConnection>}
     */
    values() {
        return Array.from(this._connectionsByPeerAddress.values());
    }

    /**
     * @returns {Iterator.<PeerConnection>}
     */
    valueIterator() {
        return this._connectionsByPeerAddress.valueIterator();
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {?PeerConnection}
     */
    getConnectionByPeerAddress(peerAddress) {
        return this._connectionsByPeerAddress.get(peerAddress);
    }

    /**
     * @param {NetAddress} netAddress
     * @returns {Array.<PeerConnection>}
     */
    getConnectionsByNetAddress(netAddress) {
        return this._connectionsByNetAddress.get(netAddress) || [];
    }

    /**
     * @param {NetAddress} netAddress
     * @returns {Array.<PeerConnection>}
     */
    getConnectionsBySubnet(netAddress) {
        return this._connectionsBySubnet.get(this._getSubnetAddress(netAddress)) || [];
    }

    /**
     * @param {NetAddress} netAddress
     * @returns {Array.<PeerConnection>}
     */
    getOutboundConnectionsBySubnet(netAddress) {
        return (this._connectionsBySubnet.get(this._getSubnetAddress(netAddress)) || [])
            .filter(/** @type {PeerConnection} */ peerConnection => peerConnection.networkConnection.outbound);
    }

    /**
     * @param {NetAddress} netAddress
     * @returns {NetAddress}
     */
    _getSubnetAddress(netAddress) {
        return netAddress.subnet(netAddress.isIPv4() ? Network.IPV4_SUBNET_MASK : Network.IPV6_SUBNET_MASK);
    }

    /**
     * @param {PeerConnection} peerConnection
     * @returns {void}
     * @private
     */
    _add(peerConnection) {
        if (peerConnection.peerAddress) {
            this._connectionsByPeerAddress.put(peerConnection.peerAddress, peerConnection);
        }
    }

    /**
     * @param {PeerConnection} peerConnection
     * @returns {void}
     * @private
     */
    _remove(peerConnection) {
        if (peerConnection.peerAddress) {
            this._connectionsByPeerAddress.remove(peerConnection.peerAddress);
        }

        if (peerConnection.networkConnection && peerConnection.networkConnection.netAddress) {
            this._removeNetAddress(peerConnection, peerConnection.networkConnection.netAddress);
        }
    }

    /**
     * @param {PeerConnection} peerConnection
     * @param {NetAddress} netAddress
     * @returns {void}
     * @private
     */
    _addNetAddress(peerConnection, netAddress) {
        // Only add reliable netAddresses.
        if (netAddress.isPseudo() || !netAddress.reliable) {
            return;
        }

        if (this._connectionsByNetAddress.contains(netAddress)) {
            this._connectionsByNetAddress.get(netAddress).push(peerConnection);
        } else {
            this._connectionsByNetAddress.put(netAddress, [peerConnection]);
        }

        const subnetAddress = this._getSubnetAddress(netAddress);
        if (this._connectionsBySubnet.contains(subnetAddress)) {
            this._connectionsBySubnet.get(subnetAddress).push(peerConnection);
        } else {
            this._connectionsBySubnet.put(subnetAddress, [peerConnection]);
        }
    }

    /**
     * @param {PeerConnection} peerConnection
     * @param {NetAddress} netAddress
     * @returns {void}
     * @private
     */
    _removeNetAddress(peerConnection, netAddress) {
        if (netAddress.isPseudo() || !netAddress.reliable) {
            return;
        }

        if (this._connectionsByNetAddress.contains(netAddress)) {
            const peerConnections = this._connectionsByNetAddress.get(netAddress);

            const index = peerConnections.indexOf(peerConnection);
            if (index >= 0) {
                peerConnections.splice(index, 1);
            }

            if (peerConnections.length === 0) {
                this._connectionsByNetAddress.remove(netAddress);
            }
        }

        const subnetAddress = this._getSubnetAddress(netAddress);
        if (this._connectionsBySubnet.contains(subnetAddress)) {
            const peerConnections = this._connectionsBySubnet.get(subnetAddress);

            const index = peerConnections.indexOf(peerConnection);
            if (index >= 0) {
                peerConnections.splice(index, 1);
            }

            if (peerConnections.length === 0) {
                this._connectionsBySubnet.remove(subnetAddress);
            }
        }
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {boolean}
     */
    _checkOutboundConnectionRequest(peerAddress) {
        if (peerAddress === null) {
            return false;
        }

        if (peerAddress.protocol !== Protocol.WS && peerAddress.protocol !== Protocol.WSS && peerAddress.protocol !== Protocol.RTC) {
            Log.e(ConnectionPool, `Cannot connect to ${peerAddress} - unsupported protocol`);
            return false;
        }

        if (this._addresses.isBanned(peerAddress)){
            Log.e(ConnectionPool, `Connecting to banned address ${peerAddress}`);
            return false;
        }

        const peerConnection = this.getConnectionByPeerAddress(peerAddress);
        if (peerConnection) {
            Log.e(ConnectionPool, `Duplicate connection to ${peerAddress}`);
            return false;
        }

        // Forbid connection if we have too many connections to the peer's IP address.
        if (peerAddress.netAddress && peerAddress.netAddress.reliable) {
            if (this.getConnectionsByNetAddress(peerAddress.netAddress).length >= Network.PEER_COUNT_PER_IP_MAX) {
                Log.e(ConnectionPool, `connection limit per ip (${Network.PEER_COUNT_PER_IP_MAX}) reached`);
                return false;
            }

            if (this.getOutboundConnectionsBySubnet(peerAddress.netAddress).length >= Network.OUTBOUND_PEER_COUNT_PER_SUBNET_MAX) {
                Log.e(ConnectionPool, `connection limit per ip (${Network.OUTBOUND_PEER_COUNT_PER_SUBNET_MAX}) reached`);
                return false;
            }
        }

        return true;
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {boolean}
     */
    connectOutbound(peerAddress) {
        // all checks in one step
        if (!this._checkOutboundConnectionRequest(peerAddress)) {
            return false;
        }

        // Connection request accepted.

        // create fresh PeerConnection instance
        const peerConnection = PeerConnection.getOutbound(peerAddress);
        this._add(peerConnection);

        // choose connector type and call
        let connecting = false;
        if (peerAddress.protocol === Protocol.WSS) {
            connecting = this._wssConnector.connect(peerAddress);
        } else if (peerAddress.protocol === Protocol.WS) {
            connecting = this._wsConnector.connect(peerAddress);
        } else {
            const signalChannel = this._addresses.getChannelByPeerId(peerAddress.peerId);
            connecting = this._rtcConnector.connect(peerAddress, signalChannel);
        }

        if (connecting) {
            this._connectingCount++;
        } else {
            this._remove(peerConnection);
            Log.d(Network, () => `Outbound attempt not connecting: ${peerAddress}`);
            return false;
        }

        return true;
    }

    /**
     * @param {PeerConnection} peerConnection
     * @returns {boolean}
     * @private
     */
    _checkConnection(peerConnection) {
        /** @type {NetworkConnection} */
        const conn = peerConnection.networkConnection;

        // Close connection if we currently do not allow inbound connections. WebRTC connections are exempt.
        if (conn.inbound && !this._allowInboundConnections && conn.protocol !== Protocol.RTC) {
            conn.close(CloseType.INBOUND_CONNECTIONS_BLOCKED, 'inbound connections are blocked temporarily');
            return false;
        }

        if (conn.netAddress && !conn.netAddress.isPseudo() && conn.netAddress.reliable) {
            // Close connection if peer's IP is banned.
            if (this._isIpBanned(conn.netAddress)) {
                conn.close(CloseType.IP_BANNED, `connection with banned IP ${conn.netAddress}`);
                return false;
            }

            // Close connection if we have too many connections to the peer's IP address.
            if (!conn.netAddress.isPrivate() && this.getConnectionsByNetAddress(conn.netAddress).length >= Network.PEER_COUNT_PER_IP_MAX) {
                conn.close(CloseType.CONNECTION_LIMIT_PER_IP, `connection limit per IP (${Network.PEER_COUNT_PER_IP_MAX}) reached`);
                return false;
            }

            // Close connection if we have too many connections to the peer's subnet.
            if (!conn.netAddress.isPrivate() && this.getConnectionsBySubnet(conn.netAddress).length >= Network.INBOUND_PEER_COUNT_PER_SUBNET_MAX) {
                conn.close(CloseType.CONNECTION_LIMIT_PER_IP, `connection limit per subnet (${Network.INBOUND_PEER_COUNT_PER_SUBNET_MAX}) reached`);
                return false;
            }
        }

        // Reject peer if we have reached max peer count.
        if (this.peerCount >= Network.PEER_COUNT_MAX
            && !conn.outbound
            && !(conn.inbound && this._allowInboundExchange)) {

            conn.close(CloseType.MAX_PEER_COUNT_REACHED, `max peer count reached (${Network.PEER_COUNT_MAX})`);
            return false;
        }

        return true;
    }

    /**
     * @listens PeerChannel#signal
     * @listens NetworkAgent#handshake
     * @listens NetworkAgent#close
     * @fires ConnectionPool#connection
     * @param {NetworkConnection} conn
     * @returns {void}
     * @private
     */
    _onConnection(conn) {
        /** @type {PeerConnection} */
        let peerConnection;
        if (conn.outbound) {
            peerConnection = this.getConnectionByPeerAddress(conn.peerAddress);

            if (!peerConnection) {
                conn.close(CloseType.INVALID_CONNECTION_STATE, `No PeerConnection present for outgoing connection (${conn.peerAddress})`);
                return;
            } else if (peerConnection.state !== PeerConnectionState.CONNECTING) {
                conn.close(CloseType.INVALID_CONNECTION_STATE, `PeerConnection state not CONNECTING, but ${peerConnection.state} (${conn.peerAddress})`);
                return;
            }

            this._connectingCount--;
            Assert.that(this._connectingCount >= 0, 'connectingCount < 0');
        } else {
            peerConnection = PeerConnection.getInbound(conn);
            this._inboundCount++;
        }

        // Set peerConnection to CONNECTED state.
        peerConnection.networkConnection = conn;

        // Register close listener early to clean up correctly in case _checkConnection() closes the connection.
        conn.on('close', (type, reason) => this._onClose(peerConnection, type, reason));

        if (!this._checkConnection(peerConnection)) {
            return;
        }

        // Connection accepted.

        if (conn.netAddress && !conn.netAddress.isPseudo()) {
            this._addNetAddress(peerConnection, conn.netAddress);
        }

        const connType = conn.inbound ? 'inbound' : 'outbound';
        Log.d(ConnectionPool, () => `Connection established (${connType}) #${conn.id} ${conn.netAddress || conn.peerAddress || '<pending>'}`);

        // Let listeners know about this connection.
        this.fire('connection', conn);

        // Create peer channel.
        const channel = new PeerChannel(conn);
        peerConnection.peerChannel = channel;

        // Create network agent.
        const agent = new NetworkAgent(this._blockchain, this._addresses, this._networkConfig, channel);
        agent.on('version', peer => this._checkHandshake(peerConnection, peer));
        agent.on('handshake', peer => this._onHandshake(peerConnection, peer));

        peerConnection.networkAgent = agent;

        // Initiate handshake with the peer.
        agent.handshake();
    }

    /**
     * @param {PeerConnection} peerConnection
     * @param {Peer} peer
     * @returns {boolean}
     * @private
     */
    _checkHandshake(peerConnection, peer) {
        // Close connection if peer's address is banned.
        if (this._addresses.isBanned(peer.peerAddress)) {
            peerConnection.peerChannel.close(CloseType.PEER_BANNED,
                `connection with banned address ${peer.peerAddress} (post version)`);
            return false;
        }

        // Duplicate/simultaneous connection check (post version):
        const storedConnection = this.getConnectionByPeerAddress(peer.peerAddress);
        if (storedConnection && storedConnection.id !== peerConnection.id) {
            // If we already have an established connection to this peer, close this connection.
            if (storedConnection.state === PeerConnectionState.ESTABLISHED) {
                peerConnection.peerChannel.close(CloseType.DUPLICATE_CONNECTION,
                    'duplicate connection (post version)');
                return false;
            }
        }

        // Close connection if we have too many dumb connections.
        if (peer.peerAddress.protocol === Protocol.DUMB && this.peerCountDumb >= Network.PEER_COUNT_DUMB_MAX) {
            peerConnection.peerChannel.close(CloseType.CONNECTION_LIMIT_DUMB,
                `connection limit for dumb peers (${Network.PEER_COUNT_DUMB_MAX}) reached`);
            return false;
        }

        // Set peerConnection to NEGOTIATING state.
        peerConnection.negotiating();

        return true;
    }

    /**
     * Handshake with this peer was successful.
     * @fires ConnectionPool#peer-joined
     * @fires ConnectionPool#peers-changed
     * @fires ConnectionPool#recyling-request
     * @param {PeerConnection} peerConnection
     * @param {Peer} peer
     * @returns {void}
     * @private
     */
    _onHandshake(peerConnection, peer) {
        if (peerConnection.networkConnection.inbound) {
            // Re-check allowInboundExchange as it might have changed.
            if (this.peerCount >= Network.PEER_COUNT_MAX && !this._allowInboundExchange) {
                peerConnection.peerChannel.close(CloseType.MAX_PEER_COUNT_REACHED,
                    `max peer count reached (${Network.PEER_COUNT_MAX})`);
                return;
            }

            // Duplicate/simultaneous connection check (post handshake):
            const storedConnection = this.getConnectionByPeerAddress(peer.peerAddress);
            if (storedConnection && storedConnection.id !== peerConnection.id) {
                switch (storedConnection.state) {
                    case PeerConnectionState.CONNECTING:
                        // Abort the stored connection attempt and accept this connection.
                        Assert.that(peer.peerAddress.protocol === Protocol.WSS || peer.peerAddress.protocol === Protocol.WS, 'Duplicate connection to non-WS node');
                        Log.d(ConnectionPool, () => `Aborting connection attempt to ${peer.peerAddress}, simultaneous inbound connection succeeded`);
                        if (peer.peerAddress.protocol === Protocol.WSS) {
                            this._wssConnector.abort(peer.peerAddress);
                        } else {
                            this._wsConnector.abort(peer.peerAddress);
                        }
                        Assert.that(!this.getConnectionByPeerAddress(peer.peerAddress), 'PeerConnection not removed');
                        break;

                    case PeerConnectionState.ESTABLISHED:
                        // If we have another established connection to this peer, close this connection.
                        peerConnection.peerChannel.close(CloseType.DUPLICATE_CONNECTION,
                            'duplicate connection (post handshake)');
                        return;

                    case PeerConnectionState.NEGOTIATING:
                        // The peer with the lower peerId accepts this connection and closes his stored connection.
                        if (this._networkConfig.peerAddress.peerId.compare(peer.peerAddress.peerId) < 0) {
                            storedConnection.peerChannel.close(CloseType.SIMULTANEOUS_CONNECTION,
                                'simultaneous connection (post handshake) - lower peerId');
                            Assert.that(!this.getConnectionByPeerAddress(peer.peerAddress), 'PeerConnection not removed');
                        }
                        // The peer with the higher peerId closes this connection and keeps his stored connection.
                        else {
                            peerConnection.peerChannel.close(CloseType.SIMULTANEOUS_CONNECTION,
                                'simultaneous connection (post handshake) - higher peerId');
                            return;
                        }
                        break;

                    default:
                        // Accept this connection and close the stored connection.
                        storedConnection.peerChannel.close(CloseType.SIMULTANEOUS_CONNECTION,
                            `simultaneous connection (post handshake) - state ${storedConnection.state}`);
                        Assert.that(!this.getConnectionByPeerAddress(peer.peerAddress), 'PeerConnection not removed');
                }
            }

            Assert.that(!this.getConnectionByPeerAddress(peer.peerAddress), `PeerConnection ${peer.peerAddress} already exists`);
            peerConnection.peerAddress = peer.peerAddress;
            this._add(peerConnection);

            this._inboundCount--;
            Assert.that(this._inboundCount >= 0, 'inboundCount < 0');
        }

        // Handshake accepted.

        // Check if we need to recycle a connection.
        if (this.peerCount >= Network.PEER_COUNT_MAX) {
            this.fire('recycling-request');
        }

        // Set peerConnection to ESTABLISHED state.
        peerConnection.peer = peer;

        if (peer.netAddress && !peer.netAddress.isPseudo() && this.getConnectionsByNetAddress(peer.netAddress).indexOf(peerConnection) < 0) {
            this._addNetAddress(peerConnection, peer.netAddress);
        }

        this._updateConnectedPeerCount(peerConnection, 1);

        // Setup signal forwarding.
        if (Network.SIGNALING_ENABLED) {
            peerConnection.peerChannel.on('signal', msg => this._signalProcessor.onSignal(peerConnection.peerChannel, msg));
        }

        // Mark address as established.
        this._addresses.established(peer.channel, peer.peerAddress);

        Log.d(ConnectionPool, () => `[PEER-JOINED] ${peer.peerAddress} ${peer.netAddress} (version=${peer.version}, services=${peer.peerAddress.services}, userAgent=${peer.userAgent || '<unknown>'}, headHash=${peer.headHash.toBase64()})`);

        // Let listeners know about this peer.
        this.fire('peer-joined', peer);

        // Let listeners know that the peers changed.
        this.fire('peers-changed');
    }

    /**
     * This peer channel was closed.
     * @param {PeerConnection} peerConnection
     * @param {number} type
     * @param {string} reason
     * @fires ConnectionPool#peer-left
     * @fires ConnectionPool#peers-changed
     * @fires ConnectionPool#close
     * @returns {void}
     * @private
     */
    _onClose(peerConnection, type, reason) {
        // Update total bytes sent/received.
        this._bytesSent += peerConnection.networkConnection.bytesSent;
        this._bytesReceived += peerConnection.networkConnection.bytesReceived;

        // Only propagate the close type (i.e. track fails/bans) if the peerAddress is set.
        // This is true for
        // - all outbound connections
        // - inbound connections post handshake (peerAddress is verified)
        if (peerConnection.peerAddress) {
            this._addresses.close(peerConnection.peerChannel, peerConnection.peerAddress, type);
        }

        this._remove(peerConnection);

        // Check if the handshake with this peer has completed.
        if (peerConnection.state === PeerConnectionState.ESTABLISHED) {
            // If closing is due to a ban, also ban the IP
            if (CloseType.isBanningType(type) && peerConnection.peer.netAddress){
                this._banIp(peerConnection.peer.netAddress);
            }

            this._updateConnectedPeerCount(peerConnection, -1);

            const kbTransferred = ((peerConnection.networkConnection.bytesSent
                + peerConnection.networkConnection.bytesReceived) / 1000).toFixed(2);
            Log.d(ConnectionPool, () => `[PEER-LEFT] ${peerConnection.peerAddress} ${peerConnection.peer.netAddress} `
                + `(transferred=${kbTransferred} kB, closeType=${type} ${reason})`);

            // Tell listeners that this peer has gone away.
            this.fire('peer-left', peerConnection.peer);

            // Let listeners know that the peers changed.
            this.fire('peers-changed');
        } else {
            if (peerConnection.networkConnection.inbound) {
                this._inboundCount--;
                Log.d(ConnectionPool, () => `Inbound connection #${peerConnection.networkConnection.id} closed pre-handshake: ${reason} (${type})`);
            } else {
                Log.d(ConnectionPool, () => `Connection #${peerConnection.networkConnection.id} to ${peerConnection.peerAddress} closed pre-handshake: ${reason} (${type})`);
                this.fire('connect-error', peerConnection.peerAddress, `${reason} (${type})`);
            }
        }

        // Let listeners know about this closing.
        this.fire('close', peerConnection, type, reason);

        // Set the peer connection to closed state.
        peerConnection.close();
    }

    /**
     * @param {NetAddress} netAddress
     * @returns {void}
     * @private
     */
    _banIp(netAddress) {
        if (!netAddress.isPseudo() && netAddress.reliable) {
            Log.w(ConnectionPool, `Banning IP ${netAddress}`);
            if (netAddress.isIPv4()) {
                this._bannedIPv4IPs.put(netAddress, Date.now() + ConnectionPool.DEFAULT_BAN_TIME);
            } else if (netAddress.isIPv6()) {
                // Ban IPv6 IPs prefix based
                this._bannedIPv6IPs.put(netAddress.ip.subarray(0,8), Date.now() + ConnectionPool.DEFAULT_BAN_TIME);
            }
        }
    }

    /**
     * @param {NetAddress} netAddress
     * @returns {boolean}
     * @private
     */
    _isIpBanned(netAddress) {
        if (netAddress.isPseudo()) return false;
        if (netAddress.isIPv4()) {
            return this._bannedIPv4IPs.contains(netAddress);
        } else if (netAddress.isIPv6()) {
            const prefix = netAddress.ip.subarray(0, 8);
            return this._bannedIPv6IPs.contains(prefix);
        }
        return false;
    }

    /**
     * @returns {void}
     * @private
     */
    _checkUnbanIps() {
        const now = Date.now();
        for (const netAddress of this._bannedIPv4IPs.keys()) {
            if (this._bannedIPv4IPs.get(netAddress) < now) {
                this._bannedIPv4IPs.remove(netAddress);
            }
        }
        for (const prefix of this._bannedIPv6IPs.keys()) {
            if (this._bannedIPv6IPs.get(prefix) < now) {
                this._bannedIPv6IPs.remove(prefix);
            }
        }
    }

    /**
     * Connection to this peer address failed.
     * @param {PeerAddress} peerAddress
     * @param {string|*} [reason]
     * @fires ConnectionPool#connect-error
     * @returns {void}
     * @private
     */
    _onConnectError(peerAddress, reason) {
        Log.d(ConnectionPool, () => `Connection to ${peerAddress} failed` + (typeof reason === 'string' ? ` - ${reason}` : ''));

        const peerConnection = this.getConnectionByPeerAddress(peerAddress);
        Assert.that(!!peerConnection, `PeerAddress not stored ${peerAddress}`);
        if (peerConnection.state !== PeerConnectionState.CONNECTING) {
            Log.e(ConnectionPool, `PeerConnection state not CONNECTING, but ${peerConnection.state} (${peerAddress})`);
            return;
        }

        this._remove(peerConnection);

        this._connectingCount--;
        Assert.that(this._connectingCount >= 0, 'connectingCount < 0');

        this._addresses.close(null, peerAddress, CloseType.CONNECTION_FAILED);

        this.fire('connect-error', peerAddress, reason);
    }

    /**
     * @param {PeerConnection} peerConnection
     * @param {number} delta
     * @returns {void}
     * @private
     */
    _updateConnectedPeerCount(peerConnection, delta) {
        const peerAddress = peerConnection.peerAddress;
        switch (peerAddress.protocol) {
            case Protocol.WS:
                this._peerCountWs += delta;
                Assert.that(this._peerCountWs >= 0, 'peerCountWs < 0');
                break;
            case Protocol.WSS:
                this._peerCountWss += delta;
                Assert.that(this._peerCountWss >= 0, 'peerCountWs < 0');
                break;
            case Protocol.RTC:
                this._peerCountRtc += delta;
                Assert.that(this._peerCountRtc >= 0, 'peerCountRtc < 0');
                break;
            case Protocol.DUMB:
                this._peerCountDumb += delta;
                Assert.that(this._peerCountDumb >= 0, 'peerCountDumb < 0');
                break;
            default:
                Log.w(PeerAddressBook, `Unknown protocol ${peerAddress.protocol}`);
        }

        if (Services.isFullNode(peerAddress.services)) {
            this._peerCountFull += delta;
            Assert.that(this._peerCountFull >= 0, 'peerCountFull < 0');
        } else if (Services.isLightNode(peerAddress.services)) {
            this._peerCountLight += delta;
            Assert.that(this._peerCountLight >= 0, 'peerCountLight < 0');
        } else {
            this._peerCountNano += delta;
            Assert.that(this._peerCountNano >= 0, 'peerCountNano < 0');
        }

        if (peerConnection.networkConnection.outbound) {
            this._peerCountOutbound += delta;
            if (Services.isFullNode(peerAddress.services) && (peerAddress.protocol === Protocol.WSS || peerAddress.protocol === Protocol.WS)) {
                this._peerCountFullWsOutbound += delta;
            }
        }
    }


    /**
     * @param {string|*} reason
     * @returns {void}
     */
    disconnect(reason) {
        // Close all active connections.
        for (const connection of this.valueIterator()) {
            if (connection.peerChannel) {
                connection.peerChannel.close(CloseType.MANUAL_NETWORK_DISCONNECT, reason || 'manual network disconnect');
            }
        }
    }

    // XXX For testing
    disconnectWebSocket() {
        // Close all websocket connections.
        for (const connection of this.valueIterator()) {
            if (connection.peerChannel && connection.peerAddress && (connection.peerAddress.protocol === Protocol.WSS || connection.peerAddress.protocol === Protocol.WS)) {
                connection.peerChannel.close(CloseType.MANUAL_WEBSOCKET_DISCONNECT, 'manual websocket disconnect');
            }
        }
    }

    /** @type {number} */
    get peerCountWs() {
        return this._peerCountWs;
    }

    /** @type {number} */
    get peerCountWss() {
        return this._peerCountWss;
    }

    /** @type {number} */
    get peerCountRtc() {
        return this._peerCountRtc;
    }

    /** @type {number} */
    get peerCountDumb() {
        return this._peerCountDumb;
    }

    /** @type {number} */
    get peerCount() {
        return this._peerCountWs + this._peerCountWss + this._peerCountRtc + this._peerCountDumb;
    }

    /** @type {number} */
    get peerCountFull() {
        return this._peerCountFull;
    }

    /** @type {number} */
    get peerCountLight() {
        return this._peerCountLight;
    }

    /** @type {number} */
    get peerCountNano() {
        return this._peerCountNano;
    }

    /** @type {number} */
    get peerCountOutbound() {
        return this._peerCountOutbound;
    }

    /** @type {number} */
    get peerCountFullWsOutbound() {
        return this._peerCountFullWsOutbound;
    }

    /** @type {number} */
    get connectingCount() {
        return this._connectingCount;
    }

    /** @type {number} */
    get count() {
        return this._connectionsByPeerAddress.length + this._inboundCount;
    }

    /** @type {number} */
    get bytesSent() {
        let bytesSent = this._bytesSent;
        for (const peerConnection of this.valueIterator()) {
            if (peerConnection.networkConnection) {
                bytesSent += peerConnection.networkConnection.bytesSent;
            }
        }
        return bytesSent;
    }

    /** @type {number} */
    get bytesReceived() {
        let bytesReceived = this._bytesReceived;
        for (const peerConnection of this.valueIterator()) {
            if (peerConnection.networkConnection) {
                bytesReceived += peerConnection.networkConnection.bytesReceived;
            }
        }
        return bytesReceived;
    }

    /** @param {boolean} value */
    set allowInboundExchange(value) {
        this._allowInboundExchange = value;
    }

    /** @type {boolean} */
    get allowInboundConnections() {
        return this._allowInboundConnections;
    }

    /** @param {boolean} value */
    set allowInboundConnections(value) {
        this._allowInboundConnections = value;
    }

}
ConnectionPool.DEFAULT_BAN_TIME = 1000 * 60 * 10; // 10 minutes
ConnectionPool.UNBAN_IPS_INTERVAL = 1000 * 60; // 1 minute

Class.register(ConnectionPool);

class PeerScorer {
    /**
     * @constructor
     * @param {NetworkConfig} networkConfig
     * @param {PeerAddressBook} addresses
     * @param {ConnectionPool} connections
     */
    constructor(networkConfig, addresses, connections) {
        /**
         * @type {NetworkConfig}
         * @private
         */
        this._networkConfig = networkConfig;

        /**
         * @type {PeerAddressBook}
         * @private
         */
        this._addresses = addresses;

        /**
         * @type {ConnectionPool}
         * @private
         */
        this._connections = connections;

        /**
         * @type {Array.<PeerConnection>}
         * @private
         */
        this._connectionScores = null;
    }

    /**
     * @returns {?PeerAddress}
     */
    pickAddress() {
        let it, numAddresses;
        // Important: this switches over a *mask*.
        switch (this._networkConfig.protocolMask) {
            case Protocol.WSS:
                it = this._addresses.wssIterator();
                numAddresses = this._addresses.knownWssAddressesCount;
                break;
            case Protocol.WS:
                it = this._addresses.wsIterator();
                numAddresses = this._addresses.knownWsAddressesCount;
                break;
            case Protocol.WS | Protocol.WSS:
                it = IteratorUtils.alternate(this._addresses.wsIterator(), this._addresses.wssIterator());
                numAddresses = this._addresses.knownWsAddressesCount + this._addresses.knownWssAddressesCount;
                break;
            case Protocol.RTC:
                it = this._addresses.rtcIterator();
                numAddresses = this._addresses.knownRtcAddressesCount;
                break;
            case Protocol.RTC | Protocol.WS:
                it = IteratorUtils.alternate(this._addresses.rtcIterator(), this._addresses.wsIterator());
                numAddresses = this._addresses.knownRtcAddressesCount + this._addresses.knownWsAddressesCount;
                break;
            case Protocol.RTC | Protocol.WSS:
                it = IteratorUtils.alternate(this._addresses.rtcIterator(), this._addresses.wssIterator());
                numAddresses = this._addresses.knownRtcAddressesCount + this._addresses.knownWssAddressesCount;
                break;
            default:
                it = this._addresses.iterator();
                numAddresses = this._addresses.knownAddressesCount;
        }

        const findCandidates = (addressStatesIterator, numAddresses, numCandidates, allowBadPeers = false) => {
            // Pick a random start index if we have a lot of addresses.
            let startIndex = 0, endIndex = numAddresses;
            if (numAddresses > numCandidates) {
                startIndex = Math.floor(Math.random() * numAddresses);
                endIndex = (startIndex + numCandidates) % numAddresses;
            }
            const overflow = startIndex > endIndex;

            // Compute address scores until we have found at 1000 candidates with score >= 0.
            const candidates = [];
            let index = -1;
            for (const addressState of addressStatesIterator) {
                index++;
                if (!overflow && index < startIndex) continue;
                if (!overflow && index >= endIndex) break;
                if (overflow && (index >= endIndex && index < startIndex)) continue;

                const score = this._scoreAddress(addressState, allowBadPeers);
                if (score >= 0) {
                    candidates.push({score, addressState});
                    if (candidates.length >= numCandidates) {
                        break;
                    }
                }
            }

            return candidates;
        };

        let candidates = findCandidates(it, numAddresses, 1000);
        if (candidates.length === 0 && this.needsGoodPeers()) {
            switch (this._networkConfig.protocolMask) {
                case Protocol.WSS:
                    it = this._addresses.wssIterator();
                    break;
                case Protocol.WS:
                    it = this._addresses.wsIterator();
                    break;
                case Protocol.WS | Protocol.WSS:
                    it = IteratorUtils.alternate(this._addresses.wsIterator(), this._addresses.wssIterator());
                    break;
                case Protocol.RTC:
                    it = this._addresses.rtcIterator();
                    break;
                case Protocol.RTC | Protocol.WS:
                    it = IteratorUtils.alternate(this._addresses.rtcIterator(), this._addresses.wsIterator());
                    break;
                case Protocol.RTC | Protocol.WSS:
                    it = IteratorUtils.alternate(this._addresses.rtcIterator(), this._addresses.wssIterator());
                    break;
                default:
                    it = this._addresses.iterator();
            }
            candidates = findCandidates(it, numAddresses, 1000, true);
        }

        if (candidates.length === 0) {
            return null;
        }

        // Return a random candidate with a high score.
        /** @type {Array.<{score: number, addressState: PeerAddressState}>} */
        const scores = candidates.sort((a, b) => b.score - a.score);
        const goodCandidates = scores.slice(0, PeerScorer.PICK_SELECTION_SIZE);
        const winner = ArrayUtils.randomElement(goodCandidates);
        return winner.addressState.peerAddress;
    }

    /**
     * @param {PeerAddressState} peerAddressState
     * @param {boolean} [allowBadPeers]
     * @returns {number}
     * @private
     */
    _scoreAddress(peerAddressState, allowBadPeers = false) {
        const peerAddress = peerAddressState.peerAddress;

        // Filter addresses that we cannot connect to (needed to filter out dumb peers).
        if (!this._networkConfig.canConnect(peerAddress.protocol)) {
            return -1;
        }

        // Filter addresses not matching our accepted services.
        if (!Services.providesServices(peerAddress.services, this._networkConfig.services.accepted)) {
            return -1;
        }

        // Filter addresses that are too old.
        if (peerAddress.exceedsAge()) {
            return -1;
        }

        // A channel to that peer address is CONNECTING, CONNECTED, NEGOTIATING OR ESTABLISHED
        if (this._connections.getConnectionByPeerAddress(peerAddress)) {
            return -1;
        }

        // If we need more good peers, only allow good peers unless allowBadPeers is true.
        if (this.needsGoodPeers() && !this.isGoodPeer(peerAddress) && !allowBadPeers) {
            return -1;
        }

        // Give all peers the same base score. Penalize peers with failed connection attempts.
        const score = 1;
        switch (peerAddressState.state) {
            case PeerAddressState.BANNED:
                return -1;

            case PeerAddressState.NEW:
            case PeerAddressState.TRIED:
                return score;

            case PeerAddressState.FAILED:
                // Don't pick failed addresses when they have failed the maximum number of times.
                return (1 - ((peerAddressState.failedAttempts + 1) / peerAddressState.maxFailedAttempts)) * score;

            default:
                return -1;
        }
    }

    /**
     * @returns {boolean}
     */
    isGoodPeerSet() {
        return !this.needsGoodPeers() && !this.needsMorePeers();
    }

    /**
     * @returns {boolean}
     */
    needsGoodPeers() {
        return this._connections.peerCountFullWsOutbound < PeerScorer.PEER_COUNT_MIN_FULL_WS_OUTBOUND;
    }

    /**
     * @returns {boolean}
     */
    needsMorePeers() {
        return this._connections.peerCountOutbound < PeerScorer.PEER_COUNT_MIN_OUTBOUND;
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {boolean}
     */
    isGoodPeer(peerAddress) {
        return Services.isFullNode(peerAddress.services) && (peerAddress.protocol === Protocol.WS || peerAddress.protocol === Protocol.WSS);
    }

    /**
     * @returns {void}
     */
    scoreConnections() {
        const candidates = [];

        for (const peerConnection of this._connections.valueIterator()) {
            if (peerConnection.state === PeerConnectionState.ESTABLISHED) {
                // Grant new connections a grace period from recycling.
                if (peerConnection.ageEstablished > PeerScorer._getMinAge(peerConnection.peerAddress)) {
                    peerConnection.score = this._scoreConnection(peerConnection);
                    candidates.push(peerConnection);
                }

                peerConnection.statistics.reset();
            }
        }

        // sort by score
        this._connectionScores = candidates.sort((a, b) => b.score - a.score);
    }

    /**
     * @param {number} count
     * @param {number} type
     * @param {string} reason
     * @returns {void}
     */
    recycleConnections(count, type, reason) {
        if (!this._connectionScores) {
            return;
        }

        while (count > 0 && this._connectionScores.length > 0) {
            const peerConnection = this._connectionScores.pop();
            if (peerConnection.state === PeerConnectionState.ESTABLISHED) {
                peerConnection.peerChannel.close(type, `${reason}`);
                count--;
            }
        }
    }

    /**
     * @param {PeerConnection} peerConnection
     * @returns {number}
     * @private
     */
    _scoreConnection(peerConnection) {
        // Connection age
        const scoreAge = this._scoreConnectionAge(peerConnection);

        // Connection type (inbound/outbound)
        const scoreOutbound = peerConnection.networkConnection.inbound ? 0 : 1;

        // Node type (full/light/nano)
        const peerAddress = peerConnection.peerAddress;
        const scoreType = Services.isFullNode(peerAddress.services)
            ? 1
            : Services.isLightNode(peerAddress.services) ? 0.5 : 0;

        // Protocol: Prefer WebSocket over WebRTC over Dumb.
        let scoreProtocol;
        switch (peerAddress.protocol) {
            case Protocol.WS:
            case Protocol.WSS:
                scoreProtocol = 0.6;
                break;
            case Protocol.RTC:
                scoreProtocol = 0.3;
                break;
            case Protocol.DUMB:
            default:
                scoreProtocol = 0;
        }
        // Boost WebSocket score when low on WebSocket connections.
        if (peerAddress.protocol === Protocol.WS || peerAddress.protocol === Protocol.WSS) {
            const distribution = (this._connections.peerCountWs + this._connections.peerCountWss) / this._connections.peerCount;
            if (distribution < PeerScorer.BEST_PROTOCOL_WS_DISTRIBUTION || this._connections.peerCountFullWsOutbound <= PeerScorer.PEER_COUNT_MIN_FULL_WS_OUTBOUND) {
                scoreProtocol = 1;
            }
        }

        // Connection speed, based on ping-pong latency median
        const medianLatency = peerConnection.statistics.latencyMedian;
        let scoreSpeed = 0;
        if (medianLatency > 0 && medianLatency < NetworkAgent.PING_TIMEOUT) {
            scoreSpeed = 1 - medianLatency / NetworkAgent.PING_TIMEOUT;
        }

        return 0.15 * scoreAge + 0.25 * scoreOutbound + 0.2 * scoreType + 0.2 * scoreProtocol + 0.2 * scoreSpeed;
    }

    /**
     * @param {PeerConnection} peerConnection
     * @returns {number}
     * @private
     */
    _scoreConnectionAge(peerConnection) {
        const score = (age, bestAge, maxAge) => Math.max(Math.min(1 - (age - bestAge) / maxAge, 1), 0);

        const age = peerConnection.ageEstablished;
        const services = peerConnection.peerAddress.services;
        if (Services.isFullNode(services)) {
            return age / (2 * PeerScorer.BEST_AGE_FULL) + 0.5;
        } else if (Services.isLightNode(services)) {
            return score(age, PeerScorer.BEST_AGE_LIGHT, PeerScorer.MAX_AGE_LIGHT);
        } else {
            return score(age, PeerScorer.BEST_AGE_NANO, PeerScorer.MAX_AGE_NANO);
        }
    }

    /**
     * @param {PeerAddress} peerAddress
     * @returns {number}
     * @private
     */
    static _getMinAge(peerAddress) {
        if (Services.isFullNode(peerAddress.services)) {
            return PeerScorer.MIN_AGE_FULL;
        } else if (Services.isLightNode(peerAddress.services)) {
            return PeerScorer.MIN_AGE_LIGHT;
        } else {
            return PeerScorer.MIN_AGE_NANO;
        }
    }

    /** @type {Number} */
    get lowestConnectionScore() {
        if (!this._connectionScores) {
            return null;
        }

        // Remove all closed connections from the end of connectionScores.
        while (this._connectionScores.length > 0
            && this._connectionScores[this._connectionScores.length - 1].state !== PeerConnectionState.ESTABLISHED) {

            this._connectionScores.pop();
        }

        return this._connectionScores.length > 0
            ? this._connectionScores[this._connectionScores.length - 1].score
            : null;
    }

    /** @type {Array.<PeerConnection>} */
    get connectionScores() {
        return this._connectionScores;
    }
}
/**
 * @type {number}
 * @constant
 */
PeerScorer.PEER_COUNT_MIN_FULL_WS_OUTBOUND = PlatformUtils.isNodeJs() ? 12 : 3;
/**
 * @type {number}
 * @constant
 */
PeerScorer.PEER_COUNT_MIN_OUTBOUND = PlatformUtils.isNodeJs() ? 12 : 6;
/**
 * @type {number}
 * @constant
 */
PeerScorer.PICK_SELECTION_SIZE = 100;

PeerScorer.MIN_AGE_FULL = 5 * 60 * 1000; // 5 minutes
PeerScorer.BEST_AGE_FULL = 24 * 60 * 60 * 1000; // 24 hours

PeerScorer.MIN_AGE_LIGHT = 2 * 60 * 1000; // 2 minutes
PeerScorer.BEST_AGE_LIGHT = 15 * 60 * 1000; // 15 minutes
PeerScorer.MAX_AGE_LIGHT = 6 * 60 * 60 * 1000; // 6 hours

PeerScorer.MIN_AGE_NANO = 60 * 1000; // 1 minute
PeerScorer.BEST_AGE_NANO = 5 * 60 * 1000; // 5 minutes
PeerScorer.MAX_AGE_NANO = 30 * 60 * 1000; // 30 minutes

PeerScorer.BEST_PROTOCOL_WS_DISTRIBUTION = 0.15; // 15%

Class.register(PeerScorer);

class NetworkConfig {
    /**
     * @returns {NetworkConfig}
     */
    static getDefault() {
        return PlatformUtils.supportsWebRTC()
            ? new RtcNetworkConfig()
            : new DumbNetworkConfig();
    }

    /**
     * @constructor
     * @param {number} protocolMask
     */
    constructor(protocolMask) {
        /** @type {number} */
        this._protocolMask = protocolMask;

        /**
         * @type {KeyPair}
         * @protected
         */
        this._keyPair = null;

        /**
         * @type {PeerId}
         * @protected
         */
        this._peerId = null;

        /**
         * @type {Services}
         * @protected
         */
        this._services = null;

        /** @type {string} */
        this._appAgent = null;
    }

    /**
     * @returns {void}
     */
    async initPersistent() {
        const db = await PeerKeyStore.getPersistent();
        await this._init(db);
    }

    /**
     * @returns {void}
     */
    async initVolatile() {
        const db = PeerKeyStore.createVolatile();
        await this._init(db);
    }

    /**
     * @private
     * @param {PeerKeyStore} db
     * @returns {void}
     */
    async _init(db) {
        if (this._keyPair) {
            return;
        }

        /** @type {KeyPair} */
        let keys = await db.get('keys');
        if (!keys) {
            keys = KeyPair.generate();
            await db.put('keys', keys);
        }

        this._keyPair = keys;
        this._peerId = keys.publicKey.toPeerId();
    }

    /**
     * @type {number}
     */
    get protocol() {
        throw new Error('Unimplemented');
    }

    /**
     * Used for filtering peer addresses by protocols.
     * @type {number}
     */
    get protocolMask() {
        return this._protocolMask;
    }

    /**
     * @type {KeyPair}
     */
    get keyPair() {
        return this._keyPair;
    }

    /**
     * @type {PublicKey}
     */
    get publicKey() {
        return this._keyPair.publicKey;
    }

    /**
     * @type {PeerId}
     */
    get peerId() {
        return this._peerId;
    }

    /**
     * @type {Services}
     */
    get services() {
        return this._services;
    }

    /**
     * @param {Services} services
     */
    set services(services) {
        this._services = services;
    }

    /**
     * @type {PeerAddress}
     */
    get peerAddress() {
        throw new Error('Not implemented');
    }

    /**
     * @param {number} protocol
     * @returns {boolean}
     */
    canConnect(protocol) {
        return (protocol & this._protocolMask) !== 0;
    }

    /** @type {string} */
    get appAgent() {
        return this._appAgent;
    }

    /** @type {string} */
    set appAgent(value) {
        this._appAgent = value;
    }
}
Class.register(NetworkConfig);

class WsNetworkConfig extends NetworkConfig {
    /**
     * @constructor
     * @param {string} host
     * @param {number} port
     * @param {{enabled: boolean, port: number, addresses: Array.<string>, header: string}} reverseProxy
     */
    constructor(host, port, reverseProxy) {
        super(Protocol.WS | Protocol.WSS);
        this._host = host;
        this._port = port;
        this._reverseProxy = reverseProxy;
    }

    /**
     * @type {number}
     * @override
     */
    get protocol() {
        return Protocol.WS;
    }

    /**
     * @type {number}
     */
    get port() {
        return this._port;
    }

    /**
     * @type {{enabled: boolean, port: number, addresses: Array.<string>, header: string}}
     */
    get reverseProxy() {
        return this._reverseProxy;
    }

    /**
     * @type {WsPeerAddress|WssPeerAddress}
     * @override
     */
    get peerAddress() {
        if (!this._services || !this._keyPair) {
            throw new Error('PeerAddress is not configured.');
        }

        const port = this._reverseProxy.enabled ? this._reverseProxy.port : this._port;
        const peerAddress = new WsPeerAddress(
            this._services.provided, Date.now(), NetAddress.UNSPECIFIED,
            this.publicKey, /*distance*/ 0,
            this._host, port);

        if (!peerAddress.globallyReachable()) {
            throw new Error('PeerAddress not globally reachable.');
        }

        peerAddress.signature = Signature.create(this._keyPair.privateKey, this.publicKey, peerAddress.serializeContent());
        return peerAddress;
    }

    /**
     * @type {boolean}
     */
    get secure() {
        return false;
    }
}
Class.register(WsNetworkConfig);

class WssNetworkConfig extends WsNetworkConfig {
    /**
     * @constructor
     * @param {string} host
     * @param {number} port
     * @param {string} [key]
     * @param {string} [cert]
     * @param {{enabled: boolean, port: number, addresses: Array.<string>, header: string}} reverseProxy
     */
    constructor(host, port, key, cert, reverseProxy) {
        super(host, port, reverseProxy);
        this._key = key;
        this._cert = cert;

        /** @type {{key: string, cert: string}} */
        this._ssl = {
            key: this._key,
            cert: this._cert
        };
    }

    /**
     * @type {number}
     * @override
     */
    get protocol() {
        return Protocol.WSS;
    }

    /**
     * @type {?{key: string, cert: string}}
     */
    get ssl() {
        return this._ssl;
    }

    /**
     * @type {WsPeerAddress|WssPeerAddress}
     * @override
     */
    get peerAddress() {
        if (!this._services || !this._keyPair) {
            throw new Error('PeerAddress is not configured.');
        }

        const port = this._reverseProxy.enabled ? this._reverseProxy.port : this._port;
        const peerAddress = new WssPeerAddress(
            this._services.provided, Date.now(), NetAddress.UNSPECIFIED,
            this.publicKey, /*distance*/ 0,
            this._host, port);

        if (!peerAddress.globallyReachable()) {
            throw new Error('PeerAddress not globally reachable.');
        }

        peerAddress.signature = Signature.create(this._keyPair.privateKey, this.publicKey, peerAddress.serializeContent());
        return peerAddress;
    }

    /**
     * @type {boolean}
     */
    get secure() {
        return true;
    }
}
Class.register(WssNetworkConfig);

class RtcNetworkConfig extends NetworkConfig {
    /**
     * @constructor
     */
    constructor() {
        super((PlatformUtils.supportsWS() ? (Protocol.WS | Protocol.WSS) : Protocol.WSS) | Protocol.RTC);
        this._rtcConfig = {
            iceServers: [
                { urls: 'stun:stun.l.google.com:19302' },
                { urls: 'stun:stun.nimiq-network.com:19302' }
            ]
        };
    }

    /**
     * @type {number}
     * @override
     */
    get protocol() {
        return Protocol.RTC;
    }

    /**
     * @returns {?RTCConfiguration}
     */
    get rtcConfig() {
        return this._rtcConfig;
    }

    /**
     * @type {RtcPeerAddress}
     * @override
     */
    get peerAddress() {
        if (!this._services || !this._keyPair) {
            throw new Error('PeerAddress is not configured.');
        }

        const peerAddress = new RtcPeerAddress(
            this._services.provided, Date.now(), NetAddress.UNSPECIFIED,
            this.publicKey, /*distance*/ 0);
        peerAddress.signature = Signature.create(this._keyPair.privateKey, this.publicKey, peerAddress.serializeContent());
        return peerAddress;
    }
}
Class.register(RtcNetworkConfig);

class DumbNetworkConfig extends NetworkConfig {
    /**
     * @constructor
     */
    constructor() {
        // Browsers served through https only speak WSS. Everything else should also support WS.
        super(PlatformUtils.supportsWS() ? (Protocol.WS | Protocol.WSS) : Protocol.WSS);
    }

    /**
     * @type {number}
     * @override
     */
    get protocol() {
        return Protocol.DUMB;
    }

    /**
     * @type {DumbPeerAddress}
     * @override
     */
    get peerAddress() {
        if (!this._services || !this._keyPair) {
            throw new Error('PeerAddress is not configured.');
        }

        const peerAddress = new DumbPeerAddress(
            this._services.provided, Date.now(), NetAddress.UNSPECIFIED,
            this.publicKey, /*distance*/ 0);
        peerAddress.signature = Signature.create(this._keyPair.privateKey, this.publicKey, peerAddress.serializeContent());
        return peerAddress;
    }
}
Class.register(DumbNetworkConfig);

class Network extends Observable {
    /**
     * @constructor
     * @param {IBlockchain} blockchain
     * @param {NetworkConfig} networkConfig
     * @param {Time} time
     * @listens PeerAddressBook#added
     * @listens ConnectionPool#peer-joined
     * @listens ConnectionPool#peer-left
     * @listens ConnectionPool#peers-changed
     * @listens ConnectionPool#recycling-request
     * @listens ConnectionPool#connect-error
     */
    constructor(blockchain, networkConfig, time) {
        super();

        /**
         * @type {IBlockchain}
         * @private
         */
        this._blockchain = blockchain;

        /**
         * @type {NetworkConfig}
         * @private
         */
        this._networkConfig = networkConfig;

        /**
         * @type {Time}
         * @private
         */
        this._time = time;

        /**
         * Flag indicating whether we should actively connect to other peers.
         * if our peer count is below PEER_COUNT_DESIRED.
         * @type {boolean}
         * @private
         */
        this._autoConnect = false;

        /**
         * Backoff for peer count check in seconds.
         * @type {number}
         * @private
         */
        this._backoff = Network.CONNECT_BACKOFF_INITIAL;

        /**
         * Flag indicating whether we already triggered a backoff.
         * @type {boolean}
         * @private
         */
        this._backedOff = false;

        /**
         * The network's addressbook
         * @type {PeerAddressBook}
         * @private
         */
        this._addresses = new PeerAddressBook(this._networkConfig);
        this._addresses.on('seeded', () => this._checkPeerCount());
        this._addresses.on('added', () => setTimeout(this._checkPeerCount.bind(this), Network.CONNECT_THROTTLE));

        /**
         * Peer connections database & operator
         * @type {ConnectionPool}
         * @private
         */
        this._connections = new ConnectionPool(this._addresses, networkConfig, blockchain);
        this._connections.on('peer-joined', peer => this._onPeerJoined(peer));
        this._connections.on('peer-left', peer => this._onPeerLeft(peer));
        this._connections.on('peers-changed', () => this._onPeersChanged());
        this._connections.on('recycling-request', () => this._onRecyclingRequest());
        this._connections.on('connect-error', () => setTimeout(this._checkPeerCount.bind(this), Network.CONNECT_THROTTLE));

        /**
         * Helper object to pick addresses from PeerAddressBook.
         * @type {PeerScorer}
         * @private
         */
        this._scorer = new PeerScorer(this._networkConfig, this._addresses, this._connections);

        /**
         * @type {?number}
         * @private
         */
        this._houseKeepingIntervalId = null;

        /**
         * @type {Timers}
         */
        this._timers = new Timers();
    }

    /**
     * @returns {void}
     */
    connect() {
        this._autoConnect = true;

        // Setup housekeeping interval.
        this._houseKeepingIntervalId = setInterval(() => this._housekeeping(), Network.HOUSEKEEPING_INTERVAL);

        // Start connecting to peers.
        this._checkPeerCount();
    }

    /**
     * @param {string|*} reason
     * @returns {void}
     */
    disconnect(reason) {
        this._autoConnect = false;

        // Clear housekeeping interval.
        clearInterval(this._houseKeepingIntervalId);

        this._connections.disconnect(reason);
        this._connections.allowInboundConnections = false;
    }

    // XXX For testing
    disconnectWebSocket() {
        this._autoConnect = false;

        this._connections.disconnectWebSocket();
    }

    /**
     * @param {Peer} peer
     * @returns {void}
     * @fires Network#peer-joined
     * @private
     */
    _onPeerJoined(peer) {
        // Recalculate the network adjusted offset
        this._updateTimeOffset();

        this.fire('peer-joined', peer);
    }

    /**
     * @param {Peer} peer
     * @returns {void}
     * @fires Network#peer-left
     * @private
     */
    _onPeerLeft(peer) {
        // Recalculate the network adjusted offset
        this._updateTimeOffset();

        this.fire('peer-left', peer);
    }

    /**
     * @returns {void}
     * @fires Network#peers-changed
     * @private
     */
    _onPeersChanged() {
        setTimeout(this._checkPeerCount.bind(this), Network.CONNECT_THROTTLE);

        this.fire('peers-changed');
    }

    /**
     * @returns {void}
     * @private
     */
    _onRecyclingRequest() {
        this._scorer.recycleConnections(1, CloseType.PEER_CONNECTION_RECYCLED_INBOUND_EXCHANGE, 'Peer connection recycled inbound exchange');

        // set ability to exchange for new inbound connections
        this._connections.allowInboundExchange = this._scorer.lowestConnectionScore !== null
            ? this._scorer.lowestConnectionScore < Network.SCORE_INBOUND_EXCHANGE
            : false;
    }

    /**
     * @returns {void}
     * @private
     */
    _checkPeerCount() {
        if (this._autoConnect
            && this._addresses.seeded
            && !this._scorer.isGoodPeerSet()
            && this._connections.connectingCount < Network.CONNECTING_COUNT_MAX) {

            // Pick a peer address that we are not connected to yet.
            const peerAddress = this._scorer.pickAddress();

            // We can't connect if we don't know any more addresses or only want connections to good peers.
            const onlyGoodPeers = this._scorer.needsGoodPeers() && !this._scorer.needsMorePeers();
            if (!peerAddress || onlyGoodPeers && !this._scorer.isGoodPeer(peerAddress)) {
                // If no backoff has been triggered, trigger one.
                // This helps us to check back whether we need more connections.
                if (!this._backedOff) {
                    this._backedOff = true;
                    const oldBackoff = this._backoff;
                    this._backoff = Math.min(Network.CONNECT_BACKOFF_MAX, oldBackoff * 2);
                    setTimeout(() => {
                        this._backedOff = false;
                        this._checkPeerCount();
                    }, oldBackoff);

                    if (this._connections.count === 0) {
                        // We are not connected to any peers (anymore) and don't know any more addresses to connect to.

                        // Tell listeners that we are disconnected. This is primarily useful for tests.
                        this.fire('disconnected');

                        // Allow inbound connections. This is important for the first seed node on the network which
                        // will never establish a consensus and needs to accept incoming connections eventually.
                        this._connections.allowInboundConnections = true;
                    }
                }

                return;
            }

            // Connect to this address.
            if (!this._connections.connectOutbound(peerAddress)) {
                this._addresses.close(null, peerAddress, CloseType.CONNECTION_FAILED);
                setTimeout(() => this._checkPeerCount(), Network.CONNECT_THROTTLE);
            }
        }
        this._backoff = Network.CONNECT_BACKOFF_INITIAL;
    }

    /**
     * Updates the network time offset by calculating the median offset
     * from all our peers.
     * @returns {void}
     * @private
     */
    _updateTimeOffset() {
        const peerConnections = this._connections.values();

        const offsets = [0]; // Add our own offset.
        peerConnections.forEach(peerConnection => {
            if (peerConnection.state === PeerConnectionState.ESTABLISHED) {
                offsets.push(peerConnection.networkAgent.peer.timeOffset);
            }
        });

        const offsetsLength = offsets.length;
        offsets.sort((a, b) => a - b);

        let timeOffset;
        if ((offsetsLength % 2) === 0) {
            timeOffset = Math.round((offsets[(offsetsLength / 2) - 1] + offsets[offsetsLength / 2]) / 2);
        } else {
            timeOffset = offsets[(offsetsLength - 1) / 2];
        }

        this._time.offset = Math.max(Math.min(timeOffset, Network.TIME_OFFSET_MAX), -Network.TIME_OFFSET_MAX);
    }

    /**
     * @returns {void}
     * @private
     */
    _housekeeping() {
        this._scorer.scoreConnections();

        // recycle
        if (this.peerCount > Network.PEER_COUNT_RECYCLING_ACTIVE) {
            // recycle 1% at PEER_COUNT_RECYCLING_ACTIVE, 20% at PEER_COUNT_MAX
            const percentageToRecycle = (this.peerCount - Network.PEER_COUNT_RECYCLING_ACTIVE) * (Network.RECYCLING_PERCENTAGE_MAX - Network.RECYCLING_PERCENTAGE_MIN) / (Network.PEER_COUNT_MAX - Network.PEER_COUNT_RECYCLING_ACTIVE) + Network.RECYCLING_PERCENTAGE_MIN;
            const connectionsToRecycle = Math.ceil(this.peerCount * percentageToRecycle);
            this._scorer.recycleConnections(connectionsToRecycle, CloseType.PEER_CONNECTION_RECYCLED, 'Peer connection recycled');
        }

        // set ability to exchange for new inbound connections
        this._connections.allowInboundExchange = this._scorer.lowestConnectionScore !== null
            ? this._scorer.lowestConnectionScore < Network.SCORE_INBOUND_EXCHANGE
            : false;


        // Request fresh addresses.
        this._refreshAddresses();
    }

    _refreshAddresses() {
        if (this._scorer.connectionScores && this._scorer.connectionScores.length > 0) {
            const cutoff = Math.min((this._connections.peerCountWs + this._connections.peerCountWss) * 2, Network.ADDRESS_REQUEST_CUTOFF);
            const length = Math.min(this._scorer.connectionScores.length, cutoff);
            for (let i = 0; i < Math.min(Network.ADDRESS_REQUEST_PEERS, this._scorer.connectionScores.length); i++) {
                const index = Math.floor(Math.random() * length);
                const peerConnection = this._scorer.connectionScores[index];
                Log.v(Network, () => `Requesting addresses from ${peerConnection.peerAddress} (score idx ${index})`);
                peerConnection.networkAgent.requestAddresses();
            }
        } else {
            const index = Math.floor(Math.random() * Math.min(this._connections.count, 10));

            /** @type {PeerConnection} */
            let peerConnection;
            let i = 0;
            for (const conn of this._connections.valueIterator()) {
                if (conn.state === PeerConnectionState.ESTABLISHED) {
                    peerConnection = conn;
                }
                if (i >= index && peerConnection) {
                    break;
                }
                i++;
            }

            if (peerConnection) {
                Log.v(Network, () => `Requesting addresses from ${peerConnection.peerAddress} (rand idx ${index})`);
                peerConnection.networkAgent.requestAddresses();
            }
        }
    }

    /** @type {Time} */
    get time() {
        return this._time;
    }

    /** @type {number} */
    get peerCount() {
        return this._connections.peerCount;
    }

    /** @type {number} */
    get peerCountWebSocket() {
        return this._connections.peerCountWs;
    }

    /** @type {number} */
    get peerCountWebSocketSecure() {
        return this._connections.peerCountWss;
    }

    /** @type {number} */
    get peerCountWebRtc() {
        return this._connections.peerCountRtc;
    }

    /** @type {number} */
    get peerCountDumb() {
        return this._connections.peerCountDumb;
    }

    /** @type {number} */
    get peerCountConnecting() {
        return this._connections.connectingCount;
    }

    /** @type {number} */
    get knownAddressesCount() {
        return this._addresses.knownAddressesCount;
    }

    /** @type {number} */
    get bytesSent() {
        return this._connections.bytesSent;
    }

    /** @type {number} */
    get bytesReceived() {
        return this._connections.bytesReceived;
    }

    /** @type {boolean} */
    get allowInboundConnections() {
        return this._connections.allowInboundConnections;
    }

    /** @param {boolean} allowInboundConnections */
    set allowInboundConnections(allowInboundConnections) {
        this._connections.allowInboundConnections = allowInboundConnections;
    }

    /** @type {PeerAddressBook} */
    get addresses() {
        return this._addresses;
    }

    /** @type {ConnectionPool} */
    get connections() {
        return this._connections;
    }

    /** @type {NetworkConfig} */
    get config() {
        return this._networkConfig;
    }
}
/**
 * @type {number}
 * @constant
 */
Network.PEER_COUNT_MAX = PlatformUtils.isBrowser() ? 12 : 4000;
/**
 * @type {number}
 * @constant
 */
Network.INBOUND_PEER_COUNT_PER_SUBNET_MAX = PlatformUtils.isBrowser() ? 2 : 100;
/**
 * @type {number}
 * @constant
 */
Network.OUTBOUND_PEER_COUNT_PER_SUBNET_MAX = 2;
/**
 * @type {number}
 * @constant
 */
Network.PEER_COUNT_PER_IP_MAX = PlatformUtils.isBrowser() ? 1 : 10;
/**
 * @type {number}
 * @constant
 */
Network.PEER_COUNT_DUMB_MAX = 1000;
/**
 * @type {number}
 * @constant
 */
Network.IPV4_SUBNET_MASK = 24;
/**
 * @type {number}
 * @constant
 */
Network.IPV6_SUBNET_MASK = 96;
/**
 * @type {number}
 * @constant
 */
Network.PEER_COUNT_RECYCLING_ACTIVE = PlatformUtils.isBrowser() ? 5 : 1000;
/**
 * @type {number}
 * @constant
 */
Network.RECYCLING_PERCENTAGE_MIN = 0.01;
/**
 * @type {number}
 * @constant
 */
Network.RECYCLING_PERCENTAGE_MAX = 0.20;
/**
 * @type {number}
 * @constant
 */
Network.CONNECTING_COUNT_MAX = 2;
/**
 * @type {number}
 * @constant
 */
Network.SIGNAL_TTL_INITIAL = 3;
/**
 * @type {number}
 * @constant
 */
Network.CONNECT_BACKOFF_INITIAL = 2000; // 2 seconds
/**
 * @type {number}
 * @constant
 */
Network.CONNECT_BACKOFF_MAX = 10 * 60 * 1000; // 10 minutes
/**
 * @type {number}
 * @constant
 */
Network.TIME_OFFSET_MAX = 10 * 60 * 1000; // 10 minutes
/**
 * @type {number}
 * @constant
 */
Network.HOUSEKEEPING_INTERVAL = 5 * 60 * 1000; // 5 minutes
/**
 * @type {number}
 * @constant
 */
Network.SCORE_INBOUND_EXCHANGE = 0.5;
/**
 * @type {number}
 * @constant
 */
Network.CONNECT_THROTTLE = 500; // 0.5 seconds
/**
 * @type {number}
 * @constant
 */
Network.ADDRESS_REQUEST_CUTOFF = 250;
/**
 * @type {number}
 * @constant
 */
Network.ADDRESS_REQUEST_PEERS = 2;
/**
 * @type {number}
 * @constant
 */
Network.SIGNALING_ENABLED = 1;

Class.register(Network);

class NetUtils {
    /**
     * @param {string|Uint8Array} ip
     * @return {boolean}
     */
    static isPrivateIP(ip) {
        if (!(ip instanceof Uint8Array)) {
            ip = NetUtils.ipToBytes(ip);
        }

        if (NetUtils.isLocalIP(ip)) {
            return true;
        }

        if (NetUtils.isIPv4Address(ip)) {
            for (const subnet of NetUtils.IPv4_PRIVATE_NETWORK) {
                if (NetUtils.isIPv4inSubnet(ip, subnet)) {
                    return true;
                }
            }
            return false;
        }

        if (NetUtils.isIPv6Address(ip)) {
            // Private subnet is fc00::/7.
            // So, we only check the first 7 bits of the address to be equal fc00.
            if ((ip[0] & 0xfe) === 0xfc) {
                return true;
            }

            // Link-local addresses are fe80::/10.
            if (ip[0] === 0xfe && (ip[1] & 0xc0) === 0x80) {
                return true;
            }

            // Does not seem to be a private IP.
            return false;
        }

        throw new Error(`Malformed IP address ${ip}`);
    }

    /**
     * @param {string|Uint8Array} ip
     * @returns {boolean}
     */
    static isLocalIP(ip) {
        if (!(ip instanceof Uint8Array)) {
            ip = NetUtils.ipToBytes(ip);
        }

        if (ip.length === NetUtils.IPv4_LENGTH) {
            return ip[0] === 127 && ip[1] === 0 && ip[2] === 0 && ip[3] === 1;
        }
        if (ip.length === NetUtils.IPv6_LENGTH) {
            for (let i = 0; i < NetUtils.IPv6_LENGTH - 1; i++) {
                if (ip[i] !== 0) return false;
            }
            return ip[NetUtils.IPv6_LENGTH - 1] === 1;
        }

        return false;
    }

    /**
     * @param {string|Uint8Array} ip
     * @param {string} subnet
     * @return {boolean}
     */
    static isIPv4inSubnet(ip, subnet) {
        if (!(ip instanceof Uint8Array)) {
            ip = NetUtils.ipToBytes(ip);
        }

        let [subIp, mask] = subnet.split('/');
        mask = -1<<(32-parseInt(mask));
        return (NetUtils._IPv4toLong(ip) & mask) === NetUtils._IPv4toLong(subIp);
    }

    /**
     * @param {string|Uint8Array} ip
     * @return {boolean}
     */
    static isIPv4Address(ip) {
        if (ip instanceof Uint8Array) return ip.length === NetUtils.IPv4_LENGTH;
        const match = ip.match(/^(\d+)\.(\d+)\.(\d+)\.(\d+)$/);
        return !!match && parseInt(match[1]) <= 255 && parseInt(match[2]) <= 255
            && parseInt(match[3]) <= 255 && parseInt(match[4]) <= 255;
    }

    /**
     * @param {string|Uint8Array} ip
     * @return {boolean}
     */
    static isIPv6Address(ip) {
        if (ip instanceof Uint8Array) return ip.length === NetUtils.IPv6_LENGTH;

        const parts = ip.toLowerCase().split(':');
        // An IPv6 address consists of at most 8 parts and at least 3.
        if (parts.length > 8 || parts.length < 3) {
            return false;
        }

        const isEmbeddedIPv4 = NetUtils.isIPv4Address(parts[parts.length - 1]);

        let innerEmpty = false;
        for (let i = 0; i < parts.length; ++i) {
            // Check whether each part is valid.
            // Note: the last part may be a IPv4 address!
            // They can be embedded in the last part. Remember that they take 32bit.
            if (!(/^[a-f0-9]{0,4}$/.test(parts[i])
                    || (i === parts.length - 1
                        && isEmbeddedIPv4
                        && parts.length < 8))) {
                return false;
            }
            // Inside the parts, there has to be at most one empty part.
            if (parts[i].length === 0 && i > 0 && i < parts.length - 1) {
                if (innerEmpty) {
                    return false; // at least two empty parts
                }
                innerEmpty = true;
            }
        }

        // In the special case of embedded IPv4 addresses, everything but the last 48 bit must be 0.
        if (isEmbeddedIPv4) {
            // Exclude the last two parts.
            for (let i=0; i<parts.length-2; ++i) {
                if (!/^0{0,4}$/.test(parts[i])) {
                    return false;
                }
            }
        }

        // If the first part is empty, the second has to be empty as well (e.g., ::1).
        if (parts[0].length === 0) {
            return parts[1].length === 0;
        }

        // If the last part is empty, the second last has to be empty as well (e.g., 1::).
        if (parts[parts.length - 1].length === 0) {
            return parts[parts.length - 2].length === 0;
        }

        // If the length is less than 7 and an IPv4 address is embedded, there has to be an empty part.
        if (isEmbeddedIPv4 && parts.length < 7) {
            return innerEmpty;
        }

        // Otherwise if the length is less than 8, there has to be an empty part.
        if (parts.length < 8) {
            return innerEmpty;
        }

        return true;
    }

    /**
     * @param {string} host
     * @returns {boolean}
     */
    static hostGloballyReachable(host) {
        // IP addresses can't have a proper certificate
        if (NetUtils.isIPv4Address(host) || NetUtils.isIPv6Address(host)) {
            return false;
        }
        // "the use of dotless domains is prohibited [in new gTLDs]" [ https://www.icann.org/resources/board-material/resolutions-new-gtld-2013-08-13-en#1 ]. Old gTLDs rarely use them.
        if (!host.match(/.+\..+$/)) {
            return false;
        }
        return true;
    }

    /**
     * @param {string|Uint8Array} ip
     * @return {number}
     */
    static _IPv4toLong(ip) {
        if (!(ip instanceof Uint8Array)) {
            ip = NetUtils.ipToBytes(ip);
        }
        return (ip[0]<<24) + (ip[1]<<16) + (ip[2]<<8) + ip[3];
    }

    /**
     * @param {string} ip
     * @returns {string}
     * @private
     */
    static _IPv4toIPv6(ip) {
        let parts = ip.split('.');
        parts = parts.map(x => parseInt(x));
        const mask = [];
        for(let i = 0; i < 4; i++) {
            mask.push(('00' + parts[i].toString(16)).slice(-2));
        }
        return `${mask[0]}${mask[1]}:${mask[2]}${mask[3]}`;
    }

    /**
     * @param {string} ip
     * @returns {Uint8Array}
     */
    static ipToBytes(ip) {
        if (NetUtils.isIPv4Address(ip)) {
            const parts = ip.split('.');
            return new Uint8Array(parts.map(x => parseInt(x)));
        }

        if (NetUtils.isIPv6Address(ip)) {
            let parts = ip.toLowerCase().split(':');

            // Handle embedded IPv4 addresses.
            if (NetUtils.isIPv4Address(parts[parts.length - 1])) {
                return NetUtils.ipToBytes(parts[parts.length - 1]);
            }

            // IPv6
            parts = NetUtils._extendIPv6(parts);
            parts = parts.map(x => parseInt(x, 16));
            const bytes = [];
            for(let i = 0; i < 8; i++) {
                bytes.push(parts[i] >> 8);
                bytes.push(parts[i] & 0xff);
            }
            return new Uint8Array(bytes);
        }

        throw new Error(`Malformed IP address ${ip}`);
    }

    /**
     * @param {Uint8Array} ip
     * @returns {string}
     */
    static bytesToIp(ip) {
        if (NetUtils.isIPv4Address(ip)) {
            return ip.join('.');
        }

        if (NetUtils.isIPv6Address(ip)) {
            const hexIp = Array.from(ip, x => ('00' + x.toString(16)).slice(-2));
            const ipv6 = [];
            for (let i = 0; i < 8; i++) {
                ipv6.push(hexIp[i*2] + hexIp[i*2+1]);
            }
            return ipv6.join(':');
        }

        throw new Error(`Malformed IP address ${ip}`);
    }

    /**
     * @param {Array.<string>} parts
     * @returns {Array.<string>}
     * @private
     */
    static _extendIPv6(parts) {
        // Handle embedded IPv4 addresses.
        if (NetUtils.isIPv4Address(parts[parts.length - 1])) {
            const ipv4 = parts[parts.length - 1];
            const ipv6 = NetUtils._IPv4toIPv6(ipv4);
            ip = ip.replace(ipv4, ipv6);
            parts = ip.toLowerCase().split(':');
        }

        let emptyPart = parts.indexOf('');
        // If there is an empty part, fill it up.
        if (emptyPart >= 0) {
            parts[emptyPart] = '0';
            for (let i = parts.length; i < 8; i++) {
                parts.splice(emptyPart, 0, '0');
            }
        }
        // Fill remaining empty fields with 0 as well.
        emptyPart = parts.indexOf('');
        while (emptyPart >= 0) {
            parts[emptyPart] = '0';
            emptyPart = parts.indexOf('');
        }

        return parts;
    }

    /**
     * @param {string|Uint8Array} ip
     * @param {number} bitCount
     * @return {string|Uint8Array}
     */
    static ipToSubnet(ip, bitCount) {
        let stringResult = false;
        if (!(ip instanceof Uint8Array)) {
            ip = NetUtils.ipToBytes(ip);
            stringResult = true;
        }

        const mask = [];
        for(let i = 0; i < ip.byteLength; i++) {
            const n = Math.min(bitCount, 8);
            mask.push(ip[i] & (256 - Math.pow(2, 8 - n)));
            bitCount -= n;
        }
        const result = new Uint8Array(mask);
        return stringResult ? NetUtils.bytesToIp(result) : result;
    }
}
NetUtils.IPv4_LENGTH = 4;
NetUtils.IPv6_LENGTH = 16;
NetUtils.IPv4_PRIVATE_NETWORK = [
    '10.0.0.0/8',
    '172.16.0.0/12',
    '192.168.0.0/16',
    '100.64.0.0/10', // link-local

    // Actually, the following one is only an approximation,
    // the first and the last /24 subnets in the range should be excluded.
    '169.254.0.0/16'
];
Class.register(NetUtils);

class PeerKeyStore {
    /**
     * @returns {Promise.<PeerKeyStore>}
     */
    static async getPersistent() {
        if (!PeerKeyStore._instance) {
            const jdb = new JDB.JungleDB('peer-key', PeerKeyStore.VERSION, { maxDbSize: PeerKeyStore.INITIAL_DB_SIZE });

            // Initialize object stores.
            jdb.createObjectStore(PeerKeyStore.KEY_DATABASE, { codec: new PeerKeyStoreCodec() });

            // Establish connection to database.
            await jdb.connect();

            PeerKeyStore._instance = new PeerKeyStore(jdb.getObjectStore(PeerKeyStore.KEY_DATABASE));
        }
        return PeerKeyStore._instance;
    }

    /**
     * @returns {PeerKeyStore}
     */
    static createVolatile() {
        const store = JDB.JungleDB.createVolatileObjectStore();
        return new PeerKeyStore(store);
    }

    /**
     * @param {IObjectStore} store
     */
    constructor(store) {
        this._store = store;
    }

    /**
     * @param {string} key
     * @returns {Promise.<KeyPair>}
     */
    get(key) {
        return this._store.get(key);
    }

    /**
     * @param {string} key
     * @param {KeyPair} keyPair
     * @returns {Promise}
     */
    put(key, keyPair) {
        return this._store.put(key, keyPair);
    }
}
PeerKeyStore._instance = null;
PeerKeyStore.VERSION = 2;
PeerKeyStore.KEY_DATABASE = 'keys';
PeerKeyStore.INITIAL_DB_SIZE = 1024*1024*10; // 10 MB
Class.register(PeerKeyStore);

/**
 * @implements {ICodec}
 */
class PeerKeyStoreCodec {
    /**
     * @param {*} obj The object to encode before storing it.
     * @returns {*} Encoded object.
     */
    encode(obj) {
        return obj.serialize();
    }

    /**
     * @param {*} buf The object to decode.
     * @param {string} key The object's primary key.
     * @returns {*} Decoded object.
     */
    decode(buf, key) {
        return KeyPair.unserialize(new SerialBuffer(buf));
    }

    /**
     * @type {string}
     */
    get leveldbValueEncoding() {
        return 'binary';
    }

    /**
     * @type {object}
     */
    get lmdbValueEncoding() {
        return JDB.JungleDB.BINARY_ENCODING;
    }
}

class Peer {
    /**
     * @param {PeerChannel} channel
     * @param {number} version
     * @param {Hash} headHash
     * @param {number} timeOffset
     * @param {string} [userAgent]
     */
    constructor(channel, version, headHash, timeOffset, userAgent) {
        /** @type {PeerChannel} */
        this._channel = channel;
        /** @type {number} */
        this._version = version;
        /** @type {Hash} */
        this._headHash = headHash;
        /** @type {BlockHeader} */
        this._head = null;
        /**
         * Offset between the peer's time and our local time.
         * @type {number}
         */
        this._timeOffset = timeOffset;
        /** @type {string} */
        this._userAgent = userAgent;

        this._setNetAddress();
    }

    /**
     * @private
     * @returns {void}
     */
    _setNetAddress() {
        // If the connector was able the determine the peer's netAddress, update the peer's advertised netAddress.
        if (this.channel.netAddress) {
            /*
             * TODO What to do if it doesn't match the currently advertised one?
             * This might happen if multiple IPs are assigned to a host.
             */
            if (this.peerAddress.netAddress && !this.peerAddress.netAddress.equals(this.channel.netAddress)) {
                Log.w(Peer, `Got different netAddress ${this.channel.netAddress} for ${this.peerAddress} `
                    + `- advertised was ${this.peerAddress.netAddress}`);
            }

            // Only set the advertised netAddress if we have the public IP of the peer.
            // WebRTC connectors might return local IP addresses for peers on the same LAN.
            if (!this.channel.netAddress.isPrivate()) {
                this.peerAddress.netAddress = this.channel.netAddress;
            }
        }
        // Otherwise, use the netAddress advertised for this peer if available.
        else if (this.channel.peerAddress.netAddress) {
            this.channel.netAddress = this.channel.peerAddress.netAddress;
        }
        // Otherwise, we don't know the netAddress of this peer. Use a pseudo netAddress.
        else {
            this.channel.netAddress = NetAddress.UNKNOWN;
        }
    }

    /** @type {PeerChannel} */
    get channel() {
        return this._channel;
    }

    /** @type {number} */
    get version() {
        return this._version;
    }

    /** @type {Hash} */
    get headHash() {
        return this._headHash;
    }

    /** @type {BlockHeader} */
    get head() {
        return this._head;
    }

    /** @param {BlockHeader} head */
    set head(head) {
        this._head = head;
        this._headHash = head.hash();
    }

    /** @type {number} */
    get timeOffset() {
        return this._timeOffset;
    }

    /** @type {number} */
    get id() {
        return this._channel.id;
    }

    /** @type {PeerAddress} */
    get peerAddress() {
        return this._channel.peerAddress;
    }

    /** @type {PeerAddress} */
    set peerAddress(value) {
        this._channel.peerAddress = value;
    }

    /** @type {NetAddress} */
    get netAddress() {
        return this._channel.netAddress;
    }

    /** @type {string} */
    get userAgent() {
        return this._userAgent;
    }

    /**
     * @param {Peer} o
     * @returns {boolean}
     */
    equals(o) {
        return o instanceof Peer
            && this._channel.equals(o.channel);
    }

    hashCode() {
        return this._channel.hashCode();
    }

    /**
     * @returns {string}
     */
    toString() {
        return `Peer{version=${this._version}, headHash=${this._headHash}, `
            + `peerAddress=${this.peerAddress}, netAddress=${this.netAddress}}`;
    }
}
Class.register(Peer);

/**
 * @deprecated
 */
class Miner extends Observable {
    /**
     * @param {BaseChain} blockchain
     * @param {Accounts} accounts
     * @param {Mempool} mempool
     * @param {Time} time
     * @param {Address} minerAddress
     * @param {Uint8Array} [extraData=new Uint8Array(0)]
     *
     * @listens Mempool#transaction-added
     * @listens Mempool#transaction-ready
     */
    constructor(blockchain, accounts, mempool, time, minerAddress, extraData = new Uint8Array(0)) {
        super();
        /** @type {BaseChain} */
        this._blockchain = blockchain;
        /** @type {Accounts} */
        this._accounts = accounts;
        /** @type {Mempool} */
        this._mempool = mempool;
        /** @type {Time} */
        this._time = time;
        /**
         * @protected
         * @type {BlockProducer}
         */
        this._producer = new BlockProducer(blockchain, accounts, mempool, time);
        /** @type {Address} */
        this._address = minerAddress;
        /** @type {Uint8Array} */
        this._extraData = extraData;

        /**
         * Number of hashes computed since the last hashrate update.
         * @type {number}
         * @private
         */
        this._hashCount = 0;

        /**
         * Timestamp of the last hashrate update.
         * @type {number}
         * @private
         */
        this._lastHashrate = 0;

        /**
         * Hashrate computation interval handle.
         * @private
         */
        this._hashrateWorker = null;

        /**
         * The current hashrate of this miner.
         * @type {number}
         * @private
         */
        this._hashrate = 0;

        /**
         * The last hash counts used in the moving average.
         * @type {Array.<number>}
         * @private
         */
        this._lastHashCounts = [];

        /**
         * The total hashCount used in the current moving average.
         * @type {number}
         * @private
         */
        this._totalHashCount = 0;

        /**
         * The time elapsed for the last measurements used in the moving average.
         * @type {Array.<number>}
         * @private
         */
        this._lastElapsed = [];

        /**
         * The total time elapsed used in the current moving average.
         * @type {number}
         * @private
         */
        this._totalElapsed = 0;

        /** @type {MinerWorkerPool} */
        this._workerPool = new MinerWorkerPool();

        const cores = PlatformUtils.hardwareConcurrency;
        this.threads = Math.ceil(cores / 2);
        if (cores === 1) this.throttleAfter = 2;
        this._workerPool.on('share', (obj) => this.onWorkerShare(obj));
        this._workerPool.on('no-share', (obj) => this.onWorkerShare(obj));

        /**
         * Flag indicating that the mempool has changed since we started mining the current block.
         * @type {boolean}
         * @private
         */
        this._mempoolChanged = false;

        /** @type {boolean} */
        this._restarting = false;

        /** @type {number} */
        this._lastRestart = 0;

        /** @type {boolean} */
        this._submittingBlock = false;

        /** @type {number} */
        this._shareCompact = 0;

        /** @type {boolean} */
        this._shareCompactSet = false;

        /** @type {number} */
        this._numBlocksMined = 0;

        /** @type {boolean} */
        this._activeConfigChanges = false;
        /** @type {boolean} */
        this._pendingConfigChanges = false;

        if (this._mempool) {
            // Listen to changes in the mempool which evicts invalid transactions
            // after every blockchain head change and then fires 'transactions-ready'
            // when the eviction process finishes. Restart work on the next block
            // with fresh transactions when this fires.
            this._mempool.on('transactions-ready', () => this._startWork());

            // Immediately start processing transactions when they come in.
            this._mempool.on('transaction-added', () => this._mempoolChanged = true);
        }
    }

    startWork() {
        if (this.working) {
            return;
        }

        // Initialize hashrate computation.
        this._hashCount = 0;
        this._lastElapsed = [];
        this._lastHashCounts = [];
        this._totalHashCount = 0;
        this._totalElapsed = 0;
        this._lastHashrate = Date.now();
        this._hashrateWorker = setInterval(() => this._updateHashrate(), 1000);
        this._retry = 0;

        // Tell listeners that we've started working.
        this.fire('start', this);

        // Kick off the mining process.
        this._startWork().catch(Log.w.tag(Miner));
    }

    async _startWork() {
        // XXX Needed as long as we cannot unregister from transactions-ready events.
        if (!this.working || this._restarting) {
            return;
        }
        try {
            this._lastRestart = Date.now();
            this._restarting = true;
            this._mempoolChanged = false;

            // Construct next block.
            this._retry = 0;
            const block = await this.getNextBlock();
            if (block === null) {
                this._stopWork();
                return;
            }

            if (block.isFull()) {
                Log.d(Miner, `Starting work on block #${block.header.height} / ${block.minerAddr.toUserFriendlyAddress()} / ${BufferUtils.toBase64(block.body.extraData)} with ${block.transactionCount} transactions (${this._hashrate} H/s)`);
            } else {
                Log.d(Miner, `Starting work on block #${block.header.height} from pool (${this._hashrate} H/s)`);
            }

            this._workerPool.startMiningOnBlock(block, this._shareCompactSet ? this._shareCompact : undefined).catch(Log.w.tag(Miner));
        } catch (e) {
            Log.e(Miner, e);
            Log.w(Miner, 'Failed to start work, retrying in 100ms');
            this._stopWork();
            setTimeout(() => this.startWork(), 100);
        } finally {
            this._restarting = false;
        }
    }

    /**
     * @param {{hash: Hash, nonce: number, block: Block}} obj
     */
    async onWorkerShare(obj) {
        this._hashCount += this._workerPool.noncesPerRun;
        if (obj.block && obj.block.prevHash.equals(this._blockchain.headHash)) {
            Log.d(Miner, () => `Received share: ${obj.nonce} / ${obj.hash.toHex()}`);
            if (!this._submittingBlock) {
                obj.block.header.nonce = obj.nonce;

                let blockValid = false;
                if (obj.block.isFull() && BlockUtils.isProofOfWork(obj.hash, obj.block.target)) {
                    this._submittingBlock = true;
                    if (await obj.block.header.verifyProofOfWork()) {
                        this._numBlocksMined++;
                        blockValid = true;

                        // Tell listeners that we've mined a block.
                        this.fire('block-mined', obj.block, this);

                        // Push block into blockchain.
                        if ((await this._blockchain.pushBlock(obj.block)) < 0) {
                            this._submittingBlock = false;
                            this._startWork().catch(Log.w.tag(Miner));
                            return;
                        } else {
                            this._submittingBlock = false;
                        }
                    } else {
                        Log.d(Miner, `Ignoring invalid share: ${await obj.block.header.pow()}`);
                    }
                }

                this.fire('share', obj.block, blockValid, this);
            }
        }
        if (this._mempoolChanged && this._lastRestart + Miner.MIN_TIME_ON_BLOCK < Date.now()) {
            this._startWork().catch(Log.w.tag(Miner));
        }
    }

    /**
     * @param {Address} [address]
     * @param {Uint8Array} [extraData]
     * @return {Promise.<Block>}
     */
    async getNextBlock(address = this._address, extraData = this._extraData) {
        this._retry++;
        try {
            return this._producer.getNextBlock(address, extraData);
        } catch (e) {
            // Retry up to three times.
            if (this._retry <= 3) return this.getNextBlock(address, extraData);
            throw e;
        }
    }

    /**
     * @fires Miner#stop
     */
    stopWork() {
        this._stopWork();
    }

    /**
     * @fires Miner#stop
     * @private
     */
    _stopWork() {
        // TODO unregister from blockchain head-changed events.
        if (!this.working) {
            return;
        }

        clearInterval(this._hashrateWorker);
        this._hashrateWorker = null;
        this._hashrate = 0;
        this._lastElapsed = [];
        this._lastHashCounts = [];
        this._totalHashCount = 0;
        this._totalElapsed = 0;

        // Tell listeners that we've stopped working.
        this._workerPool.stop();
        this.fire('stop', this);

        Log.d(Miner, 'Stopped work');
    }

    /**
     * @fires Miner#hashrate-changed
     * @private
     */
    _updateHashrate() {
        const elapsed = (Date.now() - this._lastHashrate) / 1000;
        const hashCount = this._hashCount;
        // Enable next measurement.
        this._hashCount = 0;
        this._lastHashrate = Date.now();

        // Update stored information on moving average.
        this._lastElapsed.push(elapsed);
        this._lastHashCounts.push(hashCount);
        this._totalElapsed += elapsed;
        this._totalHashCount += hashCount;

        if (this._lastElapsed.length > Miner.MOVING_AVERAGE_MAX_SIZE) {
            const oldestElapsed = this._lastElapsed.shift();
            const oldestHashCount = this._lastHashCounts.shift();
            this._totalElapsed -= oldestElapsed;
            this._totalHashCount -= oldestHashCount;
        }

        this._hashrate = Math.round(this._totalHashCount / this._totalElapsed);

        // Tell listeners about our new hashrate.
        this.fire('hashrate-changed', this._hashrate, this);
    }

    startConfigChanges() {
        this._activeConfigChanges = true;
        this._pendingConfigChanges = false;
    }

    finishConfigChanges() {
        if (this._pendingConfigChanges) {
            this._startWork().catch(Log.w.tag(Miner));
        }
        this._activeConfigChanges = false;
    }

    /** @type {Address} */
    get address() {
        return this._address;
    }

    /** @type {Address} */
    set address(addr) {
        if (addr && !addr.equals(this._address)) {
            this._address = addr;
            if (!this._activeConfigChanges) {
                this._startWork().catch(Log.w.tag(Miner));
            } else {
                this._pendingConfigChanges = true;
            }
        }
    }

    /** @type {boolean} */
    get working() {
        return !!this._hashrateWorker;
    }

    /** @type {number} */
    get hashrate() {
        return this._hashrate;
    }

    /** @type {number} */
    get threads() {
        return this._workerPool.poolSize;
    }

    /**
     * @param {number} threads
     */
    set threads(threads) {
        this._workerPool.poolSize = threads;
    }

    /** @type {number} */
    get throttleWait() {
        return this._workerPool.cycleWait;
    }

    /**
     * @param {number} throttleWait
     */
    set throttleWait(throttleWait) {
        this._workerPool.cycleWait = throttleWait;
    }

    /** @type {number} */
    get throttleAfter() {
        return this._workerPool.runsPerCycle;
    }

    /**
     * @param {number} throttleAfter
     */
    set throttleAfter(throttleAfter) {
        this._workerPool.runsPerCycle = throttleAfter;
    }

    /** @type {Uint8Array} */
    get extraData() {
        return this._extraData;
    }

    /** @type {Uint8Array} */
    set extraData(extra) {
        if (!BufferUtils.equals(extra, this._extraData)) {
            this._extraData = extra;
            if (!this._activeConfigChanges) {
                this._startWork().catch(Log.w.tag(Miner));
            } else {
                this._pendingConfigChanges = true;
            }
        }
    }

    get shareCompact() {
        if (!this._shareCompactSet) {
            return undefined;
        } else {
            return this._shareCompact;
        }
    }

    /** @type {number} */
    set shareCompact(targetCompact) {
        if (!targetCompact) {
            this._shareCompactSet = false;
        } else {
            this._shareCompact = targetCompact;
            this._shareCompactSet = true;
        }
    }

    /** @type {number} */
    get numBlocksMined() {
        return this._numBlocksMined;
    }
}

Miner.MIN_TIME_ON_BLOCK = 10000;
Miner.MOVING_AVERAGE_MAX_SIZE = 10;
Class.register(Miner);

/**
 * @abstract
 * @deprecated
 */
class BasePoolMiner extends Miner {
    /**
     * @param {BasePoolMiner.Mode} mode
     * @param {BaseChain} blockchain
     * @param {Accounts} accounts
     * @param {Mempool} mempool
     * @param {Time} time
     * @param {Address} address
     * @param {number} deviceId
     * @param {?object} deviceData
     * @param {Uint8Array} [extraData=new Uint8Array(0)]
     */
    constructor(mode, blockchain, accounts, mempool, time, address, deviceId, deviceData, extraData = new Uint8Array(0)) {
        super(blockchain, accounts, mempool, time, address, extraData);

        /** @type {Address} */
        this._ourAddress = address;

        /** @type {Uint8Array} */
        this._ourExtraData = extraData;

        /** @type {WebSocket} */
        this._ws = null;

        /** @type {number} */
        this._deviceId = deviceId;

        /** @type {object} */
        this._deviceData = deviceData;

        /** @type {BasePoolMiner.Mode} */
        this.mode = mode;

        /** @type {BasePoolMiner.ConnectionState} */
        this.connectionState = BasePoolMiner.ConnectionState.CLOSED;

        this._reconnectTimeout = null;
        this._exponentialBackoffReconnect = BasePoolMiner.RECONNECT_TIMEOUT;
    }

    requestPayout() {
        this._send({
            message: 'payout',
        });
    }

    _send(msg) {
        if (this._ws) {
            try {
                this._ws.send(JSON.stringify(msg));
            } catch (e) {
                Log.w(BasePoolMiner, 'Error sending:', e.message || e);
            }
        }
    }

    connect(host, port) {
        if (this._ws) throw new Error('Call disconnect() first');
        this._host = host;
        this._port = port;
        const ws = this._ws = new WebSocket(`wss://${host}:${port}`);
        this._ws.onopen = () => this._onOpen(ws);
        this._ws.onerror = (e) => this._onError(ws, e);
        this._ws.onmessage = (msg) => this._onMessage(ws, msg.data);
        this._ws.onclose = (e) => this._onClose(ws, e);

        this._changeConnectionState(BasePoolMiner.ConnectionState.CONNECTING);
    }

    _onOpen(ws) {
        if (ws !== this._ws) {
            ws.close();
        } else {
            this._register();
        }
    }

    _register() {
        this._send({
            message: 'register',
            mode: this.mode,
            address: this._ourAddress.toUserFriendlyAddress(),
            deviceId: this._deviceId,
            deviceData: this._deviceData,
            genesisHash: BufferUtils.toBase64(GenesisConfig.GENESIS_HASH.serialize())
        });
    }

    _onError(ws, e) {
        Log.d(BasePoolMiner, 'WebSocket connection errored', e.message || e);
        if (ws === this._ws) {
            this._timeoutReconnect();
        }
        try {
            ws.close();
        } catch (e2) {
            Log.w(BasePoolMiner, e2.message || e2);
        }
    }

    _onClose(ws, e) {
        Log.d(BasePoolMiner, 'WebSocket connection closed', e.message || e);
        if (ws === this._ws) {
            this._changeConnectionState(BasePoolMiner.ConnectionState.CLOSED);
            Log.w(BasePoolMiner, 'Disconnected from pool');
            this._timeoutReconnect();
        }
    }

    _timeoutReconnect() {
        this.disconnect();
        this._reconnectTimeout = setTimeout(() => {
            if (!this._ws) {
                this.connect(this._host, this._port);
            }
        }, this._exponentialBackoffReconnect);
        this._exponentialBackoffReconnect = Math.min(this._exponentialBackoffReconnect * 2, BasePoolMiner.RECONNECT_TIMEOUT_MAX);
    }

    disconnect() {
        this._turnPoolOff();
        if (this._ws) {
            this._changeConnectionState(BasePoolMiner.ConnectionState.CLOSED);
            Log.w(BasePoolMiner, 'Disconnected from pool');

            const ws = this._ws;
            this._ws = null;
            try {
                ws.close();
            } catch (e) {
                Log.w(BasePoolMiner, e.message || e);
            }
        }
        clearTimeout(this._reconnectTimeout);
    }

    _onMessage(ws, msgJson) {
        if (ws !== this._ws) return;
        try {
            const msg = JSON.parse(msgJson);
            if (msg && msg.message) {
                switch (msg.message) {
                    case 'settings':
                        if (!msg.address || !msg.extraData) {
                            this._turnPoolOff();
                            this._ws.close();
                        } else {
                            this._onNewPoolSettings(Address.fromUserFriendlyAddress(msg.address), BufferUtils.fromBase64(msg.extraData), msg.targetCompact || BlockUtils.targetToCompact(new BigNumber(msg.target)), msg.nonce);
                            Log.d(BasePoolMiner, `Received settings from pool: address ${msg.address}, target ${msg.target}, extraData ${msg.extraData}`);
                        }
                        break;
                    case 'balance':
                        if (msg.balance === undefined || msg.confirmedBalance === undefined) {
                            this._turnPoolOff();
                            this._ws.close();
                        } else {
                            this._onBalance(msg.balance, msg.confirmedBalance, msg.payoutRequestActive);
                            Log.d(BasePoolMiner, `Received balance from pool: ${msg.balance} (${msg.confirmedBalance} confirmed), payout request active: ${msg.payoutRequestActive}`);
                        }
                        break;
                    case 'registered':
                        this._changeConnectionState(BasePoolMiner.ConnectionState.CONNECTED);
                        this._exponentialBackoffReconnect = BasePoolMiner.RECONNECT_TIMEOUT;
                        Log.i(BasePoolMiner, 'Connected to pool');
                        break;
                    case 'error':
                        Log.w(BasePoolMiner, 'Error from pool:', msg.reason);
                        break;
                }
            } else {
                Log.w(BasePoolMiner, 'Received unknown message from pool server:', JSON.stringify(msg));
                this._ws.close();
            }
        } catch (e) {
            this._onError(ws, e);
        }
    }

    /**
     * @param {number} balance
     * @param {number} confirmedBalance
     * @param {boolean} payoutRequestActive
     * @private
     */
    _onBalance(balance, confirmedBalance, payoutRequestActive) {
        const oldBalance = this.balance, oldConfirmedBalance = this.confirmedBalance;
        this.balance = balance;
        this.confirmedBalance = confirmedBalance;
        this.payoutRequestActive = payoutRequestActive;
        if (balance !== oldBalance || confirmedBalance !== oldConfirmedBalance) {
            Log.i(BasePoolMiner, `Pool balance: ${Policy.lunasToCoins(balance)} NIM (confirmed ${Policy.lunasToCoins(confirmedBalance)} NIM)`);
        }
        if (balance !== oldBalance) {
            this.fire('balance', balance);
        }
        if (confirmedBalance !== oldConfirmedBalance) {
            this.fire('confirmed-balance', confirmedBalance);
        }
    }

    _turnPoolOff() {
        this.startConfigChanges();
        super.address = this._ourAddress;
        super.extraData = this._ourExtraData;
        super.shareCompact = null;
        this.finishConfigChanges();
    }

    /**
     * @param {Address} address
     * @param {Uint8Array} extraData
     * @param {number} targetCompact
     * @param {number} nonce
     * @private
     */
    _onNewPoolSettings(address, extraData, targetCompact, nonce) {
        this.startConfigChanges();
        super.address = address;
        super.extraData = extraData;
        super.shareCompact = targetCompact;
        super.nonce = nonce;
        this.finishConfigChanges();
    }

    _changeConnectionState(connectionState) {
        this.connectionState = connectionState;
        this.fire('connection-state', connectionState);
    }

    /**
     * @returns {boolean}
     */
    isConnected() {
        return this.connectionState === BasePoolMiner.ConnectionState.CONNECTED;
    }

    /**
     * @returns {boolean}
     */
    isDisconnected() {
        return this.connectionState === BasePoolMiner.ConnectionState.CLOSED;
    }

    /**
     * @type {string}
     */
    get host() {
        return this._host;
    }

    /**
     * @type {number}
     */
    get port() {
        return this._port;
    }

    /**
     * @type {Address}
     * @override
     */
    get address() {
        return this._ourAddress;
    }

    /**
     * @type {Address}
     * @override
     */
    set address(address) {
        this._ourAddress = address;
        if (this.isConnected()) {
            this.disconnect();
            this.connect(this._host, this._port);
        } else {
            super.address = address;
        }
    }

    /**
     * @param {NetworkConfig} networkConfig
     * @returns {number}
     */
    static generateDeviceId(networkConfig) {
        return Hash.blake2b([
            BufferUtils.fromAscii('pool_device_id'),
            networkConfig.keyPair.privateKey.serialize()
        ].reduce(BufferUtils.concatTypedArrays)).serialize().readUint32();
    }
}

BasePoolMiner.PAYOUT_NONCE_PREFIX = 'POOL_PAYOUT';
BasePoolMiner.RECONNECT_TIMEOUT = 3000; // 3 seconds
BasePoolMiner.RECONNECT_TIMEOUT_MAX = 30000; // 30 seconds

/** @enum {number} */
BasePoolMiner.ConnectionState = {
    CONNECTED: 0,
    CONNECTING: 1,
    CLOSED: 2
};

/** @enum {string} */
BasePoolMiner.Mode = {
    NANO: 'nano',
    SMART: 'smart'
};

Class.register(BasePoolMiner);

/**
 * @deprecated
 */
class SmartPoolMiner extends BasePoolMiner {
    /**
     * @param {BaseChain} blockchain
     * @param {Accounts} accounts
     * @param {Mempool} mempool
     * @param {Time} time
     * @param {Address} address
     * @param {number} deviceId
     * @param {?object} deviceData
     * @param {Uint8Array} [extraData=new Uint8Array(0)]
     */
    constructor(blockchain, accounts, mempool, time, address, deviceId, deviceData, extraData = new Uint8Array(0)) {
        super(BasePoolMiner.Mode.SMART, blockchain, accounts, mempool, time, address, deviceId, deviceData, extraData);

        this.on('share', (block, fullValid) => this._onBlockMined(block, fullValid));
    }

    /**
     * @param {Block} block
     * @param {boolean} fullValid
     * @private
     */
    async _onBlockMined(block, fullValid) {
        this._send({
            message: 'share',
            blockHeader: BufferUtils.toBase64(block.header.serialize()),
            minerAddrProof: BufferUtils.toBase64((await MerklePath.compute(block.body.getMerkleLeafs(), block.minerAddr)).serialize()),
            extraDataProof: BufferUtils.toBase64((await MerklePath.compute(block.body.getMerkleLeafs(), block.body.extraData)).serialize()),
            block: fullValid ? BufferUtils.toBase64(block.serialize()) : undefined
        });
    }
}

Class.register(SmartPoolMiner);

/**
 * @deprecated
 */
class NanoPoolMiner extends BasePoolMiner {
    /**
     * @param {BaseChain} blockchain
     * @param {Time} time
     * @param {Address} address
     * @param {number} deviceId
     * @param {?object} deviceData
     */
    constructor(blockchain, time, address, deviceId, deviceData) {
        super(BasePoolMiner.Mode.NANO, blockchain, null, null, time, address, deviceId, deviceData);

        this.on('share', (block) => this._onBlockMined(block));
        this._shouldWork = false;
    }

    /**
     * @override
     */
    startWork() {
        this._shouldWork = true;
        super.startWork();
    }

    /**
     * @override
     */
    stopWork() {
        this._shouldWork = false;
        super.stopWork();
    }

    /**
     * @param {Block} block
     * @private
     */
    _onBlockMined(block) {
        this._send({
            message: 'share',
            block: BufferUtils.toBase64(block.serialize())
        });
    }

    _onMessage(ws, msgJson) {
        if (this._ws !== ws) return;
        try {
            const msg = JSON.parse(msgJson);
            if (msg && msg.message === 'new-block') {
                this._handleNewBlock(msg);
            } else {
                super._onMessage(ws, msgJson);
            }
        } catch (e) {
            this._onError(ws, e);
        }
    }

    async _handleNewBlock(msg) {
        /** @type {Block} */
        const previousBlock = Block.unserialize(BufferUtils.fromBase64(msg.previousBlock));
        Log.d(NanoPoolMiner, `New base block from pool server, on top of ${previousBlock.hash()}`);
        let knownBlock;
        if (this._blockchain.headHash.equals(previousBlock.hash())) {
            // We are on the same head, that's great.
            this._poolNextTarget = await this._blockchain.getNextTarget();
        } else if (this._blockchain.headHash.equals(previousBlock.prevHash)) {
            // We don't know the new block yet, make sure it's kinda valid.
            if (!(await previousBlock.isImmediateSuccessorOf(this._blockchain.head))) {
                Log.w(NanoPoolMiner, `${previousBlock.hash()} (from pool) is not an immediate successor of ${this._blockchain.headHash}, but is announced as such.`);
                super.stopWork();
                return;
            }
            this._poolNextTarget = await this._blockchain.getNextTarget(this._blockchain.head, previousBlock);
        } else if (this._blockchain.head.prevHash.equals(previousBlock.hash())) {
            // Pool does not know the new block yet, waiting for it.
            super.stopWork();
            return;
        } else if (this._blockchain.height === previousBlock.height && (knownBlock = await this._blockchain.getBlock(previousBlock.prevHash))) {
            // Pool is on a different fork of length 1 and we want to please our pool
            if (!(await previousBlock.isImmediateSuccessorOf(knownBlock))) {
                Log.w(NanoPoolMiner, `${previousBlock.hash()} (from pool) is not an immediate successor of ${knownBlock}, but is announced as such.`);
                super.stopWork();
                return;
            }
        } else if ((knownBlock = await this._blockchain.getBlock(previousBlock.prevHash, true))) {
            // Pool mines a fork
            Log.w(NanoPoolMiner, `${previousBlock.hash()} (from pool) is a known fork, we don't mine on forks.`);
            super.stopWork();
            return;
        } else {
            Log.w(NanoPoolMiner, `${previousBlock.hash()} (from pool) is unknown and not a successor of the head`);
            super.stopWork();
            return;
        }
        /** @type {BlockInterlink} */
        this._poolNextInterlink = await previousBlock.getNextInterlink(this._poolNextTarget);
        /** @type {Block} */
        this._poolPrevBlock = previousBlock;
        /** @type {Hash} */
        this._poolAccountsHash = Hash.unserialize(BufferUtils.fromBase64(msg.accountsHash));
        /** @type {Hash} */
        this._poolBodyHash = Hash.unserialize(BufferUtils.fromBase64(msg.bodyHash));

        // Start with a new block
        if (this.working) {
            this._startWork().catch(Log.w.tag(Miner));
        } else if (this._shouldWork) {
            super.startWork();
        }
    }

    getNextBlock() {
        if (!this._poolPrevBlock) {
            return null;
        }
        return new Block(
            new BlockHeader(
                this._poolPrevBlock.hash(),
                this._poolNextInterlink.hash(),
                this._poolBodyHash,
                this._poolAccountsHash,
                BlockUtils.targetToCompact(this._poolNextTarget),
                this._poolPrevBlock.height + 1,
                Math.max(this._producer._getNextTimestamp(), this._poolPrevBlock.timestamp + 1),
                0),
            this._poolNextInterlink);
    }

    _turnPoolOff() {
        this.stopWork();
        super._turnPoolOff();
    }
}

Class.register(NanoPoolMiner);

class Wallet {
    /**
     * Create a new Wallet.
     * @returns {Wallet} Newly created Wallet.
     */
    static generate() {
        return new Wallet(KeyPair.generate());
    }

    /**
     * @param {Uint8Array|string} buf
     * @return {Wallet}
     */
    static loadPlain(buf) {
        if (typeof buf === 'string') buf = BufferUtils.fromHex(buf);
        if (!buf || buf.byteLength === 0) {
            throw new Error('Invalid wallet seed');
        }
        return new Wallet(KeyPair.unserialize(new SerialBuffer(buf)));
    }

    /**
     * @param {Uint8Array|string} buf
     * @param {Uint8Array|string} key
     * @return {Promise.<Wallet>}
     */
    static async loadEncrypted(buf, key) {
        if (typeof buf === 'string') buf = BufferUtils.fromHex(buf);
        if (typeof key === 'string') key = BufferUtils.fromUtf8(key);
        return new Wallet(await KeyPair.fromEncrypted(new SerialBuffer(buf), key));
    }

    /**
     * Create a new Wallet object.
     * @param {KeyPair} keyPair KeyPair owning this Wallet.
     * @returns {Wallet} A newly generated Wallet.
     */
    constructor(keyPair) {
        /** @type {KeyPair} */
        this._keyPair = keyPair;
        /** @type {Address} */
        this._address = this._keyPair.publicKey.toAddress();
    }

    /**
     * Create a Transaction that is signed by the owner of this Wallet.
     * @param {Address} recipient Address of the transaction receiver
     * @param {number} value Number of Satoshis to send.
     * @param {number} fee Number of Satoshis to donate to the Miner.
     * @param {number} validityStartHeight The validityStartHeight for the transaction.
     * @returns {Transaction} A prepared and signed Transaction object. This still has to be sent to the network.
     */
    createTransaction(recipient, value, fee, validityStartHeight) {
        const transaction = new BasicTransaction(this._keyPair.publicKey, recipient, value, fee, validityStartHeight);
        transaction.signature = Signature.create(this._keyPair.privateKey, this._keyPair.publicKey, transaction.serializeContent());
        return transaction;
    }

    /**
     * Sign a transaction by the owner of this Wallet.
     * @param {Transaction} transaction The transaction to sign.
     * @returns {SignatureProof} A signature proof for this transaction.
     */
    signTransaction(transaction) {
        const signature = Signature.create(this._keyPair.privateKey, this._keyPair.publicKey, transaction.serializeContent());
        return SignatureProof.singleSig(this._keyPair.publicKey, signature);
    }

    /**
     * @returns {Uint8Array}
     */
    exportPlain() {
        return this._keyPair.serialize();
    }

    /**
     * @param {Uint8Array|string} key
     * @return {Promise.<SerialBuffer>}
     */
    exportEncrypted(key) {
        if (typeof key === 'string') key = BufferUtils.fromUtf8(key);
        return this._keyPair.exportEncrypted(key);
    }

    /** @type {boolean} */
    get isLocked() {
        return this.keyPair.isLocked;
    }

    /**
     * @param {Uint8Array|string} key
     * @returns {Promise.<void>}
     */
    lock(key) {
        if (typeof key === 'string') key = BufferUtils.fromUtf8(key);
        return this.keyPair.lock(key);
    }

    relock() {
        this.keyPair.relock();
    }

    /**
     * @param {Uint8Array|string} key
     * @returns {Promise.<void>}
     */
    unlock(key) {
        if (typeof key === 'string') key = BufferUtils.fromUtf8(key);
        return this.keyPair.unlock(key);
    }

    /**
     * @param {Wallet} o
     * @return {boolean}
     */
    equals(o) {
        return o instanceof Wallet && this.keyPair.equals(o.keyPair) && this.address.equals(o.address);
    }

    /**
     * The address of the Wallet owner.
     * @type {Address}
     */
    get address() {
        return this._address;
    }

    /**
     * The public key of the Wallet owner
     * @type {PublicKey}
     */
    get publicKey() {
        return this._keyPair.publicKey;
    }

    /** @type {KeyPair} */
    get keyPair() {
        return this._keyPair;
    }
}

Class.register(Wallet);

class MultiSigWallet extends Wallet {
    /**
     * Create a new MultiSigWallet object.
     * @param {KeyPair} keyPair KeyPair owning this Wallet.
     * @param {number} minSignatures Number of signatures required.
     * @param {Array.<PublicKey>} publicKeys A list of all owners' public keys.
     * @returns {MultiSigWallet} A newly generated MultiSigWallet.
     */
    static fromPublicKeys(keyPair, minSignatures, publicKeys) {
        if (publicKeys.length === 0) throw new Error('publicKeys may not be empty');
        if (minSignatures <= 0) throw new Error('minSignatures must be greater than 0');
        if (!publicKeys.some(key => key.equals(keyPair.publicKey))) throw new Error('Own publicKey must be part of publicKeys');

        // Sort public keys so that the order when signing and construction does not matter.
        publicKeys = publicKeys.slice();
        publicKeys.sort((a, b) => a.compare(b));
        const combinations = [...ArrayUtils.k_combinations(publicKeys, minSignatures)];
        const multiSigKeys = combinations.map(arr => PublicKey.sum(arr));
        return new MultiSigWallet(keyPair, minSignatures, multiSigKeys);
    }

    /**
     * @param {KeyPair} keyPair
     * @param {SerialBuffer} buf
     * @returns {MultiSigWallet}
     * @private
     */
    static _loadMultiSig(keyPair, buf) {
        const minSignatures = buf.readUint8();
        const numPublicKeys = buf.readUint8();
        const publicKeys = [];
        for (let i = 0; i < numPublicKeys; ++i) {
            publicKeys.push(PublicKey.unserialize(buf));
        }
        return new MultiSigWallet(keyPair, minSignatures, publicKeys);
    }

    /**
     * @param {Uint8Array|string} buf
     * @return {MultiSigWallet}
     */
    static loadPlain(buf) {
        if (typeof buf === 'string') buf = BufferUtils.fromHex(buf);
        if (!buf || buf.byteLength === 0) {
            throw new Error('Invalid wallet seed');
        }

        const serialBuf = new SerialBuffer(buf);
        const keyPair = KeyPair.unserialize(serialBuf);
        return MultiSigWallet._loadMultiSig(keyPair, serialBuf);
    }

    /**
     * @param {Uint8Array|string} buf
     * @param {Uint8Array|string} key
     * @return {Promise.<MultiSigWallet>}
     */
    static async loadEncrypted(buf, key) {
        if (typeof buf === 'string') buf = BufferUtils.fromHex(buf);
        if (typeof key === 'string') key = BufferUtils.fromUtf8(key);

        const serialBuf = new SerialBuffer(buf);
        const keyPair = await KeyPair.fromEncrypted(serialBuf, key);
        return MultiSigWallet._loadMultiSig(keyPair, serialBuf);
    }

    /**
     * Create a new MultiSigWallet object.
     * @param {KeyPair} keyPair KeyPair owning this Wallet.
     * @param {number} minSignatures Number of signatures required.
     * @param {Array.<PublicKey>} publicKeys A list of all aggregated public keys.
     * @returns {MultiSigWallet} A newly generated MultiSigWallet.
     */
    constructor(keyPair, minSignatures, publicKeys) {
        super(keyPair);
        /** @type {number} minSignatures */
        this._minSignatures = minSignatures;
        /** @type {Array.<PublicKey>} publicKeys */
        this._publicKeys = publicKeys;
        this._publicKeys.sort((a, b) => a.compare(b));

        const merkleRoot = MerkleTree.computeRoot(this._publicKeys);
        /** @type {Address} */
        this._address = Address.fromHash(merkleRoot);
    }

    /**
     * @override
     * @returns {Uint8Array}
     */
    exportPlain() {
        const buf = new SerialBuffer(this.exportedSize);
        this._keyPair.serialize(buf);
        buf.writeUint8(this._minSignatures);
        buf.writeUint8(this._publicKeys.length);
        for (const pubKey of this._publicKeys) {
            pubKey.serialize(buf);
        }
        return buf;
    }

    /** @type {number} */
    get exportedSize() {
        return this._keyPair.serializedSize
            + /*minSignatures*/ 1
            + /*count*/ 1
            + this._publicKeys.reduce((sum, pubKey) => sum + pubKey.serializedSize, 0);
    }

    /**
     * @override
     * @param {Uint8Array|string} key
     * @return {Promise.<SerialBuffer>}
     */
    async exportEncrypted(key) {
        if (typeof key === 'string') key = BufferUtils.fromUtf8(key);

        const buf = new SerialBuffer(this.encryptedSize);
        buf.write(await this._keyPair.exportEncrypted(key));
        buf.writeUint8(this._minSignatures);
        buf.writeUint8(this._publicKeys.length);
        for (const pubKey of this._publicKeys) {
            pubKey.serialize(buf);
        }

        return buf;
    }

    /** @type {number} */
    get encryptedSize() {
        return this._keyPair.encryptedSize
            + /*minSignatures*/ 1
            + /*count*/ 1
            + this._publicKeys.reduce((sum, pubKey) => sum + pubKey.serializedSize, 0);
    }

    /**
     * Create a Transaction that still needs to be signed.
     * @param {Address} recipientAddr Address of the transaction receiver
     * @param {number} value Number of Satoshis to send.
     * @param {number} fee Number of Satoshis to donate to the Miner.
     * @param {number} validityStartHeight The validityStartHeight for the transaction.
     * @returns {Transaction} A prepared Transaction object.
     * @override
     */
    createTransaction(recipientAddr, value, fee, validityStartHeight) {
        return new ExtendedTransaction(this._address, Account.Type.BASIC,
            recipientAddr, Account.Type.BASIC, value, fee, validityStartHeight,
            Transaction.Flag.NONE, new Uint8Array(0));
    }

    /**
     * Creates a commitment pair for signing a transaction.
     * @returns {CommitmentPair} The commitment pair.
     */
    createCommitment() {
        return CommitmentPair.generate();
    }

    /**
     * @param {Transaction} transaction
     * @param {Array.<PublicKey>} publicKeys
     * @param {Commitment} aggregatedCommitment
     * @param {RandomSecret} secret
     * @returns {PartialSignature}
     */
    partiallySignTransaction(transaction, publicKeys, aggregatedCommitment, secret) {
        // Sort public keys to get the right combined public key.
        publicKeys = publicKeys.slice();
        publicKeys.sort((a, b) => a.compare(b));

        return PartialSignature.create(this._keyPair.privateKey, this._keyPair.publicKey, publicKeys,
            secret, aggregatedCommitment, transaction.serializeContent());
    }

    /**
     * Sign a transaction by the owner of this Wallet.
     * @param {Transaction} transaction The transaction to sign.
     * @param {PublicKey} aggregatedPublicKey
     * @param {Commitment} aggregatedCommitment
     * @param {Array.<PartialSignature>} signatures
     * @returns {SignatureProof} A signature proof for this transaction.
     */
    signTransaction(transaction, aggregatedPublicKey, aggregatedCommitment, signatures) {
        if (signatures.length !== this._minSignatures) {
            throw new Error('Not enough signatures to complete this transaction');
        }

        const signature = Signature.fromPartialSignatures(aggregatedCommitment, signatures);
        return SignatureProof.multiSig(aggregatedPublicKey, this._publicKeys, signature);
    }

    /**
     * @param {Transaction} transaction
     * @param {PublicKey} aggregatedPublicKey
     * @param {Commitment} aggregatedCommitment
     * @param {Array.<PartialSignature>} signatures
     * @returns {Transaction}
     */
    completeTransaction(transaction, aggregatedPublicKey, aggregatedCommitment, signatures) {
        const proof = this.signTransaction(transaction, aggregatedPublicKey, aggregatedCommitment, signatures);
        transaction.proof = proof.serialize();
        return transaction;
    }

    /** @type {number} */
    get minSignatures() {
        return this._minSignatures;
    }

    /** @type {Array.<PublicKey>} */
    get publicKeys() {
        return this._publicKeys;
    }
}
Class.register(MultiSigWallet);

// TODO: Move outside of Nimiq Core library?
class WalletStore {
    /**
     * @returns {Promise.<WalletStore>}
     */
    constructor(dbName = 'wallet') {
        this._jdb = new JDB.JungleDB(dbName, WalletStore.VERSION, {
            maxDbSize: WalletStore.INITIAL_DB_SIZE,
            autoResize: true,
            minResize: WalletStore.MIN_RESIZE
        });
        /** @type {ObjectStore} */
        this._walletStore = null;
        /** @type {ObjectStore} */
        this._multiSigStore = null;

        return this._init();
    }

    /**
     * @returns {Promise.<WalletStore>}
     */
    async _init() {
        // Initialize object stores.
        this._walletStore = this._jdb.createObjectStore(WalletStore.WALLET_DATABASE, { codec: new WalletStoreCodec() });
        this._multiSigStore = this._jdb.createObjectStore(WalletStore.MULTISIG_WALLET_DATABASE, { codec: new WalletStoreCodec() });

        // Establish connection to database.
        await this._jdb.connect();

        return this;
    }

    /**
     * @returns {Promise.<boolean>}
     */
    async hasDefault() {
        const defaultAddress = await this._walletStore.get('default');
        return !!defaultAddress;
    }

    /**
     * @param {Uint8Array|string} [key]
     * @returns {Promise.<Wallet>}
     */
    async getDefault(key) {
        const defaultAddress = await this._walletStore.get('default');
        if (!defaultAddress) {
            const defaultWallet = Wallet.generate();
            await this.put(defaultWallet);
            await this.setDefault(defaultWallet.address);
            return defaultWallet;
        }
        const base64Address = new Address(defaultAddress);
        return this.get(base64Address, key);
    }

    /**
     * @param {Address} address
     * @returns {Promise}
     */
    setDefault(address) {
        const defaultAddress = address.serialize();
        return this._walletStore.put('default', defaultAddress);
    }

    /**
     * @param {Address} address
     * @param {Uint8Array|string} [key]
     * @returns {Promise.<?Wallet>}
     */
    async get(address, key) {
        const base64Address = address.toBase64();
        const buf = await this._walletStore.get(base64Address);
        if (!buf) return null;
        if (key) {
            return Wallet.loadEncrypted(buf, key);
        }
        try {
            return Wallet.loadPlain(buf);
        } catch (e) {
            return null;
        }
    }

    /**
     * @param {Wallet} wallet
     * @param {Uint8Array|string} [key]
     * @param {Uint8Array|string} [unlockKey]
     * @returns {Promise}
     */
    async put(wallet, key, unlockKey) {
        const base64Address = wallet.address.toBase64();
        /** @type {Uint8Array} */
        let buf = null;
        if (key) {
            buf = await wallet.exportEncrypted(key, unlockKey);
        } else {
            buf = wallet.exportPlain();
        }
        return this._walletStore.put(base64Address, buf);
    }

    /**
     * @param {Address} address
     * @returns {Promise}
     */
    async remove(address) {
        const base64Address = address.toBase64();
        const tx = this._walletStore.transaction();
        tx.removeSync(base64Address);
        // Remove default address as well if they coincide.
        let defaultAddress = await this._walletStore.get('default');
        if (defaultAddress) {
            defaultAddress = new Address(defaultAddress);
            if (address.equals(defaultAddress)) {
                tx.removeSync('default');
            }
        }
        return tx.commit();
    }

    /**
     * @returns {Promise<Array.<Address>>}
     */
    async list() {
        const keys = await this._walletStore.keys();
        return Array.from(keys).filter(key => key !== 'default').map(key => Address.fromBase64(key));
    }

    /**
     * @param {Address} address
     * @param {Uint8Array|string} [key]
     * @returns {Promise.<?MultiSigWallet>}
     */
    async getMultiSig(address, key) {
        const base64Address = address.toBase64();
        const buf = await this._multiSigStore.get(base64Address);
        if (!buf) return null;
        if (key) {
            return MultiSigWallet.loadEncrypted(buf, key);
        }
        return MultiSigWallet.loadPlain(buf);
    }

    /**
     * @param {MultiSigWallet} wallet
     * @param {Uint8Array|string} [key]
     * @param {Uint8Array|string} [unlockKey]
     * @returns {Promise}
     */
    async putMultiSig(wallet, key, unlockKey) {
        const base64Address = wallet.address.toBase64();
        /** @type {Uint8Array} */
        let buf = null;
        if (key) {
            buf = await wallet.exportEncrypted(key, unlockKey);
        } else {
            buf = wallet.exportPlain();
        }
        return this._multiSigStore.put(base64Address, buf);
    }

    /**
     * @param {Address} address
     * @returns {Promise}
     */
    removeMultiSig(address) {
        const base64Address = address.toBase64();
        return this._multiSigStore.remove(base64Address);
    }

    /**
     * @returns {Promise<Array.<Address>>}
     */
    async listMultiSig() {
        const keys = await this._multiSigStore.keys();
        return Array.from(keys).map(key => Address.fromBase64(key));
    }

    close() {
        return this._jdb.close();
    }
}
Class.register(WalletStore);
WalletStore._instance = null;
WalletStore.VERSION = 1;
WalletStore.INITIAL_DB_SIZE = 1024*1024*10; // 10 MB initially
WalletStore.MIN_RESIZE = 1024*1024*10; // 10 MB
WalletStore.WALLET_DATABASE = 'wallets';
WalletStore.MULTISIG_WALLET_DATABASE = 'multisig-wallets';

/**
 * @implements {ICodec}
 */
class WalletStoreCodec {
    /**
     * @param {*} obj The object to encode before storing it.
     * @returns {*} Encoded object.
     */
    encode(obj) {
        return obj;
    }

    /**
     * @param {*} buf The object to decode.
     * @param {string} key The object's primary key.
     * @returns {*} Decoded object.
     */
    decode(buf, key) {
        return new Uint8Array(buf);
    }

    /**
     * @type {string}
     */
    get leveldbValueEncoding() {
        return 'binary';
    }

    /**
     * @type {object}
     */
    get lmdbValueEncoding() {
        return JDB.JungleDB.BINARY_ENCODING;
    }
}

/**
 * @interface
 * @deprecated
 */
class MinerWorker {
    /**
     * @param blockHeader
     * @param compact
     * @param minNonce
     * @param maxNonce
     * @returns {Promise.<{hash: Uint8Array, nonce: number}|boolean>}
     */
    async multiMine(blockHeader, compact, minNonce, maxNonce) {}
}
Class.register(MinerWorker);

/**
 * @deprecated
 */
class MinerWorkerImpl extends IWorker.Stub(MinerWorker) {
    constructor() {
        super();
        // FIXME: This is needed for Babel to work correctly. Can be removed as soon as we updated to Babel v7.
        this._superInit = super.init;
    }

    async init(name) {
        await this._superInit.call(this, name);
        if (PlatformUtils.isBrowser()) await WasmHelper.doImportBrowser();
    }

    async multiMine(input, compact, minNonce, maxNonce) {
        const hash = new Uint8Array(32);
        let wasmOut, wasmIn;
        try {
            wasmOut = Module._malloc(hash.length);
            wasmIn = Module._malloc(input.length);
            Module.HEAPU8.set(input, wasmIn);
            const nonce = Module._nimiq_argon2_target(wasmOut, wasmIn, input.length, compact, minNonce, maxNonce, 512);
            if (nonce === maxNonce) return false;
            hash.set(new Uint8Array(Module.HEAPU8.buffer, wasmOut, hash.length));
            return {hash, nonce};
        } catch (e) {
            Log.w(MinerWorkerImpl, e);
            throw e;
        } finally {
            if (wasmOut !== undefined) Module._free(wasmOut);
            if (wasmIn !== undefined) Module._free(wasmIn);
        }
    }
}

IWorker.prepareForWorkerUse(MinerWorker, new MinerWorkerImpl());

/**
 * @deprecated
 */
class MinerWorkerPool extends IWorker.Pool(MinerWorker) {
    constructor(size = 1) {
        super((name) => IWorker.startWorkerForProxy(MinerWorker, name), 'miner', size);
        /** @type {boolean} */
        this._miningEnabled = false;
        /** @type {Array.<{minNonce: number, maxNonce: number}>} */
        this._activeNonces = [];
        /** @type {Block} */
        this._block = null;
        /** @type {number} */
        this._noncesPerRun = 256;
        /** @type {Observable} */
        this._observable = new Observable();
        /** @type {number} */
        this._shareCompact = Policy.BLOCK_TARGET_MAX;
        /** @type {number} */
        this._runsPerCycle = Infinity;
        /** @type {number} */
        this._cycleWait = 100;

        // FIXME: This is needed for Babel to work correctly. Can be removed as soon as we updated to Babel v7.
        this._superUpdateToSize = super._updateToSize;

        if (PlatformUtils.isNodeJs()) {
            Log.i(MinerWorkerPool, `Using add-on optimized for instruction set: ${cpuSupport}`);

            /**
             * @param {SerialBuffer} blockHeader
             * @param {number} compact
             * @param {number} minNonce
             * @param {number} maxNonce
             * @returns {Promise.<{hash: Uint8Array, nonce: number}|boolean>}
             */
            this.multiMine = function (blockHeader, compact, minNonce, maxNonce) {
                return new Promise((resolve, fail) => {
                    NodeNative.node_argon2_target_async(async (nonce) => {
                        try {
                            if (nonce === maxNonce) {
                                resolve(false);
                            } else {
                                blockHeader.writePos -= 4;
                                blockHeader.writeUint32(nonce);
                                const hash = await (await CryptoWorker.getInstanceAsync()).computeArgon2d(blockHeader);
                                resolve({hash, nonce});
                            }
                        } catch (e) {
                            fail(e);
                        }
                    }, blockHeader, compact, minNonce, maxNonce, 512);
                });
            };
        }
    }

    /**
     * @type {number}
     */
    get noncesPerRun() {
        return this._noncesPerRun;
    }

    /**
     * @param {number} nonces
     */
    set noncesPerRun(nonces) {
        this._noncesPerRun = nonces;
    }

    /**
     * @type {number}
     */
    get runsPerCycle() {
        return this._runsPerCycle;
    }

    /**
     * @param {number} runsPerCycle
     */
    set runsPerCycle(runsPerCycle) {
        this._runsPerCycle = runsPerCycle;
    }

    /**
     * @type {number}
     */
    get cycleWait() {
        return this._cycleWait;
    }

    /**
     * @param {number} cycleWait
     */
    set cycleWait(cycleWait) {
        this._cycleWait = cycleWait;
    }

    /**
     * @param {string} type
     * @param {Function} callback
     * @return {number}
     */
    on(type, callback) { return this._observable.on(type, callback); }

    /**
     * @param {string} type
     * @param {number} id
     */
    off(type, id) { this._observable.off(type, id); }

    /**
     * @param {Block} block
     * @param {number} [shareCompact] target of a share, in compact format.
     */
    async startMiningOnBlock(block, shareCompact) {
        this._block = block;
        this._shareCompact = shareCompact || block.nBits;
        if (!this._miningEnabled) {
            await this._updateToSize();
            this._activeNonces = [];
            this._miningEnabled = true;
            for (let i = 0; i < this.poolSize; ++i) {
                this._startMiner();
            }
        } else {
            this._activeNonces = [{minNonce:0, maxNonce:0}];
        }
    }

    stop() {
        this._miningEnabled = false;
    }

    async _updateToSize() {
        if (!PlatformUtils.isNodeJs()) {
            await this._superUpdateToSize.call(this);
        }

        while (this._miningEnabled && this._activeNonces.length < this.poolSize) {
            this._startMiner();
        }
    }

    _startMiner() {
        if (this._activeNonces.length >= this.poolSize) {
            return;
        }

        const minNonce = this._activeNonces.length === 0 ? 0 : Math.max.apply(null, this._activeNonces.map((a) => a.maxNonce));
        const maxNonce = minNonce + this._noncesPerRun;
        const nonceRange = {minNonce, maxNonce};
        this._activeNonces.push(nonceRange);
        this._singleMiner(nonceRange).catch((e) => Log.e(MinerWorkerPool, e));
    }

    /**
     * @param {{minNonce: number, maxNonce: number}} nonceRange
     * @return {Promise.<void>}
     * @private
     */
    async _singleMiner(nonceRange) {
        let i = 0;
        while (this._miningEnabled && (IWorker.areWorkersAsync || PlatformUtils.isNodeJs() || i === 0) && i < this._runsPerCycle) {
            i++;
            const block = this._block;
            const result = await this.multiMine(block.header.serialize(), this._shareCompact, nonceRange.minNonce, nonceRange.maxNonce);
            if (result) {
                const hash = new Hash(result.hash);
                this._observable.fire('share', {
                    block,
                    nonce: result.nonce,
                    hash
                });
            } else {
                this._observable.fire('no-share', {
                    nonce: nonceRange.maxNonce
                });
            }
            if (this._activeNonces.length > this.poolSize) {
                this._activeNonces.splice(this._activeNonces.indexOf(nonceRange), 1);
                return;
            } else {
                const newMin = Math.max.apply(null, this._activeNonces.map((a) => a.maxNonce));
                const newRange = {minNonce: newMin, maxNonce: newMin + this._noncesPerRun};
                this._activeNonces.splice(this._activeNonces.indexOf(nonceRange), 1, newRange);
                nonceRange = newRange;
            }
        }
        if (this._miningEnabled) {
            setTimeout(() => this._singleMiner(nonceRange), this._cycleWait);
        }
    }
}

Class.register(MinerWorkerPool);

/** @typedef {number} Handle */
/** @typedef {function(blockHash: Hash):?Promise} BlockListener */
/** @typedef {function(consensusState: Client.ConsensusState):?Promise} ConsensusChangedListener */
/** @typedef {function(blockHash: Hash, reason: string, revertedBlocks: Array.<Hash>, adoptedBlocks: Array.<Hash>):?Promise} HeadChangedListener */
/** @typedef {function(transaction: Client.TransactionDetails):?Promise} TransactionListener */

/** @class Client */
class Client {
    /**
     * @param {Client.Configuration|object} config
     * @param {Promise.<BaseConsensus>} [consensus]
     */
    constructor(config, consensus) {
        /**
         * @package
         * @type {Promise.<BaseConsensus>}
         */
        this._consensus = consensus || config.createConsensus();
        /** @type {Array.<{type: string, id: number}>} */
        this._consensusListenerIds = [];
        /** @type {Synchronizer} */
        this._consensusSynchronizer = new Synchronizer();
        /** @type {HashSet.<Address>} */
        this._subscribedAddresses = new HashSet();

        /** @type {Client.Configuration|object} */
        this._config = config;

        /** @type {HashMap.<Handle, ConsensusChangedListener>} */
        this._consensusChangedListeners = new HashMap();
        /** @type {HashMap.<Handle, BlockListener>} */
        this._blockListeners = new HashMap();
        /** @type {HashMap.<Handle, HeadChangedListener>} */
        this._headChangedListeners = new HashMap();
        /** @type {HashMap.<Handle, {listener: TransactionListener, addresses: HashSet.<Address>}>} */
        this._transactionListeners = new HashMap();
        /** @type {Handle} */
        this._listenerId = 0;

        /** @type {Client.ConsensusState} */
        this._consensusState = Client.ConsensusState.CONNECTING;
        /** @type {Hash} */
        this._headHash = null;
        /** @type {HashMap.<number, HashSet.<TransactionDetails>>} */
        this._transactionConfirmWaiting = new HashMap();
        /** @type {HashMap.<number, HashSet.<TransactionDetails>>} */
        this._transactionExpireWaiting = new HashMap();
        /** @type {Synchronizer} */
        this._transactionSynchronizer = new Synchronizer();

        this._network = new Client.Network(this);
        this._mempool = new Client.Mempool(this);

        this._consensusSynchronizer
            .push(() => this._setupConsensus().catch(Log.w.tag(Client)))
            .catch(Log.w.tag(Client));
    }

    /**
     * Must be invoked in synchronizer
     * @private
     */
    async _setupConsensus() {
        const consensus = await this._consensus;
        this._consensusOn(consensus, 'block', (blockHash) => this._onBlock(blockHash));
        this._consensusOn(consensus, 'established', () => this._onConsensusChanged(Client.ConsensusState.ESTABLISHED));
        this._consensusOn(consensus, 'waiting', () => this._onConsensusChanged(Client.ConsensusState.CONNECTING));
        this._consensusOn(consensus, 'syncing', () => this._onConsensusChanged(Client.ConsensusState.SYNCING));
        this._consensusOn(consensus, 'head-changed', (blockHash, reason, revertedBlocks, adoptedBlocks) => this._onHeadChanged(blockHash, reason, revertedBlocks, adoptedBlocks));
        this._consensusOn(consensus, 'transaction-added', (tx) => this._onPendingTransaction(tx));
        this._consensusOn(consensus, 'transaction-added', (tx) => this._mempool._onTransactionAdded(tx));
        this._consensusOn(consensus, 'transaction-removed', (tx) => this._mempool._onTransactionRemoved(tx));
        this._consensusOn(consensus, 'transaction-mined', (tx, block, blockNow) => this._onMinedTransaction(block, tx, blockNow));
        this._consensusOn(consensus, 'consensus-failed', () => this._onConsensusFailed());

        this._onConsensusChanged(consensus.established ? Client.ConsensusState.ESTABLISHED : Client.ConsensusState.CONNECTING);

        if (this._config.hasFeature(Client.Feature.PASSIVE)) {
            consensus.network.allowInboundConnections = true;
        } else {
            consensus.network.connect();
        }
    }

    /**
     *
     * @param {BaseConsensus} consensus
     * @param {string} type
     * @param {function} fn
     * @private
     */
    _consensusOn(consensus, type, fn) {
        this._consensusListenerIds.push({type, id: consensus.on(type, fn)});
    }

    /**
     * Must be invoked in synchronizer
     * @param {Promise.<BaseConsensus>} newConsensus
     * @private
     */
    async _replaceConsensus(newConsensus) {
        const oldConsensus = await this._consensus;

        for (const {type, id} of this._consensusListenerIds) {
            oldConsensus.off(type, id);
        }
        this._consensusListenerIds = [];

        this._consensus = newConsensus;
        const consensus = await this._consensus;
        oldConsensus.handoverTo(consensus);
        return this._setupConsensus();
    }

    /**
     * @param {Transaction|Client.TransactionDetails} tx
     * @private
     */
    _txExpiresAt(tx) {
        return tx.validityStartHeight + Policy.TRANSACTION_VALIDITY_WINDOW + this._config.requiredBlockConfirmations - 1;
    }

    /**
     * @param {Transaction} tx
     * @private
     */
    _txWaitForExpire(tx) {
        const set = this._transactionExpireWaiting.get(this._txExpiresAt(tx)) || new HashSet();
        set.add(tx);
        this._transactionExpireWaiting.put(this._txExpiresAt(tx), set);
    }

    /**
     * @param {Transaction} tx
     * @private
     */
    _txClearFromExpire(tx) {
        if (this._transactionExpireWaiting.contains(this._txExpiresAt(tx))) {
            const set = this._transactionExpireWaiting.get(this._txExpiresAt(tx));
            set.remove(tx);
            if (set.length === 0) this._transactionExpireWaiting.remove(this._txExpiresAt(tx));
        }
    }

    /**
     * @param {number} blockHeight
     * @returns {number}
     * @private
     */
    _txConfirmsAt(blockHeight) {
        return blockHeight + this._config.requiredBlockConfirmations - 1;
    }

    /**
     * @param {Transaction} tx
     * @param {number} blockHeight
     * @private
     */
    _txWaitForConfirm(tx, blockHeight) {
        const set = this._transactionConfirmWaiting.get(this._txConfirmsAt(blockHeight)) || new HashSet();
        set.add(tx);
        this._transactionConfirmWaiting.put(this._txConfirmsAt(blockHeight), set);
    }

    /**
     * @param {Transaction} tx
     * @private
     */
    _txClearFromConfirm(tx) {
        for (const [key, value] of this._transactionConfirmWaiting.entryIterator()) {
            if (value.contains(tx)) {
                value.remove(tx);
                if (value.length === 0) {
                    this._transactionConfirmWaiting.remove(key);
                    break;
                }
            }
        }
    }

    /**
     * @param {Hash} blockHash
     * @private
     */
    _onBlock(blockHash) {
        for (const listener of this._blockListeners.values()) {
            listener(blockHash);
        }
    }

    /**
     * @param {Client.ConsensusState} state
     * @private
     */
    _onConsensusChanged(state) {
        this._consensusSynchronizer.push(async () => {
            const consensus = await this._consensus;
            if (state === this._consensusState) return;

            if (consensus.established) {
                const oldSubscription = consensus.getSubscription();
                if (oldSubscription.type === Subscription.Type.ADDRESSES) {
                    consensus.subscribe(Subscription.fromAddresses(this._subscribedAddresses.values()));
                }
            }

            this._consensusState = state;
            for (const listener of this._consensusChangedListeners.values()) {
                try {
                    await listener(state);
                } catch (e) {
                    Log.e(Client, `Error in listener: ${e}`);
                }
            }

            if (consensus.established) {
                const headHash = await consensus.getHeadHash();
                if (headHash.equals(this._headHash)) return;
                this._headHash = headHash;

                for (const listener of this._headChangedListeners.values()) {
                    try {
                        await listener(headHash, 'established', [], [headHash]);
                    } catch (e) {
                        Log.e(Client, `Error in listener: ${e}`);
                    }
                }
            }
        }).catch(Log.e.tag(Client));
    }

    _onConsensusFailed() {
        this._consensusSynchronizer.push(async () => {
            const consensus = await this._consensus;
            if (consensus instanceof PicoConsensus) {
                // Upgrade pico consensus to nano consensus
                Log.w(Client, 'Pico consensus failed, automatically upgrading to nano consensus');
                const newConsensus = new NanoConsensus(await new NanoChain(consensus.network.time), consensus.mempool, consensus.network);
                await this._replaceConsensus(Promise.resolve(newConsensus));
            }
        }).catch(Log.e.tag(Client));
    }

    /**
     * @param {Hash} blockHash
     * @param {string} reason
     * @param {Array.<Block>} revertedBlocks
     * @param {Array.<Block>} adoptedBlocks
     * @private
     */
    async _onHeadChanged(blockHash, reason, revertedBlocks, adoptedBlocks) {
        this._consensusSynchronizer.push(async () => {
            // Process head-changed listeners.
            if (this._consensusState === Client.ConsensusState.ESTABLISHED && !blockHash.equals(this._headHash)) {
                this._headHash = blockHash;

                for (const listener of this._headChangedListeners.values()) {
                    try {
                        await listener(blockHash, reason, revertedBlocks.map(b => b.hash()), adoptedBlocks.map(b => b.hash()));
                    } catch (e) {
                        Log.e(Client, `Error in listener: ${e}`);
                    }
                }
            }

            // Process transaction listeners.
            if (this._transactionListeners.length > 0) {
                const revertedTxs = new HashSet();
                const adoptedTxs = new HashSet(a => a.tx instanceof Transaction ? a.tx.hash().hashCode() : a.hash().hashCode());

                // Gather reverted transactions
                for (const block of revertedBlocks) {
                    if (block.isFull()) {
                        revertedTxs.addAll(block.transactions);
                    }
                    const set = this._transactionConfirmWaiting.get(this._txConfirmsAt(block.height));
                    if (set) {
                        for (const tx of set.valueIterator()) {
                            revertedTxs.add(tx);
                        }
                        this._transactionConfirmWaiting.remove(this._txConfirmsAt(block.height));
                    }
                }

                // Gather applied transactions
                // Only for full blocks, nano/pico nodes will fire transaction mined events later independently
                for (const block of adoptedBlocks) {
                    if (block.isFull()) {
                        for (const tx of block.transactions) {
                            if (revertedTxs.contains(tx)) {
                                revertedTxs.remove(tx);
                            }
                            adoptedTxs.add({tx, block});
                        }
                    }
                }

                // Report all reverted transactions that weren't applied again as pending
                for (const tx of revertedTxs.valueIterator()) {
                    this._onPendingTransaction(tx, adoptedBlocks[adoptedBlocks.length - 1]);
                }

                // Report confirmed transactions
                for (const block of adoptedBlocks) {
                    const set = this._transactionConfirmWaiting.get(block.height);
                    if (set) {
                        for (const tx of set.valueIterator()) {
                            this._onConfirmedTransaction(block, tx, adoptedBlocks[adoptedBlocks.length - 1]);
                        }
                        this._transactionConfirmWaiting.remove(block.height);
                    }
                }

                // Report newly applied transactions
                for (const {tx, block} of adoptedTxs.valueIterator()) {
                    this._onMinedTransaction(block, tx, adoptedBlocks[adoptedBlocks.length - 1]);
                }

                // Report expired transactions
                for (const block of adoptedBlocks) {
                    const set = this._transactionExpireWaiting.get(block.height);
                    if (set) {
                        for (const tx of set.valueIterator()) {
                            this._onExpiredTransaction(block, tx);
                        }
                        this._transactionExpireWaiting.remove(block.height);
                    }
                }
            }
        }).catch(Log.e.tag(Client));
    }

    /**
     * @param {Transaction} tx
     * @param {Block} [blockNow]
     * @private
     */
    _onPendingTransaction(tx, blockNow) {
        let details;
        let fs = [];
        for (const {listener, addresses} of this._transactionListeners.values()) {
            if (addresses.contains(tx.sender) || addresses.contains(tx.recipient)) {
                if (blockNow && blockNow.height >= this._txExpiresAt(tx)) {
                    details = details || new Client.TransactionDetails(tx, Client.TransactionState.EXPIRED);
                } else {
                    details = details || new Client.TransactionDetails(tx, Client.TransactionState.PENDING);
                }
                fs.push(async () => {
                    try {
                        await listener(details);
                    } catch (e) {
                        Log.e(Client, `Error in listener: ${e}`);
                    }
                });
            }
        }
        this._txClearFromConfirm(tx);
        if (details && details.state === Client.TransactionState.PENDING) {
            this._txWaitForExpire(tx);
        }
        if (fs.length > 0) {
            this._transactionSynchronizer.push(() => fs.forEach(f => f())).catch(Log.e.tag(Client));
        }
    }

    /**
     * @param {Block} block
     * @param {Transaction} tx
     * @param {Block} [blockNow]
     * @private
     */
    _onMinedTransaction(block, tx, blockNow) {
        let details;
        let fs = [];
        for (const {listener, addresses} of this._transactionListeners.values()) {
            if (addresses.contains(tx.sender) || addresses.contains(tx.recipient)) {
                let state = Client.TransactionState.MINED, confirmations = 1;
                if (blockNow) {
                    confirmations = (blockNow.height - block.height) + 1;
                    state = confirmations >= this._config.requiredBlockConfirmations ? Client.TransactionState.CONFIRMED : Client.TransactionState.MINED;
                }
                details = details || new Client.TransactionDetails(tx, state, block.hash(), block.height, confirmations, block.timestamp);
                fs.push(async () => {
                    try {
                        await listener(details);
                    } catch (e) {
                        Log.e(Client, `Error in listener: ${e}`);
                    }
                });
            }
        }
        this._txClearFromExpire(tx);
        if (details && details.state === Client.TransactionState.MINED) {
            this._txWaitForConfirm(tx, block.height);
        }
        if (fs.length > 0) {
            this._transactionSynchronizer.push(() => fs.forEach(f => f())).catch(Log.e.tag(Client));
        }
    }

    /**
     * @param {Block} block
     * @param {Transaction} tx
     * @param {Block} blockNow
     * @private
     */
    _onConfirmedTransaction(block, tx, blockNow) {
        let details;
        let fs = [];
        for (const {listener, addresses} of this._transactionListeners.values()) {
            if (addresses.contains(tx.sender) || addresses.contains(tx.recipient)) {
                details = details || new Client.TransactionDetails(tx, Client.TransactionState.CONFIRMED, block.hash(), block.height, (blockNow.height - block.height) + 1, block.timestamp);
                fs.push(async () => {
                    try {
                        await listener(details);
                    } catch (e) {
                        Log.e(Client, `Error in listener: ${e}`);
                    }
                });
            }
        }
        if (fs.length > 0) {
            this._transactionSynchronizer.push(() => fs.forEach(f => f())).catch(Log.e.tag(Client));
        }
    }

    /**
     * @param {Block} block
     * @param {Transaction} tx
     * @private
     */
    _onExpiredTransaction(block, tx) {
        let details;
        let fs = [];
        for (const {listener, addresses} of this._transactionListeners.values()) {
            if (addresses.contains(tx.sender) || addresses.contains(tx.recipient)) {
                details = details || new Client.TransactionDetails(tx, Client.TransactionState.EXPIRED);
                fs.push(async () => {
                    try {
                        await listener(details);
                    } catch (e) {
                        Log.e(Client, `Error in listener: ${e}`);
                    }
                });
            }
        }
        if (fs.length > 0) {
            this._transactionSynchronizer.push(() => fs.forEach(f => f())).catch(Log.e.tag(Client));
        }
    }

    /**
     * Fetches the hash of the current tip of the chain.
     *
     * Data returned by this method authenticated according to the current tip of the blockchain. Any further changes to
     * as well as forks of the blockchain might invalidate the data.
     * @returns {Promise.<Hash>} Hash of the current tip of the chain
     */
    async getHeadHash() {
        const consensus = await this._consensus;
        return consensus.getHeadHash();
    }

    /**
     * Fetches the height or block number of the current tip of the chain.
     *
     * Data returned by this method authenticated according to the current tip of the blockchain. Any further changes to
     * as well as forks of the blockchain might invalidate the data.
     *
     * @returns {Promise.<number>} The height or block number of the current tip of the chain.
     */
    async getHeadHeight() {
        const consensus = await this._consensus;
        return consensus.getHeadHeight();
    }

    /**
     * Fetches the block that is the current tip of the chain.
     *
     * Data returned by this method authenticated according to the current tip of the blockchain. Any further changes to
     * as well as forks of the blockchain might invalidate the data.
     *
     * @param {boolean} [includeBody = true] Whether to include the transactions and other details of the block. If the
     *                                       client is not able to do so, it will return a block without such data.
     * @returns {Promise.<Block>} The block that is the current tip of the chain
     */
    async getHeadBlock(includeBody = true) {
        const consensus = await this._consensus;
        const hash = await consensus.getHeadHash();
        return consensus.getBlock(hash, includeBody);
    }

    /**
     * Fetches the block with the specified hash. Depending on your client configuration, this might include blocks
     * that do not exist on the current chain but are present on forks.
     *
     * @param {Hash|string} hash The hash of a block
     * @param {boolean} [includeBody = true] Whether to include the transactions and other details of the block. If the
     *                                       client is not able to do so, it will return a block without such data.
     * @returns {Promise.<Block>} The block with the specified hash. Throws an error if the block cannot be retrieved or
     *                            no block with the specified hash exists.
     */
    async getBlock(hash, includeBody = true) {
        hash = Hash.fromAny(hash);

        const consensus = await this._consensus;
        return consensus.getBlock(hash, includeBody);
    }

    /**
     * Fetches the block at the specified height or block number.
     *
     * Data returned by this method authenticated according to the current tip of the blockchain. Any further forks of
     * the blockchain might invalidate the data.
     *
     * @param {number} height The height or block number of the block to fetch
     * @param {boolean} [includeBody = true] Whether to include the transactions and other details of the block. If the
     *                                       client is not able to do so, it will return a block without such data.
     * @returns {Promise.<Block>} The block at the specified height or block number. Throws an error if the block cannot
     *                            be retrieved or no block at the specified height exists.
     */
    async getBlockAt(height, includeBody) {
        const consensus = await this._consensus;
        return consensus.getBlockAt(height, includeBody);
    }

    /**
     * Creates a template for the next block to be generated. This can be used to mine further blocks on top of the
     * current chain.
     *
     * Note that this functionality might not be available depending on your client configuration.
     *
     * @param {Address|string} minerAddress Address that will be rewarded for mining the block.
     * @param {Uint8Array|string} [extraData] Optional extra data to be embedded in the block.
     * @returns {Promise.<Block>} Template for the next block to be generated
     */
    async getBlockTemplate(minerAddress, extraData) {
        this._config.requireFeatures(Client.Feature.MINING, Client.Feature.MEMPOOL);
        minerAddress = Address.fromAny(minerAddress);

        if (typeof extraData === 'string') {
            extraData = BufferUtils.fromHex(extraData);
        } else if (extraData && !(extraData instanceof Uint8Array)) {
            throw new Error('Invalid extra data');
        }

        const consensus = await this._consensus;
        return consensus.getBlockTemplate(minerAddress, extraData);
    }

    /**
     * Submits a block to the blockchain.
     *
     * Note that this functionality might not be available depending on your client configuration.
     *
     * @param {Block|string} block The block to append to the blockchain.
     * @returns {Promise.<boolean>}
     */
    async submitBlock(block) {
        this._config.requireFeatures(Client.Feature.MINING);
        block = Block.fromAny(block);

        const consensus = await this._consensus;
        return consensus.submitBlock(block);
    }

    /**
     * Fetches a single account and its associated data by its address.
     *
     * Data returned by this method authenticated according to the current tip of the blockchain. Any further changes to
     * as well as forks of the blockchain might invalidate the data. To ensure up-to-date information, subscribe to head
     * changes (via {@link #addHeadChangedListener}) and refetch the account details.
     *
     * @param {Address|string} address Address of an account
     * @returns {Promise.<Account>} Single account and its associated data
     */
    async getAccount(address) {
        return (await this.getAccounts([address]))[0];
    }

    /**
     * Fetches multiple accounts and their associated data by their addresses.
     *
     * Data returned by this method authenticated according to the current tip of the blockchain. Any further changes to
     * as well as forks of the blockchain might invalidate the data. To ensure up-to-date information, subscribe to head
     * changes (via {@link #addHeadChangedListener}) and refetch the account details.
     *
     * @param {Array.<Address|string>} addresses List of addresses of accounts
     * @returns {Promise.<Array.<Account>>} List of accounts and their associated data
     */
    async getAccounts(addresses) {
        addresses = addresses.map(a => Address.fromAny(a));

        const consensus = await this._consensus;
        return consensus.getAccounts(addresses);
    }

    /**
     * Fetches a single transaction by its transaction hash. This method can be used to fetch transactions that
     * have been mined as well as pending transactions.
     *
     * If you happen to know the hash and height of the block that contained the transaction, for example from a
     * transaction receipt fetched earlier, you can provide such details to speed up the process of verification.
     *
     * Data returned by this method is authenticated. Note that transactions with the state
     * {@link Client.TransactionState.MINED} may be reverted as the chain is forked. Transactions with state
     * {@link Client.TransactionState.CONFIRMED} are considered confirmed according to the configuration provided
     * during client initialization.
     *
     * @param {Hash|string} hash Hash of a transaction
     * @param {Hash|string} [blockHash] The hash of the block containing that transaction
     * @param {number} [blockHeight] The height of the block containing that transaction
     * @returns {Promise.<TransactionDetails>} Details about the requested transaction. Throws an error if the no such
     *                                         transaction exists.
     */
    async getTransaction(hash, blockHash, blockHeight) {
        hash = Hash.fromAny(hash);
        if (blockHash) blockHash = Hash.fromAny(blockHash);

        const consensus = await this._consensus;

        const pending = await consensus.getPendingTransactions([hash]);
        if (pending && pending[0]) {
            this._txWaitForExpire(pending[0]);
            return new Client.TransactionDetails(pending[0], Client.TransactionState.PENDING);
        }

        if (!blockHash) {
            const receipts = await consensus.getTransactionReceiptsByHashes([hash]);
            if (receipts && receipts.length === 1 && receipts[0]) {
                blockHash = receipts[0].blockHash;
                blockHeight = receipts[0].blockHeight;
            } else {
                throw new Error('Unknown transaction hash');
            }
        }

        const block = await consensus.getBlock(blockHash, false, true, blockHeight);
        if (block) {
            blockHeight = block.height;
        } else {
            throw new Error('Unknown block hash');
        }

        const txs = await consensus.getTransactionsFromBlock([hash], blockHash, blockHeight, block);
        if (txs && txs[0]) {
            const tx = txs[0];
            const height = await consensus.getHeadHeight();
            const confirmations = (height - blockHeight) + 1;
            const confirmed = confirmations >= this._config.requiredBlockConfirmations;
            if (!confirmed) this._txWaitForConfirm(tx, blockHeight);
            return new Client.TransactionDetails(tx, confirmed ? Client.TransactionState.CONFIRMED : Client.TransactionState.MINED, blockHash, blockHeight, confirmations, block.timestamp);
        }

        throw new Error('Unknown transaction hash');
    }

    /**
     * Fetches a single transaction receipt by its transaction hash.
     *
     * Note that transaction receipts might be unauthenticated data depending on your client configuration and should
     * not necessarily be considered a confirmation that a transaction was actually mined in a block.
     *
     * @param {Hash|string} hash Hash of a transaction
     * @returns {Promise.<?TransactionReceipt>}
     */
    async getTransactionReceipt(hash) {
        hash = Hash.fromAny(hash);

        return (await this.getTransactionReceiptsByHashes([hash]))[0];
    }

    /**
     * Fetches transaction history as receipts for a single address.
     *
     * Note that transaction receipts might be unauthenticated data depending on your client configuration and should
     * not necessarily be considered a confirmation that a transaction was actually mined in a block.
     *
     * @param {Address|string} address Address of an account
     * @param {number} [limit=Infinity] Maximum number of receipts to return, may be exceeded depending on your client configuration.
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    async getTransactionReceiptsByAddress(address, limit = Infinity) {
        address = Address.fromAny(address);

        const consensus = await this._consensus;
        return consensus.getTransactionReceiptsByAddress(address, limit);
    }

    /**
     * Fetches multiple transaction receipts by their transaction hash.
     *
     * Note that transaction receipts might be unauthenticated data depending on your client configuration and should
     * not necessarily be considered a confirmation that a transaction was actually mined in a block.
     *
     * @param {Array.<Hash|string>} hashes List of hashes of transactions
     * @returns {Promise.<Array.<TransactionReceipt>>}
     */
    async getTransactionReceiptsByHashes(hashes) {
        hashes = hashes.map(hash => Hash.fromAny(hash));

        const consensus = await this._consensus;
        return consensus.getTransactionReceiptsByHashes(hashes);
    }

    /**
     * This method can be used to fetch the transaction history for a specific address as well as any pending
     * transactions related to it.
     *
     * If you already fetched the transaction history before, you can provide some of this information.
     * - If you provide {@param sinceBlockHeight}, the logic assumes that you already know all transactions up to that
     *   state and are completely certain about its status. This should not be the last known block height, but a lower
     *   value that could not have been forked from (i.e. this should be lower than last known block height - required
     *   block confirmations, as else you would not be informed about transactions being confirmed)
     * - If you are aware of transactions that happened since {@param sinceBlockHeight} or were pending before you can
     *   provide them as well. This ensures you receive an update on them even with misbehaving peers. Pending
     *   transactions that appear to not have been mined will be stored in the local mempool and send to peers to
     *   ensure they are aware as well.
     *
     * Data returned by this method is authenticated. Note that transactions with the state
     * {@link Client.TransactionState.MINED} may be reverted as the chain is forked. Transactions with state
     * {@link Client.TransactionState.CONFIRMED} are considered confirmed according to the configuration provided
     * during client initialization.
     *
     * @param {Address|string} address Address of an account
     * @param {number} [sinceBlockHeight=0] Minimum block height to consider for updates
     * @param {Array.<Client.TransactionDetails>} [knownTransactionDetails] List of transaction details on already known transactions since {@param sinceBlockHeight}
     * @param {number} [limit=Infinity] Maximum number of transactions to return, this number may be exceeded for large knownTransactionDetails sets.
     * @return {Promise.<Array.<Client.TransactionDetails>>}
     */
    async getTransactionsByAddress(address, sinceBlockHeight = 0, knownTransactionDetails, limit = Infinity) {
        address = Address.fromAny(address);
        const knownTxs = new HashMap();
        if (knownTransactionDetails) {
            knownTransactionDetails = knownTransactionDetails.map(tx => Client.TransactionDetails.fromPlain(tx));
            for (const receipt of knownTransactionDetails) {
                knownTxs.put(receipt.transactionHash, receipt);
            }
        }

        // Get pending transactions from local mempool.
        const consensus = await this._consensus;
        const txs = new HashSet((i) => i instanceof Hash ? i.hashCode() : i.transactionHash.hashCode());
        try {
            const pending = await consensus.getPendingTransactionsByAddress(address, limit);
            for (const tx of pending) {
                this._txWaitForExpire(tx);
                txs.add(new Client.TransactionDetails(tx, Client.TransactionState.PENDING));
            }
        } catch (e) {
            // Ignore
        }

        // Fetch transaction receipts.
        const receipts = new HashSet((receipt) => receipt.transactionHash.hashCode());
        if (txs.length < limit) receipts.addAll(await consensus.getTransactionReceiptsByAddress(address, limit - txs.length));

        /** @type {HashMap.<string, HashSet.<Hash>>} */
        const requestProofs = new HashMap();
        /** @type {HashMap.<string, number>} */
        const blockHeights = new HashMap();
        for (const receipt of receipts.valueIterator()) {
            // Skip known transactions that are already considered confirmed.
            const knownTx = knownTxs.get(receipt.transactionHash);
            if (knownTx && knownTx.state === Client.TransactionState.CONFIRMED && receipt.blockHash.equals(knownTx.blockHash)) {
                continue;
            }

            // Check all receipts that are newer than sinceBlockHeight.
            if (receipt.blockHeight >= sinceBlockHeight) {
                const pendingProofAtBlock = requestProofs.get(receipt.blockHash.toBase64()) || new HashSet();
                pendingProofAtBlock.add(receipt.transactionHash);
                requestProofs.put(receipt.blockHash.toBase64(), pendingProofAtBlock);
                blockHeights.put(receipt.blockHash.toBase64(), receipt.blockHeight);
            }
        }

        // Re-check known (mined or confirmed) transactions that are not contained in the receipts.
        for (const details of knownTxs.valueIterator()) {
            if ((details.state === Client.TransactionState.MINED || details.state === Client.TransactionState.CONFIRMED)
                && details.blockHeight >= sinceBlockHeight
                && !receipts.contains(details)) {

                const transactionsToProve = requestProofs.get(details.blockHash.toBase64()) || new HashSet();
                transactionsToProve.add(details.transactionHash);
                requestProofs.put(details.blockHash.toBase64(), transactionsToProve);
                blockHeights.put(details.blockHash.toBase64(), details.blockHeight);
            }
        }

        // Retrieve proofs for the transaction we want to check.
        const height = await consensus.getHeadHeight();
        for (const [blockHashBase64, /** @type {HashSet.<Hash>} */ transactionsToProve] of requestProofs.entryIterator()) {
            const blockHash = Hash.fromBase64(blockHashBase64);
            if (blockHash.equals(Hash.NULL)) {
                throw new Error(`Illegal request for ${blockHashBase64} vs ${blockHash}`);
            }

            const blockHeight = blockHeights.get(blockHashBase64);
            const block = await consensus.getBlock(blockHash, false, true, blockHeight);
            const moreTx = await consensus.getTransactionsFromBlock(transactionsToProve.values(), blockHash, blockHeight, block);
            const confirmations = (height - blockHeight) + 1;
            const confirmed = confirmations >= this._config.requiredBlockConfirmations;

            for (const tx of moreTx) {
                if (!confirmed) this._txWaitForConfirm(tx, blockHeight);
                txs.add(new Client.TransactionDetails(tx, confirmed ? Client.TransactionState.CONFIRMED : Client.TransactionState.MINED, blockHash, blockHeight, confirmations, block.timestamp));
            }
        }

        // Track known (new or pending) transactions
        for (const /** @type {Client.TransactionDetails} */ details of knownTxs.valueIterator()) {
            if ((details.state === Client.TransactionState.NEW || details.state === Client.TransactionState.PENDING)
                && !txs.contains(details)) {

                if (this._txExpiresAt(details) <= height) {
                    txs.add(new Client.TransactionDetails(details.transaction, Client.TransactionState.EXPIRED));
                } else {
                    // Add to mempool.
                    txs.add(await this.sendTransaction(details.transaction));
                }
            }
        }

        return txs.values();
    }

    /**
     * @param {Transaction|object|string} tx
     * @returns {Promise.<TransactionDetails>}
     */
    async sendTransaction(tx) {
        tx = Transaction.fromAny(tx);

        const consensus = await this._consensus;
        switch (await consensus.sendTransaction(tx)) {
            case BaseConsensus.SendTransactionResult.EXPIRED:
                return new Client.TransactionDetails(tx, Client.TransactionState.EXPIRED);
            case BaseConsensus.SendTransactionResult.INVALID:
                return new Client.TransactionDetails(tx, Client.TransactionState.INVALIDATED);
            case BaseConsensus.SendTransactionResult.KNOWN:
            case BaseConsensus.SendTransactionResult.RELAYED:
            case BaseConsensus.SendTransactionResult.PENDING_LOCAL:
                return new Client.TransactionDetails(tx, Client.TransactionState.PENDING);
            case BaseConsensus.SendTransactionResult.ALREADY_MINED:
                return this.getTransaction(tx.hash());
        }
        return new Client.TransactionDetails(tx, Client.TransactionState.NEW);
    }

    /**
     * @param {BlockListener} listener
     * @return {Promise.<Handle>}
     */
    async addBlockListener(listener) { // eslint-disable-line require-await
        const listenerId = this._listenerId++;
        this._blockListeners.put(listenerId, listener);
        return listenerId;
    }

    /**
     * @param {ConsensusChangedListener} listener
     * @return {Promise.<Handle>}
     */
    async addConsensusChangedListener(listener) { // eslint-disable-line require-await
        const listenerId = this._listenerId++;
        this._consensusChangedListeners.put(listenerId, listener);
        return listenerId;
    }

    /**
     * @param {HeadChangedListener} listener
     * @return {Promise.<Handle>}
     */
    async addHeadChangedListener(listener) { // eslint-disable-line require-await
        const listenerId = this._listenerId++;
        this._headChangedListeners.put(listenerId, listener);
        return listenerId;
    }

    /**
     * @param {TransactionListener} listener
     * @param {Array.<Address|string>} addresses
     * @return {Promise.<Handle>}
     */
    async addTransactionListener(listener, addresses) {
        addresses = addresses.map(addr => Address.fromAny(addr));
        const set = new HashSet();
        set.addAll(addresses);

        this._subscribedAddresses.addAll(set);
        await this._consensusSynchronizer.push(async () => {
            const consensus = await this._consensus;
            if (consensus.established) {
                const oldSubscription = consensus.getSubscription();
                if (oldSubscription.type === Subscription.Type.ADDRESSES) {
                    consensus.subscribe(Subscription.fromAddresses(this._subscribedAddresses.values()));
                }
            }
        });
        const listenerId = this._listenerId++;
        this._transactionListeners.put(listenerId, {listener, addresses: set});
        return listenerId;
    }

    /**
     * @param {Handle} handle
     * @returns {Promise}
     */
    async removeListener(handle) { // eslint-disable-line require-await
        this._blockListeners.remove(handle);
        this._consensusChangedListeners.remove(handle);
        this._headChangedListeners.remove(handle);
        this._transactionListeners.remove(handle);
        if (this._transactionListeners.length === 0) {
            this._transactionConfirmWaiting.clear();
            this._transactionExpireWaiting.clear();
        }
    }

    /**
     * @returns {Promise}
     */
    waitForConsensusEstablished() {
        return new Promise(resolve => {
            if (this._consensusState === Client.ConsensusState.ESTABLISHED) {
                resolve();
            } else {
                let handle;
                // eslint-disable-next-line prefer-const
                handle = this.addConsensusChangedListener(async state => {
                    if (state === Client.ConsensusState.ESTABLISHED) {
                        await this.removeListener(handle);
                        resolve();
                    }
                });
            }
        });
    }

    /**
     * Access and modify network information such as connected peers.
     * @type {Client.Network}
     */
    get network() {
        return this._network;
    }

    /**
     * Access the mempool directly. Allows for unfiltered processing of all transactions in the mempool.
     * @type {Client.Mempool}
     */
    get mempool() {
        this._config.requireFeatures(Client.Feature.MEMPOOL);
        return this._mempool;
    }
}

Client.ConsensusState = {
    /**
     * The client is connecting to the network
     */
    CONNECTING: 'connecting',
    /**
     * The client is syncing data from peers to reach consensus
     */
    SYNCING: 'syncing',
    /**
     * The client reached consensus with its peers
     */
    ESTABLISHED: 'established'
};

Class.register(Client);

/** @class Client.Configuration */
Client.Configuration = class Configuration {
    /**
     * @param {NetworkConfig} networkConfig
     * @param {Array.<Client.Feature>} features
     * @param {boolean} useVolatileStorage
     * @param {number} requiredBlockConfirmations
     * @package
     */
    constructor(networkConfig, features = [], useVolatileStorage = false, requiredBlockConfirmations = 10) {
        this._networkConfig = networkConfig;
        this._features = features;
        this._useVolatileStorage = useVolatileStorage;
        this._requiredBlockConfirmations = requiredBlockConfirmations;
    }

    get features() {
        return this._features;
    }

    get requiredBlockConfirmations() {
        return this._requiredBlockConfirmations;
    }

    get networkConfig() {
        return this._networkConfig;
    }

    /**
     * @returns {Promise.<BaseConsensus>}
     * @package
     */
    createConsensus() {
        if (this._useVolatileStorage) {
            if (this._features.includes(Client.Feature.MEMPOOL) || this._features.includes(Client.Feature.MINING)) {
                return Consensus.volatileLight(this._networkConfig);
            } else {
                return Consensus.volatilePico(this._networkConfig);
            }
        } else {
            if (this._features.includes(Client.Feature.LOCAL_HISTORY)) {
                return Consensus.full(this._networkConfig);
            } else if (this._features.includes(Client.Feature.MEMPOOL) || this._features.includes(Client.Feature.MINING)) {
                return Consensus.light(this._networkConfig);
            } else {
                return Consensus.pico(this._networkConfig);
            }
        }
    }

    /**
     * @param {Client.Feature} feature
     * @returns {boolean}
     */
    hasFeature(feature) {
        return this._features.includes(feature);
    }

    /**
     * @param {...Client.Feature} features
     * @throws
     */
    requireFeatures(...features) {
        for (const feature of features) {
            if (!this.hasFeature(feature)) {
                throw new Error(`Missing required client feature: ${feature}`);
            }
        }
    }

    /**
     * @returns {Client}
     */
    instantiateClient() {
        return new Client(this);
    }

    static builder() {
        return new Client.ConfigurationBuilder();
    }
};

/** @class Client.ConfigurationBuilder */
Client.ConfigurationBuilder = class ConfigurationBuilder {
    constructor() {
        this._features = new HashSet();
    }

    /**
     * Configure the client to be not reachable from the outside.
     * @returns {Client.ConfigurationBuilder}
     */
    dumb() {
        return this.protocol('dumb');
    }

    /**
     * Configure the client to be publicly reachable via WebRTC.
     * @returns {Client.ConfigurationBuilder}
     */
    rtc() {
        return this.protocol('rtc');
    }

    /**
     * Configure the client to provide a public, insecure WebSocket server.
     *
     * @param {string} host Publicly reachable hostname of this node
     * @param {number} [port=8443] Publicly reachable port
     * @returns {Client.ConfigurationBuilder}
     */
    ws(host, port = 8443) {
        return this.protocol('ws', host, port);
    }

    /**
     * Configure the client to provide a public, secure WebSocket server.
     *
     * @param {string} host Publicly reachable hostname of this node
     * @param {number} [port=8443] Publicly reachable port
     * @param {string} tlsKey Path to the tls private key
     * @param {string} tlsCert Path to the tls certificate
     * @returns {Client.ConfigurationBuilder}
     */
    wss(host, port = 8443, tlsKey, tlsCert) {
        return this.protocol('wss', host, port, tlsKey, tlsCert);
    }

    /**
     * Configure the protocol this client uses. Defaults to rtc for supported browsers and dumb otherwise.
     *
     * @param {'dumb'|'rtc'|'ws'|'wss'} protocol One of: dumb, rtc, ws, wss
     * @param {string} [host] Publicly reachable hostname of this node (required for ws and wss)
     * @param {number} [port=8443] Publicly reachable port (required for ws and wss)
     * @param {string} [tlsKey] Path to the tls private key (required for wss)
     * @param {string} [tlsCert] Path to the tls certificate (required for wss)
     * @returns {Client.ConfigurationBuilder}
     */
    protocol(protocol, host, port = 8443, tlsKey, tlsCert) {
        if (this._protocol) throw new Error('Protocol already configured');
        this._protocol = this._requiredSet(protocol, 'protocol', 'dumb', 'rtc', 'ws', 'wss');
        if (this._protocol === 'ws' || this._protocol === 'wss') {
            this._host = this._requiredType(host, 'host', 'string');
            this._port = this._requiredType(port, 'port', 'number');
        }
        if (this._protocol === 'wss') {
            this._tlsKey = this._requiredType(tlsKey, 'tlsKey', 'string');
            this._tlsCert = this._requiredType(tlsCert, 'tlsCert', 'string');
        }
        return this;
    }

    /**
     * Disable persistent storage. By default persistent storage will be used.
     * @param {boolean} [volatile]
     * @returns {Client.ConfigurationBuilder}
     */
    volatile(volatile = true) {
        if (typeof this._volatile !== 'undefined') throw new Error('volatile already set');
        this._volatile = this._requiredType(volatile, 'volatile', 'boolean');
        return this;
    }

    /**
     * Sets the number of blocks required to consider a transaction confirmed. Defaults to 10.
     * @param {number} confirmations
     * @returns {Client.ConfigurationBuilder}
     */
    blockConfirmations(confirmations) {
        if (typeof this._blockConfirmations !== 'undefined') throw new Error('blockConfirmations already set.');
        this._blockConfirmations = this._requiredType(confirmations, 'confirmations', 'number');
        return this;
    }

    /**
     * @param {...Client.Feature} feature
     * @returns {Client.ConfigurationBuilder}
     */
    feature(...feature) {
        this._features.addAll(feature);
        return this;
    }

    /**
     * @param {number} port
     * @param {string} header
     * @param {...string} addresses
     * @returns {Client.ConfigurationBuilder}
     */
    reverseProxy(port, header, ...addresses) {
        if (this._protocol !== 'ws' && this._protocol !== 'wss') throw new Error('Protocol must be ws or wss for reverse proxy.');
        this._reverseProxy = {
            enabled: true,
            port: this._requiredType(port, 'port', 'number'),
            header: this._requiredType(header, 'header', 'string'),
            addresses: addresses
        };
        return this;
    }

    /**
     * @returns {Client.Configuration} The configuration object to create a client with.
     */
    build() {
        if (this._volatile && this._features.contains(Client.Feature.LOCAL_HISTORY)) {
            throw new Error('Local history is not available with volatile storage');
        }
        if (!this._protocol) {
            if (PlatformUtils.supportsWebRTC()) this._protocol = 'rtc';
            this._protocol = 'dumb';
        }
        if (!this._reverseProxy) {
            this._reverseProxy = {enabled: false};
        }
        if (typeof this._blockConfirmations !== 'number') this._blockConfirmations = 10;
        let networkConfig;
        switch (this._protocol) {
            case 'dumb':
                networkConfig = new DumbNetworkConfig();
                break;
            case 'rtc':
                if (PlatformUtils.supportsWebRTC()) throw new Error('WebRTC not supported on this platform');
                networkConfig = new RtcNetworkConfig();
                break;
            case 'ws':
                networkConfig = new WsNetworkConfig(this._host, this._port, this._reverseProxy);
                break;
            case 'wss':
                networkConfig = new WssNetworkConfig(this._host, this._port, this._tlsKey, this._tlsCert, this._reverseProxy);
                break;
        }
        return new Client.Configuration(networkConfig, this._features.values(), !!this._volatile, this._blockConfirmations);
    }

    /**
     * Instantiates a client from this configuration builder.
     * @returns {Client}
     */
    instantiateClient() {
        return this.build().instantiateClient();
    }

    _requiredType(val, name, type) {
        if (typeof val !== type) throw new Error(`Type of ${name} must be ${type}, but is ${typeof val}`);
        return val;
    }

    _requiredSet(val, name, ...values) {
        if (!val) throw new Error(`${name} is required`);
        if (!values.includes(val)) throw new Error(`${name} must be one of: ${values.join(', ')}`);
        return val;
    }
};

/** @enum Client.Feature */
Client.Feature = {
    /**
     * Allow the client to generate blocks and attach new blocks to the chain. This is required to use the
     * {@link Client#getBlockTemplate} and {@link Client#submitBlock} functions.
     *
     * This features is <b>not</b> required for pool assisted mining.
     */
    MINING: 'MINING',
    /**
     * Store the history of all blocks and transactions locally. This is required to have transaction receipts
     * become authenticated data.
     */
    LOCAL_HISTORY: 'LOCAL_HISTORY',
    /**
     * Have a full local mempool. This is required to build blocks using the {@link Client#getBlockTemplate} and to
     * access the {@link Client#mempool}.
     */
    MEMPOOL: 'MEMPOOL',
    /**
     * Make the client not connect to the network actively, but only accept incoming connections.
     * Useful only if this node is registered as a seed node for the rest of the network.
     */
    PASSIVE: 'PASSIVE',
};

/** @typedef {function(transactionHash: Hash):void} MempoolListener */
/** @class Client.Mempool */
Client.Mempool = class Mempool {
    /**
     * @param {Client} client
     * @package
     */
    constructor(client) {
        this._client = client;

        /** @type {HashMap.<Handle, MempoolListener>} */
        this._transactionAddedListeners = new HashMap();
        /** @type {HashMap.<Handle, MempoolListener>} */
        this._transactionRemovedListeners = new HashMap();
        /** @type {Handle} */
        this._listenerId = 0;
    }

    /**
     * @param {Transaction} tx
     * @package
     */
    _onTransactionAdded(tx) {
        for (const listener of this._transactionAddedListeners.valueIterator()) {
            listener(tx.hash());
        }
    }

    /**
     * @param {Transaction} tx
     * @package
     */
    _onTransactionRemoved(tx) {
        for (const listener of this._transactionRemovedListeners.valueIterator()) {
            listener(tx.hash());
        }
    }

    /**
     * @returns {Promise.<Hash[]>} The hashes of all transactions in the current mempool.
     */
    async getTransactions() {
        const consensus = await this._client._consensus;
        return consensus.getMempoolContents().map(tx => tx.hash());
    }

    /**
     * Gives some statistics on the current mempool. Well suited to estimate the ideal fee for a transaction
     *
     * @returns {Promise.<Client.MempoolStatistics>} Some statistics on the current mempool.
     */
    async getStatistics() {
        const consensus = await this._client._consensus;
        return new Client.MempoolStatistics(consensus.getMempoolContents());
    }

    /**
     * @param {MempoolListener} listener
     * @return {Promise<Handle>}
     */
    async addTransactionAddedListener(listener) {
        const listenerId = this._listenerId++;
        this._transactionAddedListeners.put(listenerId, listener);
        return listenerId;
    }

    /**
     * @param {MempoolListener} listener
     * @return {Promise<Handle>}
     */
    async addTransactionRemovedListener(listener) {
        const listenerId = this._listenerId++;
        this._transactionRemovedListeners.put(listenerId, listener);
        return listenerId;
    }

    /**
     * @param {Handle} handle
     */
    removeListener(handle) {
        this._transactionAddedListeners.remove(handle);
        this._transactionRemovedListeners.remove(handle);
    }
};

/** @class Client.MempoolStatistics */
Client.MempoolStatistics = class MempoolStatistics {
    /**
     * @param {Array.<Transaction>} mempoolContents
     */
    constructor(mempoolContents) {
        const buckets = [10000, 5000, 2000, 1000, 500, 200, 100, 50, 20, 10, 5, 2, 1, 0];
        this._countPerBucket = {buckets: []};
        this._sizePerBucket = {buckets: []};
        this._totalCount = mempoolContents.length;
        this._totalSize = 0;
        this._requiredFeePerByte = 0;
        // Transactions are ordered by feePerByte
        for (const tx of mempoolContents) {
            // Find appropriate bucked
            let i = 0;
            while (i < buckets.length && tx.feePerByte < buckets[i]) i++;
            const bucket = buckets[i];
            if (bucket !== undefined) {
                if (!this._countPerBucket[bucket]) {
                    this._countPerBucket[bucket] = 0;
                    this._countPerBucket.buckets.push(bucket);
                    this._sizePerBucket[bucket] = 0;
                    this._sizePerBucket.buckets.push(bucket);
                }
                this._countPerBucket[bucket]++;
                this._sizePerBucket[bucket] += tx.serializedSize;
            }
            this._totalSize += tx.serializedSize;
            if (this._totalSize < Policy.BLOCK_SIZE_MAX) {
                this._requiredFeePerByte = tx.feePerByte;
            }
        }
        if (this._totalSize < Policy.BLOCK_SIZE_MAX) this._requiredFeePerByte = 0;
    }

    /**
     * The number of transactions in the local mempool.
     * @returns {number}
     */
    get count() {
        return this._totalCount;
    }

    /**
     * Total summed size of all transactions in the local mempool.
     * @returns {number}
     */
    get size() {
        return this._totalSize;
    }

    /**
     * The fee per byte required to be included in the next block according to the local mempool.
     * @type {number}
     */
    get requiredFeePerByte() {
        return this._requiredFeePerByte;
    }

    /**
     * The number of transactions sorted into buckets by fee per byte
     * @returns {{buckets: Array}|*}
     */
    get countInBuckets() {
        return this._countPerBucket;
    }

    /**
     * The summed size of transactions sorted into buckets by fee per byte
     * @returns {{buckets: Array}|*}
     */
    get sizeInBuckets() {
        return this._sizePerBucket;
    }
};

/** @class Client.Network */
Client.Network = class Network {
    /**
     * @param {Client} client
     * @package
     */
    constructor(client) {
        this._client = client;
    }

    /**
     * @returns {Promise.<Array.<Client.PeerInfo>>} List of peers currently connected to this node.
     */
    async getPeers() {
        const consensus = await this._client._consensus;
        const infos = [];
        for (const connection of consensus.network.connections.valueIterator()) {
            infos.push(new Client.PeerInfo(connection));
        }
        return infos;
    }

    /**
     * @param {PeerAddress|Client.AddressInfo|string} address
     * @returns {Promise.<?Client.PeerInfo>}
     */
    async getPeer(address) {
        const consensus = await this._client._consensus;
        const connection = consensus.network.connections.getConnectionByPeerAddress(await this._toPeerAddress(address));
        if (connection) {
            return new Client.PeerInfo(connection);
        }
        return null;
    }

    /**
     * @returns {Promise.<Array.<Client.AddressInfo>>} List of addresses known to this node.
     */
    async getAddresses() {
        const consensus = await this._client._consensus;
        const infos = [];
        for (const addressState of consensus.network.addresses.iterator()) {
            infos.push(new Client.AddressInfo(addressState));
        }
        return infos;
    }

    /**
     * @param {PeerAddress|Client.AddressInfo|string} address
     * @returns {Promise.<?Client.AddressInfo>}
     */
    async getAddress(address) {
        const consensus = await this._client._consensus;
        const addressState = consensus.network.addresses.getState(await this._toPeerAddress(address));
        if (addressState) {
            return new Client.AddressInfo(addressState);
        }
        return null;
    }

    /**
     * @returns {Promise.<Client.BasicAddress>}
     */
    async getOwnAddress() {
        const consensus = await this._client._consensus;
        return new Client.BasicAddress(consensus.network.config.peerAddress);
    }

    /**
     * @returns {Promise.<Client.NetworkStatistics>} Statistics on the network
     */
    async getStatistics() {
        const consensus = await this._client._consensus;
        return new Client.NetworkStatistics(consensus.network);
    }

    /**
     * @param {PeerAddress|Client.BasicAddress|string} address
     * @returns {Promise.<void>}
     */
    async connect(address) {
        const consensus = await this._client._consensus;
        consensus.network.connections.connectOutbound(await this._toPeerAddress(address));
    }

    /**
     * @param {PeerAddress|Client.BasicAddress|string} address
     * @returns {Promise.<void>}
     */
    async disconnect(address) {
        const consensus = await this._client._consensus;
        const connection = consensus.network.connections.getConnectionByPeerAddress(await this._toPeerAddress(address));
        if (connection) {
            connection.peerChannel.close(CloseType.MANUAL_PEER_DISCONNECT);
        }
    }

    /**
     * @param {PeerAddress|Client.BasicAddress|string} address
     * @returns {Promise.<void>}
     */
    async ban(address) {
        const consensus = await this._client._consensus;
        const peerAddress = await this._toPeerAddress(address);
        const connection = consensus.network.connections.getConnectionByPeerAddress(peerAddress);
        if (connection) {
            connection.peerChannel.close(CloseType.MANUAL_PEER_BAN);
        } else {
            const state = consensus.network.addresses.getState(peerAddress);
            state.state = PeerAddressState.BANNED;
        }
    }

    async unban(address) {
        const consensus = await this._client._consensus;
        const state = consensus.network.addresses.getState(await this._toPeerAddress(address));
        state.state = PeerAddressState.TRIED;
    }

    /**
     * @param {PeerAddress|Client.BasicAddress|string} address
     * @returns {Promise.<PeerAddress>}
     */
    async _toPeerAddress(address) {
        const consensus = await this._client._consensus;
        let peerAddress;
        if (address instanceof PeerAddress) {
            peerAddress = consensus.network.addresses.get(address);
        } else if (address instanceof Client.BasicAddress) {
            peerAddress = consensus.network.addresses.get(address.peerAddress);
        } else if (typeof address === 'string') {
            for (const peerAddressState of consensus.network.addresses.iterator()) {
                if (peerAddressState.peerAddress.toString() === address) {
                    peerAddress = peerAddressState.peerAddress;
                    break;
                }
            }
        }
        if (!peerAddress) throw new Error('Invalid or unknown peer address');
        return peerAddress;
    }
};

/** @class Client.BasicAddress */
Client.BasicAddress = class BasicAddress {
    /**
     * @param {PeerAddress} address
     */
    constructor(address) {
        this._address = address;
    }

    /** @type {PeerAddress} */
    get peerAddress() {
        return this._address;
    }

    /** @type {PeerId} */
    get peerId() {
        return this._address.peerId;
    }

    /** @type {Array.<String>} */
    get services() {
        return Services.toNameArray(Services.legacyProvideToCurrent(this._address.services));
    }

    /** @type {object} */
    toPlain() {
        return {
            peerAddress: this.peerAddress.toString(),
            peerId: this.peerId.toString(),
            services: this.services
        };
    }
};

/** @class Client.AddressInfo */
Client.AddressInfo = class AddressInfo extends Client.BasicAddress {
    /**
     * @param {PeerAddressState} addressState
     */
    constructor(addressState) {
        super(addressState.peerAddress);
        this._state = addressState.state;
    }

    /** @type {boolean} */
    get banned() {
        return this._state === PeerAddressState.BANNED;
    }

    /** @type {boolean} */
    get connected() {
        return this._state === PeerAddressState.ESTABLISHED;
    }

    /** @type {number} */
    get state() {
        return this._state;
    }

    /** @type {object} */
    toPlain() {
        const plain = super.toPlain();
        plain.banned = this.banned;
        plain.connected = this.connected;
        return plain;
    }
};

/** @class Client.PeerInfo */
Client.PeerInfo = class PeerInfo extends Client.BasicAddress {
    /**
     * @param {PeerConnection} connection
     */
    constructor(connection) {
        super(connection.peerAddress);
        this._connection = connection;
        const networkConnection = this._connection.networkConnection;
        const peer = this._connection.peer;
        this._bytesReceived = networkConnection ? networkConnection.bytesReceived : 0;
        this._bytesSent = networkConnection ? networkConnection.bytesSent : 0;
        this._latency = this._connection.statistics.latencyMedian;
        this._state = this._connection.state;
        this._version = peer ? peer.version : undefined;
        this._timeOffset = peer ? peer.timeOffset : undefined;
        this._headHash = peer ? peer.headHash : undefined;
        this._userAgent = peer ? peer.userAgent : undefined;
    }

    /** @type {number} */
    get connectionSince() {
        return this._connection.establishedSince;
    }

    /** @type {NetAddress} */
    get netAddress() {
        return this._connection.networkConnection.netAddress;
    }

    /** @type {number} */
    get bytesReceived() {
        return this._bytesReceived;
    }

    /** @type {number} */
    get bytesSent() {
        return this._bytesSent;
    }

    /** @type {number} */
    get latency() {
        return this._latency;
    }

    /** @type {number} */
    get version() {
        return this._version;
    }

    /** @type {number} */
    get state() {
        return this._state;
    }

    /** @type {number} */
    get timeOffset() {
        return this._timeOffset;
    }

    /** @type {Hash} */
    get headHash() {
        return this._headHash;
    }

    /** @type {string} */
    get userAgent() {
        return this._userAgent;
    }

    /** @type {object} */
    toPlain() {
        const plain = super.toPlain();
        plain.connectionSince = this.connectionSince;
        plain.netAddress = this.netAddress.toString();
        plain.bytesReceived = this.bytesReceived;
        plain.bytesSent = this.bytesSent;
        plain.latency = this.latency;
        plain.version = this.version;
        plain.state = this.state;
        plain.timeOffset = this.timeOffset;
        plain.headHash = this.headHash.toPlain();
        plain.userAgent = this.userAgent;
        return plain;
    }
};

/** @class Client.NetworkStatistics */
Client.NetworkStatistics = class NetworkStatistics {
    /**
     * @param {Network} network
     */
    constructor(network) {
        this._bytesReceived = network.bytesReceived;
        this._bytesSent = network.bytesSent;
        this._peerCounts = {
            total: network.peerCount,
            connecting: network.peerCountConnecting,
            dumb: network.peerCountDumb,
            rtc: network.peerCountWebRtc,
            ws: network.peerCountWebSocket,
            wss: network.peerCountWebSocketSecure
        };
        this._knownAddressesCounts = {
            total: network.knownAddressesCount,
            rtc: network.addresses.knownRtcAddressesCount,
            ws: network.addresses.knownWsAddressesCount,
            wss: network.addresses.knownWssAddressesCount
        };
        this._timeOffset = network.time.offset;
    }

    /** @type {number} */
    get bytesReceived() {
        return this._bytesReceived;
    }

    /** @type {number} */
    get bytesSent() {
        return this._bytesSent;
    }

    /** @type {number} */
    get totalPeerCount() {
        return this._peerCounts.total;
    }

    get peerCountsByType() {
        return this._peerCounts;
    }

    /** @type {number} */
    get totalKnownAddresses() {
        return this._knownAddressesCounts.total;
    }

    get knownAddressesByType() {
        return this._knownAddressesCounts;
    }

    /** @type {number} */
    get timeOffset() {
        return this._timeOffset;
    }

    /** @type {object} */
    toPlain() {
        return {
            bytesReceived: this.bytesReceived,
            bytesSent: this.bytesSent,
            totalPeerCount: this.totalPeerCount,
            peerCountsByType: this.peerCountsByType,
            totalKnownAddresses: this.totalKnownAddresses,
            knownAddressesByType: this.knownAddressesByType,
            timeOffset: this.timeOffset
        };
    }
};

/** @class Client.TransactionDetails */
Client.TransactionDetails = class TransactionDetails {
    /**
     * @param {Transaction} transaction
     * @param {Client.TransactionState} state
     * @param {Hash} [blockHash]
     * @param {number} [blockHeight]
     * @param {number} [confirmations]
     * @param {number} [timestamp]
     * @package
     */
    constructor(transaction, state, blockHash, blockHeight, confirmations, timestamp) {
        this._transaction = transaction;
        this._state = state;
        this._blockHash = blockHash;
        this._blockHeight = blockHeight;
        this._confirmations = confirmations;
        this._timestamp = timestamp;
    }

    /** @type {Hash} */
    get transactionHash() {
        return this._transaction.hash();
    }

    /** @type {Transaction.Format} */
    get format() {
        return this._transaction.format;
    }

    /** @type {Address} */
    get sender() {
        return this._transaction.sender;
    }

    /** @type {Account.Type} */
    get senderType() {
        return this._transaction.senderType;
    }

    /** @type {Address} */
    get recipient() {
        return this._transaction.recipient;
    }

    /** @type {Account.Type} */
    get recipientType() {
        return this._transaction.recipientType;
    }

    /** @type {number} */
    get value() {
        return this._transaction.value;
    }

    /** @type {number} */
    get fee() {
        return this._transaction.fee;
    }

    /** @type {number} */
    get feePerByte() {
        return this._transaction.feePerByte;
    }

    /** @type {number} */
    get validityStartHeight() {
        return this._transaction.validityStartHeight;
    }

    /** @type {number} */
    get network() {
        return this._transaction.networkId;
    }

    /** @type {number} */
    get flags() {
        return this._transaction.flags;
    }

    /** @type {{raw: Uint8Array}} */
    get data() {
        const o = Account.TYPE_MAP.get(this.recipientType).dataToPlain(this._transaction.data);
        o.raw = this._transaction.data;
        return o;
    }

    /** @type {{raw: Uint8Array}} */
    get proof() {
        const o = Account.TYPE_MAP.get(this.recipientType).proofToPlain(this._transaction.proof);
        o.raw =  this._transaction.proof;
        return o;
    }

    /** @type {number} */
    get size() {
        return this._transaction.serializedSize;
    }

    /** @type {boolean} */
    get valid() {
        return this._transaction.verify();
    }

    /** @type {Transaction} */
    get transaction() {
        return this._transaction;
    }

    /** @type {Client.TransactionState} */
    get state() {
        return this._state;
    }

    /** @type {Hash|undefined} */
    get blockHash() {
        return this._blockHash;
    }

    /** @type {number|undefined} */
    get blockHeight() {
        return this._blockHeight;
    }

    /** @type {number|undefined} */
    get confirmations() {
        return this._confirmations;
    }

    /** @type {number|undefined} */
    get timestamp() {
        return this._timestamp;
    }

    /**
     * @returns {object}
     */
    toPlain() {
        const o = this._transaction.toPlain();
        o.state = this._state;
        o.blockHash = this._blockHash ? this._blockHash.toPlain() : null;
        o.blockHeight = this._blockHeight;
        o.confirmations = this._confirmations;
        o.timestamp = this._timestamp;
        return o;
    }

    /**
     * @param {object} o
     * @returns {Client.TransactionDetails}
     */
    static fromPlain(o) {
        return new Client.TransactionDetails(Transaction.fromPlain(o), o.state || Client.TransactionState.NEW, o.blockHash ? Hash.fromAny(o.blockHash) : undefined, o.blockHeight || undefined, o.confirmations || undefined, o.timestamp || undefined);
    }
};

/** @enum Client.TransactionState */
Client.TransactionState = {
    NEW: 'new',
    PENDING: 'pending',
    MINED: 'mined',
    INVALIDATED: 'invalidated',
    EXPIRED: 'expired',
    CONFIRMED: 'confirmed',
};

// Print stack traces to the console.
Error.prototype.toString = function () {
    return this.stack;
};

// Don't exit on uncaught exceptions.
process.on('uncaughtException', (err) => {
    // Blacklist unsupressable WebSocket errors.
    const message = err.message;
    if (message
        && (
            message.startsWith('connect E')
            || message === "Cannot read property 'aborted' of null")
        ) {
        return;
    }

    console.error(`Uncaught exception: ${err.message || err}`, err);
});

//# sourceMappingURL=node.js.map
